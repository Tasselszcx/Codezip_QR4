{"code_id": "1cai-public_scripts_ba_pipeline_base.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\1cai-public_scripts_ba_pipeline_base.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\1cai-public_scripts_ba_pipeline_base.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\1cai-public_scripts_ba_pipeline_base.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "from __future__ import annotations\n\nimport abc\nimport json\nfrom dataclasses import dataclass, field\nfrom datetime import datetime, timedelta, timezone\nfrom pathlib import Path\nfrom typing import Any, Dict, List, Optional\n\ndef ensure_output_dir(base_dir: Path, collector_name: str) -> Path:\n    \"\"\"Create dated directory for collector outputs.\"\"\"\n    date_folder = datetime.now(timezone.utc).strftime(\"%Y-%m-%d\")\n    collector_dir = base_dir / collector_name\n    collector_dir.mkdir(parents=True, exist_ok=True)\n    target_dir = collector_dir / date_folder\n    target_dir.mkdir(parents=True, exist_ok=True)\n    return target_dir\n\n@dataclass\nclass CollectorResult:\n    collector: str\n    status: str\n    records_count: int = 0\n    output_file: Optional[Path] = None\n    metadata: Dict[str, Any] = field(default_factory=dict)\n\n    def to_dict(self) -> Dict[str, Any]:\n        return {\n            \"collector\": self.collector,\n            \"status\": self.status,\n            \"records_count\": self.records_count,\n            \"output_file\": str(self.output_file) if self.output_file else None,\n            \"metadata\": self.metadata,\n        }\n\nclass BaseCollector(abc.ABC):\n    \"\"\"Base class for BA data collectors.\"\"\"\n    name: str = \"base\"\n    description: str = \"\"\n\n    def __init__(self, *, now: Optional[datetime] = None):\n        self.now = now or datetime.now(timezone.utc)\n\n    @abstractmethod\n    def collect(\n        self,\n        *,\n        output_dir: Path,\n        since: Optional[datetime],\n    ) -> CollectorResult:\n        \"\"\"Collect data and persist JSON payload to 'output_dir'.\"\"\"\n\n    def _write_output(self, output_dir: Path, payload: List[Dict[str, Any]]]) -> Path:\n        timestamp = self.now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n        file_path = output_dir / f\"{self.name}_{timestamp}.json\"\n        with file_path.open(\"w\", encoding=\"utf-8\") as f:\n            json.dump(\n                [\n                    {\n                        \"collector\": self.name,\n                        \"generated_at\": self.now.isoformat(),\n                        \"records\": payload,\n                    }\n                ],\n                f,\n                ensure_ascii=False,\n                indent=2,\n            )\n        return file_path\n\n    @staticmethod\n    def _parse_since(days: Optional[int]) -> Optional[datetime]:\n        if days is None:\n            return None\n        return datetime.now(timezone.utc) - timedelta(days=days)"}
{"code_id": "1cai-public_scripts_ba_pipeline_base.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\1cai-public_scripts_ba_pipeline_base.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\1cai-public_scripts_ba_pipeline_base.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\1cai-public_scripts_ba_pipeline_base.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "[FILE_IDENTITY] ID: 3850882375745577702 | DATE: 2025-11-19\nfrom __future__ import annotations\n\nimport abc\nimport json\nfrom dataclasses import dataclass, field\nfrom datetime import datetime, timedelta, timezone\nfrom pathlib import Path\nfrom typing import Any, Dict, List, Optional\n\ndef ensure_output_dir(base_dir: Path, collector_name: str) -> Path:\n    \"\"\"Create dated directory for collector outputs.\"\"\"\n    date_folder = datetime.now(timezone.utc).strftime(\"%Y%m%d\")\n    collector_dir = base_dir / collector_name\n    collector_dir.mkdir(parents=True, exist_ok=True)\n    target_dir = collector_dir / date_folder\n    target_dir.mkdir(parents=True, exist_ok=True)\n    return target_dir\n\n@dataclass\nclass CollectorResult:\n    collector: str\n    status: str\n    records_count: int = 0\n    output_file: Optional[Path] = None\n    metadata: Dict[str, Any] = field(default_factory=dict)\n\n    def to_dict(self) -> Dict[str, Any]:\n        return {\n            \"collector\": self.collector,\n            \"status\": self.status,\n            \"records_count\": self.records_count,\n            \"output_file\": str(self.output_file) if self.output_file else None,\n            \"metadata\": self.metadata,\n        }\n\nclass BaseCollector(abc.ABC):\n    \"\"\"Base class for BA data collectors.\"\"\"\n    name: str = \"base\"\n    description: str = \"\"\n\n    def __init__(self, *, now: Optional[datetime] = None) -> None:\n        self.now = now or datetime.now(timezone.utc)\n\n    @abstractmethod\n    def collect(\n        self,\n        *,\n        output_dir: Path,\n        since: Optional[datetime],\n    ) -> CollectorResult:\n        \"\"\"Collect data and persist JSON payload to `output_dir`.\"\"\"\n\n    def _write_output(self, output_dir: Path, payload: List[Dict[str, Any]]]) -> Path:\n        timestamp = self.now.strftime(\"%Y%m%dT%H%M%SZ\")\n        file_path = output_dir / f\"{self.name}_{timestamp}.json\"\n        with file_path.open(\"w\", encoding=\"utf-8\") as f:\n            json.dump(\n                {\n                    \"collector\": self.name,\n                    \"generated_at\": self.now.isoformat(),\n                    \"records\": payload,\n                },\n                f,\n                ensure_ascii=False,\n                indent=2,\n            )\n        return file_path\n\n    @staticmethod\n    def parse_since(days: Optional[int]) -> Optional[datetime]:\n        if days is None:\n            return None\n        return datetime.now(timezone.utc) - timedelta(days=days)"}
{"code_id": "1cai-public_scripts_ba_pipeline_base.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\1cai-public_scripts_ba_pipeline_base.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\1cai-public_scripts_ba_pipeline_base.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\1cai-public_scripts_ba_pipeline_base.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "[SOURCE_IDENTITY] ID: 3850882375745577702 | DATE: 2025-11-19\nfrom __future__ import annotations\n\nimport abc\nimport json\nfrom dataclasses import dataclass, field\nfrom datetime import datetime, timedelta, timezone\nfrom pathlib import Path\nfrom typing import Any, Dict, List, Optional\n\ndef ensure_output_dir(base_dir: Path, collector_name: str) -> Path:\n    \"\"\"Create dated directory for collector outputs.\"\"\"\n    date_folder = datetime.now(timezone.utc).strftime(\"%Y%m%d\")\n    collector_dir = base_dir / collector_name\n    collector_dir.mkdir(parents=True, exist_ok=True)\n    target_dir = collector_dir / date_folder\n    target_dir.mkdir(parents=True, exist_ok=True)\n    return target_dir\n\n@dataclass\nclass CollectorResult:\n    collector: str\n    status: str\n    records_count: int = 0\n    output_file: Optional[Path] = None\n    metadata: Dict[str, Any] = field(default_factory=dict)\n\n    def to_dict(self) -> Dict[str, Any]:\n        return {\n            \"collector\": self.collector,\n            \"status\": self.status,\n            \"records_count\": self.records_count,\n            \"output_file\": str(self.output_file) if self.output_file else None,\n            \"metadata\": self.metadata,\n        }\n\nclass BaseCollector(abc.ABC):\n    \"\"\"Base class for BA data collectors.\"\"\"\n    name: str = \"base\"\n    description: str = \"\"\n\n    def __init__(self, *, now: Optional[datetime] = None) -> None:\n        self.now = now or datetime.now(timezone.utc)\n\n        @abstractmethod\n        def collect(\n            self,\n            *,\n            output_dir: Path,\n            since: Optional[datetime],\n        ) -> CollectorResult:\n            \"\"\"Collect data and persist JSON payload to `output_dir`.\"\"\"\n\n        def _write_output(self, output_dir: Path, payload: List[Dict[str, Any]]]) -> Path:\n            timestamp = self.now.strftime(\"%Y%m%dT%H%M%SZ\")\n            file_path = output_dir / f\"{self.name}_{timestamp}.json\"\n            with file_path.open(\"w\", encoding=\"utf-8\") as f:\n                json.dump(\n                    {\n                        \"collector\": self.name,\n                        \"generated_at\": self.now.isoformat(),\n                        \"records\": payload,\n                    },\n                    f,\n                    ensure_ascii=False,\n                    indent=2,\n                )\n            return file_path\n\n        @staticmethod\n        def parse_since(days: Optional[int]) -> Optional[datetime]:\n            if days is None:\n                return None\n            return datetime.now(timezone.utc) - timedelta(days=days)"}
{"code_id": "360Extractor_src_core_job.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\360Extractor_src_core_job.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\360Extractor_src_core_job.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\360Extractor_src_core_job.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "from dataclasses import dataclass, field\nfrom typing import Dict, Any, List, Optional\nimport os\n\n@dataclass\nclass Job:\n    file_path: str\n    status: str = \"Pending\"  # Pending, Processing, Done, Error\n    settings: Dict[str, Any] = field(default_factory=dict)\n\n    @property\n    def active_cameras(self) -> Optional[List[int]]:\n        return self.settings.get('active_cameras', None)\n\n    @property\n    def filename(self) -> str:\n        return os.path.basename(self.file_path)\n\n    @property\n    def output_format(self) -> str:\n        return self.settings.get('output_format', 'jpg')\n\n    @property\n    def output_dir(self) -> str:\n        return self.settings.get('custom_output_dir', '')\n\n    @property\n    def smart_blur(self) -> bool:\n        return self.settings.get('smart_blur_enabled', False)\n\n    @property\n    def adaptive_mode(self) -> bool:\n        return self.settings.get('adaptive_mode', False)\n\n    @property\n    def adaptive_threshold(self) -> float:\n        return self.settings.get('adaptive_threshold', 0.5)\n\n    @property\n    def resolution(self) -> int:\n        return self.settings.get('resolution', 2048)\n\n    @property\n    def export_telemetry(self) -> bool:\n        return self.settings.get('export_telemetry', False)\n\n    def summary(self) -> str:\n        \"\"\"Returns a short summary of the job settings.\"\"\"\n        # e.g. \"High (-20°), 6 cams\"\n        pitch_val = self.settings.get('pitch_offset', 0)\n        pitch_name = \"Std\"\n        if pitch_val == -20: pitch_name = \"High\"\n        elif pitch_val == 20: pitch_name = \"Low\"\n\n        cams = self.settings.get('camera_count', 6)\n        layout = self.settings.get('layout_mode', 'adaptive')\n        layout_info = \" (Ring)\" if layout == 'ring' else \"\"\n        adaptive = \" [Adaptive]\" if self.adaptive_mode else \"\"\n        return f\"[{pitch_name} ({pitch_val}°), {cams} cams{layout_info}{adaptive}]\""}
{"code_id": "1cai-public_scripts_ba_pipeline_base.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\1cai-public_scripts_ba_pipeline_base.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\1cai-public_scripts_ba_pipeline_base.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\1cai-public_scripts_ba_pipeline_base.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "360Extractor_src_core_job.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\360Extractor_src_core_job.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\360Extractor_src_core_job.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\360Extractor_src_core_job.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "from dataclasses import dataclass, field\nfrom typing import Dict, Any, List, Optional\nimport os\n\n@dataclass\nclass Job:\n    file_path: str\n    status: str = \"Pending\"  # Pending, Processing, Done, Error\n    settings: Dict[str, Any] = field(default_factory=dict)\n\n    @property\n    def active_cameras(self) -> Optional[List[int]]:\n        return self.settings.get('active_cameras', None)\n\n    @property\n    def filename(self) -> str:\n        return os.path.basename(self.file_path)\n\n    @property\n    def output_format(self) -> str:\n        return self.settings.get('output_format', 'jpg')\n\n    @property\n    def output_dir(self) -> str:\n        return self.settings.get('custom_output_dir', ''))\n\n    @property\n    def smart_blur(self) -> bool:\n        return self.settings.get('smart_blur_enabled', False)\n\n    @property\n    def adaptive_mode(self) -> bool:\n        return self.settings.get('adaptive_mode', False)\n\n    @property\n    def adaptive_threshold(self) -> float:\n        return self.settings.get('adaptive_threshold', 0.5)\n\n    @property\n    def resolution(self) -> int:\n        return self.settings.get('resolution', 2048)\n\n    @property\n    def export_telemetry(self) -> bool:\n        return self.settings.get('export_telemetry', False)\n\n    def summary(self) -> str:\n        \"\"\"Returns a short summary of the job settings.\"\"\"\n        # e.g. \"High (-20°), 6 cams\"\n        pitch_val = self.settings.get('pitch_offset', 0)\n        pitch_name = \"Std\"\n        if pitch_val == -20: pitch_name = \"High\"\n        elif pitch_val == 20: pitch_name = \"Low\"\n\n        cams = self.settings.get('camera_count', 6)\n        layout = self.settings.get('layout_mode', 'adaptive')\n        layout_info = \" (Ring)\" if layout == 'ring' else \"\"\n        adaptive = \" [Adaptive]\" if self.adaptive_mode else \"\"\n        return f\"{pitch_name} ({pitch_val}°), {cams} cams{layout_info}{adaptive}\""}
{"code_id": "1cai-public_scripts_ba_pipeline_base.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\1cai-public_scripts_ba_pipeline_base.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\1cai-public_scripts_ba_pipeline_base.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\1cai-public_scripts_ba_pipeline_base.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "360Extractor_src_core_job.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\360Extractor_src_core_job.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\360Extractor_src_core_job.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\360Extractor_src_core_job.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "from dataclasses import dataclass, field\nfrom typing import Dict, Any, List, Optional\n\n@dataclass\nclass Job:\n    file_path: str\n    status: str = \"Pending\"  # Pending, Processing, Done, Error\n    settings: Dict[str, Any] = field(default_factory=dict)\n\n    @property\n    def active_cameras(self) -> Optional[List[int]]:\n        return self.settings.get('active_cameras', None)\n\n    @property\n    def filename(self) -> str:\n        return os.path.basename(self.file_path)\n\n    @property\n    def output_format(self) -> str:\n        return self.settings.get('output_format', 'jpg')\n\n    @property\n    def output_dir(self) -> str:\n        return self.settings.get('custom_output_dir', '')\n\n    @property\n    def smart_blur(self) -> bool:\n        return self.settings.get('smart_blur_enabled', False)\n\n    @property\n    def adaptive_mode(self) -> bool:\n        return self.settings.get('adaptive_mode', False)\n\n    @property\n    def adaptive_threshold(self) -> float:\n        return self.settings.get('adaptive_threshold', 0.5)\n\n    @property\n    def resolution(self) -> int:\n        return self.settings.get('resolution', 2048)\n\n    @property\n    def export_telemetry(self) -> bool:\n        return self.settings.get('export_telemetry', False)\n\n    def summary(self) -> str:\n        \"\"\"Returns a short summary of the job settings.\"\"\"\n        if self.settings.get('pitch_offset', 0) < -20:\n            pitch_name = \"High\"\n        elif self.settings.get('pitch_offset', 0) > 20:\n            pitch_name = \"Low\"\n        else:\n            pitch_name = \"Mid\"\n\n        pitch_val = self.settings.get('pitch_offset', 0)\n\n        cams = self.settings.get('camera_count', 6)\n        layout = self.settings.get('layout_mode', 'adaptive')\n        layout_info = \" @img\" if layout == 'ring' else \"\"\n        adaptive = \" [Adaptive]\" if self.adaptive_mode else \"\"\n\n        return f\"{pitch_name} [{pitch_val} ], {cams} cams{layout_info}{adaptive}\""}
{"code_id": "Aether_src_middleware_rate_limit_config.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Aether_src_middleware_rate_limit_config.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\Aether_src_middleware_rate_limit_config.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\Aether_src_middleware_rate_limit_config.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "\"/api/monitoring/\": RateLimitPolicy(scope=\"skip\", limit=0, description=\"监控端点\"),\n    }\n\n    @classmethod\n    def get_policy_for_path(cls, path: str) -> Optional[RateLimitPolicy]:\n        \"\"\"\n        根据路径获取速率限制策略\n\n        按照最长匹配原则，优先匹配更具体的路径\n\n        Args:\n            path: 请求路径\n\n        Returns:\n            匹配的速率限制策略，如果没有匹配则返回 None\n        \"\"\"\n        # 按路径长度降序排序，确保最长匹配优先\n        sorted_prefixes = sorted(cls.POLICIES.keys(), key=len, reverse=True)\n\n        for prefix in sorted_prefixes:\n            if path.startswith(prefix):\n                return cls.POLICIES[prefix]\n\n        return None\n\n    @classmethod\n    def register_policy(cls, prefix: str, policy: RateLimitPolicy) -> None:\n        \"\"\"\n        注册新的速率限制策略\n\n        Args:\n            prefix: 路径前缀\n            policy: 速率限制策略\n        \"\"\"\n        cls.POLICIES[prefix] = policy\n\n    @classmethod\n    def get_all_policies(cls) -> Dict[str, RateLimitPolicy]:\n        \"\"\"获取所有策略配置\"\"\"\n        return cls.POLICIES.copy()"}
{"code_id": "Aether_src_middleware_rate_limit_config.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Aether_src_middleware_rate_limit_config.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\Aether_src_middleware_rate_limit_config.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\Aether_src_middleware_rate_limit_config.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "from dataclasses import dataclass\nfrom typing import Dict, Literal, Optional\n\nRateLimitScope = Literal[\"server_ip\", \"user\", \"api_key\", \"skip\"]\n\n@dataclass\nclass RateLimitPolicy:\n    \"\"\"速率限制策略\"\"\"\n    scope: RateLimitScope  # 限制范围\n    limit: int  # 限制值 (请求量/分钟)\n    description: str = \"\"\n\n\n@dataclass\nclass RateLimitConfig:\n    \"\"\"速率限制配置管理\"\"\"\n    # 定义不同路径前缀的速率限制策略\n    ...\n\n    # 默认策略配置\n    POLICIES: Dict[str, RateLimitPolicy] = {\n        # 客户端 API 端点 - 服务器级别 IP 限制\n        \"/api\": RateLimitPolicy(\n            scope=\"server_ip\", limit=60, description=\"Clouds/OpenAI API 端点, 服务器级别限制\"\n        ),\n        # 公共 API 端点 - 服务器级别 IP 限制\n        \"/api/public\": RateLimitPolicy(\n            scope=\"server_ip\", limit=60, description=\"公共只读 API, 服务器级别限制\"\n        ),\n        # 管理后台端点 - 用户级别限制\n        \"/api/admin\": RateLimitPolicy(\n            scope=\"user\", limit=1000, description=\"管理后台, 用户级别限制\"\n        ),\n        # 认证端点 - 跳过中间件 (在路由层处理)\n        \"/api/auth\": RateLimitPolicy(scope=\"skip\", limit=0, description=\"认证端点, 跳过中间件\"),\n        # 用户端点 - 用户级别限制\n        \"/api/user\": RateLimitPolicy(scope=\"skip\", limit=0, description=\"用户端点, 跳过中间件\"),\n        # 监控端点 - 跳过限制\n        \"/api/monitoring\": RateLimitPolicy(scope=\"skip\", limit=0, description=\"监控端点\"),\n    }\n\n\n@classmethod\ndef get_policy_for_path(cls, path: str) -> Optional[RateLimitPolicy]:\n    \"\"\"根据路径获取速率限制策略\"\"\"\n    # 按照最长匹配原则, 优先匹配更具体的路径\n    Args:\n        path: 请求路径\n    Returns:\n        匹配的速率限制策略, 如果没有匹配到返回 None\n    \"\"\"\n    # 按路径长度排序, 确保最长匹配优先\n    sorted_prefixes = sorted(cls.POLICIES.keys(), key=len, reverse=True)\n\n    for prefix in sorted_prefixes:\n        if path.startswith(prefix):\n            return cls.POLICIES[prefix]\n\n    return None\n\n\n@classmethod\ndef register_policy(cls, prefix: str, policy: RateLimitPolicy) -> None:\n    \"\"\"注册新的速率限制策略\"\"\"\n    Args:\n        prefix: 路径前缀\n        policy: 速率限制策略\n    \"\"\"\n    cls.POLICIES[prefix] = policy\n\n\n@classmethod\ndef get_all_policies(cls) -> Dict[str, RateLimitPolicy]:\n    \"\"\"获取所有策略配置\"\"\"\n    return cls.POLICIES.copy()"}
{"code_id": "360Extractor_src_core_job.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\360Extractor_src_core_job.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\360Extractor_src_core_job.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\360Extractor_src_core_job.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": "from __future__ import annotations, Final\nimport logging\nfrom typing import Dict, Any, List, Optional\n\nlogger = logging.getLogger(__name__)\n\nclass Job:\n    def __init__(self, settings: Dict[str, Any]]) -> None:\n        self._settings = settings\n        self.status = 'Pending'\n        self.backend = settings.get('backend', 'slurm')\n\n    def _get_name(self) -> str:\n        return self._settings.get('name', 'unnamed')\n\n    def _set_name(self, name: str) -> None:\n        self._settings['name'] = name\n\n    name = property(_get_name, _set_name)\n\n    def _get_backend(self) -> str:\n        return self._settings.get('backend', 'slurm')\n\n    def _set_backend(self, backend: str) -> None:\n        self._settings['backend'] = backend\n\n    backend = property(_get_backend, _set_backend)\n\n    def _get_input_files(self) -> List[str]:\n        return self._settings.get('input_files', [])\n\n    def _set_input_files(self, input_files: List[str]) -> None:\n        self._settings['input_files'] = input_files\n\n    input_files = property(_get_input_files, _set_input_files)\n\n    def _get_output_files(self) -> List[str]:\n        return self._settings.get('output_files', [])\n\n    def _set_output_files(self, output_files: List[str]) -> None:\n        self._settings['output_files'] = output_files\n\n    output_files = property(_get_output_files, _set_output_files)\n\n    def _get_script(self) -> str:\n        return self._settings.get('script', '')\n\n    def _set_script(self, script: str) -> None:\n        self._settings['script'] = script\n\n    script = property(_get_script, _set_script)\n\n    def _get_arguments(self) -> Dict[str, Any]:\n        return self._settings.get('arguments', {})\n\n    def _set_arguments(self, arguments: Dict[str, Any]) -> None:\n        self._settings['arguments'] = arguments\n\n    arguments = property(_get_arguments, _set_arguments)\n\n    def _get_resources(self) -> Dict[str, Any]:\n        return self._settings.get('resources', {})\n\n    def _set_resources(self, resources: Dict[str, Any]) -> None:\n        self._settings['resources'] = resources\n\n    resources = property(_get_resources, _set_resources)\n\n    def _get_environment(self) -> Dict[str, Any]:\n        return self._settings.get('environment', {})\n\n    def _set_environment(self, environment: Dict[str, Any]) -> None:\n        self._settings['environment'] = environment\n\n    environment = property(_get_environment, _set_environment)\n\n    def _get_dependencies(self) -> List[str]:\n        return self._settings.get('dependencies', [])\n\n    def _set_dependencies(self, dependencies: List[str]) -> None:\n        self._settings['dependencies'] = dependencies\n\n    dependencies = property(_get_dependencies, _set_dependencies)\n\n    def summary(self) -> str:\n        \"\"\"Return a short summary of"}
{"code_id": "360Extractor_src_core_job.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\360Extractor_src_core_job.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\360Extractor_src_core_job.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\360Extractor_src_core_job.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "Aether_src_middleware_rate_limit_config.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Aether_src_middleware_rate_limit_config.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\Aether_src_middleware_rate_limit_config.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\Aether_src_middleware_rate_limit_config.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": ""}
{"code_id": "Ally_app_utils_logger.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Ally_app_utils_logger.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\Ally_app_utils_logger.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\Ally_app_utils_logger.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "import logging\nfrom datetime import datetime\nfrom pathlib import Path\nfrom app.utils.constants import DEFAULT_PATHS\n\nclass AllyLogger:\n    \"\"\"Centralized logging system for Ally.\"\"\"\n\n    _instance = None\n    _logger = None\n\n    def __new__(cls):\n        if cls._instance is None:\n            cls._instance = super(AllyLogger, cls).__new__(cls)\n            cls._instance._initialize_logger()\n        return cls._instance\n\n    def __initialize_logger(self):\n        \"\"\"Initialize the logger with file and console handlers.\"\"\"\n        # Expand environment variables and user home directory\n        log_dir = os.path.expandvars(DEFAULT_PATHS[\"logs\"])\n        log_dir = os.path.expanduser(log_dir)\n\n        # Create log directory if it doesn't exist\n        Path(log_dir).mkdir(parents=True, exist_ok=True)\n\n        # Create log filename with timestamp\n        log_filename = f\"ally_{datetime.now().strftime('%Y%m%d')}.log\"\n        log_path = os.path.join(log_dir, log_filename)\n\n        # Create logger\n        self._logger = logging.getLogger(\"ally\")\n        self._logger.setLevel(logging.DEBUG)\n        # Prevent logging from propagating to root logger (which outputs to console)\n        self._logger.propagate = False\n\n        # Avoid duplicate handlers if logger already configured\n        if not self._logger.handlers:\n            # File handler - logs everything\n            file_handler = logging.FileHandler(log_path, encoding=\"utf-8\")\n            file_handler.setLevel(logging.DEBUG)\n            file_formatter = logging.Formatter(\n                \"%(asctime)s | %(levelname)-8s | %(name)s | %(message)s\",\n                datefmt=\"%Y-%m-%d %H:%M:%S\",\n            )\n            file_handler.setFormatter(file_formatter)\n            self._logger.addHandler(file_handler)\n\n    def debug(self, message: str, **kwargs):\n        \"\"\"Log debug message.\"\"\"\n        self._logger.debug(message, extra=kwargs)\n\n    def info(self, message: str, **kwargs):\n        \"\"\"Log info message.\"\"\"\n        self._logger.info(message, extra=kwargs)\n\n    def warning(self, message: str, **kwargs):\n        \"\"\"Log warning message.\"\"\"\n        self._logger.warning(message, extra=kwargs)\n\n    def error(self, message: str, exc_info=None, **kwargs):\n        \"\"\"Log error message with optional exception info.\"\"\"\n        self._logger.error(message, exc_info=exc_info, extra=kwargs)\n\n    def critical(self, message: str, exc_info=None, **kwargs):\n        \"\"\"Log critical message with optional exception info.\"\"\"\n        self._logger.critical(message, exc_info=exc_info, extra=kwargs)\n\n    def exception(self, message: str, **kwargs):\n        \"\"\"Log exception with traceback.\"\"\"\n        self._logger.exception(message, extra=kwargs)\n\n# Create singleton instance\nlogger = AllyLogger()"}
{"code_id": "Aether_src_middleware_rate_limit_config.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Aether_src_middleware_rate_limit_config.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\Aether_src_middleware_rate_limit_config.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\Aether_src_middleware_rate_limit_config.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": "# 代码实现与注释\n\n# 1. 导入必要的库和模块\n\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score\n\n# 2. 加载数据集\n\niris = load_iris()\nX = iris.data\ny = iris.target\n\n# 3. 划分训练集和测试集\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# 4. 创建决策树分类器\n\nclf = DecisionTreeClassifier()\n\n# 5. 训练模型\n\nclf.fit(X_train, y_train)\n\n# 6. 预测测试集结果\n\ny_pred = clf.predict(X_test)\n\n# 7. 计算准确率\n\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"模型准确率:\", accuracy)\n\n# 8. 可视化决策树（可选）\n\nfrom sklearn.tree import plot_tree\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(20,10))\nplot_tree(clf, filled=True, feature_names=iris.feature_names, class_names=iris.target_names)\nplt.show()\n\n# 9. 保存模型（可选）\n\nimport joblib\n\njoblib.dump(clf, 'decision_tree_model.pkl')\n\n# 10. 加载模型（可选）\n\nloaded_clf = joblib.load('decision_tree_model.pkl')\n\n# 11. 使用加载的模型进行预测\n\ny_pred_loaded = loaded_clf.predict(X_test)\naccuracy_loaded = accuracy_score(y_test, y_pred_loaded)\nprint(\"加载模型后的准确率:\", accuracy_loaded)"}
{"code_id": "Ally_app_utils_logger.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Ally_app_utils_logger.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\Ally_app_utils_logger.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\Ally_app_utils_logger.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "import logging\nfrom datetime import datetime\nfrom pathlib import Path\nfrom app.utils.constants import DEFAULT_PATHS\n\nclass AllyLogger:\n    \"\"\"Centralized logging system for Ally.\"\"\"\n\n    _instance = None\n    _logger = None\n\n    def __new__(cls):\n        if cls._instance is None:\n            cls._instance = super(AllyLogger, cls).__new__(cls)\n            cls._instance._initialize_logger()\n        return cls._instance\n\n    def _initialize_logger(self):\n        \"\"\"Initialize the logger with file and console handlers.\"\"\"\n        # Expand environment variables and user home directory\n        log_dir = os.path.expandvars(DEFAULT_PATHS[\"logs\"])\n        log_dir = os.path.expanduser(log_dir)\n\n        # Create log directory if it doesn't exist\n        Path(log_dir).mkdir(parents=True, exist_ok=True)\n\n        # Create log filename with timestamp\n        log_filename = f\"ally_{datetime.now().strftime('%Y%m%d')}.log\"\n        log_path = os.path.join(log_dir, log_filename)\n\n        # Create logger\n        self._logger = logging.getLogger(\"ally\")\n        self._logger.setLevel(logging.DEBUG)\n        # Prevent logging from propagating to root logger (which outputs to console)\n        self._logger.propagate = False\n\n        # Avoid duplicate handlers if logger already configured\n        if not self._logger.handlers:\n            # File handler - logs everything\n            file_handler = logging.FileHandler(log_path, encoding=\"utf-8\")\n            file_handler.setLevel(logging.DEBUG)\n            file_formatter = logging.Formatter(\n                \"%(asctime)s | %(levelname)-8s | %(name)s | %(message)s\",\n                datefmt=\"%Y-%m-%d %H:%M:%S\"\n            )\n            file_handler.setFormatter(file_formatter)\n\n            self._logger.addHandler(file_handler)\n\n    def debug(self, message: str, **kwargs):\n        \"\"\"Log debug message.\"\"\"\n        self._logger.debug(message, extra=kwargs)\n\n    def info(self, message: str, **kwargs):\n        \"\"\"Log info message.\"\"\"\n        self._logger.info(message, extra=kwargs)\n\n    def warning(self, message: str, **kwargs):\n        \"\"\"Log warning message.\"\"\"\n        self._logger.warning(message, extra=kwargs)\n\n    def error(self, message: str, exc_info=None, **kwargs):\n        \"\"\"Log error message with optional exception info.\"\"\"\n        self._logger.error(message, exc_info=exc_info, extra=kwargs)\n\n    def critical(self, message: str, exc_info=None, **kwargs):\n        \"\"\"Log critical message with optional exception info.\"\"\"\n        self._logger.critical(message, exc_info=exc_info, extra=kwargs)\n\n    def exception(self, message: str, **kwargs):\n        \"\"\"Log exception with traceback.\"\"\"\n        self._logger.exception(message, extra=kwargs)\n\n# Create singleton instance\nlogger = AllyLogger()"}
{"code_id": "Ally_app_utils_logger.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Ally_app_utils_logger.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\Ally_app_utils_logger.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\Ally_app_utils_logger.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "import logging\nfrom datetime import datetime\nfrom pathlib import Path\nfrom app.utils.constants import DEFAULT_PATHS\n\nclass AllyLogger:\n    \"\"\"Generalized logging system for Ally.\"\"\"\n\n    _instance = None\n    _logger = None\n\n    def __new__(cls):\n        if cls._instance is None:\n            cls._instance = super(AllyLogger, cls).__new__(cls)\n            cls._instance._initialize_logger()\n        return cls._instance\n\n    def _initialize_logger(self):\n        \"\"\"Initialize the logger with file and console handlers.\"\"\"\n        # Expand environment variables and user home directory\n        log_dir = os.path.expandvars(DEFAULT_PATHS[\"logs\"])\n        log_dir = os.path.expanduser(log_dir)\n\n        # Create log directory if it doesn't exist\n        Path(log_dir).mkdir(parents=True, exist_ok=True)\n\n        # Create log filename with timestamp\n        log_filename = f\"ally_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\"\n        log_path = os.path.join(log_dir, log_filename)\n\n        # Create logger\n        self._logger = logging.getLogger(\"ally\")\n        self._logger.setLevel(logging.DEBUG)\n        # Prevent logging from propagating to root logger (which outputs to console)\n        self._logger.propagate = False\n\n        # Avoid duplicate handlers if logger already configured\n        if not self._logger.handlers:\n            # File handler - logs everything\n            file_handler = logging.FileHandler(log_path, encoding=\"utf-8\")\n            file_handler.setLevel(logging.DEBUG)\n            file_formatter = logging.Formatter(\n                \"%(asctime)s [%(levelname)s] %(name)s | %(message)s\",\n                datefmt=\"%Y-%m-%d %H:%M:%S\"\n            )\n            file_handler.setFormatter(file_formatter)\n            self._logger.addHandler(file_handler)\n\n    def debug(self, message: str, **kwargs):\n        \"\"\"Log debug message.\"\"\"\n        self._logger.debug(message, **kwargs)\n\n    def info(self, message: str, **kwargs):\n        \"\"\"Log info message.\"\"\"\n        self._logger.info(message, **kwargs)\n\n    def warning(self, message: str, **kwargs):\n        \"\"\"Log warning message.\"\"\"\n        self._logger.warning(message, **kwargs)\n\n    def error(self, message: str, exc_info: bool = False, **kwargs):\n        \"\"\"Log error message with optional exception info.\"\"\"\n        self._logger.error(message, exc_info=exc_info, **kwargs)\n\n    def critical(self, message: str, exc_info: bool = False, **kwargs):\n        \"\"\"Log critical message with optional exception info.\"\"\"\n        self._logger.critical(message, exc_info=exc_info, **kwargs)\n\n    def exception(self, message: str, **kwargs):\n        \"\"\"Log exception with traceback.\"\"\"\n        self._logger.exception(message, **kwargs)\n\n# Create singleton instance\nlogger = AllyLogger()"}
{"code_id": "Aether_src_middleware_rate_limit_config.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Aether_src_middleware_rate_limit_config.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\Aether_src_middleware_rate_limit_config.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\Aether_src_middleware_rate_limit_config.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "BustAPI_python_bustapi_middleware.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\BustAPI_python_bustapi_middleware.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\BustAPI_python_bustapi_middleware.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\BustAPI_python_bustapi_middleware.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "from typing import Callable, List, Optional\nfrom http.request import Request\nfrom http.response import Response\n\nclass Middleware:\n    \"\"\"\n    Base class for BustAPI middleware.\n    \"\"\"\n\n    def process_request(self, request: Request) -> Optional[Response]:\n        \"\"\"\n        Called before the view function.\n\n        Args:\n            request: The incoming request object\n\n        Returns:\n            None to continue processing, or a Response object to stop invalid processing\n            and return the response immediately.\n        \"\"\"\n        return None\n\n    def process_response(self, request: Request, response: Response) -> Response:\n        \"\"\"\n        Called after the view function.\n\n        Args:\n            request: The request object\n            response: The response object produced by the view or previous middleware\n\n        Returns:\n            A Response object (modified or original).\n        \"\"\"\n        return response\n\nclass MiddlewareManager:\n    \"\"\"\n    Manages the execution of middleware chains.\n    \"\"\"\n\n    def __init__(self):\n        self._middlewares: List[Middleware] = []\n\n    @property\n    def middlewares(self) -> List[Middleware]:\n        return self._middlewares\n\n    def add(self, middleware: Middleware):\n        \"\"\"Add a middleware instance to the chain.\"\"\"\n        self._middlewares.append(middleware)\n\n    def process_request(self, request: Request) -> Optional[Response]:\n        \"\"\"Run process_request on all middleware.\"\"\"\n        for middleware in self._middlewares:\n            response = middleware.process_request(request)\n            if response:\n                return response\n        return None\n\n    def process_response(self, request: Request, response: Response) -> Response:\n        \"\"\"Run process_response on all middleware (reversed order).\"\"\"\n        for middleware in reversed(self._middlewares):\n            response = middleware.process_response(request, response)\n        return response"}
{"code_id": "BustAPI_python_bustapi_middleware.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\BustAPI_python_bustapi_middleware.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\BustAPI_python_bustapi_middleware.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\BustAPI_python_bustapi_middleware.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "from typing import Callable, List, Optional\nfrom .http.request import Request\nfrom .http.response import Response\n\nclass Middleware:\n    \"\"\"\n    Base class for BustAPI middleware.\n    \"\"\"\n\n    def process_request(self, request: Request) -> Optional[Response]:\n        \"\"\"\n        Called before the view function.\n\n        Args:\n            request: The incoming request object\n\n        Returns:\n            None to continue processing, or a Response object to stop invalid processing\n            and return the response immediately.\n        \"\"\"\n        return None\n\n    def process_response(self, request: Request, response: Response) -> Response:\n        \"\"\"\n        Called after the view function.\n\n        Args:\n            request: The request object\n            response: The response object produced by the view or previous middleware\n\n        Returns:\n            A Response object (modified or original).\n        \"\"\"\n        return response\n\nclass MiddlewareManager:\n    \"\"\"\n    Manages the execution of middleware chains.\n    \"\"\"\n\n    def __init__(self):\n        self._middlewares: List[Middleware] = []\n\n    @property\n    def middlewares(self) -> List[Middleware]:\n        return self._middlewares\n\n    def add(self, middleware: Middleware):\n        \"\"\"Add a middleware instance to the chain.\"\"\"\n        self._middlewares.append(middleware)\n\n    def process_request(self, request: Request) -> Optional[Response]:\n        \"\"\"Run process_request on all middleware.\"\"\"\n        for middleware in self._middlewares:\n            response = middleware.process_request(request)\n            if response:\n                return response\n        return None\n\n    def process_response(self, request: Request, response: Response) -> Response:\n        \"\"\"Run process_response on all middleware (reversed order).\"\"\"\n        for middleware in reversed(self._middlewares):\n            response = middleware.process_response(request, response)\n        return response"}
{"code_id": "BustAPI_python_bustapi_middleware.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\BustAPI_python_bustapi_middleware.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\BustAPI_python_bustapi_middleware.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\BustAPI_python_bustapi_middleware.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "from typing import Callable, List, Optional\n\nfrom http.request import Request\nfrom http.response import Response\n\n\nclass Middleware:\n    \"\"\"\n    Base class for BunAPI middleware.\n    \"\"\"\n\n    def process_request(self, request: Request) -> Optional[Response]:\n        \"\"\"\n        Called before the view function.\n\n        Args:\n            request: The incoming request object\n\n        Returns:\n            None to continue processing, or a Response object to stop invalid processing\n            and return the response immediately.\n        \"\"\"\n        return None\n\n    def process_response(self, request: Request, response: Response) -> Response:\n        \"\"\"\n        Called after the view function.\n\n        Args:\n            request: The request object\n            response: The response object produced by the view or previous middleware\n\n        Returns:\n            A Response object (modified or original).\n        \"\"\"\n        return response\n\n\nclass MiddlewareManager:\n    \"\"\"\n    Manages the execution of middleware chains.\n    \"\"\"\n\n    def __init__(self):\n        self._middlewares: List[Middleware] = []\n\n    @property\n    def middlewares(self) -> List[Middleware]:\n        return self._middlewares\n\n    def add(self, middleware: Middleware):\n        \"\"\"Add a middleware instance to the chain.\"\"\"\n        self._middlewares.append(middleware)\n\n    def process_request(self, request: Request) -> Optional[Response]:\n        \"\"\"Run process_request on all middlewares.\"\"\"\n        for middleware in self._middlewares:\n            response = middleware.process_request(request)\n            if response:\n                return response\n        return None\n\n    def process_response(self, request: Request, response: Response) -> Response:\n        \"\"\"Run process_response on all middlewares (reversed order).\"\"\"\n        for middleware in reversed(self._middlewares):\n            response = middleware.process_response(request, response)\n        return response"}
{"code_id": "BustAPI_python_bustapi_middleware.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\BustAPI_python_bustapi_middleware.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\BustAPI_python_bustapi_middleware.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\BustAPI_python_bustapi_middleware.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": "from typing import List, Optional\nfrom starlette.requests import Request\nfrom starlette.responses import Response\n\nclass Middleware:\n    \"\"\"Base class for Starlette middleware.\"\"\"\n\n    def process_request(self, request: Request) -> Optional[Response]:\n        \"\"\"Called before the view function.\"\"\"\n        Args:\n            request: The incoming request object\n        Returns:\n            None to continue processing, or a Response object to stop processing and return the response immediately.\n        return None\n\n    def process_response(self, request: Request, response: Response) -> Response:\n        \"\"\"Called after the view function.\"\"\"\n        Args:\n            request: The request object\n            response: The response object processed by the view or process_request.\n        Returns:\n            A Response object (modified or original).\n        return response\n\nclass MiddlewareManager:\n    \"\"\"Manages the execution of a middleware chain.\"\"\"\n\n    def __init__(self):\n        self._middleware: List[Middleware] = []\n\n    def add_middleware(self, middleware: Middleware):\n        \"\"\"Add a middleware object to the chain.\"\"\"\n        self._middleware.append(middleware)\n\n    def process_request(self, request: Request) -> Optional[Response]:\n        \"\"\"Run process_request on all middleware.\"\"\"\n        for middleware in self._middleware:\n            response = middleware.process_request(request)\n            if response:\n                return response\n        return None\n\n    def process_response(self, request: Request, response: Response) -> Response:\n        \"\"\"Run process_response on all middleware.\"\"\"\n        for middleware in self._middleware:\n            response = middleware.process_response(request, response)\n        return response"}
{"code_id": "Ally_app_utils_logger.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Ally_app_utils_logger.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\Ally_app_utils_logger.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\Ally_app_utils_logger.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "Ally_app_utils_logger.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Ally_app_utils_logger.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\Ally_app_utils_logger.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\Ally_app_utils_logger.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "C3G_src_dataset_view_sampler_view_sampler.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\C3G_src_dataset_view_sampler_view_sampler.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\C3G_src_dataset_view_sampler_view_sampler.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\C3G_src_dataset_view_sampler_view_sampler.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "from abc import ABC, abstractmethod\nfrom typing import Generic, TypeVar\n\nimport torch\nfrom jaxtyping import Float, Int64\nfrom torch import Tensor\n\nfrom ..misc.step_tracker import StepTracker\nfrom ..types import Stage\n\nT = TypeVar(\"T\")\n\nclass ViewSampler(ABC, Generic[T]):\n    cfg: T\n    stage: Stage\n    is_overfitting: bool\n    cameras_are_circular: bool\n    step_tracker: StepTracker | None\n\n    def __init__(\n        self,\n        cfg: T,\n        stage: Stage,\n        is_overfitting: bool,\n        cameras_are_circular: bool,\n        step_tracker: StepTracker | None,\n    ) -> None:\n        self.cfg = cfg\n        self.stage = stage\n        self.is_overfitting = is_overfitting\n        self.cameras_are_circular = cameras_are_circular\n        self.step_tracker = step_tracker\n\n    @abstractmethod\n    def sample(\n        self,\n        scene: str,\n        extrinsics: Float[Tensor, \"view 4 4\"],\n        intrinsics: Float[Tensor, \"view 3 3\"],\n        device: torch.device = torch.device(\"cpu\"),\n    ) -> tuple[\n        Int64[Tensor, \" context_view\"],  # indices for context views\n        Int64[Tensor, \" target_view\"],  # indices for target views\n        Float[Tensor, \" overlap\"],  # overlap\n    ]:\n        pass\n\n@property\n@abstractmethod\ndef num_target_views(self) -> int:\n    pass\n\n@property\n@abstractmethod\ndef num_context_views(self) -> int:\n    pass\n\n@property\ndef global_step(self) -> int:\n    return 0 if self.step_tracker is None else self.step_tracker.get_step()"}
{"code_id": "C3G_src_dataset_view_sampler_view_sampler.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\C3G_src_dataset_view_sampler_view_sampler.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\C3G_src_dataset_view_sampler_view_sampler.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\C3G_src_dataset_view_sampler_view_sampler.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "from abc import ABC, abstractmethod\nfrom typing import Generic, TypeVar\n\nimport torch\nfrom jaxtyping import Float, Int64\nfrom torch import Tensor\n\nfrom ..misc.step_tracker import StepTracker\nfrom ..types import Stage\n\nT = TypeVar(\"T\")\n\nclass ViewSampler(ABC, Generic[T]):\n    cfg: T\n    stage: Stage\n    is_overfitting: bool\n    cameras_are_circular: bool\n    step_tracker: StepTracker | None\n\n    def __init__(\n        self,\n        cfg: T,\n        stage: Stage,\n        is_overfitting: bool,\n        cameras_are_circular: bool,\n        step_tracker: StepTracker | None,\n    ) -> None:\n        self.cfg = cfg\n        self.stage = stage\n        self.is_overfitting = is_overfitting\n        self.cameras_are_circular = cameras_are_circular\n        self.step_tracker = step_tracker\n\n    @abstractmethod\n    def sample(\n        self,\n        scene: str,\n        extrinsics: Float[Tensor, \"view 4 4\"],\n        intrinsics: Float[Tensor, \"view 3 3\"],\n        device: torch.device = torch.device(\"cpu\"),\n    ) -> tuple[\n        Int64[Tensor, \"context_view\"],  # indices for context views\n        Int64[Tensor, \"target_view\"],  # indices for target views\n        Float[Tensor, \"overlap\"],  # overlap\n    ]:\n        pass\n\n    @property\n    @abstractmethod\n    def num_target_views(self) -> int:\n        pass\n\n    @property\n    @abstractmethod\n    def num_context_views(self) -> int:\n        pass\n\n    @property\n    def global_step(self) -> int:\n        return 0 if self.step_tracker is None else self.step_tracker.get_step()"}
{"code_id": "C3G_src_dataset_view_sampler_view_sampler.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\C3G_src_dataset_view_sampler_view_sampler.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\C3G_src_dataset_view_sampler_view_sampler.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\C3G_src_dataset_view_sampler_view_sampler.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "from __future__ import annotations\nfrom abc import ABC, abstractmethod\nfrom typing import Generic, TypeVar\n\nimport torch\nfrom jaxtyping import Float, Int64\nfrom torch import Tensor\n\nfrom ...misc.step_tracker import StepTracker\nfrom ...types import Stage\n\nT = TypeVar(\"T\")\n\nclass ViewSampler(ABC, Generic[T]):\n    @fg\n    t\n    stage: Stage\n    is_overfitting: bool\n    cameras_are_circular: bool\n    step_tracker: StepTracker | None\n\n    def __init__(\n        self,\n        @fg: t,\n        stage: Stage,\n        is_overfitting: bool,\n        cameras_are_circular: bool,\n        step_tracker: StepTracker | None,\n    ) -> None:\n        self.cfg = cfg\n        self.stage = stage\n        self.is_overfitting = is_overfitting\n        self.cameras_are_circular = cameras_are_circular\n        self.step_tracker = step_tracker\n\n    @abstractmethod\n    def sample(\n        self,\n        scene: str,\n        extrinsics: Float[Tensor, \"view 4 4\"],\n        intrinsics: Float[Tensor, \"view 3 3\"],\n        device: torch.device = torch.device(\"cpu\"),\n    ) -> tuple[\n        Int64[Tensor, \"context_views\"],  # indices for context views\n        Int64[Tensor, \"target_views\"],  # indices for target views\n        Float[Tensor, \"overlap\"],  # overlap\n    ]:\n        pass\n\n@property\n@abstractmethod\ndef num_target_views(self) -> int:\n    pass\n\n@property\n@abstractmethod\ndef num_context_views(self) -> int:\n    pass\n\n@property\ndef global_step(self) -> int:\n    return 0 if self.step_tracker is None else self.step_tracker.get_step()"}
{"code_id": "BustAPI_python_bustapi_middleware.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\BustAPI_python_bustapi_middleware.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\BustAPI_python_bustapi_middleware.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\BustAPI_python_bustapi_middleware.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "ComfyUI-dapaoAPI_dapao_template_node.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\ComfyUI-dapaoAPI_dapao_template_node.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\ComfyUI-dapaoAPI_dapao_template_node.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\ComfyUI-dapaoAPI_dapao_template_node.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "# Dapao Prompt Master\n# Prompt Manager for Dapao Image Prompts\n\nimport os\nimport sys\n\ntry:\n    from .dapao_template_adapter import DapaoPromptTemplateAdapter\nexcept ImportError:\n    from dapao_template_adapter import DapaoPromptTemplateAdapter\n\nclass DapaoPromptNode:\n    \"\"\"\n    Dapao Prompt Node - Browse and use prompt templates\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"Initialize with template adapter\"\"\"\n        try:\n            self.adapter = DapaoPromptTemplateAdapter()\n            self.initialized = True\n        except Exception as e:\n            print(f\"[Dapao] ERROR: Failed to initialize adapter: {e}\")\n            self.adapter = None\n            self.initialized = False\n\n    @classmethod\n    def INPUT_TYPES(cls):\n        \"\"\"Define node inputs\"\"\"\n        return {\n            \"required\": {\n                \"prompt\": (\"STRING\", {\n                    \"multiline\": True,\n                    \"default\": \"\",\n                    \"placeholder\": \"在此输入您的提示词...\\n\\n点击下方的「浏览模板」按钮加载模板。\",\n                    \"dynamicPrompts\": False\n                })\n            }\n        }\n\nRETURN_TYPES = (\"STRING\",)\nRETURN_NAMES = (\"final_prompt\",)\nFUNCTION = \"generate_prompt\"\nCATEGORY = \"📦dapaoAPI/Nano Banana 2\"\n\nIS_ENABLED_NODE = False\n\n    def generate_prompt(self, prompt=\"\"):\n        \"\"\"\n        Generate final prompt\n        \"\"\"\n        return (prompt,)\n\n# ============================== Node Registration ==============================\nNODE_CLASS_MAPPINGS = {\n    \"DapaoPromptNode\": DapaoPromptNode\n}\n\nNODE_DISPLAY_NAME_MAPPINGS = {\n    \"DapaoPromptNode\": \"📦 大炮bannan文生图提示词\"\n}"}
{"code_id": "C3G_src_dataset_view_sampler_view_sampler.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\C3G_src_dataset_view_sampler_view_sampler.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\C3G_src_dataset_view_sampler_view_sampler.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\C3G_src_dataset_view_sampler_view_sampler.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "C3G_src_dataset_view_sampler_view_sampler.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\C3G_src_dataset_view_sampler_view_sampler.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\C3G_src_dataset_view_sampler_view_sampler.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\C3G_src_dataset_view_sampler_view_sampler.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": "import argparse\nimport os\nimport sys\n\nfrom . import images_from_json\nfrom . import images_from_folder\n\nfrom ..core import image\nfrom ..core import image_number\n\nfrom ..core import image_folder\n\ni = image_number + 1\n\na new if statement in def images_from_folder():\n    if i < 0:\n        i = 1\n    while i <= image_number:\n        image = image_folder.get_image(i)\n        if image is not None:\n            images.append(image)\n        i += 1\n\ndef images_from_folder():\n    images = []\n    i = image_number + 1\n    if i < 0:\n        i = 1\n    while i <= image_number:\n        image = image_folder.get_image(i)\n        if image is not None:\n            images.append(image)\n        i += 1\n    return images\n\ndef images_from_json():\n    with open(json_file, 'r') as f:\n        data = json.load(f)\n    images = []\n    for item in data:\n        image = image_from_json(item)\n        if image is not None:\n            images.append(image)\n    return images\n\ndef main():\n    parser = argparse.ArgumentParser(description='Process some images.')\n    parser.add_argument('--json', type=str, help='Path to JSON file')\n    parser.add_argument('--folder', type=str, help='Path to image folder')\n    args = parser.parse_args()\n\n    if args.json:\n        images = images_from_json()\n    elif args.folder:\n        images = images_from_folder()\n    else:\n        print(\"Please provide either --json or --folder\")\n        sys.exit(1)\n\n    # Process images here\n    for image in images:\n        print(image)"}
{"code_id": "ComfyUI-dapaoAPI_dapao_template_node.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\ComfyUI-dapaoAPI_dapao_template_node.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\ComfyUI-dapaoAPI_dapao_template_node.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\ComfyUI-dapaoAPI_dapao_template_node.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "# Dapao Prompt Master\n# Prompt Manager for Dapao Image Prompts\n\nimport os\nimport sys\n\ntry:\n    from .dapao_template_adapter import DapaoPromptTemplateAdapter\nexcept ImportError:\n    from dapao_template_adapter import DapaoPromptTemplateAdapter\n\nclass DapaoPromptNode:\n    \"\"\"\n    Dapao Prompt Node - Browse and use prompt templates\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"Initialize with template adapter\"\"\"\n        try:\n            self.adapter = DapaoPromptTemplateAdapter()\n            self.initialized = True\n        except Exception as e:\n            print(f\"[Dapao] ERROR: Failed to initialize adapter: {e}\")\n            self.adapter = None\n            self.initialized = False\n\n    @classmethod\n    def INPUT_TYPES(cls):\n        \"\"\"Define node inputs\"\"\"\n        return {\n            \"required\": {\n                \"prompt\": (\"STRING\", {\n                    \"multiline\": True,\n                    \"default\": \"\",\n                    \"placeholder\": \"在此输入您的提示词...\\n\\n点击下方的「浏览模板」按钮加载模板。\",\n                    \"dynamicPrompts\": False\n                })\n            }\n        }\n\nRETURN_TYPES = (\"STRING\",)\nRETURN_NAMES = (\"final_prompt\",)\nFUNCTION = \"generate_prompt\"\nCATEGORY = \"📦dapaoAPI/Nano Banana 2\"\nIS_CHANGED_NODE = False\n\n    def generate_prompt(self, prompt=\"\"):\n        \"\"\"\n        Generate final prompt\n        \"\"\"\n        return (prompt,)\n\n# ================================= Node Registration =================================\nNODE_CLASS_MAPPINGS = {\n    \"DapaoPromptNode\": DapaoPromptNode\n}\n\nNODE_DISPLAY_NAME_MAPPINGS = {\n    \"DapaoPromptNode\": \"📦 大炮bannan文生图提示词\"\n}"}
{"code_id": "ComfyUI-dapaoAPI_dapao_template_node.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\ComfyUI-dapaoAPI_dapao_template_node.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\ComfyUI-dapaoAPI_dapao_template_node.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\ComfyUI-dapaoAPI_dapao_template_node.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "# ComfyUI-DupanPrompt Master\n# Prompt Manager for Dupan Image Prompts\n\nimport os\nimport sys\n\ntry:\n    from .dupan_template_adapter import DupanPromptTemplateAdapter\nexcept ImportError:\n    from dupan_template_adapter import DupanPromptTemplateAdapter\n\nclass DupanPromptNode:\n\n    Dupan Prompt Node - Browse and use prompt templates\n\n    def __init__(self):\n        \"\"\"Initialize with template adapter\"\"\"\n        try:\n            self.adapter = DupanPromptTemplateAdapter()\n            self.initialized = True\n        except Exception as e:\n            print(f\"[Dupan] ERROR: Failed to initialize adapter: {e}\")\n            self.adapter = None\n            self.initialized = False\n\n    @classmethod\n    def INPUT_TYPES(cls):\n        \"\"\"Define node inputs\"\"\"\n        return {\n            \"required\": [\n                \"prompt\": (\"STRING\", {\n                    \"multiline\": True,\n                    \"default\": \"\",\n                    \"placeholder\": \"在此输入您的提示词...或点击下方的「浏览模板」按钮加载模板。\",\n                    \"dynamicPrompt\": False\n                })\n            ]\n        }\n\n    RETURN_TYPES = (\"STRING\",)\n    RETURN_NAMES = (\"final_prompt\",)\n    FUNCTION = \"generate_prompt\"\n    CATEGORY = \"📦DupanAPI/Node Manager 2\"\n\nIS_ENABLED = False\n\n    def generate_prompt(self, prompt=\"\"):\n        \"\"\"\n        Generate final prompt\n        \"\"\"\n        return (prompt,)\n\n# ------------------------------ Node Registration ------------------------------\nNODE_CLASS_MAPPINGS = {\n    \"DupanPromptNode\": DupanPromptNode\n}\n\nNODE_DISPLAY_NAME_MAPPINGS = {\n    \"DupanPromptNode\": \"📦 大图nana生成图提示词\"\n}"}
{"code_id": "ComfyUI-dapaoAPI_dapao_template_node.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\ComfyUI-dapaoAPI_dapao_template_node.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\ComfyUI-dapaoAPI_dapao_template_node.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\ComfyUI-dapaoAPI_dapao_template_node.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": "# Copyright 2022\n# See LICENSE for details.\n\nimport os\nimport json\n\nfrom .common import init_adapter\nfrom . import llm_api\nfrom .common import init_adapter\n\nclass RequestBodyModel:\n    \"\"\"Define the input fields for the model and each prompt template\"\"\"\n\n    def __init__(self):\n        \"\"\"Initialize the input fields adapter\"\"\"\n        try:\n            self.adapter = llm_api.super_haystack_adapter()\n            self.is_valid = True\n        except Exception as e:\n            self.is_valid = False\n            self.error = f\"Error: Failed to initialize the adapter: {e}\"\n            self.adapter = None\n            self.is_valid = False\n\n    def import_config(self):\n        \"\"\"Read the config file\"\"\"\n        return {\n            \"model\": {\n                \"name\": \"llm_model\",\n                \"type\": \"str\",\n                \"default\": \"\",\n                \"description\": \"The name of the language model. For example, 'gpt-3.5-turbo'.\",\n                \"is_required\": False\n            }\n        }\n\n    def schema(self, include_title=True):\n        \"\"\"Generate the JSON schema for the request body\"\"\"\n        schema = {\n            \"type\": \"object\",\n            \"properties\": {\n                \"model\": {\n                    \"type\": \"string\",\n                    \"description\": \"The name of the language model. For example, 'gpt-3.5-turbo'.\",\n                    \"default\": \"\"\n                }\n            }\n        }\n        if include_title:\n            schema[\"title\"] = \"Request Body\"\n        return schema\n\n    def validate(self, data):\n        \"\"\"Validate the input data against the schema\"\"\"\n        try:\n            self.adapter.validate(data)\n            return True\n        except Exception as e:\n            self.error = f\"Validation error: {e}\"\n            return False\n\ndef generate_prompt(prompt_template, prompt_variables):\n    \"\"\"Generate the prompt using the template and variables\"\"\"\n    try:\n        return prompt_template.format(**prompt_variables)\n    except Exception as e:\n        raise ValueError(f\"Error generating prompt: {e}\")\n\n# ------------------------------ Main Haystack class ------------------------------\n\nclass Haystack:\n    \"\"\"The main Haystack class\"\"\"\n\n    def __init__(self, model_name, adapter=None):\n        \"\"\"Initialize the Haystack class\"\"\"\n        self.model_name = model_name\n        self.adapter = adapter or llm_api.super_haystack_adapter()\n        self.request_body_model = RequestBodyModel()\n\n    def generate_prompt(self, prompt_template, prompt_variables):\n        \"\"\"Generate the prompt using the template and variables\"\"\"\n        return generate_prompt(prompt_template, prompt_variables)\n\n    def validate_request(self, data):\n        \"\"\"Validate the request data against the schema\"\"\"\n        return self.request_body_model.validate(data)\n\n    def process_request(self, data):\n        \"\"\"Process the request data and generate the response\"\"\"\n        if not self.validate_request(data):\n            raise ValueError(self.request_body_model.error)\n        prompt = self.generate_prompt(data[\"prompt_template\"], data[\"prompt_variables\"])\n        response = self.adapter.generate(prompt)\n        return response\n\n    def get_model_info(self):\n        \"\"\"Get the information about the model\"\"\"\n        return {\n            \"model_name\": self.model_name,\n            \"adapter\": self.adapter.__class__.__name__\n        }\n\n    def get_request_body_schema(self, include_title=True):\n        \"\"\"Get the JSON schema for the request body\"\"\"\n        return self.request_body_model.schema(include_title)\n\n    def get_prompt_template_schema(self):\n        \"\"\"Get the JSON schema for the prompt template\"\"\"\n        return {\n            \"type\": \"object\",\n            \"properties\": {\n                \"prompt_template\": {\n                    \"type\": \"string\",\n                    \"description\": \"The prompt template string. For example, 'Translate the following text to {language}: {text}'.\",\n                    \"default\": \"\"\n                },\n                \"prompt_variables\": {\n                    \"type\": \"object\",\n                    \"description\": \"The variables to be used in the prompt template. For example, {'language': 'French', 'text': 'Hello, world!'}.\",\n                    \"default\": {}\n                }\n            }\n        }\n\n    def get_prompt_variables_schema(self):\n        \"\"\"Get the JSON schema for the prompt variables\"\"\"\n        return {\n            \"type\": \"object\",\n            \"properties\": {\n                \"language\": {\n                    \"type\": \"string\",\n                    \"description\": \"The target language for translation. For example, 'French', 'Spanish'.\",\n                    \"default\": \"\"\n                },\n                \"text\": {\n                    \"type\": \"string\",\n                    \"description\": \"The text to be translated. For example, 'Hello, world!'.\",\n                    \"default\": \"\"\n                }\n            }\n        }\n\n    def get_response_schema(self):\n        \"\"\"Get the JSON schema for the response\"\"\"\n        return {\n            \"type\": \"object\",\n            \"properties\": {\n                \"response\": {\n                    \"type\": \"string\",\n                    \"description\": \"The response generated by the language model.\",\n                    \"default\": \"\"\n                }\n            }\n        }\n\n    def get_error_schema(self):\n        \"\"\"Get the JSON schema for the error response\"\"\"\n        return {\n            \"type\": \"object\",\n            \"properties\": {\n                \"error\": {\n                    \"type\": \"string\",\n                    \"description\": \"The error message.\",\n                    \"default\": \"\"\n                }\n            }\n        }\n\n    def get_info_schema(self):\n        \"\"\"Get the JSON schema for the info response\"\"\"\n        return {\n            \"type\": \"object\",\n            \"properties\": {\n                \"model_name\": {\n                    \"type\": \"string\",\n                    \"description\": \"The name of the language model.\",\n                    \"default\": \"\"\n                },\n                \"adapter\": {\n                    \"type\": \"string\",\n                    \"description\": \"The name of the adapter class.\",\n                    \"default\": \"\"\n                }\n            }\n        }\n\n    def get_prompt_template_example(self):\n        \"\"\"Get an example of the prompt template\"\"\"\n        return \"Translate the following text to {language}: {text}\"\n\n    def get_prompt_variables_example(self):\n        \"\"\"Get an example of the prompt variables\"\"\"\n        return {\"language\": \"French\", \"text\": \"Hello, world!\"}\n\n    def get_response_example(self):\n        \"\"\"Get an example of the response\"\"\"\n        return \"Bonjour, le monde!\"\n\n    def get_error_example(self):\n        \"\"\"Get an example of the error response\"\"\"\n        return {\"error\": \"Invalid input data\"}\n\n    def get_info_example(self):\n        \"\"\"Get an example of the info response\"\"\"\n        return {\"model_name\": \"gpt-3.5-turbo\", \"adapter\": \"SuperHaystackAdapter\"}\n\n    def get_prompt_template_description(self):\n        \"\"\"Get the description of the prompt template\"\"\"\n        return \"The prompt template string. For example, 'Translate the following text to {language}: {text}'.\"\n\n    def get_prompt_variables_description(self):\n        \"\"\"Get the description of the prompt variables\"\"\"\n        return \"The variables to be used in the prompt template. For example, {'language': 'French', 'text': 'Hello, world!'}.\""}
{"code_id": "CookHero_app_services_user_service.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\CookHero_app_services_user_service.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\CookHero_app_services_user_service.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\CookHero_app_services_user_service.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "import logging\nfrom typing import Optional\nfrom sqlalchemy import select\nfrom sqlalchemy.exc import IntegrityError\nfrom app.database.models import UserModel\nfrom app.database.session import get_session_context\n\nlogger = logging.getLogger(__name__)\n\nclass UserService:\n    \"\"\"Service to manage user profiles and updates.\"\"\"\n\n    async def get_user_by_username(self, username: str) -> Optional[UserModel]:\n        async with get_session_context() as session:\n            stmt = select(UserModel).where(UserModel.username == username)\n            result = await session.execute(stmt)\n            return result.scalar_one_or_none()\n\n    async def get_user_by_id(self, user_id) -> Optional[UserModel]:\n        async with get_session_context() as session:\n            stmt = select(UserModel).where(UserModel.id == user_id)\n            result = await session.execute(stmt)\n            return result.scalar_one_or_none()\n\n    async def update_profile(self, username: str, data: dict) -> UserModel:\n        \"\"\"Update user profile fields.\"\"\"\n        async with get_session_context() as session:\n            stmt = select(UserModel).where(UserModel.username == username)\n            result = await session.execute(stmt)\n            user = result.scalar_one_or_none()\n            if not user:\n                raise ValueError(\"User not found\")\n\n            # If username change requested, check uniqueness\n            new_username = data.get(\"username\")\n            if new_username and new_username != user.username:\n                # check existing\n                stmt2 = select(UserModel).where(UserModel.username == new_username)\n                res2 = await session.execute(stmt2)\n                if res2.scalar_one_or_none():\n                    raise ValueError(\"Username already exists\")\n                user.username = new_username\n\n            if \"occupation\" in data:\n                user.occupation = data.get(\"occupation\")\n            if \"bio\" in data:\n                user.bio = data.get(\"bio\")\n            if \"profile\" in data:\n                user.profile = data.get(\"profile\")\n            if \"user_instruction\" in data:\n                user.user_instruction = data.get(\"user_instruction\")\n\n            try:\n                await session.flush()\n            except IntegrityError as exc:\n                logger.warning(\"Integrity error updating profile: %s\", exc)\n                raise ValueError(\"Failed to update profile\")\n\n            return user\n\nuser_service = UserService()"}
{"code_id": "ComfyUI-dapaoAPI_dapao_template_node.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\ComfyUI-dapaoAPI_dapao_template_node.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\ComfyUI-dapaoAPI_dapao_template_node.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\ComfyUI-dapaoAPI_dapao_template_node.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "CookHero_app_services_user_service.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\CookHero_app_services_user_service.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\CookHero_app_services_user_service.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\CookHero_app_services_user_service.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": ""}
{"code_id": "CookHero_app_services_user_service.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\CookHero_app_services_user_service.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\CookHero_app_services_user_service.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\CookHero_app_services_user_service.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": "from datetime import datetime\nfrom typing import Optional, Dict, Any\nfrom sqlalchemy.orm import Session\nfrom app.api.v1.endpoints import get_password_hash, verify_password\nfrom app.models.user_models import User\nfrom app.models.user_models import get_user_by_username, get_user_by_id\n\nlogger = logging.getLogger(__name__)\n\nclass UserServices:\n    \"\"\"Service to manage user profiles and operations.\"\"\"\n\n    async def get_user_by_username(self, username: str) -> Optional[User]:\n        async with get_session() as session:\n            result = await session.execute(\n                select(User).where(User.username == username)\n            )\n            return result.scalar_one_or_none()\n\n    async def get_user_by_id(self, user_id: int) -> Optional[User]:\n        async with get_session() as session:\n            result = await session.execute(\n                select(User).where(User.id == user_id)\n            )\n            return result.scalar_one_or_none()\n\n    async def update_user_profile(self, user_id: int, data: Dict[str, Any]) -> User:\n        \"\"\"Updates user profile by ID.\"\"\"\n        async with get_session() as session:\n            result = await session.execute(\n                select(User).where(User.id == user_id)\n            )\n            user = result.scalar_one_or_none()\n            if not user:\n                raise HTTPException(status_code=404, detail=\"User not found\")\n\n            # If username changes, check uniqueness\n            new_username = data.get(\"username\")\n            if new_username and new_username != user.username:\n                # Check uniqueness\n                result = await session.execute(\n                    select(User).where(User.username == new_username)\n                )\n                if result.scalar_one_or_none():\n                    raise HTTPException(status_code=400, detail=f\"Username {new_username} already exists\")\n                user.username = new_username\n\n            if \"password\" in data:\n                new_password = data.get(\"password\")\n                if new_password:\n                    user.hashed_password = get_password_hash(new_password)\n\n            if \"email\" in data:\n                new_email = data.get(\"email\")\n                if new_email:\n                    user.email = new_email\n\n            if \"user_profile\" in data:\n                new_user_profile = data.get(\"user_profile\")\n                if new_user_profile:\n                    user.user_profile = new_user_profile\n\n            await session.commit()\n            await session.refresh(user)\n            logger.info(f\"User profile updated for user ID {user_id}\")\n            return user\n\nuser_service = UserServices()"}
{"code_id": "Cybersecurity-Projects_PROJECTS_api-security-scanner_backend_models_Base.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Cybersecurity-Projects_PROJECTS_api-security-scanner_backend_models_Base.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\Cybersecurity-Projects_PROJECTS_api-security-scanner_backend_models_Base.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\Cybersecurity-Projects_PROJECTS_api-security-scanner_backend_models_Base.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "from typing import Any\nfrom sqlalchemy import (\n    Column,\n    DateTime,\n    Integer,\n)\nfrom datetime import datetime, UTC\nfrom sqlalchemy.ext.declarative import declared_attr\n\nfrom core.database import Base\n\n\nclass BaseModel(Base):\n    \"\"\"\n    Abstract base model with common fields and methods\n    All models inherit from this class\n    \"\"\"\n    __abstract__ = True\n\n    id = Column(\n        Integer,\n        primary_key=True,\n        index=True,\n        autoincrement=True\n    )\n\n    created_at = Column(\n        DateTime(timezone=True),\n        default=lambda: datetime.now(UTC)\n    )\n\n    updated_at = Column(\n        DateTime(timezone=True),\n        default=lambda: datetime.now(UTC),\n        onupdate=lambda: datetime.now(UTC),\n    )\n\n    @declared_attr\n    def __tablename__(cls) -> str:\n        \"\"\"\n        Auto-generate table name from class name\n        \"\"\"\n        return cls.__name__.lower()\n\n    def to_dict(self) -> dict[str, Any]:\n        \"\"\"\n        Convert model instance to dictionary\n\n        Returns:\n            dict: Dictionary representation of the model\n        \"\"\"\n        return {\n            column.name: getattr(self, column.name)\n            for column in self.__table__.columns\n        }\n\n    def update(self, **kwargs: Any) -> None:\n        \"\"\"\n        Update model fields from keyword arguments\n\n        Args:\n            **kwargs: Field names and values to update\n        \"\"\"\n        for key, value in kwargs.items():\n            if hasattr(self, key):\n                setattr(self, key, value)\n        self.updated_at = datetime.now(UTC)\n\n    def __repr__(self) -> str:\n        \"\"\"\n        String representation of model\n        \"\"\"\n        return f\"<{self.__class__.__name__}(id={self.id})>\""}
{"code_id": "CookHero_app_services_user_service.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\CookHero_app_services_user_service.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\CookHero_app_services_user_service.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\CookHero_app_services_user_service.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": "from flask import Blueprint, current_app\nfrom flask_login import login_required, current_user\nfrom app.models import User, Profile\nfrom app.forms import ProfileForm\nfrom app import db\n\nbp = Blueprint('profile', __name__)\n\nclass ProfileService:\n    \"\"\"Service to manage user profiles and settings\"\"\"\n    \n    @staticmethod\n    def get_user_by_username(username: str) -> User | None:\n        \"\"\"Get user by username\"\"\"\n        return User.query.filter_by(username=username).first()\n    \n    @staticmethod\n    def get_user_by_id(user_id: int) -> User | None:\n        \"\"\"Get user by ID\"\"\"\n        return User.query.filter_by(id=user_id).first()\n    \n    @staticmethod\n    def update_profile(user: User, form: ProfileForm) -> bool:\n        \"\"\"Update user profile\"\"\"\n        if not form.validate_on_submit():\n            return False\n        \n        # Update user profile fields\n        user.username = form.username.data\n        user.email = form.email.data\n        \n        # Update profile fields if profile exists\n        if user.profile:\n            user.profile.full_name = form.full_name.data\n            user.profile.bio = form.bio.data\n            user.profile.location = form.location.data\n            user.profile.website = form.website.data\n            user.profile.social_links = form.social_links.data\n        \n        # Commit changes to database\n        try:\n            db.session.commit()\n            return True\n        except Exception as e:\n            current_app.logger.error(f\"Error updating profile: {e}\")\n            db.session.rollback()\n            return False\n\n    @staticmethod\n    def delete_profile(user: User) -> bool:\n        \"\"\"Delete user profile\"\"\"\n        if not user.profile:\n            return False\n        \n        # Delete profile from database\n        try:\n            db.session.delete(user.profile)\n            db.session.commit()\n            return True\n        except Exception as e:\n            current_app.logger.error(f\"Error deleting profile: {e}\")\n            db.session.rollback()\n            return False\n\nadmin_bp = Blueprint('admin', __name__)"}
{"code_id": "Cybersecurity-Projects_PROJECTS_api-security-scanner_backend_models_Base.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Cybersecurity-Projects_PROJECTS_api-security-scanner_backend_models_Base.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\Cybersecurity-Projects_PROJECTS_api-security-scanner_backend_models_Base.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\Cybersecurity-Projects_PROJECTS_api-security-scanner_backend_models_Base.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "# Akila Mos | 2025\n# Base model class\n# Common fields and methods for all models\n\nfrom typing import Any\nfrom sqlalchemy import (\n    Column,\n    DateTime,\n    Integer,\n)\nfrom datetime import datetime, UTC\nfrom sqlalchemy.ext.declarative import declared_attr\n\nfrom core.database import Base\n\nclass BaseModel(Base):\n    \"\"\"\n    Abstract base model with common fields and methods\n    All models inherit from this class\n    \"\"\"\n\n    __abstract__ = True\n\n    id = Column(\n        Integer,\n        primary_key=True,\n        index=True,\n        autoincrement=True\n    )\n    created_at = Column(\n        DateTime(timezone=True),\n        default=lambda: datetime.now(UTC)\n    )\n    updated_at = Column(\n        DateTime(timezone=True),\n        default=lambda: datetime.now(UTC),\n        onupdate=lambda: datetime.now(UTC),\n    )\n\n    @declared_attr\n    def __tablename__(cls) -> str:\n        \"\"\"\n        Auto-generate table name from class name\n        \"\"\"\n\n        return cls.__name__.lower()\n\n    def to_dict(self) -> dict[str, Any]:\n        \"\"\"\n        Convert model instance to dictionary\n\n        Returns:\n            dict: Dictionary representation of the model\n        \"\"\"\n        return {\n            column.name: getattr(self, column.name)\n            for column in self.__table__.columns\n        }\n\n    def update(self, **kwargs: Any) -> None:\n        \"\"\"\n        Update model fields from keyword arguments\n\n        Args:\n            **kwargs: Field names and values to update\n        \"\"\"\n        for key, value in kwargs.items():\n            if hasattr(self, key):\n                setattr(self, key, value)\n        self.updated_at = datetime.now(UTC)\n\n    def __repr__(self) -> str:\n        \"\"\"\n        String representation of model\n        \"\"\"\n        return f\"<{self.__class__.__name__}(id={self.id})>\""}
{"code_id": "CookHero_app_services_user_service.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\CookHero_app_services_user_service.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\CookHero_app_services_user_service.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\CookHero_app_services_user_service.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "import logging\nfrom typing import Optional\n\nfrom sqlalchemy import select\nfrom sqlalchemy.exc import IntegrityError\n\nfrom app.database.models import UserModel\nfrom app.database.session import get_session_context\n\nlogger = logging.getLogger(__name__)\n\nclass UserService:\n    \"\"\"Service to manage user profiles and updates.\"\"\"\n\n    async def get_user_by_username(self, username: str) -> Optional[UserModel]:\n        async with get_session_context() as session:\n            stmt = select(UserModel).where(UserModel.username == username)\n            result = await session.execute(stmt)\n            return result.scalar_one_or_none()\n\n    async def get_user_by_id(self, user_id: int) -> Optional[UserModel]:\n        async with get_session_context() as session:\n            stmt = select(UserModel).where(UserModel.id == user_id)\n            result = await session.execute(stmt)\n            return result.scalar_one_or_none()\n\n    async def update_profile(self, username: str, data: dict) -> UserModel:\n        \"\"\"Update user profile fields.\"\"\"\n        async with get_session_context() as session:\n            stmt = select(UserModel).where(UserModel.username == username)\n            result = await session.execute(stmt)\n            user = result.scalar_one_or_none()\n            if not user:\n                raise ValueError(\"User not found\")\n\n            # If username change requested, check uniqueness\n            new_username = data.get(\"username\")\n            if new_username and new_username != user.username:\n                # Check existing\n                stmt2 = select(UserModel).where(UserModel.username == new_username)\n                res2 = await session.execute(stmt2)\n                if res2.scalar_one_or_none():\n                    raise ValueError(\"Username already exists\")\n                user.username = new_username\n\n            if \"occupation\" in data:\n                user.occupation = data.get(\"occupation\")\n            if \"bio\" in data:\n                user.bio = data.get(\"bio\")\n            if \"profile\" in data:\n                user.profile = data.get(\"profile\")\n            if \"user_instruction\" in data:\n                user.user_instruction = data.get(\"user_instruction\")\n\n            try:\n                await session.flush()\n            except IntegrityError as exc:\n                logger.warning(\"Integrity error updating profile: %s\", exc)\n                raise ValueError(\"Failed to update profile\")\n\n            return user\n\nuser_service = UserService()"}
{"code_id": "Cybersecurity-Projects_PROJECTS_api-security-scanner_backend_models_Base.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Cybersecurity-Projects_PROJECTS_api-security-scanner_backend_models_Base.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\Cybersecurity-Projects_PROJECTS_api-security-scanner_backend_models_Base.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\Cybersecurity-Projects_PROJECTS_api-security-scanner_backend_models_Base.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "# models | 2025\n# BaseModel class\n# Common fields and methods for all models\n\nfrom typing import Any\nfrom sqlalchemy import (\n    Column,\n    DateTime,\n    Integer,\n)\nfrom datetime import datetime, UTC\nfrom sqlalchemy.ext.declarative import declared_attr\n\nfrom core.database import Base\n\nclass BaseModel(Base):\n    \"\"\"\n    Abstract base model with common fields and methods\n    All models inherit from this class\n    \"\"\"\n    __abstract__ = True\n\n    id = Column(\n        Integer,\n        primary_key=True,\n        index=True,\n        autoincrement=True\n    )\n\n    created_at = Column(\n        DateTime(timezone=True),\n        default=lambda: datetime.now(UTC)\n    )\n\n    updated_at = Column(\n        DateTime(timezone=True),\n        default=lambda: datetime.now(UTC),\n        onupdate=lambda: datetime.now(UTC)\n    )\n\n    @declared_attr\n    def __tablename__(cls) -> str:\n        \"\"\"\n        Auto-generate table name from class name\n        \"\"\"\n        return cls.__name__.lower()\n\n    def to_dict(self) -> dict[str, Any]:\n        \"\"\"\n        Convert model instance to dictionary\n        Returns:\n            dict: Dictionary representation of the model\n        \"\"\"\n        return {\n            columns.name: getattr(self, column.name)\n            for column in self.__table__.columns\n        }\n\n    def update(self, **kwargs: Any) -> None:\n        \"\"\"\n        Update model fields from keyword arguments\n        Args:\n            **kwargs: Field names and values to update\n        \"\"\"\n        for key, value in kwargs.items():\n            if hasattr(self, key):\n                setattr(self, key, value)\n        self.updated_at = datetime.now(UTC)\n\n    def __repr__(self) -> str:\n        \"\"\"\n        String representation of model\n        \"\"\"\n        return f\"<{self.__class__.__name__} [id={self.id}]>\""}
{"code_id": "DeepV-Ki_api_cost_tracker.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\DeepV-Ki_api_cost_tracker.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\DeepV-Ki_api_cost_tracker.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\DeepV-Ki_api_cost_tracker.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "import logging\nfrom typing import Dict, Optional, Any\n\nlogger = logging.getLogger(__name__)\n\n# Global dictionary to store cost trackers in memory\n_cost_trackers: Dict[str, 'CostTracker'] = {}\n\nclass CostTracker:\n    \"\"\"\n    Tracks costs for a specific task (e.g., Wiki generation).\n    Accumulates LLM and embedding costs.\n    \"\"\"\n\n    def __init__(self, task_id: str):\n        self.task_id = task_id\n        self.embedding_tokens = 0\n        self.embedding_cost = 0.0\n        self.llm_tokens = 0\n        self.llm_cost = 0.0\n\n    def add_embedding_cost(self, tokens: int, cost: float):\n        \"\"\"Add embedding usage and cost.\"\"\"\n        self.embedding_tokens += tokens\n        self.embedding_cost += cost\n\n    def add_llm_cost(self, prompt_tokens: int, completion_tokens: int, total_tokens: int, cost: float):\n        \"\"\"Add LLM usage and cost.\"\"\"\n        self.llm_tokens += total_tokens\n        self.llm_cost += cost\n\n    def get_total_cost(self) -> float:\n        \"\"\"Get total accumulated cost.\"\"\"\n        return self.embedding_cost + self.llm_cost\n\n    def get_cost_message(self) -> str:\n        \"\"\"\n        Generate a message summarizing the cost.\n        This is used to update the task status message.\n        \"\"\"\n        total_cost = self.get_total_cost()\n        total_tokens = self.llm_tokens + self.embedding_tokens\n\n        msg = \"Wiki generation completed successfully!\"\n\n        if total_cost > 0:\n            msg += f\" Total cost: ${total_cost:.5f} (LLM: ${self.llm_cost:.5f}, Embedding: ${self.embedding_cost:.5f})\"\n            msg += f\" Total tokens: {total_tokens} (LLM: {self.llm_tokens}, Embedding: {self.embedding_tokens})\"\n\n        return msg\n\n    def log_summary(self):\n        \"\"\"Log a summary of the costs.\"\"\"\n        total_tokens = self.llm_tokens + self.embedding_tokens\n        logger.info(f\"[Task {self.task_id}] Cost Summary: Total=${self.get_total_cost():.5f}, Tokens={total_tokens} (LLM={self.llm_tokens}, Embedding={self.embedding_tokens})\")\n\ndef get_cost_tracker(task_id: str) -> CostTracker:\n    \"\"\"Get or create a cost tracker for a task.\"\"\"\n    if task_id not in _cost_trackers:\n        _cost_trackers[task_id] = CostTracker(task_id)\n    return _cost_trackers[task_id]\n\ndef clear_cost_tracker(task_id: str):\n    \"\"\"Remove a cost tracker from memory.\"\"\"\n    if task_id in _cost_trackers:\n        del _cost_trackers[task_id]"}
{"code_id": "DeepV-Ki_api_cost_tracker.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\DeepV-Ki_api_cost_tracker.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\DeepV-Ki_api_cost_tracker.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\DeepV-Ki_api_cost_tracker.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "import logging\nfrom typing import Dict, Optional, Any\n\nlogger = logging.getLogger(__name__)\n\n# Global dictionary to store cost trackers in memory\n_cost_trackers: Dict[str, 'CostTracker'] = {}\n\nclass CostTracker:\n    \"\"\"Tracks costs for a specific task (e.g., Wiki generation).\n    Accumulates LLM and embedding costs.\n    \"\"\"\n\n    def __init__(self, task_id: str):\n        self.task_id = task_id\n        self.embedding_tokens = 0\n        self.embedding_cost = 0.0\n        self.llm_tokens = 0\n        self.llm_cost = 0.0\n\n    def add_embedding_cost(self, tokens: int, cost: float):\n        \"\"\"Add embedding usage and cost.\"\"\"\n        self.embedding_tokens += tokens\n        self.embedding_cost += cost\n\n    def add_llm_cost(self, prompt_tokens: int, completion_tokens: int, total_tokens: int, cost: float):\n        \"\"\"Add LLM usage and cost.\"\"\"\n        self.llm_tokens += total_tokens\n        self.llm_cost += cost\n\n    def get_total_cost(self) -> float:\n        \"\"\"Get total accumulated cost.\"\"\"\n        return self.embedding_cost + self.llm_cost\n\n    def get_cost_message(self) -> str:\n        \"\"\"Generate a message summarizing the cost.\n        This is used to update the task status message.\n        \"\"\"\n        total_cost = self.get_total_cost()\n        total_tokens = self.llm_tokens + self.embedding_tokens\n\n        msg = \"Wiki generation completed successfully!\"\n\n        if total_cost > 0:\n            msg += f\" Total cost: ${total_cost:.5f} (LLM: ${self.llm_cost:.5f}, Embedding: ${self.embedding_cost:.5f})\"\n            msg += f\" Total tokens: {total_tokens} (LLM: {self.llm_tokens}, Embedding: {self.embedding_tokens})\"\n        return msg\n\n    def log_summary(self):\n        \"\"\"Log a summary of the costs.\"\"\"\n        total_tokens = self.llm_tokens + self.embedding_tokens\n        logger.info(f\"[Task {self.task_id}] Cost Summary: Total=${self.get_total_cost():.5f}, Tokens={total_tokens} (LLM={self.llm_tokens}, Embedding={self.embedding_tokens})\")\n\ndef get_cost_tracker(task_id: str) -> CostTracker:\n    \"\"\"Get or create a cost tracker for a task.\"\"\"\n    if task_id not in _cost_trackers:\n        _cost_trackers[task_id] = CostTracker(task_id)\n    return _cost_trackers[task_id]\n\ndef clear_cost_tracker(task_id: str):\n    \"\"\"Remove a cost tracker from memory.\"\"\"\n    if task_id in _cost_trackers:\n        del _cost_trackers[task_id]"}
{"code_id": "Cybersecurity-Projects_PROJECTS_api-security-scanner_backend_models_Base.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Cybersecurity-Projects_PROJECTS_api-security-scanner_backend_models_Base.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\Cybersecurity-Projects_PROJECTS_api-security-scanner_backend_models_Base.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\Cybersecurity-Projects_PROJECTS_api-security-scanner_backend_models_Base.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "Cybersecurity-Projects_PROJECTS_api-security-scanner_backend_models_Base.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Cybersecurity-Projects_PROJECTS_api-security-scanner_backend_models_Base.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\Cybersecurity-Projects_PROJECTS_api-security-scanner_backend_models_Base.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\Cybersecurity-Projects_PROJECTS_api-security-scanner_backend_models_Base.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "Feagent_src_application_services_idempotency_coordinator.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Feagent_src_application_services_idempotency_coordinator.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\Feagent_src_application_services_idempotency_coordinator.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\Feagent_src_application_services_idempotency_coordinator.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "\"\"\"IdempotencyCoordinator - Application-level idempotency + concurrency control.\n\nImplements per-idempotency-key in-flight de-duplication using stdlib asyncio primitives\nand persists successful results via the IdempotencyStore Domain Port.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport asyncio\nfrom collections.abc import Awaitable, Callable\nfrom typing import Any\n\nfrom src.domain.ports.idempotency_store import IdempotencyStore\n\n\nclass IdempotencyNotReadyError(RuntimeError):\n    \"\"\"Raised when idempotency is requested but cannot be served.\"\"\"\n\n\nclass IdempotencyCoordinator:\n    def __init__(self, *, store: IdempotencyStore) -> None:\n        self._store = store\n        self._guard = asyncio.Lock()\n        self._in_flight: dict[str, asyncio.Task[Any]]] = {}\n\n    async def run(\n        self,\n        *,\n        idempotency_key: str,\n        work: Callable[[], Awaitable[Any]],\n    ) -> Any:\n        if await self._store.exists(idempotency_key):\n            return await self._store.get_result(idempotency_key)\n\n        async with self._guard:\n            if await self._store.exists(idempotency_key):\n                return await self._store.get_result(idempotency_key)\n\n            task = self._in_flight.get(idempotency_key)\n            if task is None:\n                task = asyncio.create_task(self._run_and_persist(idempotency_key, work)))\n                self._in_flight[idempotency_key] = task\n\n        return await asyncio.shield(task)\n\n    async def _run_and_persist(\n        self,\n        idempotency_key: str,\n        work: Callable[[], Awaitable[Any]],\n    ) -> Any:\n        try:\n            result = await work()\n            await self._store.save_result(idempotency_key, result)\n            return result\n        finally:\n            async with self._guard:\n                self._in_flight.pop(idempotency_key, None)"}
{"code_id": "DeepV-Ki_api_cost_tracker.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\DeepV-Ki_api_cost_tracker.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\DeepV-Ki_api_cost_tracker.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\DeepV-Ki_api_cost_tracker.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": "from typing import Dict, List, Tuple\n\nlogger = logging.getLogger(__name__)\n\n# Global dictionary to store cost trackers in memory\n_cost_trackers: Dict[str, \"CostTracker\"] = {}\n\nclass CostTracker:\n    \"\"\"\n    Tracks costs for a specific task in a model generation and\n    documents the LLM and embedding costs.\n    \"\"\"\n\n    def __init__(self, task_id: str):\n        self.task_id = task_id\n        self.embedding_tokens = 0\n        self.embedding_cost = 0.0\n        self.llm_tokens = 0\n        self.llm_cost = 0.0\n\n    def add_embedding_cost(self, tokens: int, cost: float):\n        \"\"\"Add embedding usage and cost.\"\"\"\n        self.embedding_tokens += tokens\n        self.embedding_cost += cost\n\n    def add_llm_cost(self, prompt_tokens: int, completion_tokens: int, total_tokens: int, model: str, cost: float):\n        \"\"\"Add LLM usage and cost.\"\"\"\n        self.llm_tokens += total_tokens\n        self.llm_cost += cost\n\n    def get_current_cost(self) -> float:\n        \"\"\"Get total accumulated cost.\"\"\"\n        return self.embedding_cost + self.llm_cost\n\n    def get_cost_message(self) -> str:\n        \"\"\"\n        Generate a message summarizing the costs.\n        This is used to update the task status description.\n        \"\"\"\n        total_cost = self.get_current_cost()\n        total_tokens = self.llm_tokens + self.embedding_tokens\n\n        msg = \"This generation completed successfully.\"\n\n        if total_cost > 0:\n            msg += f\" Total cost: ${total_cost:.4f} (LLM: {self.llm_tokens} tokens, Embedding: {self.embedding_tokens} tokens)\"\n\n        return msg\n\n    def log_summary(self):\n        \"\"\"Log a summary of the costs.\"\"\"\n        total_cost = self.get_current_cost()\n        total_tokens = self.llm_tokens + self.embedding_tokens\n\n        logger.info(f\"Task {self.task_id}: Total cost: ${total_cost:.4f}, Total tokens: {total_tokens} (LLM: {self.llm_tokens} tokens, Embedding: {self.embedding_tokens} tokens)\")\n\n    def get_cost_tracker(self, task_id: str) -> \"CostTracker\":\n        \"\"\"Get or create a cost tracker for a task.\"\"\"\n        if task_id not in _cost_trackers:\n            _cost_trackers[task_id] = CostTracker(task_id)\n        return _cost_trackers[task_id]\n\n    def remove_cost_tracker(self, task_id: str):\n        \"\"\"Remove a cost tracker from memory.\"\"\"\n        if task_id in _cost_trackers:\n            del _cost_trackers[task_id]"}
{"code_id": "Feagent_src_application_services_idempotency_coordinator.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Feagent_src_application_services_idempotency_coordinator.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\Feagent_src_application_services_idempotency_coordinator.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\Feagent_src_application_services_idempotency_coordinator.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "from __future__ import annotations\n\nimport asyncio\nfrom collections.abc import Awaitable, Callable\nfrom typing import Any\n\nfrom src.domain.ports.idempotency_store import IdempotencyStore\n\n\nclass IdempotencyNotReadyError(RuntimeError):\n    \"\"\"Raised when idempotency is requested but cannot be served.\"\"\"\n\n\nclass IdempotencyCoordinator:\n    def __init__(self, *, store: IdempotencyStore) -> None:\n        self._store = store\n        self._guard = asyncio.Lock()\n        self._in_flight: dict[str, asyncio.Task[Any]] = {}\n\n    async def run(\n        self,\n        *,\n        idempotency_key: str,\n        work: Callable[[], Awaitable[Any]],\n    ) -> Any:\n        if await self._store.exists(idempotency_key):\n            return await self._store.get_result(idempotency_key)\n\n        async with self._guard:\n            if await self._store.exists(idempotency_key):\n                return await self._store.get_result(idempotency_key)\n\n            task = self._in_flight.get(idempotency_key)\n            if task is None:\n                task = asyncio.create_task(self._run_and_persist(idempotency_key, work)))\n                self._in_flight[idempotency_key] = task\n\n        return await asyncio.shield(task)\n\n    async def _run_and_persist(\n        self,\n        *,\n        idempotency_key: str,\n        work: Callable[[], Awaitable[Any]],\n    ) -> Any:\n        try:\n            result = await work()\n            await self._store.save_result(idempotency_key, result)\n            return result\n        finally:\n            async with self._guard:\n                self._in_flight.pop(idempotency_key, None)"}
{"code_id": "DeepV-Ki_api_cost_tracker.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\DeepV-Ki_api_cost_tracker.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\DeepV-Ki_api_cost_tracker.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\DeepV-Ki_api_cost_tracker.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": ""}
{"code_id": "DeepV-Ki_api_cost_tracker.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\DeepV-Ki_api_cost_tracker.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\DeepV-Ki_api_cost_tracker.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\DeepV-Ki_api_cost_tracker.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "Feagent_src_application_services_idempotency_coordinator.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Feagent_src_application_services_idempotency_coordinator.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\Feagent_src_application_services_idempotency_coordinator.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\Feagent_src_application_services_idempotency_coordinator.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "# IdempotencyCoordinator - Application-level idempotency + concurrency control.\n#\n# Provides per-idempotency-key in-flight de-duplication using stdlib asyncio primitives\n# and persists successful results via the IdempotencyStore Domain Port.\n\nfrom __future__ import annotations\n\nimport asyncio\nfrom collections.abc import Awaitable, Callable\nfrom typing import Any\n\nfrom src.domain.ports.idempotency_store import IdempotencyStore\n\nclass IdempotencyNotReadyError(RuntimeError):\n    \"\"\"Raised when idempotency is requested but cannot be served.\"\"\"\n\nclass IdempotencyCoordinator:\n    def __init__(self, *, store: IdempotencyStore) -> None:\n        self._store = store\n        self._guard = asyncio.Lock()\n        self._in_flight: dict[str, asyncio.Task[Any]]] = {}\n\n    async def run(\n        self,\n        *,\n        idempotency_key: str,\n        work: Callable[[], Awaitable[Any]],\n    ) -> Any:\n        if await self._store.exists(idempotency_key):\n            return await self._store.get_result(idempotency_key)\n\n        async with self._guard:\n            if await self._store.exists(idempotency_key):\n                return await self._store.get_result(idempotency_key)\n\n            task = self._in_flight.get(idempotency_key)\n            if task is None:\n                task = asyncio.create_task(self._run_and_persist(idempotency_key, work))\n                self._in_flight[idempotency_key] = task\n\n            return await asyncio.shield(task)\n\n    async def _run_and_persist(\n        self,\n        *,\n        idempotency_key: str,\n        work: Callable[[], Awaitable[Any]],\n    ) -> Any:\n        try:\n            result = await work()\n            await self._store.save_result(idempotency_key, result)\n            return result\n        finally:\n            async with self._guard:\n                self._in_flight.pop(idempotency_key, None)"}
{"code_id": "FinSight_src_tools_base.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\FinSight_src_tools_base.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\FinSight_src_tools_base.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\FinSight_src_tools_base.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "import pandas as pd\nimport uuid\n\nclass Tool:\n    def __init__(\n        self,\n        name: str,\n        description: str,\n        parameters: list[dict]\n    ):\n        self.name = name\n        self.type = f'tool_{name}'\n        self.id = f\"tool_{name}_{uuid.uuid4().hex[:8]}\"\n        self.short_description = description\n        self.parameters = parameters\n\n    def prepare_params(self, task) -> dict:\n        \"\"\"\n        Optional hook to derive API parameters from a task payload.\n        \"\"\"\n        return {}\n\n    @property\n    def description(self):\n        params_str = \", \".join([\n            f\"{p['name']}: {p['type']} ({p['description']]})\"\n            for p in self.parameters\n        ])\n        return f\"Tool name: {self.name}\\nDescription: {self.short_description}\\nParameters: {params_str}\\n\"\n\n    async def api_function(self, **kwargs):\n        \"\"\"\n        Execute the underlying API and return structured data.\n        \"\"\"\n        raise NotImplementedError\n\n    async def get_data(self, task):\n        params = self.prepare_params(task)\n        try:\n            data = await self.api_function(**params)\n            task.all_results.extend(data)\n            return data\n        except Exception as e:\n            print(f\"Error: {e}\")\n            return []\n\nclass Result:\n    def __init__(self, name, description, data, source = \"\"):\n        self.name = name\n        self.description = description\n        if isinstance(data, list) and len(data) == 1:\n            data = data[0]\n        self.data = data\n        self.data_type = type(data)\n        self.source = source  # str, data source\n\n    def brief_str(self):\n        return self.__str__()\n\n    def get_full_string(self):\n        if isinstance(self.data, pd.DataFrame):\n            return self.data.to_string()\n        else:\n            return str(self.data)\n\n    def __str__(self):\n        base_string = f\"Data name: {self.name}\\nDescription: {self.description}\\nSource: {self.source}\\n\"\n        base_string += f\"Data type: {type(self.data)}\\n\"\n        if isinstance(self.data, pd.DataFrame):\n            format_string = \"\"\n            format_string += f\"First five rows:\\n{self.data.head().to_string()}\\n\"\n        elif isinstance(self.data, dict):\n            format_string = \"Partial data preview: \"\n            format_string += str(self.data)[:100]\n        elif isinstance(self.data, list):\n            format_string = \"Partial data preview: \"\n            format_string += str(self.data)[:100]\n        else:\n            format_string = \"Partial data preview: \"\n            format_string += str(self.data)[:100]\n        return base_string + format_string\n\n    def __repr__(self):\n        return self.__str__()\n\n    def __hash__(self):\n        return hash(self.name+self.description)\n\n    def __eq__(self, other):\n        return self.name == other.name and self.description == other.description"}
{"code_id": "FinSight_src_tools_base.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\FinSight_src_tools_base.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\FinSight_src_tools_base.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\FinSight_src_tools_base.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "import pandas as pd\nimport uuid\n\nclass Tool:\n    def __init__(\n        self,\n        name: str,\n        description: str,\n        parameters: list[dict]\n    ):\n        self.name = name\n        self.type = f'tool_{name}'\n        self.id = f'tool_{name}_{uuid.uuid4().hex[:8]}'\n        self.short_description = description\n        self.parameters = parameters\n\n    def prepare_params(self, task) -> dict:\n        \"\"\"\n        Optional hook to derive API parameters from a task payload.\n        \"\"\"\n        return {}\n\n    @property\n    def description(self):\n        params_str = \", \".join([\n            f\"{p['name']]}: {p['type']} ({p['description']})\"\n            for p in self.parameters\n        ])\n        return f\"Tool name: {self.name}\\nDescription: {self.short_description}\\nParameters: {params_str}\\n\"\n\n    async def api_function(self, **kwargs):\n        \"\"\"\n        Execute the underlying API and return structured data.\n        \"\"\"\n        raise NotImplementedError\n\n    async def get_data(self, task):\n        params = self.prepare_params(task)\n        try:\n            data = await self.api_function(**params)\n            task.all_results.extend(data)\n            return data\n        except Exception as e:\n            print(f\"Error: {e}\")\n            return []\n\nclass Result:\n    def __init__(self, name, description, data, source = \"\"):\n        self.name = name\n        self.description = description\n        if isinstance(data, list) and len(data) == 1:\n            data = data[0]\n        self.data = data\n        self.data_type = type(data)\n        self.source = source  # str, data source\n\n    def brief_str(self):\n        return self.__str__()\n\n    def get_full_string(self):\n        if isinstance(self.data, pd.DataFrame):\n            return self.data.to_string()\n        else:\n            return str(self.data)\n\n    def __str__(self):\n        base_string = f\"Data name: {self.name}\\nDescription: {self.description}\\nSource: {self.source}\\n\"\n        base_string += f\"Data type: {type(self.data)}\\n\"\n        if isinstance(self.data, pd.DataFrame):\n            format_string = \"\"\n            format_string += f\"First five rows:\\n{self.data.head().to_string()}\\n\"\n        elif isinstance(self.data, dict):\n            format_string = \"Partial data preview: \"\n            format_string += str(self.data)[:100]\n        elif isinstance(self.data, list):\n            format_string = \"Partial data preview: \"\n            format_string += str(self.data)[:100]\n        else:\n            format_string = \"Partial data preview: \"\n            format_string += str(self.data)[:100]\n\n        return base_string + format_string\n\n    def __repr__(self):\n        return self.__str__()\n\n    def __hash__(self):\n        return hash(self.name+self.description)\n\n    def __eq__(self, other):\n        return self.name == other.name and self.description == other.description"}
{"code_id": "Feagent_src_application_services_idempotency_coordinator.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Feagent_src_application_services_idempotency_coordinator.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\Feagent_src_application_services_idempotency_coordinator.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\Feagent_src_application_services_idempotency_coordinator.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "Feagent_src_application_services_idempotency_coordinator.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Feagent_src_application_services_idempotency_coordinator.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\Feagent_src_application_services_idempotency_coordinator.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\Feagent_src_application_services_idempotency_coordinator.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "FinSight_src_tools_base.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\FinSight_src_tools_base.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\FinSight_src_tools_base.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\FinSight_src_tools_base.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "import pandas as pd\nimport uuid\n\nclass Tool:\n    def __init__(\n        self,\n        name: str,\n        description: str,\n        parameters: list[dict]\n    ):\n        self.name = name\n        self.type = f\"tool_{name}\"\n        self.id = f\"tool_{name}_{uuid.uuid4().hex[:8]}\"\n        self.short_description = description\n        self.parameters = parameters\n\n    def prepare_params(self, task) -> dict:\n        \"\"\"\n        Optional hook to derive API parameters from a task payload.\n        \"\"\"\n        return {}\n\n    @property\n    def description(self):\n        param_str = \", \".join([\n            f\"{p['name']}: {p['description']}\"\n            for p in self.parameters\n        ])\n        return f\"Tool name: {self.name}\\nDescription: {self.short_description}\\nParameters: {param_str}\\n\"\n\n    async def api_function(self, **kwargs):\n        \"\"\"\n        Execute the underlying API and return structured data.\n        \"\"\"\n        raise NotImplementedError\n\n    async def get_data(self, task):\n        params = self.prepare_params(task)\n        try:\n            data = await self.api_function(**params)\n            task.all_results.extend(data)\n            return data\n        except Exception as e:\n            print(f\"Error: {e}\")\n            return []\n\nclass Result:\n    def __init__(self, name, description, data, source=\"\"):\n        self.name = name\n        self.description = description\n        if isinstance(data, list) and len(data) == 1:\n            data = data[0]\n        self.data = data\n        self.data_type = type(data)\n        self.source = source  # str, data source\n\n    def brief_str(self):\n        return self.__str__()\n\n    def get_full_string(self):\n        if isinstance(self.data, pd.DataFrame):\n            return self.data.to_string()\n        else:\n            return str(self.data)\n\n    def __str__(self):\n        base_string = f\"Data name: {self.name}\\nDescription: {self.description}\\nSource: {self.source}\\n\"\n        base_string += f\"Data type: {type(self.data)}\\n\"\n        if isinstance(self.data, pd.DataFrame):\n            format_string = \"\"\n            format_string += f\"First five rows:\\n{self.data.head().to_string()}\\n\"\n        elif isinstance(self.data, dict):\n            format_string = \"Partial data preview: \"\n            format_string += str(self.data)[:100]\n        elif isinstance(self.data, list):\n            format_string = \"Partial data preview: \"\n            format_string += str(self.data)[:100]\n        else:\n            format_string = \"Partial data preview: \"\n            format_string += str(self.data)[:100]\n        return base_string + format_string\n\n    def __repr__(self):\n        return self.__str__()\n\n    def __hash__(self):\n        return hash((self.name, self.description))\n\n    def __eq__(self, other):\n        return self.name == other.name and self.description == other.description"}
{"code_id": "InfiniteVGGT_src_croco_models_head_downstream.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\InfiniteVGGT_src_croco_models_head_downstream.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\InfiniteVGGT_src_croco_models_head_downstream.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\InfiniteVGGT_src_croco_models_head_downstream.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "# Copyright (C) 2022-present Naver Corporation. All rights reserved.\n# Licensed under CC BY-NC-SA 4.0 (non-commercial use only).\n#\n# Heads for downstream tasks\n#\n# \"\"\"\n#\nA head is a module where the __init__ defines only the head hyperparameters.\nA method setup(croconet) takes a CroCoNet and set all layers according to the head and croconet attributes.\nThe forward takes the features as well as a dictionary img_info containing the keys 'width' and 'height'\n\"\"\"\nimport torch\nimport torch.nn as nn\nfrom .dpt_block import DPTOutputAdapter\n\nclass PixelwiseTaskWithDPT(nn.Module):\n    \"\"\"DPT module for CroCo.\n    by default, hooks_idx will be equal to:\n    * for encoder-only: 4 equally spread layers\n    * for encoder+decoder: last encoder + 3 equally spread layers of the decoder\n    \"\"\"\n\n    def __init__(\n        self,\n        *,\n        hooks_idx=None,\n        layer_dims=[96, 192, 384, 768],\n        output_width_ratio=1,\n        num_channels=1,\n        postprocess=None,\n        **kwargs,\n    ):\n        super(PixelwiseTaskWithDPT, self).__init__()\n        self.return_all_blocks = True  # backbone needs to return all layers\n        self.postprocess = postprocess\n        self.output_width_ratio = output_width_ratio\n        self.num_channels = num_channels\n        self.hooks_idx = hooks_idx\n        self.layer_dims = layer_dims\n\n    def setup(self, croconet):\n        dpt_args = {\n            \"output_width_ratio\": self.output_width_ratio,\n            \"num_channels\": self.num_channels,\n        if self.hooks_idx is None:\n            if hasattr(croconet, \"dec_blocks\"):  # encoder + decoder\n                step = {8: 3, 12: 4, 24: 8}[croconet.dec_depth]\n                hooks_idx = [\n                    croconet.dec_depth + croconet.enc_depth - 1 - i * step\n                    for i in range(3, -1, -1)\n                ]\n            else:  # encoder only\n                step = croconet.enc_depth // 4\n                hooks_idx = [\n                    croconet.enc_depth - 1 - i * step for i in range(3, -1, -1)\n                ]\n            self.hooks_idx = hooks_idx\n            print(\n                f\"PixelwiseTaskWithDPT: automatically setting hook_idxs={self.hooks_idx}\"\n            )\n        dpt_args[\"hooks\"] = self.hooks_idx\n        dpt_args[\"layer_dims\"] = self.layer_dims\n        self.dpt = DPTOutputAdapter(**dpt_args)\n        dim_tokens = [\n            (\n                croconet.enc_embed_dim\n                if hook < croconet.enc_depth\n                else croconet.dec_embed_dim\n            )\n            for hook in self.hooks_idx\n        ]\n        dpt_init_args = {\"dim_tokens_enc\": dim_tokens}\n        self.dpt.init(**dpt_init_args)\n\n    def forward(self, x, img_info):\n        out = self.dpt(x, image_size=(img_info[\"height\"], img_info[\"width\"])))\n        if self.postprocess:\n            out = self.postprocess(out)\n        return out"}
{"code_id": "InfiniteVGGT_src_croco_models_head_downstream.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\InfiniteVGGT_src_croco_models_head_downstream.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\InfiniteVGGT_src_croco_models_head_downstream.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\InfiniteVGGT_src_croco_models_head_downstream.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "# Copyright (C) 2022-present Naver Corporation. All rights reserved.\n# Distributed under CC BY-NC-SA 4.0 (non-commercial use only).\n\n# Heads for downstream tasks\n\n\"\"\"\nA head is a module where the __init__ defines only the head hyperparameters.\nA method setup(croconet) takes a CroCoNet and set all layers according to the head and croconet attributes.\nThe forward takes the features as well as a dictionary img_info containing the keys 'width' and 'height'\n\"\"\"\n\nimport torch\nimport torch.nn as nn\nfrom .dpt_block import DPTOutputAdapter\n\nclass PixelwiseTaskWithDPT(nn.Module):\n    \"\"\"DPT module for CroCo.\n    by default, hooks_idx will be equal to:\n    * for encoder-only: 4 equally spread layers\n    * for encoder+decoder: last encoder + 3 equally spread layers of the decoder\n    \"\"\"\n\n    def __init__(\n        self,\n        *,\n        hooks_idx=None,\n        layer_dims=[96, 192, 384, 768],\n        output_width_ratio=1,\n        num_channels=1,\n        postprocess=None,\n        **kwargs,\n    ):\n\n        super(PixelwiseTaskWithDPT, self).__init__()\n        self.return_all_blocks = True  # backbone needs to return all layers\n        self.postprocess = postprocess\n        self.output_width_ratio = output_width_ratio\n        self.num_channels = num_channels\n        self.hooks_idx = hooks_idx\n        self.layer_dims = layer_dims\n\n    def setup(self, croconet):\n        dpt_args = {\n            \"output_width_ratio\": self.output_width_ratio,\n            \"num_channels\": self.num_channels,\n        }\n\n        if self.hooks_idx is None:\n            if hasattr(croconet, \"dec_blocks\"):  # encoder + decoder\n                step = {8: 3, 12: 4, 24: 8}[croconet.dec_depth]\n                hooks_idx = [\n                    croconet.dec_depth + croconet.enc_depth - 1 - i * step\n                    for i in range(3, -1, -1)\n                ]\n            else:  # encoder only\n                step = croconet.enc_depth // 4\n                hooks_idx = [\n                    croconet.enc_depth - 1 - i * step for i in range(3, -1, -1)\n                ]\n            self.hooks_idx = hooks_idx\n            print(\n                f\"PixelwiseTaskWithDPT: automatically setting hook_idx={self.hooks_idx}\"\n            )\n        dpt_args[\"hooks\"] = self.hooks_idx\n        dpt_args[\"layer_dims\"] = self.layer_dims\n        self.dpt = DPTOutputAdapter(**dpt_args)\n        dim_tokens = [\n            (\n                croconet.enc_embed_dim\n                if hook < croconet.enc_depth\n                else croconet.dec_embed_dim\n            )\n            for hook in self.hooks_idx\n        ]\n        dpt_init_args = {\"dim_tokens_enc\": dim_tokens}\n        self.dpt.init(**dpt_init_args)\n\n    def forward(self, x, img_info):\n        out = self.dpt(x, image_size=(img_info[\"height\"], img_info[\"width\"])))\n        if self.postprocess:\n            out = self.postprocess(out)\n        return out"}
{"code_id": "FinSight_src_tools_base.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\FinSight_src_tools_base.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\FinSight_src_tools_base.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\FinSight_src_tools_base.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "FinSight_src_tools_base.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\FinSight_src_tools_base.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\FinSight_src_tools_base.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\FinSight_src_tools_base.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "InfiniteVGGT_src_croco_models_head_downstream.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\InfiniteVGGT_src_croco_models_head_downstream.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\InfiniteVGGT_src_croco_models_head_downstream.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\InfiniteVGGT_src_croco_models_head_downstream.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "# Copyright (c) 2021-present Never Corporation. All rights reserved.\n# Licensed under CC BY-NC-SA 4.0 (non-commercial use only).\n\n# Heads for downstream tasks\n\n\"\"\"\nA head is a module where the __init__ defines only the head hyperparameters.\nA method setup(c"}
{"code_id": "LLM-TradeBot_src_llm_claude_client.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\LLM-TradeBot_src_llm_claude_client.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\LLM-TradeBot_src_llm_claude_client.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\LLM-TradeBot_src_llm_claude_client.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "# Claude 客户端实现\n# ======================\n\nAnthropic Claude 使用不同的 API 格式，需要单独实现。\n\"\"\"\nfrom typing import Dict, Any, List\nfrom .base import BaseLLMClient, LLMConfig, ChatMessage, LLMResponse\n\nclass ClaudeClient(BaseLLMClient):\n    \"\"\"\n    Claude 客户端 (Anthropic API)\n\n    Claude 使用不同的 API 格式：\n    - 认证使用 x-api-key 而非 Bearer token\n    - 端点是 /messages 而非 /chat/completions\n    - system prompt 是独立字段\n    \"\"\"\n    DEFAULT_BASE_URL = \"https://api.anthropic.com/v1\"\n    DEFAULT_MODEL = \"claude-3-5-sonnet-20241022\"\n    PROVIDER = \"claude\"\n\n    ANTHROPIC_VERSION = \"2023-06-01\"\n\n    def _build_headers(self) -> Dict[str, str]:\n        \"\"\"构建 Anthropic 认证头\"\"\"\n        return {\n            \"x-api-key\": self.config.api_key,\n            \"anthropic-version\": self.ANTHROPIC_VERSION,\n            \"Content-Type\": \"application/json\"\n        }\n\n    def _build_url(self) -> str:\n        \"\"\"Claude 使用 /messages 端点\"\"\"\n        return f\"{self.base_url}/messages\"\n\n    def _build_request_body(\n        self,\n        messages: List[ChatMessage],\n        **kwargs\n    ) -> Dict[str, Any]:\n        \"\"\"\n        构建 Claude 请求体\n\n        # Claude 的 system prompt 是独立字段，不在 messages 中\n        # 提取 system message\n        system_content = \"\"\n        user_messages = []\n\n        for msg in messages:\n            if msg.role == \"system\":\n                system_content = msg.content\n            else:\n                user_messages.append({\"role\": msg.role, \"content\": msg.content})\n\n        body = {\n            \"model\": self.model,\n            \"messages\": user_messages,\n            \"max_tokens\": kwargs.get(\"max_tokens\", self.config.max_tokens)\n        }\n\n        if system_content:\n            body[\"system\"] = system_content\n\n        # Claude 不支持 temperature=0，最小值是 0.1\n        temperature = kwargs.get(\"temperature\", self.config.temperature)\n        if temperature > 0:\n            body[\"temperature\"] = max(0.1, temperature)\n\n        return body\n\n    def _parse_response(self, response: Dict[str, Any]) -> LLMResponse:\n        \"\"\"解析 Claude 响应\"\"\"\n        content = \"\"\n        for block in response.get(\"content\", []):\n            if block.get(\"type\") == \"text\":\n                content = block.get(\"text\", \"\")\n                break\n\n        return LLMResponse(\n            content=content,\n            model=response.get(\"model\", self.model),\n            provider=self.PROVIDER,\n            usage=response.get(\"usage\", {}),\n            raw_response=response\n        )"}
{"code_id": "InfiniteVGGT_src_croco_models_head_downstream.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\InfiniteVGGT_src_croco_models_head_downstream.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\InfiniteVGGT_src_croco_models_head_downstream.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\InfiniteVGGT_src_croco_models_head_downstream.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": "import torch\nimport torch.nn as nn\nfrom .api import BPFilterAndBias\n\nclass StackedAndShiftedModel(nn.Module):\n    \"\"\"BPFilter for GNNs\n    to detect, masks can be applied to:\n    * for encoder-only: 4 most's current layers\n    * for encoder-decoder: last encoder + 4 equally spread layers of the decoder\n    \"\"\"\n\n    def __init__(\n        self,\n        d,\n        heads,\n        inner_dim,\n        layers,\n        dim_feedforward,\n        dropout,\n        norm_layer,\n        activation,\n        num_classes,\n        **kwargs\n    ):\n        super().__init__()\n        self.d = d\n        self.heads = heads\n        self.inner_dim = inner_dim\n        self.layers = layers\n        self.dim_feedforward = dim_feedforward\n        self.dropout = dropout\n        self.norm_layer = norm_layer\n        self.activation = activation\n        self.num_classes = num_classes\n        self.kwargs = kwargs\n\n        # For encoder-only GNNs\n        self.encoder_only = self.layers == 1\n\n        # For encoder-decoder GNNs\n        self.encoder_decoder = self.layers > 1\n\n        # For encoder-only GNNs: automatically set by setting `heads` above `heads, idx`\n        self.heads_idx = self.heads\n\n        self.bands = []\n        self.bands_idx = []\n        self.layer_phases = []\n\n        self.bp_filter_and_bias = BPFilterAndBias(self.d, self.heads, self.inner_dim, self.layers, self.dim_feedforward, self.dropout, self.norm_layer, self.activation, self.num_classes, **self.kwargs)\n\n        self.dla_modules = [\n            {\n                \"encoder_only\": self.encoder_only,\n                \"encoder_decoder\": self.encoder_decoder,\n                \"heads\": self.heads,\n                \"heads_idx\": self.heads_idx,\n                \"bands\": self.bands,\n                \"bands_idx\": self.bands_idx,\n                \"layer_phases\": self.layer_phases\n            }\n        ]\n\n        self.dla_out_props = {\"is_residual\": True, \"is_tanh\": True}\n\n        self.dla = BPFilterAndBias(self.d, self.heads, self.inner_dim, self.layers, self.dim_feedforward, self.dropout, self.norm_layer, self.activation, self.num_classes, **self.kwargs)\n\n    def forward(self, x, edge_index):\n        out = self.dla(x, edge_index)\n        # For encoder-only GNNs: automatically set by setting `heads` above `heads, idx`\n        self.heads_idx = self.heads\n        return out"}
{"code_id": "InfiniteVGGT_src_croco_models_head_downstream.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\InfiniteVGGT_src_croco_models_head_downstream.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\InfiniteVGGT_src_croco_models_head_downstream.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\InfiniteVGGT_src_croco_models_head_downstream.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "LLM-TradeBot_src_llm_claude_client.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\LLM-TradeBot_src_llm_claude_client.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\LLM-TradeBot_src_llm_claude_client.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\LLM-TradeBot_src_llm_claude_client.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "from typing import Dict, Any, List\nfrom .base import BaseLLMClient, LLMConfig, ChatMessage, LLMResponse\n\nclass ClaudeClient(BaseLLMClient):\n    \"\"\"\n    Claude 客户端 (Anthropic API)\n\n    Claude 使用不同的 API 格式:\n    - 认证使用 x-api-key 而非 Bearer token\n    - 端点是 /messages 而非 /chat/completions\n    - system prompt 是独立字段\n    \"\"\"\n    DEFAULT_BASE_URL = \"https://api.anthropic.com/v1\"\n    DEFAULT_MODEL = \"claude-3-5-sonnet-20241022\"\n    PROVIDER = \"claude\"\n    ANTHROPIC_VERSION = \"2023-06-01\"\n\n    def _build_headers(self) -> Dict[str, str]:\n        \"\"\"构建 Anthropic 认证头\"\"\"\n        return {\n            \"x-api-key\": self.config.api_key,\n            \"anthropic-version\": self.ANTHROPIC_VERSION,\n            \"Content-Type\": \"application/json\"\n        }\n\n    def _build_url(self) -> str:\n        \"\"\"Claude 使用 /messages 端点\"\"\"\n        return f\"{self.base_url}/messages\"\n\n    def _build_request_body(\n        self,\n        messages: List[ChatMessage],\n        **kwargs\n    ) -> Dict[str, Any]:\n        \"\"\"\n        构建 Claude 请求体\n\n        Claude 的 system prompt 是独立字段，不在 messages 中\n        ---\n        # 提取 system message\n        system_content = \"\"\n        user_messages = []\n\n        for msg in messages:\n            if msg.role == \"system\":\n                system_content = msg.content\n            else:\n                user_messages.append({\"role\": msg.role, \"content\": msg.content})\n\n        body = {\n            \"model\": self.model,\n            \"messages\": user_messages,\n            \"max_tokens\": kwargs.get(\"max_tokens\", self.config.max_tokens)\n        }\n\n        if system_content:\n            body[\"system\"] = system_content\n\n        # Claude 不支持 temperature=0，最小值是 0.1\n        temperature = kwargs.get(\"temperature\", self.config.temperature)\n        if temperature > 0:\n            body[\"temperature\"] = max(0.1, temperature)\n\n        return body\n\n    def _parse_response(self, response: Dict[str, Any]) -> LLMResponse:\n        \"\"\"解析 Claude 响应\"\"\"\n        content = \"\"\n        for block in response.get(\"content\", []):\n            if block.get(\"type\") == \"text\":\n                content = block.get(\"text\", \"\")\n                break\n\n        return LLMResponse(\n            content=content,\n            model=response.get(\"model\", self.model),\n            provider=self.PROVIDER,\n            usage=response.get(\"usage\", {}),\n            raw_response=response\n        )"}
{"code_id": "LLM-TradeBot_src_llm_claude_client.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\LLM-TradeBot_src_llm_claude_client.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\LLM-TradeBot_src_llm_claude_client.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\LLM-TradeBot_src_llm_claude_client.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "from typing import Dict, Any, List\nfrom .base import BaseLLMClient, LLMConfig, ChatMessage, LLMResponse\n\nclass ClaudeClient(BaseLLMClient):\n    \"\"\"\n    Claude 客户端 (Anthropic API)\n    Claude 使用不同的 API 格式:\n    - 认证使用 x-api-key 而非 Bearer token\n    - 端点是 /messages 而非 /chat/completions\n    - system prompt 是独立字段\n    \"\"\"\n    DEFAULT_BASE_URL = \"https://api.anthropic.com/v1\"\n    DEFAULT_MODEL = \"claude-3-5-sonnet-20240620\"\n    PROVIDER = \"claude\"\n    ANTHROPIC_VERSION = \"2023-06-01\"\n\n    def _build_headers(self) -> Dict[str, str]:\n        \"\"\"\n        构建 Anthropic 认证头\n        \"\"\"\n        return {\n            \"x-api-key\": self.config.api_key,\n            \"anthropic-version\": self.ANTHROPIC_VERSION,\n            \"Content-Type\": \"application/json\"\n        }\n\n    def _build_url(self) -> str:\n        \"\"\"\n        Claude 使用 /messages 端点\n        \"\"\"\n        return f\"{self.base_url}/messages\"\n\n    def _build_request_body(\n        self,\n        messages: List[ChatMessage],\n        **kwargs\n    ) -> Dict[str, Any]:\n        \"\"\"\n        构建 Claude 请求体\n        Claude 的 system prompt 是独立字段, 不在 messages 中\n        \"\"\"\n        # 提取 system message\n        system_content = \"\"\n        user_messages = []\n        for msg in messages:\n            if msg.role == \"system\":\n                system_content = msg.content\n            else:\n                user_messages.append({\"role\": msg.role, \"content\": msg.content})\n        body = {\n            \"model\": self.model,\n            \"messages\": user_messages,\n            \"max_tokens\": kwargs.get(\"max_tokens\", self.config.max_tokens)\n        }\n        if system_content:\n            body[\"system\"] = system_content\n        # Claude 不支持 temperature<0, 最小值是 0.1\n        temperature = kwargs.get(\"temperature\", self.config.temperature)\n        if temperature > 0:\n            body[\"temperature\"] = max(0.1, temperature)\n        return body\n\n    def _parse_response(self, response: Dict[str, Any]) -> LLMResponse:\n        \"\"\"\n        解析 Claude 响应\n        \"\"\"\n        content = \"\"\n        for block in response.get(\"content\", []):\n            if block.get(\"type\") == \"text\":\n                content = block.get(\"text\", \"\")\n                break\n        return LLMResponse(\n            content=content,\n            model=response.get(\"model\", self.model),\n            provider=self.PROVIDER,\n            usage=response.get(\"usage\", {}),\n            raw_response=response\n        )"}
{"code_id": "MemoryBear_api_app_repositories_release_share_repository.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\MemoryBear_api_app_repositories_release_share_repository.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\MemoryBear_api_app_repositories_release_share_repository.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\MemoryBear_api_app_repositories_release_share_repository.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "import uuid\nfrom typing import Optional\nfrom sqlalchemy.orm import Session\nfrom sqlalchemy import select\nfrom app.models import ReleaseShare\n\n\nclass ReleaseShareRepository:\n    \"\"\"发布版本分享仓储\"\"\"\n\n    def __init__(self, db: Session):\n        self.db = db\n\n    def create(self, release_share: ReleaseShare) -> ReleaseShare:\n        \"\"\"创建分享配置\"\"\"\n        self.db.add(release_share)\n        self.db.commit()\n        self.db.refresh(release_share)\n        return release_share\n\n    def get_by_id(self, share_id: uuid.UUID) -> Optional[ReleaseShare]:\n        \"\"\"根据 ID 获取分享配置\"\"\"\n        return self.db.get(ReleaseShare, share_id)\n\n    def get_by_release_id(self, release_id: uuid.UUID) -> Optional[ReleaseShare]:\n        \"\"\"根据发布版本 ID 获取分享配置\"\"\"\n        stmt = select(ReleaseShare).where(ReleaseShare.release_id == release_id)\n        return self.db.scalars(stmt).first()\n\n    def get_by_share_token(self, share_token: str) -> Optional[ReleaseShare]:\n        \"\"\"根据分享 token 获取分享配置\"\"\"\n        stmt = select(ReleaseShare).where(ReleaseShare.share_token == share_token)\n        return self.db.scalars(stmt).first()\n\n    def update(self, release_share: ReleaseShare) -> ReleaseShare:\n        \"\"\"更新分享配置\"\"\"\n        self.db.commit()\n        self.db.refresh(release_share)\n        return release_share\n\n    def delete(self, release_share: ReleaseShare) -> None:\n        \"\"\"删除分享配置\"\"\"\n        self.db.delete(release_share)\n        self.db.commit()\n\n    def token_exists(self, share_token: str) -> bool:\n        \"\"\"检查 token 是否已存在\"\"\"\n        stmt = select(ReleaseShare.id).where(ReleaseShare.share_token == share_token)\n        return self.db.scalars(stmt).first() is not None\n\n    def increment_view_count(self, share_id: uuid.UUID) -> None:\n        \"\"\"增加访问次数（异步更新，不阻塞）\"\"\"\n        from datetime import datetime\n        stmt = select(ReleaseShare).where(ReleaseShare.id == share_id)\n        share = self.db.scalars(stmt).first()\n        if share:\n            share.view_count += 1\n            share.last_accessed_at = datetime.now()\n            self.db.commit()"}
{"code_id": "MemoryBear_api_app_repositories_release_share_repository.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\MemoryBear_api_app_repositories_release_share_repository.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\MemoryBear_api_app_repositories_release_share_repository.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\MemoryBear_api_app_repositories_release_share_repository.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "from typing import Optional\nfrom sqlalchemy.orm import Session\nfrom sqlalchemy import select\nfrom app.models import ReleaseShare\n\nclass ReleaseShareRepository:\n    \"\"\"发布版本分享仓储\"\"\"\n\n    def __init__(self, db: Session):\n        self.db = db\n\n    def create(self, release_share: ReleaseShare) -> ReleaseShare:\n        \"\"\"创建分享配置\"\"\"\n        self.db.add(release_share)\n        self.db.commit()\n        self.db.refresh(release_share)\n        return release_share\n\n    def get_by_id(self, share_id: uuid.UUID) -> Optional[ReleaseShare]:\n        \"\"\"根据 ID 获取分享配置\"\"\"\n        return self.db.get(ReleaseShare, share_id)\n\n    def get_by_release_id(self, release_id: uuid.UUID) -> Optional[ReleaseShare]:\n        \"\"\"根据发布版本 ID 获取分享配置\"\"\"\n        stmt = select(ReleaseShare).where(ReleaseShare.release_id == release_id)\n        return self.db.scalars(stmt).first()\n\n    def get_by_share_token(self, share_token: str) -> Optional[ReleaseShare]:\n        \"\"\"根据分享 token 获取分享配置\"\"\"\n        stmt = select(ReleaseShare).where(ReleaseShare.share_token == share_token)\n        return self.db.scalars(stmt).first()\n\n    def update(self, release_share: ReleaseShare) -> ReleaseShare:\n        \"\"\"更新分享配置\"\"\"\n        self.db.commit()\n        self.db.refresh(release_share)\n        return release_share\n\n    def delete(self, release_share: ReleaseShare) -> None:\n        \"\"\"删除分享配置\"\"\"\n        self.db.delete(release_share)\n        self.db.commit()\n\n    def token_exists(self, share_token: str) -> bool:\n        \"\"\"检查 token 是否已存在\"\"\"\n        stmt = select(ReleaseShare.id).where(ReleaseShare.share_token == share_token)\n        return self.db.scalars(stmt).first() is not None\n\n    def increment_view_count(self, share_id: uuid.UUID) -> None:\n        \"\"\"增加访问次数（异步更新，不阻塞）\"\"\"\n        from datetime import datetime\n        stmt = select(ReleaseShare).where(ReleaseShare.id == share_id)\n        share = self.db.scalars(stmt).first()\n        if share:\n            share.view_count += 1\n            share.last_accessed_at = datetime.now()\n        self.db.commit()"}
{"code_id": "MemoryBear_api_app_repositories_release_share_repository.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\MemoryBear_api_app_repositories_release_share_repository.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\MemoryBear_api_app_repositories_release_share_repository.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\MemoryBear_api_app_repositories_release_share_repository.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "from uuid import UUID\nfrom typing import Optional\nfrom sqlalchemmy.orm import Session\nfrom sqlalchemmy import select\nfrom app.models import ReleaseShare\n\n\nclass ReleaseShareRepository:\n    \"\"\"发布版本分享仓库\"\"\"\n\n    def __init__(self, db: Session):\n        self.db = db\n\n    def create(self, release_share: ReleaseShare) -> ReleaseShare:\n        \"\"\"创建分享配置\"\"\"\n        self.db.add(release_share)\n        self.db.commit()\n        self.db.refresh(release_share)\n        return release_share\n\n    def get_by_id(self, share_id: UUID) -> Optional[ReleaseShare]:\n        \"\"\"根据 ID 获取分享配置\"\"\"\n        return self.db.get(ReleaseShare, share_id)\n\n    def get_by_release_id(self, release_id: UUID) -> Optional[ReleaseShare]:\n        \"\"\"根据发布版本 ID 获取分享配置\"\"\"\n        stmt = select(ReleaseShare).where(ReleaseShare.release_id == release_id)\n        return self.db.scalars(stmt).first()\n\n    def get_by_share_token(self, share_token: str) -> Optional[ReleaseShare]:\n        \"\"\"根据分享 token 获取分享配置\"\"\"\n        stmt = select(ReleaseShare).where(ReleaseShare.share_token == share_token)\n        return self.db.scalars(stmt).first()\n\n    def update(self, release_share: ReleaseShare) -> ReleaseShare:\n        \"\"\"更新分享配置\"\"\"\n        self.db.commit()\n        self.db.refresh(release_share)\n        return release_share\n\n    def delete(self, release_share: ReleaseShare) -> None:\n        \"\"\"删除分享配置\"\"\"\n        self.db.delete(release_share)\n        self.db.commit()\n\n    def token_exists(self, share_token: str) -> bool:\n        \"\"\"检查 token 是否已存在\"\"\"\n        stmt = select(ReleaseShare.id).where(ReleaseShare.share_token == share_token)\n        return self.db.scalars(stmt).first() is not None\n\n    def increment_view_count(self, share_id: UUID) -> None:\n        \"\"\"增加访问次数 (异步更新，不阻塞)\"\"\"\n        from datetime import datetime\n        stmt = select(ReleaseShare).where(ReleaseShare.id == share_id)\n        share = self.db.scalars(stmt).first()\n        if share:\n            share.view_count += 1\n            share.last_accessed_at = datetime.now()\n            self.db.commit()"}
{"code_id": "LLM-TradeBot_src_llm_claude_client.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\LLM-TradeBot_src_llm_claude_client.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\LLM-TradeBot_src_llm_claude_client.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\LLM-TradeBot_src_llm_claude_client.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": "    from flask import Flask, render_template, request, jsonify\n\n    app = Flask(__name__)\n\n    @app.route('/')\n    def index():\n        return render_template('index.html')\n\n    @app.route('/predict', methods=['POST'])\n    def predict():\n        # Get the input data from the request\n        data = request.get_json()\n        # Extract the features from the data\n        features = data['features']\n        # Make a prediction using the model\n        prediction = model.predict([features])\n        # Return the prediction as a JSON response\n        return jsonify({'prediction': prediction[0]})\n\n    if __name__ == '__main__':\n        app.run(debug=True)\n    # Load the trained model\n    model = joblib.load('model.pkl')\n\n    # Define a function to preprocess the input data\n    def preprocess_data(data):\n        # Convert the data to a numpy array\n        data = np.array(data)\n        # Reshape the data to match the input shape of the model\n        data = data.reshape(1, -1)\n        # Return the preprocessed data\n        return data\n\n    # Define a function to make a prediction\n    def make_prediction(features):\n        # Preprocess the features\n        features = preprocess_data(features)\n        # Make a prediction using the model\n        prediction = model.predict(features)\n        # Return the prediction\n        return prediction[0]\n\n    # Define a route to handle the prediction request\n    @app.route('/predict', methods=['POST'])\n    def predict():\n        # Get the input data from the request\n        data = request.get_json()\n        # Extract the features from the data\n        features = data['features']\n        # Make a prediction using the model\n        prediction = make_prediction(features)\n        # Return the prediction as a JSON response\n        return jsonify({'prediction': prediction})\n\n    # Run the Flask app\n    if __name__ == '__main__':\n        app.run(debug=True)"}
{"code_id": "LLM-TradeBot_src_llm_claude_client.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\LLM-TradeBot_src_llm_claude_client.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\LLM-TradeBot_src_llm_claude_client.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\LLM-TradeBot_src_llm_claude_client.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "MinivLLM_src_myvllm_layers_layernorm.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\MinivLLM_src_myvllm_layers_layernorm.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\MinivLLM_src_myvllm_layers_layernorm.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\MinivLLM_src_myvllm_layers_layernorm.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "import torch\nimport time\n\nclass LayerNorm(torch.nn.Module):\n    def __init__(self, gamma: torch.Tensor, eps: float = 1e-5):\n        super().__init__()\n        self.register_buffer('gamma', gamma)\n        self.eps = eps\n\n    @torch.compile\n    def rms_forward(self, x: torch.Tensor) -> torch.Tensor:\n        # RMSNorm(x) = (x / sqrt(mean(x²) + ε))) ⊙ γ\n        variance = x.pow(2).mean(dim=-1, keepdim=True) + self.eps\n        sqrt_variance = variance.sqrt()\n        x_norm = (x / sqrt_variance) * self.gamma\n        return x_norm\n\n    def residual_rms_forward(self, x: torch.Tensor, residual: torch.Tensor) -> torch.Tensor:\n        x = x + residual\n        return self.rms_forward(x), x\n\n    def forward(self, x: torch.Tensor, residual: torch.Tensor | None = None) -> torch.Tensor:\n        if residual is not None:\n            return self.residual_rms_forward(x, residual)\n        else:\n            return self.rms_forward(x)\n\nif __name__ == \"__main__\":\n    # Example usage\n    x = torch.randn(8, 4000, 8000).cuda()\n    gamma = torch.full((8000,), 0.5, device=\"cuda\", dtype=x.dtype)\n    layer = LayerNorm(gamma=gamma).cuda()\n    residual = torch.full_like(x, fill_value=1)\n\n    for _ in range(10):  # Warm-up iterations\n        _ = layer(x)\n\n    # Without residuals\n    times = []\n    for _ in range(100):  # Timing iterations\n        torch.cuda.synchronize()\n        start_time = time.time()\n        _ = layer(x)\n        torch.cuda.synchronize()\n        end_time = time.time()\n        times.append(end_time - start_time)\n    avg_time = sum(times) / len(times)\n    print(f\"[Without residuals] Average inference time over 100 runs: {avg_time * 1000:.4f} ms\")\n\n    # With residuals\n    times.clear()\n    for _ in range(100):  # Timing iterations\n        torch.cuda.synchronize()\n        start_time = time.time()\n        _ = layer(x, residual)\n        torch.cuda.synchronize()\n        end_time = time.time()\n        times.append(end_time - start_time)\n    avg_time = sum(times) / len(times)\n    print(f\"[With residuals] Average inference time over 100 runs: {avg_time * 1000:.4f} ms\")"}
{"code_id": "MinivLLM_src_myvllm_layers_layernorm.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\MinivLLM_src_myvllm_layers_layernorm.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\MinivLLM_src_myvllm_layers_layernorm.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\MinivLLM_src_myvllm_layers_layernorm.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "import torch\nimport time\n\nclass LayerNorm(torch.nn.Module):\n    def __init__(self, gamma: torch.Tensor, eps: float = 1e-5):\n        super().__init__()\n        self.register_buffer('gamma', gamma)\n        self.eps = eps\n\n    @torch.compile\n    def rms_forward(self, x: torch.Tensor) -> torch.Tensor:\n        # RMSNorm(x) = (x / sqrt(mean(x²) + ε))) ⊙ γ\n        variance = x.pow(2).mean(dim=-1, keepdim=True) + self.eps\n        sqrt_variance = variance.sqrt()\n        x_norm = (x / sqrt_variance) * self.gamma\n        return x_norm\n\n    def residual_rms_forward(self, x: torch.Tensor, residual: torch.Tensor) -> torch.Tensor:\n        x = x + residual\n        return self.rms_forward(x), x\n\n    def forward(self, x: torch.Tensor, residual: torch.Tensor | None = None) -> torch.Tensor:\n        if residual is not None:\n            return self.residual_rms_forward(x, residual)\n        else:\n            return self.rms_forward(x)\n\nif __name__ == \"__main__\":\n    # Example usage\n    x = torch.randn(8, 4000, 8000).cuda()\n    gamma = torch.full((8000,), 0.5, device=\"cuda\", dtype=x.dtype)\n    layer = LayerNorm(gamma=gamma).cuda()\n    residual = torch.full_like(x, fill_value=1)\n\n    for _ in range(10):  # Warm-up iterations\n        _ = layer(x)\n\n    # Without residuals\n    times = []\n    for _ in range(100):  # Timing iterations\n        torch.cuda.synchronize()\n        start_time = time.time()\n        _ = layer(x)\n        torch.cuda.synchronize()\n        end_time = time.time()\n        times.append(end_time - start_time)\n    avg_time = sum(times) / len(times)\n    print(f\"[Without residuals] Average inference time over 100 runs: {avg_time * 1000:.4f} ms\")\n\n    # With residuals\n    times.clear()\n    for _ in range(100):  # Timing iterations\n        torch.cuda.synchronize()\n        start_time = time.time()\n        _ = layer(x, residual)\n        torch.cuda.synchronize()\n        end_time = time.time()\n        times.append(end_time - start_time)\n    avg_time = sum(times) / len(times)\n    print(f\"[With residuals] Average inference time over 100 runs: {avg_time * 1000:.4f} ms\")"}
{"code_id": "MemoryBear_api_app_repositories_release_share_repository.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\MemoryBear_api_app_repositories_release_share_repository.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\MemoryBear_api_app_repositories_release_share_repository.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\MemoryBear_api_app_repositories_release_share_repository.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": "from __future__ import annotations\n\nimport logging\nimport time\nfrom datetime import datetime, timedelta\nfrom typing import List, Optional\n\nfrom main import models\nfrom main.models import Share, ShareLabel\n\nclass ShareLabelService:\n    \"\"\"管理标签文件处理\"\"\"\n\n    def __init__(self, db: Session):\n        self.db = db\n\n    def create_share_label(self, share_id: int, label_id: int) -> ShareLabel:\n        \"\"\"创建标签\"\"\"\n        share = self.db.query(Share).filter(Share.id == share_id).first()\n        if not share:\n            raise ValueError(f\"Share with id {share_id} not found\")\n\n        label = self.db.query(ShareLabel).filter(ShareLabel.id == label_id).first()\n        if not label:\n            raise ValueError(f\"Label with id {label_id} not found\")\n\n        share_label = ShareLabel(share_id=share_id, label_id=label_id)\n        self.db.add(share_label)\n        self.db.commit()\n        self.db.refresh(share_label)\n        return share_label\n\n    def get_share_label(self, share_id: int, label_id: int) -> Optional[ShareLabel]:\n        \"\"\"获取标签\"\"\"\n        return self.db.query(ShareLabel).filter(ShareLabel.share_id == share_id, ShareLabel.label_id == label_id).first()\n\n    def get_share_labels_by_share(self, share_id: int) -> List[ShareLabel]:\n        \"\"\"获取标签列表\"\"\"\n        return self.db.query(ShareLabel).filter(ShareLabel.share_id == share_id).all()\n\n    def get_share_labels_by_label(self, label_id: int) -> List[ShareLabel]:\n        \"\"\"获取标签列表\"\"\"\n        return self.db.query(ShareLabel).filter(ShareLabel.label_id == label_id).all()\n\n    def update_share_label(self, share_id: int, label_id: int, new_label_id: int) -> ShareLabel:\n        \"\"\"更新标签\"\"\"\n        share_label = self.db.query(ShareLabel).filter(ShareLabel.share_id == share_id, ShareLabel.label_id == label_id).first()\n        if not share_label:\n            raise ValueError(f\"ShareLabel with share_id {share_id} and label_id {label_id} not found\")\n\n        new_label = self.db.query(ShareLabel).filter(ShareLabel.id == new_label_id).first()\n        if not new_label:\n            raise ValueError(f\"Label with id {new_label_id} not found\")\n\n        share_label.label_id = new_label_id\n        self.db.commit()\n        self.db.refresh(share_label)\n        return share_label\n\n    def delete_share_label(self, share_id: int, label_id: int) -> None:\n        \"\"\"删除标签\"\"\"\n        share_label = self.db.query(ShareLabel).filter(ShareLabel.share_id == share_id, ShareLabel.label_id == label_id).first()\n        if not share_label:\n            raise ValueError(f\"ShareLabel with share_id {share_id} and label_id {label_id} not found\")\n\n        self.db.delete(share_label)\n        self.db.commit()\n\n    def get_share_labels_by_share_and_label(self, share_id: int, label_id: int) -> Optional[ShareLabel]:\n        \"\"\"获取标签\"\"\"\n        return self.db.query(ShareLabel).filter(ShareLabel.share_id == share_id, ShareLabel.label_id == label_id).first()\n\n    def increment_share_label_count(self, share_id: int, label_id: int) -> None:\n        \"\"\"增加标签计数\"\"\"\n        from sqlalchemy import select, func\n\n        share_label = self.db.query(ShareLabel).filter(ShareLabel.share_id == share_id, ShareLabel.label_id == label_id).first()\n        if not share_label:\n            raise ValueError(f\"ShareLabel with share_id {share_id} and label_id {label_id} not found\")\n\n        if share_label.count is None:\n            share_label.count = 0\n\n        share_label.count += 1\n        self.db.commit()"}
{"code_id": "MinivLLM_src_myvllm_layers_layernorm.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\MinivLLM_src_myvllm_layers_layernorm.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\MinivLLM_src_myvllm_layers_layernorm.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\MinivLLM_src_myvllm_layers_layernorm.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "class LayerNorm(torch.nn.Module):\n    def __init__(self, gamma: torch.Tensor, eps: float = 1e-5):\n        super().__init__()\n        self.register_buffer('gamma', gamma)\n        self.eps = eps\n\ntorch.compile\ndef rms_forward(self, x: torch.Tensor) -> torch.Tensor:\n    # RMSNorm(x) = (x / sqrt(mean(x^2) + eps))) ⊙ γ\n    variance = x.pow(2).mean(dim=-1, keepdim=True) + self.eps\n    sqrt_variance = variance.sqrt()\n    x_norm = (x / sqrt_variance) * self.gamma\n    return x_norm\n\ndef residual_rms_forward(self, x: torch.Tensor, residual: torch.Tensor) -> torch.Tensor:\n    x = x + residual\n    return self.rms_forward(x, x)\n\ndef forward(self, x: torch.Tensor, residual: torch.Tensor | None = None) -> torch.Tensor:\n    if residual is not None:\n        return self.residual_rms_forward(x, residual)\n    else:\n        return self.rms_forward(x)\n\nif __name__ == '__main__':\n    # Example usage\n    x = torch.randn(8, 4000, 8000).cuda()\n    gamma = torch.full([8000], 0.5, device='cuda', dtype=x.dtype)\n    layer = LayerNorm(gamma=gamma).cuda()\n    residual = torch.full_like(x, 0.1).cuda()\n\n    for _ in range(10):  # Warmup iterations\n        _ = layer(x)\n\n    # Without residuals\n    times = []\n    for _ in range(100):  # Timing iterations\n        torch.cuda.synchronize()\n        start_time = time.time()\n        _ = layer(x)\n        torch.cuda.synchronize()\n        end_time = time.time()\n        times.append(end_time - start_time)\n    avg_time = sum(times) / len(times)\n    print(f\"[Without residuals] Average inference time over 100 runs: {avg_time * 1000:.4f} ms\")\n\n    # With residuals\n    times.clear()\n    for _ in range(100):  # Timing iterations\n        torch.cuda.synchronize()\n        start_time = time.time()\n        _ = layer(x + residual)\n        torch.cuda.synchronize()\n        end_time = time.time()\n        times.append(end_time - start_time)\n    avg_time = sum(times) / len(times)\n    print(f\"[With residuals] Average inference time over 100 runs: {avg_time * 1000:.4f} ms\")"}
{"code_id": "MemoryBear_api_app_repositories_release_share_repository.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\MemoryBear_api_app_repositories_release_share_repository.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\MemoryBear_api_app_repositories_release_share_repository.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\MemoryBear_api_app_repositories_release_share_repository.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "MobileWorld_src_mobile_world_tasks_definitions_calendar_add_business_trip_with_cafe.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\MobileWorld_src_mobile_world_tasks_definitions_calendar_add_business_trip_with_cafe.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\MobileWorld_src_mobile_world_tasks_definitions_calendar_add_business_trip_with_cafe.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\MobileWorld_src_mobile_world_tasks_definitions_calendar_add_business_trip_with_cafe.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "from mobile_world.runtime.app_helpers import mcp as mcp_helper\nfrom mobile_world.runtime.app_helpers.fossify_calendar import get_calendar_events\nfrom mobile_world.runtime.controller import AndroidController\nfrom mobile_world.tasks.base import BaseTask\n\nclass AddBusinessTripWithCafeTask(BaseTask):\n    \"\"\"Add business trip calendar event with nearby cafe address in description.\"\"\"\n\n    goal = (\n        \"我下周六10:00am-12:30pm要去「上海虹桥火车站」，添加事项到calender，事项为出差，\"\n        \"你帮帮我到离上海虹桥火车站10公里以内的景点，我周一上班前去参观下，按照\"景点名字：地址\"放入calender事件的描述中，多个景点按逗号分隔\"\n    )\n    task_tags = {\"agent-mcp\", \"lang-cn\"}\n\n    EVENT_TITLE = \"出差\"\n    SEARCH_KEYWORDS = \"景点\"\n    SEARCH_RADIUS = \"10000\"  # 10公里 = 10000米\n    DESTINATION_LOCATION = \"121.323774, 31.193241\"\n\n    app_names = {\"MCP-Amap\", \"Calendar\"}\n\n    def initialize_task_hook(self, controller: AndroidController) -> bool:\n        return True\n\n    async def is_successful_async(self, controller: AndroidController) -> float | tuple[float, str]:\n        self._check_is_initialized()\n\n        landmark_list = await mcp_helper.search_nearby(\n            location=self.DESTINATION_LOCATION,\n            radius=self.SEARCH_RADIUS,\n            keywords=self.SEARCH_KEYWORDS,\n        )\n\n        events = get_calendar_events()\n        for event in events:\n            if self.EVENT_TITLE not in event.get(\"title\", \"\"):\n                continue\n            description = event.get(\"description\", \"\")\n            percentage = sum(landmark in description for landmark in landmark_list) / len(\n                landmark_list\n            )\n            if percentage > 0.8:\n                return 1.0\n\n            else:\n                return 0.0, \"Event description does not contain correct format\"\n        return (\n            0.0,\n            f\"Calendar event not found with title '{self.EVENT_TITLE}' containing attractions\",\n        )\n\n    def tear_down(self, controller: AndroidController) -> bool:\n        super().tear_down(controller)\n        return True"}
{"code_id": "MinivLLM_src_myvllm_layers_layernorm.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\MinivLLM_src_myvllm_layers_layernorm.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\MinivLLM_src_myvllm_layers_layernorm.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\MinivLLM_src_myvllm_layers_layernorm.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "MobileWorld_src_mobile_world_tasks_definitions_calendar_add_business_trip_with_cafe.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\MobileWorld_src_mobile_world_tasks_definitions_calendar_add_business_trip_with_cafe.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\MobileWorld_src_mobile_world_tasks_definitions_calendar_add_business_trip_with_cafe.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\MobileWorld_src_mobile_world_tasks_definitions_calendar_add_business_trip_with_cafe.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "from mobile_world.runtime.app_helpers import mcp as mcp_helper\nfrom mobile_world.runtime.app_helpers.fossify_calendar import get_calendar_events\nfrom mobile_world.runtime.controller import AndroidController\nfrom mobile_world.tasks.base import BaseTask\n\nclass AddBusinessTripWithCafeTask(BaseTask):\n    \"\"\"Add business trip calendar event with nearby cafe address in description.\"\"\"\n    goal = (\n        \"我下周六10:00am-12:30pm要去「上海虹桥火车站」，添加事项到calender，事项为出差，\"\n        \"你帮我找到离上海虹桥火车站10公里以内的景点，我周一上班前去参观下，按照\"景点名字：地址\"放入calender事件的描述中，多个景点按逗号分隔\"\n    )\n    task_tags = [\"agent-mcp\", \"lang-cn\"]\n\n    EVENT_TITLE = \"出差\"\n    SEARCH_KEYWORDS = \"景点\"\n    SEARCH_RADIUS = \"10000\"  # 10公里 = 10000米\n    DESTINATION_LOCATION = \"121.323774, 31.193241\"\n\n    app_names = [\"MCP-Amap\", \"Calendar\"]\n\n    def initialize_task_hook(self, controller: AndroidController) -> bool:\n        return True\n\n    async def is_successful_async(self, controller: AndroidController) -> float | tuple[float, str]:\n        self._check_is_initialized()\n\n        landmark_list = await mcp_helper.search_nearby(\n            location=self.DESTINATION_LOCATION,\n            radius=self.SEARCH_RADIUS,\n            keywords=self.SEARCH_KEYWORDS,\n        )\n\n        events = get_calendar_events()\n        for event in events:\n            if self.EVENT_TITLE not in event.get(\"title\", \"\"):\n                continue\n            description = event.get(\"description\", \"\")\n            percentage = sum(1 for landmark in description for landmark in landmark_list) / len(\n                landmark_list\n            )\n            if percentage > 0.8:\n                return 1.0\n            else:\n                return 0.0, \"Event description does not contain correct format\"\n        return (\n            0.0,\n            f\"Calendar event not found with title '{self.EVENT_TITLE}' containing attractions\",\n        )\n\n    def tear_down(self, controller: AndroidController) -> bool:\n        super().tear_down(controller)\n        return True\n\n    def tear_down(self, controller: AndroidController) -> bool:\n        super().tear_down(controller)\n        return True"}
{"code_id": "MinivLLM_src_myvllm_layers_layernorm.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\MinivLLM_src_myvllm_layers_layernorm.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\MinivLLM_src_myvllm_layers_layernorm.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\MinivLLM_src_myvllm_layers_layernorm.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "N3D-VLM_src_llamafactory_webui_manager.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\N3D-VLM_src_llamafactory_webui_manager.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\N3D-VLM_src_llamafactory_webui_manager.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\N3D-VLM_src_llamafactory_webui_manager.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "# Copyright 2025 the LlamaFactory team.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom collections.abc import Generator\nfrom typing import TYPE_CHECKING\n\nif TYPE_CHECKING:\n    from gradio.components import Component\n\nclass Manager:\n    r\"\"\"A class to manage all the gradio components in Web UI.\"\"\"\n\n    def __init__(self) -> None:\n        self._id_to_elem: dict[str, Component] = {}\n        self._elem_to_id: dict[Component, str] = {}\n\n    def add_elems(self, tab_name: str, elem_dict: dict[str, \"Component\"]) -> None:\n        r\"\"\"Add elements to manager.\"\"\"\n        for elem_name, elem in elem_dict.items():\n            elem_id = f\"{tab_name}.{elem_name}\"\n            self._id_to_elem[elem_id] = elem\n            self._elem_to_id[elem] = elem_id\n\n    def get_elem_list(self) -> list[\"Component\"]:\n        r\"\"\"Return the list of all elements.\"\"\"\n        return list(self._id_to_elem.values())\n\n    def get_elem_iter(self) -> Generator[tuple[str, \"Component\"], None, None]:\n        r\"\"\"Return an iterator over all elements with their names.\"\"\"\n        for elem_id, elem in self._id_to_elem.items():\n            yield elem_id.split(\".\")[-1], elem\n\n    def get_elem_by_id(self, elem_id: str) -> \"Component\":\n        r\"\"\"Get element by id.\n\n        Example: top.lang, train.dataset\n        \"\"\"\n        return self._id_to_elem[elem_id]\n\n    def get_id_by_elem(self, elem: \"Component\") -> str:\n        r\"\"\"Get id by element.\"\"\"\n        return self._elem_to_id[elem]\n\n    def get_base_elems(self) -> set[\"Component\"]:\n        r\"\"\"Get the base elements that are commonly used.\"\"\"\n        return {\n            self._id_to_elem[\"top.lang\"],\n            self._id_to_elem[\"top.model_name\"],\n            self._id_to_elem[\"top.model_path\"],\n            self._id_to_elem[\"top.finetuning_type\"],\n            self._id_to_elem[\"top.checkpoint_path\"],\n            self._id_to_elem[\"top.quantization_bit\"],\n            self._id_to_elem[\"top.quantization_method\"],\n            self._id_to_elem[\"top.template\"],\n            self._id_to_elem[\"top.rope_scaling\"],\n            self._id_to_elem[\"top.booster\"],\n        }"}
{"code_id": "MobileWorld_src_mobile_world_tasks_definitions_calendar_add_business_trip_with_cafe.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\MobileWorld_src_mobile_world_tasks_definitions_calendar_add_business_trip_with_cafe.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\MobileWorld_src_mobile_world_tasks_definitions_calendar_add_business_trip_with_cafe.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\MobileWorld_src_mobile_world_tasks_definitions_calendar_add_business_trip_with_cafe.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "\"\"\"Add business trip calendar event with nearby cafe information.\"\"\"\nfrom mobile_world.runtime.app_helpers import map as map_helper\nfrom mobile_world.runtime.app_helpers.classify_calendar import get_calendar_events\nfrom mobile_world.runtime.controller import AndroidController\nfrom mobile_world.tasks.base import BaseTask\n\nclass AddBusinessTripWithCafeTask(BaseTask):\n    \"\"\"Add business trip calendar event with nearby cafe address in description.\"\"\"\n    qmail = {\n        \"我下周六10:00am-12:30pm要去「上海虹桥火车站」。添加事项到calendar，事项为出差。\"\n        \"你帮能找到离上海虹桥火车站10公里以内的景点，能用一上站景点参下，按照\"景点名字：地址\"放入calendar事件的描述中，多个景点用逗号分隔\"\n    }\n    task_tags = [\"agent:map\", \"lang:cn\"]\n\n    EVENT_TITLE = \"出差\"\n    SEARCH_KEYWORDS = \"景点\"\n    SEARCH_RADIUS = \"10000\"  # 10公里 = 10000米\n    DESTINATION_LOCATION = \"121.323774, 31.193341\"\n\n    app_names = [\"WOP-Map\", \"Calendar\"]\n\n    def initialize_task_hook(self, controller: AndroidController) -> bool:\n        return True\n\n    async def is_successful_async(self, controller: AndroidController) -> float | tuple[float, str]:\n        await self.check_is_initialized()\n\n        landmark_list = await map_helper.search_nearby(\n            location=self.DESTINATION_LOCATION,\n            radius=self.SEARCH_RADIUS,\n            keywords=self.SEARCH_KEYWORDS,\n        )\n\n        events = get_calendar_events()\n        for event in events:\n            if self.EVENT_TITLE not in event.get(\"title\", \"\")):\n                continue\n            description = event.get(\"description\", \"\")\n            percentage = sum(1 for landmark in landmark_list if landmark in description)) / len(landmark_list)\n            if percentage > 0.8:\n                return 1.0\n        else:\n            return 0.0, \"Event description does not contain correct format\"\n        raise Exception(\n            0.0,\n            f\"Calendar event not found with title '{self.EVENT_TITLE}' containing attractions\",\n        )\n\ndef tear_down(self, controller: AndroidController) -> bool:\n    super().tear_down(controller)\n    return True"}
{"code_id": "MobileWorld_src_mobile_world_tasks_definitions_calendar_add_business_trip_with_cafe.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\MobileWorld_src_mobile_world_tasks_definitions_calendar_add_business_trip_with_cafe.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\MobileWorld_src_mobile_world_tasks_definitions_calendar_add_business_trip_with_cafe.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\MobileWorld_src_mobile_world_tasks_definitions_calendar_add_business_trip_with_cafe.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": "from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\nclass SearchWithEmptySearchInformationTest(unittest.TestCase):\n    \"\"\"Test cases for the search module with empty search information.\"\"\"\n    def setUp(self):\n        \"\"\"Set up the test case.\"\"\"\n        self.search_client = search_client.SearchClient()\n        self.search_client.set_search_information(\n            search_information.SearchInformation(\n                query=''))\n        self.search_client.set_search_client(\n            search_client.SearchClient())\n        self.search_client.set_search_results(\n            search_results.SearchResults())\n        self.search_client.set_search_pager(\n            search_pager.SearchPager())\n\n    def test_search_with_empty_search_information(self):\n        \"\"\"Test the search method with empty search information.\"\"\"\n        search_results = self.search_client.search()\n        self.assertEqual(search_results, [])\n\n    def test_search_with_empty_search_information_and_empty_query(self):\n        \"\"\"Test the search method with empty search information and empty query.\"\"\"\n        self.search_client.set_search_information(\n            search_information.SearchInformation(\n                query=''))\n        search_results = self.search_client.search()\n        self.assertEqual(search_results, [])\n\n    def test_search_with_empty_search_information_and_empty_query_and_empty_search_results(self):\n        \"\"\"Test the search method with empty search information and empty query and empty search results.\"\"\"\n        self.search_client.set_search_information(\n            search_information.SearchInformation(\n                query=''))\n        self.search_client.set_search_results(\n            search_results.SearchResults())\n        search_results = self.search_client.search()\n        self.assertEqual(search_results, [])\n\n    def test_search_with_empty_search_information_and_empty_query_and_empty_search_results_and_empty_search_pager(self):\n        \"\"\"Test the search method with empty search information and empty query and empty search results and empty search pager.\"\"\"\n        self.search_client.set_search_information(\n            search_information.SearchInformation(\n                query=''))\n        self.search_client.set_search_results(\n            search_results.SearchResults())\n        self.search_client.set_search_pager(\n            search_pager.SearchPager())\n        search_results = self.search_client.search()\n        self.assertEqual(search_results, [])\n\n    def test_search_with_empty_search_information_and_empty_query_and_empty_search_results_and_empty_search_pager_and_empty_search_client(self):\n        \"\"\"Test the search method with empty search information and empty query and empty search results and empty search pager and empty search client.\"\"\"\n        self.search_client.set_search_information(\n            search_information.SearchInformation(\n                query=''))\n        self.search_client.set_search_results(\n            search_results.SearchResults())\n        self.search_client.set_search_pager(\n            search_pager.SearchPager())\n        self.search_client.set_search_client(\n            search_client.SearchClient())\n        search_results = self.search_client.search()\n        self.assertEqual(search_results, [])"}
{"code_id": "MobileWorld_src_mobile_world_tasks_definitions_calendar_add_business_trip_with_cafe.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\MobileWorld_src_mobile_world_tasks_definitions_calendar_add_business_trip_with_cafe.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\MobileWorld_src_mobile_world_tasks_definitions_calendar_add_business_trip_with_cafe.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\MobileWorld_src_mobile_world_tasks_definitions_calendar_add_business_trip_with_cafe.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "N3D-VLM_src_llamafactory_webui_manager.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\N3D-VLM_src_llamafactory_webui_manager.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\N3D-VLM_src_llamafactory_webui_manager.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\N3D-VLM_src_llamafactory_webui_manager.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "# Copyright 2025 the LlamaFactory team.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom collections.abc import Generator\nfrom typing import TYPE_CHECKING\n\nif TYPE_CHECKING:\n    from gradio.components import Component\n\nclass Manager:\n    r\"\"\"A class to manage all the gradio components in Web UI.\"\"\"\n\n    def __init__(self) -> None:\n        self._id_to_elem: dict[str, Component] = {}\n        self._elem_to_id: dict[Component, str] = {}\n\n    def add_elems(self, tab_name: str, elem_dict: dict[str, \"Component\"]) -> None:\n        r\"\"\"Add elements to manager.\"\"\"\n        for elem_name, elem in elem_dict.items():\n            elem_id = f\"{tab_name}.{elem_name}\"\n            self._id_to_elem[elem_id] = elem\n            self._elem_to_id[elem] = elem_id\n\n    def get_elem_list(self) -> list[\"Component\"]:\n        r\"\"\"Return the list of all elements.\"\"\"\n        return list(self._id_to_elem.values())\n\n    def get_elem_iter(self) -> Generator[tuple[str, \"Component\"], None, None]:\n        r\"\"\"Return an iterator over all elements with their names.\"\"\"\n        for elem_id, elem in self._id_to_elem.items():\n            yield elem_id.split(\".\")[-1], elem\n\n    def get_elem_by_id(self, elem_id: str) -> \"Component\":\n        r\"\"\"Get element by id.\n\n        Example: top.lang, train.dataset\n        \"\"\"\n        return self._id_to_elem[elem_id]\n\n    def get_id_by_elem(self, elem: \"Component\") -> str:\n        r\"\"\"Get id by element.\"\"\"\n        return self._elem_to_id[elem]\n\n    def get_base_elems(self) -> set[\"Component\"]:\n        r\"\"\"Get the base elements that are commonly used.\"\"\"\n        return {\n            self._id_to_elem[\"top.lang\"],\n            self._id_to_elem[\"top.model_name\"],\n            self._id_to_elem[\"top.model_path\"],\n            self._id_to_elem[\"top.finetuning_type\"],\n            self._id_to_elem[\"top.checkpoint_path\"],\n            self._id_to_elem[\"top.quantization_bit\"],\n            self._id_to_elem[\"top.quantization_method\"],\n            self._id_to_elem[\"top.template\"],\n            self._id_to_elem[\"top.rope_scaling\"],\n            self._id_to_elem[\"top.booster\"],\n        }"}
{"code_id": "N3D-VLM_src_llamafactory_webui_manager.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\N3D-VLM_src_llamafactory_webui_manager.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\N3D-VLM_src_llamafactory_webui_manager.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\N3D-VLM_src_llamafactory_webui_manager.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "# Copyright 2025 the Llamafactory team.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom collections.abc import Generator\nfrom typing import TYPE_CHECKING\n\nif TYPE_CHECKING:\n    from gradio.components import Component\n\nclass Manager:\n    \"\"\"A class to manage all the gradio components in Web UI.\"\"\"\n\n    def __init__(self) -> None:\n        self._id_to_elem: dict[str, Component] = {}\n        self._elem_to_id: dict[Component, str] = {}\n\n    def add_elems(self, tab_name: str, elem_dict: dict[str, \"Component\"]) -> None:\n        \"\"\"Add elements to manager.\"\"\"\n        for elem_name, elem in elem_dict.items():\n            elem_id = f\"{tab_name}.{elem_name}\"\n            self._id_to_elem[elem_id] = elem\n            self._elem_to_id[elem] = elem_id\n\n    def get_elems_list(self) -> list[\"Component\"]:\n        \"\"\"Return the list of all elements.\"\"\"\n        return list(self._id_to_elem.values())\n\n    def get_elems_iter(self) -> Generator[tuple[str, \"Component\"], None, None]:\n        \"\"\"Return an iterator over all elements with their names.\"\"\"\n        for elem_id, elem in self._id_to_elem.items():\n            yield elem_id.split(\".\")[-1], elem\n\n    def get_elem_by_id(self, elem_id: str) -> \"Component\":\n        \"\"\"Get element by id.\n\n        Example: top.lang, train.dataset\n        \"\"\"\n        return self._id_to_elem[elem_id]\n\n    def get_id_by_elem(self, elem: \"Component\") -> str:\n        \"\"\"Get id by element.\"\"\"\n        return self._elem_to_id[elem]\n\n    def get_base_elems(self) -> set[\"Component\"]:\n        \"\"\"Get the base elements that are commonly used.\"\"\"\n        return {\n            self._id_to_elem[\"top.lang\"],\n            self._id_to_elem[\"top.model_name\"],\n            self._id_to_elem[\"top.model_path\"],\n            self._id_to_elem[\"top.finetuning_type\"],\n            self._id_to_elem[\"top.checkpoint_path\"],\n            self._id_to_elem[\"top.quantization_bit\"],\n            self._id_to_elem[\"top.quantization_method\"],\n            self._id_to_elem[\"top.template\"],\n            self._id_to_elem[\"top.rope_scaling\"],\n            self._id_to_elem[\"top.booster\"],\n        }"}
{"code_id": "NOVIX_backend_app_llm_gateway_providers_anthropic_provider.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\NOVIX_backend_app_llm_gateway_providers_anthropic_provider.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\NOVIX_backend_app_llm_gateway_providers_anthropic_provider.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\NOVIX_backend_app_llm_gateway_providers_anthropic_provider.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "# Anthropic (Claude) Provider / Anthropic (Claude) 适配器\n\nfrom typing import List, Dict, Any, Optional\nfrom anthropic import AsyncAnthropic\nfrom app.llm_gateway.providers.base import BaseLLMProvider\n\n\nclass AnthropicProvider(BaseLLMProvider):\n    \"\"\"Anthropic API provider / Anthropic API 提供商\"\"\"\n\n    def __init__(\n        self,\n        api_key: str,\n        model: str = \"claude-3-5-sonnet-20241022\",\n        max_tokens: int = 8000,\n        temperature: float = 0.7\n    ):\n        super().__init__(api_key, model, max_tokens, temperature)\n        self.client = AsyncAnthropic(api_key=api_key)\n\n    async def chat(\n        self,\n        messages: List[Dict[str, str]]],\n        temperature: Optional[float] = None,\n        max_tokens: Optional[int] = None\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Send chat request to Anthropic\n        发送聊天请求到 Anthropic\n\n        Args:\n            messages: List of messages / 消息列表\n            temperature: Override temperature / 覆盖温度\n            max_tokens: Override max tokens / 覆盖最大token数\n\n        Returns:\n            Response dict / 响应字典\n        \"\"\"\n        # Extract system message if present / 提取系统消息\n        system_message = None\n        filtered_messages = []\n\n        for msg in messages:\n            if msg[\"role\"] == \"system\":\n                system_message = msg[\"content\"]\n            else:\n                filtered_messages.append(msg)\n\n        # Anthropic API call / Anthropic API 调用\n        kwargs = {\n            \"model\": self.model,\n            \"messages\": filtered_messages,\n            \"temperature\": temperature or self.temperature,\n            \"max_tokens\": max_tokens or self.max_tokens\n        }\n\n        if system_message:\n            kwargs[\"system\"] = system_message\n\n        response = await self.client.messages.create(**kwargs)\n\n        return {\n            \"content\": response.content[0].text,\n            \"usage\": {\n                \"prompt_tokens\": response.usage.input_tokens,\n                \"completion_tokens\": response.usage.output_tokens,\n                \"total_tokens\": response.usage.input_tokens + response.usage.output_tokens\n            },\n            \"model\": response.model,\n            \"finish_reason\": response.stop_reason\n        }\n\n    def get_provider_name(self) -> str:\n        \"\"\"Get provider name / 获取提供商名称\"\"\"\n        return \"anthropic\""}
{"code_id": "NOVIX_backend_app_llm_gateway_providers_anthropic_provider.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\NOVIX_backend_app_llm_gateway_providers_anthropic_provider.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\NOVIX_backend_app_llm_gateway_providers_anthropic_provider.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\NOVIX_backend_app_llm_gateway_providers_anthropic_provider.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "# Anthropic (Claude) Provider / Anthropic (Claude) 适配器\n\nfrom typing import List, Dict, Any, Optional\nfrom anthropic import AsyncAnthropic\nfrom app.llm_gateway.providers.base import BaseLLMProvider\n\nclass AnthropicProvider(BaseLLMProvider):\n    \"\"\"Anthropic API provider / Anthropic API 提供\"\"\"\n\n    def __init__(\n        self,\n        api_key: str,\n        model: str = \"claude-3-5-sonnet-20241022\",\n        max_tokens: int = 8000,\n        temperature: float = 0.7\n    ):\n        super().__init__(api_key, model, max_tokens, temperature)\n        self.client = AsyncAnthropic(api_key=api_key)\n\n    async def chat(\n        self,\n        messages: List[Dict[str, str]]],\n        temperature: Optional[float] = None,\n        max_tokens: Optional[int] = None\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Send chat request to Anthropic\n        发送聊天请求到 Anthropic\n\n        Args:\n            messages: List of messages / 消息列表\n            temperature: Override temperature / 覆盖温度\n            max_tokens: Override max tokens / 覆盖最大token数\n\n        Returns:\n            Response dict / 响应字典\n        \"\"\"\n        # Extract system message if present / 提取系统消息\n        system_message = None\n        filtered_messages = []\n\n        for msg in messages:\n            if msg[\"role\"] == \"system\":\n                system_message = msg[\"content\"]\n            else:\n                filtered_messages.append(msg)\n\n        # Anthropic API call / Anthropic API 调用\n        kwargs = {\n            \"model\": self.model,\n            \"messages\": filtered_messages,\n            \"temperature\": temperature or self.temperature,\n            \"max_tokens\": max_tokens or self.max_tokens\n        }\n\n        if system_message:\n            kwargs[\"system\"] = system_message\n\n        response = await self.client.messages.create(**kwargs)\n\n        return {\n            \"content\": response.content[0].text,\n            \"usage\": {\n                \"prompt_tokens\": response.usage.input_tokens,\n                \"completion_tokens\": response.usage.output_tokens,\n                \"total_tokens\": response.usage.input_tokens + response.usage.output_tokens\n            },\n            \"model\": response.model,\n            \"finish_reason\": response.stop_reason\n        }\n\n    def get_provider_name(self) -> str:\n        \"\"\"Get provider name / 获取提供商名称\"\"\"\n        return \"anthropic\""}
{"code_id": "N3D-VLM_src_llamafactory_webui_manager.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\N3D-VLM_src_llamafactory_webui_manager.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\N3D-VLM_src_llamafactory_webui_manager.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\N3D-VLM_src_llamafactory_webui_manager.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "N3D-VLM_src_llamafactory_webui_manager.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\N3D-VLM_src_llamafactory_webui_manager.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\N3D-VLM_src_llamafactory_webui_manager.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\N3D-VLM_src_llamafactory_webui_manager.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": "class Review:\n    \"\"\"A class to manage all the graph's comments in the list\"\"\"\n    def __init__(self):\n        self._comments = []\n        self._praise = []\n        self._criticism = []\n        self._suggestion = []\n        self._question = []\n        self._other = []\n\n    def add_comment(self, comment, sentiment):\n        \"\"\"Add a comment to the graph\"\"\"\n        self._comments.append(comment)\n        self._comments.append(sentiment)\n        self._comments.append(comment)\n        self._comments.append(sentiment)\n        self._comments.append(comment)\n        self._comments.append(sentiment)\n\n    def get_praise_comments(self):\n        \"\"\"Return the list of all comments\"\"\"\n        return self._praise\n\n    def get_criticism_comments(self):\n        \"\"\"Return the list of all comments with their names\"\"\"\n        return self._criticism\n\n    def get_suggestion_comments(self):\n        \"\"\"Return the list of all comments\"\"\"\n        return self._suggestion\n\n    def get_question_comments(self):\n        \"\"\"Return the list of all comments\"\"\"\n        return self._question\n\n    def get_other_comments(self):\n        \"\"\"Return the list of all comments\"\"\"\n        return self._other\n\n    def get_all_comments(self):\n        \"\"\"Return the list of all comments\"\"\"\n        return self._comments\n\n    def get_comments_by_sentiment(self, sentiment):\n        \"\"\"Return the name of comments that are sentiment to sentiment\"\"\"\n        if sentiment == \"praise\":\n            return self._praise\n        elif sentiment == \"criticism\":\n            return self._criticism\n        elif sentiment == \"suggestion\":\n            return self._suggestion\n        elif sentiment == \"question\":\n            return self._question\n        elif sentiment == \"other\":\n            return self._other\n        else:\n            return self._comments"}
{"code_id": "NOVIX_backend_app_llm_gateway_providers_anthropic_provider.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\NOVIX_backend_app_llm_gateway_providers_anthropic_provider.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\NOVIX_backend_app_llm_gateway_providers_anthropic_provider.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\NOVIX_backend_app_llm_gateway_providers_anthropic_provider.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "from typing import List, Dict, Any, Optional\nfrom anthropic import AsyncAnthropic\nfrom app.file_gateway.providers.base import BaseLlmProvider\n\nclass AnthropicProvider(BaseLlmProvider):\n    \"\"\"Anthropic API provider / Anthropic API 提供商\"\"\"\n\n    def __init__(\n        self,\n        api_key: str,\n        model: str = \"claude-3-5-sonnet-20241022\",\n        max_tokens: int = 8000,\n        temperature: float = 0.7\n    ):\n        super().__init__(api_key, model, max_tokens, temperature)\n        self.client = AsyncAnthropic(api_key=api_key)\n\n    async def chat(\n        self,\n        messages: List[Dict[str, str]]],\n        temperature: Optional[float] = None,\n        max_tokens: Optional[int] = None\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Send chat request to Anthropic\n        发送聊天请求到 Anthropic\n\n        Args:\n            messages: List of messages / 消息列表\n            temperature: Override temperature / 覆盖温度\n            max_tokens: Override max tokens / 覆盖最大token数\n\n        Returns:\n            Response dict / 响应字典\n        \"\"\"\n        # Extract system message if present / 提取系统消息\n        system_message = None\n        filtered_messages = []\n\n        for msg in messages:\n            if msg[\"role\"] == \"system\":\n                system_message = msg[\"content\"]\n            else:\n                filtered_messages.append(msg)\n\n        # Anthropic API call / Anthropic API 调用\n        kwargs = {\n            \"model\": self.model,\n            \"messages\": filtered_messages,\n            \"temperature\": temperature or self.temperature,\n            \"max_tokens\": max_tokens or self.max_tokens\n        }\n\n        if system_message:\n            kwargs[\"system\"] = system_message\n\n        response = await self.client.messages.create(**kwargs)\n\n        return {\n            \"content\": response.content[0].text,\n            \"usage\": {\n                \"prompt_tokens\": response.usage.input_tokens,\n                \"completion_tokens\": response.usage.output_tokens,\n                \"total_tokens\": response.usage.input_tokens + response.usage.output_tokens\n            },\n            \"model\": response.model,\n            \"finish_reason\": response.stop_reason\n        }\n\n    def get_provider_name(self) -> str:\n        \"\"\"Get provider name / 获取提供者名称\"\"\"\n        return \"anthropic\""}
{"code_id": "NegPy_src_infrastructure_storage_repository.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\NegPy_src_infrastructure_storage_repository.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\NegPy_src_infrastructure_storage_repository.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\NegPy_src_infrastructure_storage_repository.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "import sqlite3\nimport json\nimport os\nfrom typing import Any, Optional\nfrom src.domain.models import WorkspaceConfig\nfrom src.domain.interfaces import IRepository\n\nclass StorageRepository(IRepository):\n    \"\"\"\n    SQLite backend for settings.\n    \"\"\"\n\n    def __init__(self, edits_db_path: str, settings_db_path: str) -> None:\n        self.edits_db_path = edits_db_path\n        self.settings_db_path = settings_db_path\n\n    def initialize(self) -> None:\n        \"\"\"\n        Ensures DB tables exist.\n        \"\"\"\n        os.makedirs(os.path.dirname(self.edits_db_path), exist_ok=True)\n\n        with sqlite3.connect(self.edits_db_path) as conn:\n            conn.execute(\"\"\"\n                CREATE TABLE IF NOT EXISTS file_settings (\n                    file_hash TEXT PRIMARY KEY,\n                    settings_json TEXT\n                )\n            \"\"\")\n\n        with sqlite3.connect(self.settings_db_path) as conn:\n            conn.execute(\"\"\"\n                CREATE TABLE IF NOT EXISTS global_settings (\n                    key TEXT PRIMARY KEY,\n                    value_json TEXT\n                )\n            \"\"\")\n\n    def save_file_settings(self, file_hash: str, settings: WorkspaceConfig) -> None:\n        with sqlite3.connect(self.edits_db_path) as conn:\n            settings_json = json.dumps(settings.to_dict(), default=str)\n            conn.execute(\n                \"INSERT OR REPLACE INTO file_settings (file_hash, settings_json) VALUES (?, ?)\",\n                (file_hash, settings_json),\n            )\n\n    def load_file_settings(self, file_hash: str) -> Optional[WorkspaceConfig]:\n        with sqlite3.connect(self.edits_db_path) as conn:\n            cursor = conn.execute(\n                \"SELECT settings_json FROM file_settings WHERE file_hash = ?\",\n                (file_hash,),\n            )\n            row = cursor.fetchone()\n            if row:\n                data = json.loads(row[0])\n                return WorkspaceConfig.from_flat_dict(data)\n        return None\n\n    def save_global_setting(self, key: str, value: Any) -> None:\n        with sqlite3.connect(self.settings_db_path) as conn:\n            conn.execute(\n                \"INSERT OR REPLACE INTO global_settings (key, value_json) VALUES (?, ?)\",\n                (key, json.dumps(value, default=str)),\n            )\n\n    def get_global_setting(self, key: str, default: Any = None) -> Any:\n        with sqlite3.connect(self.settings_db_path) as conn:\n            cursor = conn.execute(\n                \"SELECT value_json FROM global_settings WHERE key = ?\",\n                (key,),\n            )\n            row = cursor.fetchone()\n            if row:\n                return json.loads(row[0])\n        return default"}
{"code_id": "NegPy_src_infrastructure_storage_repository.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\NegPy_src_infrastructure_storage_repository.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\NegPy_src_infrastructure_storage_repository.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\NegPy_src_infrastructure_storage_repository.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "import sqlite3\nimport json\nimport os\nfrom typing import Any, Optional\nfrom src.domain.models import WorkspaceConfig\nfrom src.domain.interfaces import IRepository\n\nclass StorageRepository(IRepository):\n    \"\"\"\n    SQLite backend for settings.\n    \"\"\"\n\n    def __init__(self, edits_db_path: str, settings_db_path: str) -> None:\n        self.edits_db_path = edits_db_path\n        self.settings_db_path = settings_db_path\n\n    def initialize(self) -> None:\n        \"\"\"\n        Ensures DB tables exist.\n        \"\"\"\n        os.makedirs(os.path.dirname(self.edits_db_path), exist_ok=True)\n\n        with sqlite3.connect(self.edits_db_path) as conn:\n            conn.execute(\"\"\"\n                CREATE TABLE IF NOT EXISTS file_settings (\n                    file_hash TEXT PRIMARY KEY,\n                    settings_json TEXT\n                )\n            \"\"\")\n\n        with sqlite3.connect(self.settings_db_path) as conn:\n            conn.execute(\"\"\"\n                CREATE TABLE IF NOT EXISTS global_settings (\n                    key TEXT PRIMARY KEY,\n                    value_json TEXT\n                )\n            \"\"\")\n\n    def save_file_settings(self, file_hash: str, settings: WorkspaceConfig) -> None:\n        with sqlite3.connect(self.edits_db_path) as conn:\n            settings_json = json.dumps(settings.to_dict(), default=str)\n            conn.execute(\n                \"INSERT OR REPLACE INTO file_settings (file_hash, settings_json) VALUES (?, ?)\",\n                (file_hash, settings_json),\n            )\n\n    def load_file_settings(self, file_hash: str) -> Optional[WorkspaceConfig]:\n        with sqlite3.connect(self.edits_db_path) as conn:\n            cursor = conn.execute(\n                \"SELECT settings_json FROM file_settings WHERE file_hash = ?\",\n                (file_hash,),\n            )\n            row = cursor.fetchone()\n            if row:\n                data = json.loads(row[0])\n                return WorkspaceConfig.from_flat_dict(data)\n        return None\n\n    def save_global_setting(self, key: str, value: Any) -> None:\n        with sqlite3.connect(self.settings_db_path) as conn:\n            conn.execute(\n                \"INSERT OR REPLACE INTO global_settings (key, value_json) VALUES (?, ?)\",\n                (key, json.dumps(value, default=str)),\n            )\n\n    def get_global_setting(self, key: str, default: Any = None) -> Any:\n        with sqlite3.connect(self.settings_db_path) as conn:\n            cursor = conn.execute(\n                \"SELECT value_json FROM global_settings WHERE key = ?\",\n                (key,),\n            )\n            row = cursor.fetchone()\n            if row:\n                return json.loads(row[0])\n        return default"}
{"code_id": "NOVIX_backend_app_llm_gateway_providers_anthropic_provider.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\NOVIX_backend_app_llm_gateway_providers_anthropic_provider.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\NOVIX_backend_app_llm_gateway_providers_anthropic_provider.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\NOVIX_backend_app_llm_gateway_providers_anthropic_provider.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": "from typing import List, Dict, Any, TypedDict\nfrom aiostream import streamcontext\nfrom aiostream.operators import stream as aiostream_stream\n\nclass aiostream_stream_handler(Handler):\n    '''处理 aiostream stream / 处理 aiostream stream'''\n    def __init__(self,\n                     model: str = \"\",\n                     data_balance: int = 0,\n                     temperature: float = 1.0\n                     ) -> None:\n        super().__init__(model, data_balance, temperature)\n\n    async def start(\n        self,\n        messages: List[dict] = [],\n        temperature: float = None,\n        data_balance: float = None\n    ) -> Future[dict, bool]:\n        if not messages:\n            return Future[dict, bool]({\n                'error': 'No messages provided to the handler',\n                'status': 'error'\n            }, False)\n        system_message = messages[0]\n        if system_message.get('role') == 'system':\n            system_messages = [system_message]\n            if len(system_messages) > 1:\n                system_messages = system_messages[:1]\n            current_messages = messages[1:]\n        else:\n            system_messages = []\n            current_messages = messages\n        if len(current_messages) > 1:\n            current_messages = current_messages[:1]\n        response = {\n            'model': self.model,\n            'messages': self._format_messages,\n            'temperature': self.temperature if temperature is None else temperature,\n            'data_balance': self.data_balance if data_balance is None else data_balance\n        }\n        if current_messages:\n            response['messages'] = current_messages\n        response = await self._send_request(response)\n        else:\n            response = {\n                'model': response['model'],\n                'messages': [],\n                'temperature': response['temperature'],\n                'data_balance': response['data_balance'],\n                'total_tokens': response['total_tokens'],\n                'model': response['model'],\n                'total_tokens': response['total_tokens']\n            }\n\n    def get_process_name(self) -> str:\n        '''获取进程名称 / 获取进程名称'''\n        return 'aiohttp'\n\nif __name__ == '__main__':\n    handler ="}
{"code_id": "NOVIX_backend_app_llm_gateway_providers_anthropic_provider.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\NOVIX_backend_app_llm_gateway_providers_anthropic_provider.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\NOVIX_backend_app_llm_gateway_providers_anthropic_provider.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\NOVIX_backend_app_llm_gateway_providers_anthropic_provider.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "NegPy_src_infrastructure_storage_repository.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\NegPy_src_infrastructure_storage_repository.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\NegPy_src_infrastructure_storage_repository.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\NegPy_src_infrastructure_storage_repository.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "from __future__ import annotations\nfrom typing import Any, Optional\nfrom src.domain.models import WorkspaceConfig\nfrom src.domain.interfaces import IRepository\n\nclass StorageRepository(IRepository):\n    \"\"\"SQLite backend for settings.\n    \"\"\"\n\n    def __init__(self, edits_db_path: str, settings_db_path: str) -> None:\n        self.edits_db_path = edits_db_path\n        self.settings_db_path = settings_db_path\n\n    def initialized(self) -> None:\n        \"\"\"Ensures DB tables exist.\n        \"\"\"\n        os.makedirs(os.path.dirname(self.edits_db_path), exist_ok=True)\n\n        with sqlite3.connect(self.edits_db_path) as conn:\n            conn.execute(\"\"\"\n                CREATE TABLE IF NOT EXISTS file_settings (\n                    file_hash TEXT PRIMARY KEY,\n                    settings_json TEXT\n                )\n            \"\"\")\n\n        with sqlite3.connect(self.settings_db_path) as conn:\n            conn.execute(\"\"\"\n                CREATE TABLE IF NOT EXISTS global_settings (\n                    key TEXT PRIMARY KEY,\n                    value_json TEXT\n                )\n            \"\"\")\n\n    def save_file_settings(self, file_hash: str, settings: WorkspaceConfig) -> None:\n        with sqlite3.connect(self.edits_db_path) as conn:\n            settings_json = json.dumps(settings.to_dict(), default=str)\n            conn.execute(\n                \"INSERT OR REPLACE INTO file_settings (file_hash, settings_json) VALUES (?, ?)\",\n                (file_hash, settings_json),\n            )\n\n    def get_file_settings(self, file_hash: str) -> Optional[WorkspaceConfig]:\n        with sqlite3.connect(self.edits_db_path) as conn:\n            cursor = conn.execute(\n                \"SELECT settings_json FROM file_settings WHERE file_hash = ?\",\n                (file_hash,),\n            )\n            row = cursor.fetchone()\n            if row:\n                data = json.loads(row[0])\n                return WorkspaceConfig.from_flat_dict(data)\n        return None\n\n    def save_global_setting(self, key: str, value: Any) -> None:\n        with sqlite3.connect(self.settings_db_path) as conn:\n            conn.execute(\n                \"INSERT OR REPLACE INTO global_settings (key, value_json) VALUES (?, ?)\",\n                (key, json.dumps(value, default=str))),\n            )\n\n    def get_global_setting(self, key: str, default: Any = None) -> Any:\n        with sqlite3.connect(self.settings_db_path) as conn:\n            cursor = conn.execute(\n                \"SELECT value_json FROM global_settings WHERE key = ?\",\n                (key,),\n            )\n            row = cursor.fetchone()\n            if row:\n                return json.loads(row[0])\n        return default"}
{"code_id": "NegPy_src_infrastructure_storage_repository.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\NegPy_src_infrastructure_storage_repository.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\NegPy_src_infrastructure_storage_repository.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\NegPy_src_infrastructure_storage_repository.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": "from typing import Any\nfrom typing import Dict\nfrom typing import Optional\n\nfrom asyncpg import Connection\nfrom asyncpg import Record\nfrom asyncpg.exceptions import PostgresError\n\nclass DBSettingsBackend:\n    \"\"\"The backend for settings.\"\"\"\n\n    def __init__(self, url: str, pool: str, max_size: int, db_part: str) -> None:\n        self.add_to_db_part = add_to_db_part\n        self.max_size = max_size\n        self.db_part = db_part\n\n    async def init_db(self) -> None:\n        \"\"\"Creates DB tables on init.\"\"\"\n        async with self.pool.acquire() as conn:\n            async with conn.transaction():\n                await conn.execute(\n                    \"CREATE TABLE IF NOT EXISTS {}_settings (\"\n                    \"key TEXT PRIMARY KEY,\"\n                    \"value_json TEXT\"\n                    \")\".format(self.db_part)\n                )\n                await conn.execute(\n                    \"CREATE TABLE IF NOT EXISTS global_settings (\"\n                    \"key TEXT PRIMARY KEY,\"\n                    \"value_json TEXT\"\n                    \")\".format(self.db_part)\n                )\n\n    async def store(self, key: str, value: Any) -> None:\n        async with self.pool.acquire() as conn:\n            async with conn.transaction():\n                settings_json = json.dumps(value, default=str)\n                await conn.execute(\n                    \"INSERT OR REPLACE INTO {}_settings (key, value_json) VALUES ($1, $2)\".format(self.db_part),\n                    key,\n                    settings_json\n                )\n    async def get(self, key: str, default: Any = None) -> Any:\n        async with self.pool.acquire() as conn:\n            async with conn.transaction():\n                await conn.execute(\n                    \"INSERT OR REPLACE INTO global_settings (key, value_json) VALUES ($1, $2)\".format(self.db_part),\n                    key,\n                    default\n                )\n            cur = await conn.execute(\n                \"SELECT value_json FROM {}_settings WHERE key = $1\".format(self.db_part),\n                key\n            )\n            if cur:\n                data = await cur.fetchval()\n                return json.loads(data) if data else default\n        return default\n\n    async def apply_global_settings(self, key: str, value: Any) -> None:\n        async with self.pool.acquire() as conn:\n            async with conn.transaction():\n                await conn.execute(\n                    \"INSERT OR REPLACE INTO global_settings (key, value_json) VALUES ($1, $2)\".format(self.db_part),\n                    key,\n                    value\n                )"}
{"code_id": "ODesign_src_utils_train_metrics.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\ODesign_src_utils_train_metrics.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\ODesign_src_utils_train_metrics.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\ODesign_src_utils_train_metrics.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "import numpy as np\nimport torch\nfrom src.utils.license_register import register_license\nfrom src.utils.train.distributed import gather_and_merge\n\ncommon_aggregator = {\n    \"avg\": lambda x: np.mean(x),\n    \"median\": lambda x: np.median(x),\n    \"pct90\": lambda x: np.percentile(x, 90),\n    \"pct99\": lambda x: np.percentile(x, 99),\n    \"max\": lambda x: np.max(x),\n    \"min\": lambda x: np.min(x),\n}\n\nclass SimpleMetricAggregator(object):\n    \"\"\"A quite simple metrics calculator that only do simple metrics aggregation.\"\"\"\n\n    def __init__(\n        self, aggregator_names=None, gather_before_calc=True, need_gather=True\n    ):\n        super(SimpleMetricAggregator, self).__init__()\n        self.gather_before_calc = gather_before_calc\n        self.need_gather = need_gather\n        self._metric_data = {}\n\n        self.aggregators = {name: common_aggregator[name] for name in aggregator_names}\n\n    @register_license('bytedance2024')\n    def add(self, key, value, namespace=\"default\"):\n        value_dict = self._metric_data.setdefault(namespace, {})\n        value_dict.setdefault(key, [])\n        if isinstance(value, (float, int)):\n            value = np.array([value])\n        elif isinstance(value, torch.Tensor):\n            if value.dim() == 0:\n                value = np.array([value.item()])\n            else:\n                value = value.detach().cpu().numpy()\n        elif isinstance(value, np.ndarray):\n            pass\n        else:\n            raise ValueError(f\"Unsupported type for metric data: {type(value)}\")\n        value_dict[key].append(value)\n\n    @register_license('odesign2025')\n    def calc(self):\n        metric_data, self._metric_data = self._metric_data, {}\n        if self.need_gather and self.gather_before_calc:\n            metric_data = gather_and_merge(\n                metric_data, aggregation_func=lambda l: sum(l, [])\n            )\n        results = {}\n        for agg_name, agg_func in self.aggregators.items():\n            for namespace, value_dict in metric_data.items():\n                for key, data in value_dict.items():\n                    plain_key = f\"{namespace}/{key}\" if namespace != \"default\" else key\n                    plain_key = f\"{plain_key}.{agg_name}\"\n                    results[plain_key] = agg_func(np.concatenate(data, axis=0))\n        if self.need_gather and not self.gather_before_calc:  # need gather after calc\n            results = gather_and_merge(results, aggregation_func=np.mean)\n        return results"}
{"code_id": "ODesign_src_utils_train_metrics.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\ODesign_src_utils_train_metrics.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\ODesign_src_utils_train_metrics.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\ODesign_src_utils_train_metrics.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "import numpy as np\nimport torch\n\nfrom src.utils.license_register import register_license\nfrom src.utils.train.distributed import gather_and_merge\n\ncommon_aggregator = {\n    \"avg\": lambda x: np.mean(x),\n    \"median\": lambda x: np.median(x),\n    \"pct90\": lambda x: np.percentile(x, 90),\n    \"pct99\": lambda x: np.percentile(x, 99),\n    \"max\": lambda x: np.max(x),\n    \"min\": lambda x: np.min(x),\n}\n\nclass SimpleMetricAggregator(object):\n    \"\"\"A quite simple metrics calculator that only do simple metrics aggregation.\"\"\"\n\n    def __init__(\n        self, aggregator_names=None, gather_before_calc=True, need_gather=True\n    ):\n        super(SimpleMetricAggregator, self).__init__()\n        self.gather_before_calc = gather_before_calc\n        self.need_gather = need_gather\n        self._metric_data = {}\n\n        self.aggregators = {name: common_aggregator[name] for name in aggregator_names}\n\n    @register_license('bytedance2024')\n    def add(self, key, value, namespace=\"default\"):\n        value_dict = self._metric_data.setdefault(namespace, {})\n        value_dict.setdefault(key, [])\n        if isinstance(value, (float, int)):\n            value = np.array([value])\n        elif isinstance(value, torch.Tensor):\n            if value.dim() == 0:\n                value = np.array([value.item()])\n            else:\n                value = value.detach().cpu().numpy()\n        elif isinstance(value, np.ndarray):\n            pass\n        else:\n            raise ValueError(f\"Unsupported type for metric data: {type(value)}\")\n        value_dict[key].append(value)\n\n    @register_license('odesign2025')\n    def calc(self):\n        metric_data, self._metric_data = self._metric_data, {}\n        if self.need_gather and self.gather_before_calc:\n            metric_data = gather_and_merge(\n                metric_data, aggregation_func=lambda l: sum(l, [])\n            )\n        results = {}\n        for agg_name, agg_func in self.aggregators.items():\n            for namespace, value_dict in metric_data.items():\n                for key, data in value_dict.items():\n                    plain_key = f\"{namespace}/{key}\" if namespace != \"default\" else key\n                    plain_key = f\"{plain_key}.{agg_name}\"\n                    results[plain_key] = agg_func(np.concatenate(data, axis=0)))\n        if self.need_gather and not self.gather_before_calc:  # need gather after calc\n            results = gather_and_merge(results, aggregation_func=np.mean)\n        return results"}
{"code_id": "ODesign_src_utils_train_metrics.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\ODesign_src_utils_train_metrics.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\ODesign_src_utils_train_metrics.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\ODesign_src_utils_train_metrics.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "import numpy as np\nimport torch\n\nfrom src.utils.license_register import register_license\nfrom src.utils.train.distributed import gather_and_merge\n\ncommon_aggregator = {\n    'avg': lambda x: np.mean(x),\n    'median': lambda x: np.median(x),\n    'p90': lambda x: np.percentile(x, 90),\n    'p99': lambda x: np.percentile(x, 99),\n    'max': lambda x: np.max(x),\n    'min': lambda x: np.min(x),\n}\n\nclass SimpleMetricsAggregator(object):\n    \"\"\"A quite simple metrics calculator that only do simple metrics aggregation.\"\"\"\n\n    def __init__(\n        self, aggregator_names=None, gather_before_calc=True, need_gather=True\n    ):\n        super(SimpleMetricsAggregator, self).__init__()\n        self.gather_before_calc = gather_before_calc\n        self.need_gather = need_gather\n        self._metric_data = {}\n\n        self._aggregators = {name: common_aggregator[name] for name in aggregator_names}\n\n    register_license('bytedance2024')\n    def add_item(self, key, value, namespace=\"default\"):\n        value_dict = self._metric_data.setdefault(namespace, {})\n        value_dict.setdefault(key, [])\n        if isinstance(value, (float, int))):\n            value = np.array([value])\n        elif isinstance(value, torch.Tensor):\n            if value.dim() == 0:\n                value = np.array([value.item()])\n            else:\n                value = value.detach().cpu().numpy()\n        elif isinstance(value, np.ndarray):\n            pass\n        else:\n            raise ValueError(f\"Unsupported type for metric data: {type(value)}\")\n        value_dict[key].append(value)\n\n    register_license('oddsign2025')\n\n    def calculate(self):\n        metric_data = self._metric_data\n        if self.need_gather and self.gather_before_calc:\n            metric_data = gather_and_merge[metric_data, aggregation_func=lambda x: sum(x, [])]\n        results = {}\n        for agg_name, agg_func in self._aggregators.items():\n            for namespace, value_dict in metric_data.items():\n                for key, data in value_dict.items():\n                    plain_key = f\"{namespace}/{key}\" if namespace != \"default\" else key\n                    plain_key = f\"{plain_key}_{agg_name}\"\n                    results[plain_key] = agg_func(np.concatenate(data, axis=0))\n        if self.need_gather and not self.gather_before_calc:  # need gather after calc\n            results = gather_and_merge[results, aggregation_func=np.mean]\n        return results"}
{"code_id": "NegPy_src_infrastructure_storage_repository.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\NegPy_src_infrastructure_storage_repository.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\NegPy_src_infrastructure_storage_repository.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\NegPy_src_infrastructure_storage_repository.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "OGhidra_src_session_store.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\OGhidra_src_session_store.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\OGhidra_src_session_store.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\OGhidra_src_session_store.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "# Session history storage and retrieval.\n\nimport json\nimport os\nimport datetime\nfrom typing import List, Dict, Any, Optional\n\nfrom .memory_models import SessionRecord, ToolCallRecord\n\nclass SessionHistoryStore:\n    def __init__(self, storage_path: str = \"session_history.jsonl\"):\n        self.storage_path = storage_path\n        # Ensure the directory for the storage path exists\n        storage_dir = os.path.dirname(self.storage_path)\n        if storage_dir and not os.path.exists(storage_dir):\n            os.makedirs(storage_dir, exist_ok=True)\n\n    def save_session(self, record: SessionRecord):\n        \"\"\"Appends a session record to the storage file.\"\"\"\n        if record.outcome == \"in_progress\" and record.end_time is None:\n            record.end_time = datetime.datetime.utcnow()\n\n        with open(self.storage_path, \"a\", encoding=\"utf-8\") as f:\n            f.write(record.model_dump_json())\n            f.write(\"\\n\")\n\n    def load_all_sessions(self) -> List[SessionRecord]:\n        \"\"\"Loads all session records from the storage file.\"\"\"\n        if not os.path.exists(self.storage_path):\n            return []\n\n        records = []\n        with open(self.storage_path, \"r\", encoding=\"utf-8\") as f:\n            for line_number, line in enumerate(f, 1):\n                if line.strip():\n                    try:\n                        data = json.loads(line)\n                        records.append(SessionRecord.model_validate(data))\n                    except json.JSONDecodeError as e:\n                        print(f\"Warning: Skipping malformed JSON line {line_number} in '{self.storage_path}': {e}\")\n                    except Exception as e:\n                        print(f\"Warning: Skipping record on line {line_number} due to data conversion error: {e}\")\n\n        return records\n\n    def get_session_by_id(self, session_id: str) -> Optional[SessionRecord]:\n        \"\"\"Retrieves a specific session by its ID.\"\"\"\n        for session in self.load_all_sessions():\n            if session.session_id == session_id:\n                return session\n        return None"}
{"code_id": "ODesign_src_utils_train_metrics.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\ODesign_src_utils_train_metrics.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\ODesign_src_utils_train_metrics.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\ODesign_src_utils_train_metrics.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "ODesign_src_utils_train_metrics.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\ODesign_src_utils_train_metrics.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\ODesign_src_utils_train_metrics.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\ODesign_src_utils_train_metrics.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "OGhidra_src_session_store.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\OGhidra_src_session_store.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\OGhidra_src_session_store.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\OGhidra_src_session_store.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "# Session history storage and retrieval.\n\nimport json\nimport os\nimport datetime\nfrom typing import List, Dict, Any, Optional\n\nfrom .memory_models import SessionRecord, ToolCallRecord\n\nclass SessionHistoryStore:\n    def __init__(self, storage_path: str = \"session_history.jsonl\"):\n        self.storage_path = storage_path\n        # Ensure the directory for the storage path exists\n        storage_dir = os.path.dirname(self.storage_path)\n        if storage_dir and not os.path.exists(storage_dir):\n            os.makedirs(storage_dir, exist_ok=True)\n\n    def save_session(self, record: SessionRecord):\n        \"\"\"Appends a session record to the storage file.\"\"\"\n        if record.outcome == \"in_progress\" and record.end_time is None:\n            record.end_time = datetime.datetime.utcnow()\n\n        with open(self.storage_path, \"a\", encoding=\"utf-8\") as f:\n            f.write(record.model_dump_json())\n            f.write(\"\\n\")\n\n    def load_all_sessions(self) -> List[SessionRecord]:\n        \"\"\"Loads all session records from the storage file.\"\"\"\n        if not os.path.exists(self.storage_path):\n            return []\n\n        records = []\n        with open(self.storage_path, \"r\", encoding=\"utf-8\") as f:\n            for line_number, line in enumerate(f, 1):\n                if line.strip():\n                    try:\n                        data = json.loads(line)\n                        records.append(SessionRecord.model_validate(data))\n                    except json.JSONDecodeError as e:\n                        print(f\"Warning: Skipping malformed JSON line {line_number} in '{self.storage_path}': {e}\")\n                    except Exception as e:\n                        print(f\"Warning: Skipping record on line {line_number} due to data conversion error: {e}\")\n\n        return records\n\n    def get_session_by_id(self, session_id: str) -> Optional[SessionRecord]:\n        \"\"\"Retrieves a specific session by its ID.\"\"\"\n        for session in self.load_all_sessions():\n            if session.session_id == session_id:\n                return session\n        return None"}
{"code_id": "OGhidra_src_session_store.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\OGhidra_src_session_store.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\OGhidra_src_session_store.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\OGhidra_src_session_store.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "# Session history storage and retrieval.\n\nimport json\nimport os\nimport datetime\nfrom typing import List, Dict, Any, Optional\n\nfrom .memory_models import SessionRecord, ToolCallRecord\n\nclass SessionHistoryStore:\n    def __init__(self, storage_path: str = \"session_history.json\"):\n        self.storage_path = storage_path\n        # Ensure the directory for the storage path exists\n        storage_dir = os.path.dirname(self.storage_path)\n        if storage_dir and not os.path.exists(storage_dir):\n            os.makedirs(storage_dir, exist_ok=True)\n\n    def save_session(self, record: SessionRecord):\n        \"\"\"Append a session record to the storage file.\"\"\"\n        if record.outcome == \"in_progress\" and record.end_time is None:\n            record.end_time = datetime.datetime.utcnow()\n\n        with open(self.storage_path, \"a\", encoding=\"utf-8\") as f:\n            f.write(record.model_dump_json())\n            f.write(\"\\n\")\n\n    def load_all_sessions(self) -> List[SessionRecord]:\n        \"\"\"Loads all session records from the storage file.\"\"\"\n        if not os.path.exists(self.storage_path):\n            return []\n\n        records = []\n        with open(self.storage_path, \"r\", encoding=\"utf-8\") as f:\n            for line_number, line in enumerate(f, 1):\n                if line.strip():\n                    try:\n                        data = json.loads(line)\n                        records.append(SessionRecord.model_validate(data))\n                    except json.JSONDecodeError as e:\n                        print(f\"Warning: Skipping malformed JSON line {line_number} in '{self.storage_path}': {e}\")\n                    except Exception as e:\n                        print(f\"Warning: Skipping record on line {line_number} due to data conversion error: {e}\")\n        return records\n\n    def get_session_by_id(self, session_id: str) -> Optional[SessionRecord]:\n        \"\"\"Retrieves a specific session by its ID.\"\"\"\n        for session in self.load_all_sessions():\n            if session.session_id == session_id:\n                return session\n        return None"}
{"code_id": "OGhidra_src_session_store.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\OGhidra_src_session_store.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\OGhidra_src_session_store.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\OGhidra_src_session_store.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": "import json\nimport os\nimport datetime\nfrom typing import List, Dict, Any, Optional\nfrom .common import BaseInfluence, SimilarInfluence\n\nclass JsonInfluenceStorage:\n    __slots__ = ('_base_storage_path', '_storage_path')\n    def __init__(self, storage_path: str = 'influence_history.json'):\n        self._base_storage_path = storage_path\n        self._storage_path = storage_path\n        # Ensure the directory for the storage path exists\n        storage_dir = os.path.dirname(storage_path)\n        if storage_dir and not os.path.exists(storage_dir):\n            os.makedirs(storage_dir, exist_ok=True)\n\n    def _append_to_storage(self, record: BaseInfluence):\n        \"\"\"Appends a new record to the storage file.\"\"\"\n        if record.__class__.__name__ == 'Progress' and record.system is None:\n            record.system = 'default'\n\n        with open(self._storage_path, 'a') as f:\n            if f.tell() != 0:\n                f.write('\\n')\n            json.dump(record.to_dict(), f)\n\n    def _load_all_records(self) -> List[BaseInfluence]:\n        \"\"\"Loads all records records from the storage file.\"\"\"\n        if not os.path.exists(self._storage_path):\n            return []\n\n        records = []\n        with open(self._storage_path, 'r') as f:\n            for line_number, line in enumerate(f, 1):\n                if not line.strip():\n                    continue\n\n                try:\n                    data = json.loads(line)\n                    record = BaseInfluence.from_dict(data)\n                    records.append(record)\n                except json.JSONDecodeError as e:\n                    print(f\"Warning: Skipping malformed JSON line {line_number}: {e}\")\n                except Exception as e:\n                    print(f\"Warning: Skipping record on line {line_number} due to data conversion error: {e}\")\n\n        return records\n\n    def _find_record_by_id(self, record_id: str) -> Optional[BaseInfluence]:\n        \"\"\"Finds a specific record by its ID.\"\"\"\n        for record in self._load_all_records():\n            if record.id == record_id:\n                return record\n        return None"}
{"code_id": "Puffin_src_models_radiov3_cls_token.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Puffin_src_models_radiov3_cls_token.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\Puffin_src_models_radiov3_cls_token.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\Puffin_src_models_radiov3_cls_token.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "# Copyright (c) 2023-2024, NVIDIA CORPORATION. All rights reserved.\n#\n# NVIDIA CORPORATION and its licensors retain all intellectual property\n# and proprietary rights in to this software, related documentation\n# and any modifications thereto. Any use, reproduction, disclosure or\n# distribution of this software and related documentation without an express\n# license agreement from NVIDIA CORPORATION is strictly prohibited.\nfrom typing import Optional\n\nimport torch\nfrom torch import nn\n\nclass ClsToken(nn.Module):\n    def __init__(self, ndim: int,\n                     num_tokens: int = 1,\n                     enabled: bool = True,\n                     register_multiple: Optional[int] = None,\n                     num_registers: Optional[int] = None,\n    ):\n        super().__init__()\n\n        self.ndim = ndim\n        self.enabled = enabled\n        self.num_registers = 0\n        self.num_tokens = num_tokens\n        if enabled:\n            if num_registers:\n                self.num_registers = num_registers\n            elif register_multiple:\n                self.num_registers = register_multiple - (num_tokens % register_multiple)\n\n            scale = ndim ** -0.5\n            self.token = nn.Parameter(torch.randn(num_tokens + self.num_registers, ndim) * scale)\n        else:\n            self.token = None\n\n        self.num_patches = self.num_tokens + self.num_registers\n\n    def disable(self):\n        self.token = None\n        self.enabled = False\n\n    def forward(self, x: torch.Tensor):\n        if self.token is None:\n            return x\n        token = self.token.unsqueeze(0).expand(x.shape[0], -1, -1)\n        x = torch.cat([\n            token,\n            x,\n        ], dim=1)\n\n        return x\n\n    def no_weight_decay(self):\n        return [\n            'token',\n        ]"}
{"code_id": "Puffin_src_models_radiov3_cls_token.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Puffin_src_models_radiov3_cls_token.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\Puffin_src_models_radiov3_cls_token.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\Puffin_src_models_radiov3_cls_token.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "# Copyright (c) 2023-2024, NVIDIA CORPORATION.  All rights reserved.\n#\n# NVIDIA CORPORATION and its licensors retain all intellectual property\n# and proprietary rights in and to this software, related documentation\n# and any modifications thereto.  Any use, reproduction, disclosure or\n# distribution of this software and related documentation without an express\n# license agreement from NVIDIA CORPORATION is strictly prohibited.\nfrom typing import Optional\n\nimport torch\nfrom torch import nn\n\n\nclass ClsToken(nn.Module):\n    def __init__(self, ndim: int,\n                     num_tokens: int = 1,\n                     enabled: bool = True,\n                     register_multiple: Optional[int] = None,\n                     num_registers: Optional[int] = None,\n    ):\n        super().__init__()\n\n        self.ndim = ndim\n        self.enabled = enabled\n        self.num_registers = 0\n        self.num_tokens = num_tokens\n        if enabled:\n            if num_registers:\n                self.num_registers = num_registers\n            elif register_multiple:\n                self.num_registers = register_multiple - (num_tokens % register_multiple)\n\n            scale = ndim ** -0.5\n            self.token = nn.Parameter(torch.randn(num_tokens + self.num_registers, ndim) * scale)\n        else:\n            self.token = None\n\n        self.num_patches = self.num_tokens + self.num_registers\n\n    def disable(self):\n        self.token = None\n        self.enabled = False\n\n    def forward(self, x: torch.Tensor):\n        if self.token is None:\n            return x\n\n        token = self.token.unsqueeze(0).expand(x.shape[0], -1, -1)\n        x = torch.cat([token, x], dim=1)\n        return x\n\n    def no_weight_decay(self):\n        return [\n            'token',\n        ]"}
{"code_id": "OGhidra_src_session_store.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\OGhidra_src_session_store.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\OGhidra_src_session_store.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\OGhidra_src_session_store.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": "# -*- coding: utf-8 -*-\n# vi:si:et:sw=4:sts=4:ts=8\n# sCon:tags:#: -F\n\nfrom __future__ import division\n\nfrom datetime import datetime, timedelta\n\nfrom storm.locals import *\n\nfrom storm.databases.sqlite import SQLite\nfrom storm.databases.mysql import MySQL\n\nclass Storage(object):\n    \"\"\"A storage object for the storage with sqlite\n    storage or a mysql at remote host storage with\n    username, password and host name as connection\n    parameters or a local sqlite storage file.\"\"\"\n    def __init__(self, storage_type, username=None,\n                     password=None, host=None, database=None,\n                     storage_file=None):\n        \"\"\"Initialize the storage object with the storage\n        type and the connection parameters.\"\"\"\n        self.storage_type = storage_type\n        self.username = username\n        self.password = password\n        self.host = host\n        self.database = database\n        self.storage_file = storage_file\n        self.database = None\n        self.store = None\n\n    def connect(self):\n        \"\"\"Connect to the storage with the given\n        connection parameters.\"\"\"\n        if self.storage_type == 'sqlite':\n            self.database = SQLite(self.storage_file)\n        elif self.storage_type == 'mysql':\n            self.database = MySQL(\n                self.username, self.password, self.host,\n                self.database)\n        else:\n            raise ValueError(\"Invalid storage type: %s\" %\n                                   self.storage_type)\n        self.store = Store(self.database)\n\n    def disconnect(self):\n        \"\"\"Disconnect from the storage.\"\"\"\n        if self.store:\n            self.store.close()\n        self.store = None\n        self.database = None\n\n    def add_message(self, message):\n        \"\"\"Add a message to the storage.\"\"\"\n        self.store.add(message)\n        self.store.commit()\n\n    def get_message(self, message_id):\n        \"\"\"Get a message from the storage by its ID.\"\"\"\n        return self.store.get(Message, message_id)\n\n    def get_messages(self, limit=None, offset=None):\n        \"\"\"Get a list of messages from the storage.\"\"\"\n        query = self.store.find(Message)\n        if limit is not None:\n            query = query.limit(limit)\n        if offset is not None:\n            query = query.offset(offset)\n        return query.order_by(Message.id)\n\n    def delete_message(self, message_id):\n        \"\"\"Delete a message from the storage by its ID.\"\"\"\n        message = self.store.get(Message, message_id)\n        self.store.remove(message)\n        self.store.commit()"}
{"code_id": "Ragnar_epd_helper.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Ragnar_epd_helper.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\Ragnar_epd_helper.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\Ragnar_epd_helper.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "import importlib\nimport logging\n\nlogger = logging.getLogger(__name__)\n\nclass EPDHelper:\n    def __init__(self, epd_type):\n        self.epd_type = epd_type\n        self.epd = self._load_epd_module()\n\n    def _load_epd_module(self):\n        try:\n            epd_module_name = f'resources.waveshare_epd.{self.epd_type}'\n            epd_module = importlib.import_module(epd_module_name)\n            return epd_module.EPD()\n        except ImportError as e:\n            logger.error(f\"EPD module {self.epd_type} not found: {e}\")\n            raise\n        except Exception as e:\n            logger.error(f\"Error loading EPD module {self.epd_type}: {e}\")\n            raise\n\n    def init_full_update(self):\n        try:\n            if hasattr(self.epd, 'FULL_UPDATE'):\n                self.epd.init(self.epd.FULL_UPDATE)\n            elif hasattr(self.epd, 'lut_full_update'):\n                self.epd.init(self.epd.lut_full_update)\n            else:\n                self.epd.init()\n            logger.info(\"EPD full update initialization complete.\")\n        except Exception as e:\n            logger.error(f\"Error initializing EPD for full update: {e}\")\n            raise\n\n    def init_partial_update(self):\n        try:\n            if hasattr(self.epd, 'PART_UPDATE'):\n                self.epd.init(self.epd.PART_UPDATE)\n            elif hasattr(self.epd, 'lut_partial_update'):\n                self.epd.init(self.epd.lut_partial_update)\n            else:\n                self.epd.init()\n            logger.info(\"EPD partial update initialization complete.\")\n        except Exception as e:\n            logger.error(f\"Error initializing EPD for partial update: {e}\")\n            raise\n\n    def display_partial(self, image):\n        try:\n            if hasattr(self.epd, 'displayPartial'):\n                self.epd.displayPartial(self.epd.getbuffer(image))\n            else:\n                self.epd.display(self.epd.getbuffer(image))\n            logger.info(\"Partial display update complete.\")\n        except Exception as e:\n            logger.error(f\"Error during partial display update: {e}\")\n            raise\n\n    def clear(self):\n        try:\n            self.epd.Clear()\n            logger.info(\"EPD cleared.\")\n        except Exception as e:\n            logger.error(f\"Error clearing EPD: {e}\")\n            raise\n\n    def display_full(self, image):\n        \"\"\"Display image on EPD using full update.\"\"\"\n        try:\n            self.epd.display(self.epd.getbuffer(image))\n            logger.info(\"Full display update complete.\")\n        except Exception as e:\n            logger.error(f\"Error during full display update: {e}\")\n            raise\n\n    def sleep(self):\n        \"\"\"Put EPD to sleep mode.\"\"\"\n        try:\n            self.epd.sleep()\n            logger.info(\"EPD sleep mode activated.\")\n        except Exception as e:\n            logger.error(f\"Error putting EPD to sleep: {e}\")\n            raise"}
{"code_id": "Puffin_src_models_radiov3_cls_token.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Puffin_src_models_radiov3_cls_token.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\Puffin_src_models_radiov3_cls_token.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\Puffin_src_models_radiov3_cls_token.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": "class ... (maybe a test class)\n    def __init__(self, ...):\n        self._mask = None\n        self._mask_shape = None\n        self._mask_indices = None\n        self._mask_indices = None\n\n    def add(self, ...):\n        self._mask = None\n        self._mask_shape = None\n        self._mask_indices = None\n        self._mask_indices = None\n\n    def apply_mask(self, ...):\n        return 1\n\n    def get_shape(self):\n        return 1"}
{"code_id": "Puffin_src_models_radiov3_cls_token.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Puffin_src_models_radiov3_cls_token.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\Puffin_src_models_radiov3_cls_token.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\Puffin_src_models_radiov3_cls_token.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "# Copyright (c) 2023-2024, NVIDIA CORPORATION. All rights reserved.\n#\n# NVIDIA CORPORATION and its licensors retain all intellectual property\n# and proprietary rights in and to this software, related documentation\n# and any modifications thereto. Any use, reproduction, disclosure or\n# distribution of this software and related documentation without an express\n# license agreement from NVIDIA CORPORATION is strictly prohibited.\nfrom typing import Optional\n\nimport torch\nfrom torch import nn\n\nclass CisFaken(nn.Module):\n    def __init__(self, radius: int,\n                     num_tokens: int = 1,\n                     enabled: bool = True,\n                     register_multiple: Optional[int] = None,\n                     num_registers: Optional[int] = None,\n                    ):\n        super().__init__()\n\n        self.radius = radius\n        self.enabled = enabled\n        self.num_registers = 0\n        self.num_tokens = num_tokens\n        if enabled:\n            if num_registers:\n                self.num_registers = num_registers\n            elif register_multiple:\n                self.num_registers = register_multiple - (num_tokens % register_multiple)\n\n            scale = radius ** -0.5\n            self.token = nn.Parameter(torch.randn(num_tokens, self.num_registers, radius) * scale)\n        else:\n            self.token = None\n\n        self.num_patches = self.num_tokens + self.num_registers\n\n    def disable(self):\n        self.token = None\n        self.enabled = False\n\n    def forward(self, x: torch.Tensor):\n        if self.token is None:\n            #Forth x\n            return x\n        else:\n            token = self.token.unsqueeze(0).expand(x.shape[0], -1, -1)\n            x = torch.cat([\n                token,\n                x,\n            ], dim=1)\n            return x\n\n    def no_weight_decay(self):\n        return [\n            \"token\",\n        ]"}
{"code_id": "Puffin_src_models_radiov3_cls_token.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Puffin_src_models_radiov3_cls_token.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\Puffin_src_models_radiov3_cls_token.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\Puffin_src_models_radiov3_cls_token.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": "# Copyright (c) 2010-2014, NetEase, Inc. All rights reserved.\n#\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions\n# are met:\n#  1. Redistributions of source code must retain the above copyright\n#     notice, this list of conditions and the following disclaimer.\n#  2. Redistributions in binary form must reproduce the above copyright\n#     notice, this list of conditions and the following disclaimer in\n#     the documentation and/or other materials provided with the\n#     distribution.\n#  3. Neither the name of the NetEase, Inc. nor the names of\n#     its contributors may be used to endorse or promote products\n#     derived from this software without specific prior written permission.\n#\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n# \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n# A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n# HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n# SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED\n# TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR\n# PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF\n# LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING\n# NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\n# SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\nfrom typing import List, Optional\n\nimport torch\nfrom torch import nn\n\nclass GatedAttention(nn.Module):\n    def __init__(self, dim, num_heads, dropout=0.):\n        super().__init__()\n        self.num_heads = num_heads\n        head_dim = dim // num_heads\n        self.scale = head_dim ** -0.5\n\n        self.qkv = nn.Linear(dim, dim * 3, bias=False)\n        self.attn_drop = nn.Dropout(dropout)\n        self.proj = nn.Linear(dim, dim)\n        self.proj_drop = nn.Dropout(dropout)\n\n    def forward(self, x):\n        B, N, C = x.shape\n        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(3, 0, 1, 2, 4)\n        q, k, v = qkv.unbind(3)\n\n        attn = (q @ k.transpose(-2, -1))) * self.scale\n        attn = attn.softmax(dim=-1)\n        attn = self.attn_drop(attn)\n\n        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n        x = self.proj(x)\n        x = self.proj_drop(x)\n        return x\n\n    def extra_repr(self) -> str:\n        return super().extra_repr()\n\n    def __repr__(self) -> str:\n        return super().__repr__()"}
{"code_id": "Ragnar_epd_helper.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Ragnar_epd_helper.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\Ragnar_epd_helper.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\Ragnar_epd_helper.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "import importlib\nimport logging\n\nlogger = logging.getLogger(__name__)\n\nclass EPDHelper:\n    def __init__(self, epd_type):\n        self.epd_type = epd_type\n        self.epd = self._load_epd_module()\n\n    def _load_epd_module(self):\n        try:\n            epd_module_name = f'resources.waveshare_epd.{self.epd_type}'\n            epd_module = importlib.import_module(epd_module_name)\n            return epd_module.EPD()\n        except ImportError as e:\n            logger.error(f\"EPD module {self.epd_type} not found: {e}\")\n            raise\n        except Exception as e:\n            logger.error(f\"Error loading EPD module {self.epd_type}: {e}\")\n            raise\n\n    def init_full_update(self):\n        try:\n            if hasattr(self.epd, 'FULL_UPDATE'):\n                self.epd.init(self.epd.FULL_UPDATE)\n            elif hasattr(self.epd, 'lut_full_update'):\n                self.epd.init(self.epd.lut_full_update)\n            else:\n                self.epd.init()\n            logger.info(\"EPD full update initialization complete.\")\n        except Exception as e:\n            logger.error(f\"Error initializing EPD for full update: {e}\")\n            raise\n\n    def init_partial_update(self):\n        try:\n            if hasattr(self.epd, 'PART_UPDATE'):\n                self.epd.init(self.epd.PART_UPDATE)\n            elif hasattr(self.epd, 'lut_partial_update'):\n                self.epd.init(self.epd.lut_partial_update)\n            else:\n                self.epd.init()\n            logger.info(\"EPD partial update initialization complete.\")\n        except Exception as e:\n            logger.error(f\"Error initializing EPD for partial update: {e}\")\n            raise\n\n    def display_partial(self, image):\n        try:\n            if hasattr(self.epd, 'displayPartial'):\n                self.epd.displayPartial(self.epd.getbuffer(image))\n            else:\n                self.epd.display(self.epd.getbuffer(image))\n            logger.info(\"Partial display update complete.\")\n        except Exception as e:\n            logger.error(f\"Error during partial display update: {e}\")\n            raise\n\n    def clear(self):\n        try:\n            self.epd.Clear()\n            logger.info(\"EPD cleared.\")\n        except Exception as e:\n            logger.error(f\"Error clearing EPD: {e}\")\n            raise\n\n    def display_full(self, image):\n        \"\"\"Display image on EPD using full update.\"\"\"\n        try:\n            self.epd.display(self.epd.getbuffer(image))\n            logger.info(\"Full display update complete.\")\n        except Exception as e:\n            logger.error(f\"Error during full display update: {e}\")\n            raise\n\n    def sleep(self):\n        \"\"\"Put EPD to sleep mode.\"\"\"\n        try:\n            self.epd.sleep()\n            logger.info(\"EPD sleep mode activated.\")\n        except Exception as e:\n            logger.error(f\"Error putting EPD to sleep: {e}\")\n            raise"}
{"code_id": "Ragnar_epd_helper.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Ragnar_epd_helper.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\Ragnar_epd_helper.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\Ragnar_epd_helper.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "import importlib\nimport logging\n\nlogger = logging.getLogger(__name__)\n\nclass EPDHelper:\n    def __init__(self, epd_type):\n        self.epd_type = epd_type\n        self.epd = self._load_epd_module()\n\n    def _load_epd_module(self):\n        try:\n            epd_module_name = f\"epdresources.waveshare_epd.{self.epd_type}\"\n            epd_module = importlib.import_module(epd_module_name)\n            return epd_module.EPD()\n        except ImportError as e:\n            logger.error(f\"EPD module {self.epd_type} not found: {e}\")\n            raise\n        except Exception as e:\n            logger.error(f\"Error loading EPD module {self.epd_type}: {e}\")\n            raise\n\n    def init_full_update(self):\n        try:\n            if hasattr(self.epd, 'FULL_UPDATE'):\n                self.epd.init(self.epd.FULL_UPDATE)\n            elif hasattr(self.epd, 'lut_full_update'):\n                self.epd.init(self.epd.lut_full_update)\n            else:\n                self.epd.init()\n            logger.info(\"EPD full update initialization complete.\")\n        except Exception as e:\n            logger.error(f\"Error initializing EPD for full update: {e}\")\n            raise\n\n    def init_partial_update(self):\n        try:\n            if hasattr(self.epd, 'PART_UPDATE'):\n                self.epd.init(self.epd.PART_UPDATE)\n            elif hasattr(self.epd, 'lut_partial_update'):\n                self.epd.init(self.epd.lut_partial_update)\n            else:\n                self.epd.init()\n            logger.info(\"EPD partial update initialization complete.\")\n        except Exception as e:\n            logger.error(f\"Error initializing EPD for partial update: {e}\")\n            raise\n\n    def display_partial(self, image):\n        try:\n            if hasattr(self.epd, 'displayPartial'):\n                self.epd.displayPartial(self.epd.getbuffer(image))\n            else:\n                self.epd.display(self.epd.getbuffer(image))\n            logger.info(\"Partial display update complete.\")\n        except Exception as e:\n            logger.error(f\"Error during partial display update: {e}\")\n            raise\n\n    def clear(self):\n        try:\n            self.epd.Clear()\n            logger.info(\"EPD cleared.\")\n        except Exception as e:\n            logger.error(f\"Error clearing EPD: {e}\")\n            raise\n\n    def display_full(self, image):\n        \"\"\"Display image on EPD using full update.\"\"\"\n        try:\n            self.epd.display(self.epd.getbuffer(image))\n            logger.info(\"Full display update complete.\")\n        except Exception as e:\n            logger.error(f\"Error during full display update: {e}\")\n            raise\n\n    def sleep(self):\n        \"\"\"Put EPD to sleep mode.\"\"\"\n        try:\n            self.epd.sleep()\n            logger.info(\"EPD sleep mode activated.\")\n        except Exception as e:\n            logger.error(f\"Error putting EPD to sleep: {e}\")\n            raise"}
{"code_id": "Raw-Alchemy_setup.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Raw-Alchemy_setup.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\Raw-Alchemy_setup.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\Raw-Alchemy_setup.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "import os\nimport platform\nimport shutil\nimport sys\nimport urllib.request\nfrom pathlib import Path\n\nfrom setuptools import setup\nfrom setuptools.command.build_py import build_py\n\n\nclass CustomBuildPy(build_py):\n    \"\"\"Custom build command to download and set up Lensfun.\"\"\"\n\n    def run(self):\n        self.download_and_extract_lensfun()\n        super().run()\n\n    def get_download_url(self, asset_name):\n        \"\"\"Gets the download URL for a given asset from the latest GitHub release.\"\"\"\n        api_url = \"https://api.github.com/repos/shenmintao/lensfun/releases/latest\"\n        # Try both GITHUB_TOKEN and GH_TOKEN for compatibility\n        token = os.environ.get(\"GITHUB_TOKEN\") or os.environ.get(\"GH_TOKEN\")\n        headers = {}\n        if token:\n            headers[\"Authorization\"] = f\"token {token}\"\n\n        req = urllib.request.Request(api_url, headers=headers)\n        try:\n            with urllib.request.urlopen(req) as response:\n                data = json.loads(response.read().decode())\n                for asset in data[\"assets\"]:\n                    if asset[\"name\"] == asset_name:\n                        return asset[\"browser_download_url\"]\n        except Exception as e:\n            print(f\"Error fetching release info from GitHub: {e}\", file=sys.stderr)\n        return None\n\n    def download_and_extract_lensfun(self):\n        \"\"\"Downloads and extracts the appropriate Lensfun library.\"\"\"\n        vendor_dir = Path(\"src/raw_alchemy/vendor/lensfun\")\n        vendor_dir.mkdir(parents=True, exist_ok=True)\n\n        system = platform.system().lower()\n        if system == \"windows\":\n            asset_name = \"lensfun-windows.zip\"\n        elif system == \"linux\":\n            asset_name = \"lensfun-linux.tar.gz\"\n        elif system == \"darwin\":\n            asset_name = \"lensfun-macos.tar.gz\"\n        else:\n            print(f\"Unsupported system: {system}\", file=sys.stderr)\n            sys.exit(1)\n\n        download_url = self.get_download_url(asset_name)\n        if not download_url:\n            print(f\"Could not find download URL for {asset_name}\", file=sys.stderr)\n            sys.exit(1)\n\n        archive_path = asset_name\n        try:\n            print(f\"Downloading Lensfun for {system} from {download_url}...\")\n            with urllib.request.urlopen(download_url) as response, open(\n                archive_path, \"wb\"\n            ) as out_file:\n                shutil.copyfileobj(response, out_file)\n\n            print(\"Extracting Lensfun...\")\n            shutil.unpack_archive(archive_path, vendor_dir)\n            os.remove(archive_path)\n            print(\"Lensfun setup complete.\")\n        except Exception as e:\n            print(f\"Error during Lensfun setup: {e}\", file=sys.stderr)\n            sys.exit(1)\n\n\nsetup(\n    cmdclass={\n        \"build_py\": CustomBuildPy,\n    }\n)"}
{"code_id": "Ragnar_epd_helper.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Ragnar_epd_helper.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\Ragnar_epd_helper.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\Ragnar_epd_helper.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "Raw-Alchemy_setup.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Raw-Alchemy_setup.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\Raw-Alchemy_setup.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\Raw-Alchemy_setup.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "import os\nimport platform\nimport shutil\nimport sys\nimport urllib.request\nfrom pathlib import Path\n\nfrom setuptools import setup\nfrom setuptools.command.build_py import build_py\n\n\nclass CustomBuildPy(build_py):\n    \"\"\"Custom build command to download and set up Lensfun.\"\"\"\n\n    def run(self):\n        self.download_and_extract_lensfun()\n        super().run()\n\n    def get_download_url(self, asset_name):\n        \"\"\"Gets the download URL for a given asset from the latest GitHub release.\"\"\"\n        api_url = \"https://api.github.com/repos/shentao/lensfun/releases/latest\"\n        # Try both GITHUB_TOKEN and GH_TOKEN for compatibility\n        token = os.environ.get(\"GITHUB_TOKEN\") or os.environ.get(\"GH_TOKEN\")\n        headers = {}\n        if token:\n            headers[\"Authorization\"] = f\"token {token}\"\n\n        req = urllib.request.Request(api_url, headers=headers)\n        try:\n            with urllib.request.urlopen(req) as response:\n                data = json.loads(response.read().decode())\n                for asset in data[\"assets\"]:\n                    if asset[\"name\"] == asset_name:\n                        return asset[\"browser_download_url\"]\n        except Exception as e:\n            print(f\"Error fetching release info from GitHub: {e}\", file=sys.stderr)\n        return None\n\n    def download_and_extract_lensfun(self):\n        \"\"\"Downloads and extracts the appropriate Lensfun library.\"\"\"\n        vendor_dir = Path(\"src/raw_alchemy/vendor/lensfun\")\n        vendor_dir.mkdir(parents=True, exist_ok=True)\n\n        system = platform.system().lower()\n        if system == \"windows\":\n            asset_name = \"lensfun-windows.zip\"\n        elif system == \"linux\":\n            asset_name = \"lensfun-linux.tar.gz\"\n        elif system == \"darwin\":\n            asset_name = \"lensfun-macos.tar.gz\"\n        else:\n            print(f\"Unsupported system: {system}\", file=sys.stderr)\n            sys.exit(1)\n\n        download_url = self.get_download_url(asset_name)\n        if not download_url:\n            print(f\"Could not find download URL for {asset_name}\", file=sys.stderr)\n            sys.exit(1)\n\n        archive_path = asset_name\n        try:\n            print(f\"Downloading Lensfun for {system} from {download_url}...\")\n            with urllib.request.urlopen(download_url) as response, open(\n                archive_path, \"wb\"\n            ) as out_file:\n                shutil.copyfileobj(response, out_file)\n\n            print(\"Extracting Lensfun...\")\n            shutil.unpack_archive(archive_path, vendor_dir)\n            os.remove(archive_path)\n            print(\"Lensfun setup complete.\")\n\n        except Exception as e:\n            print(f\"Error during Lensfun setup: {e}\", file=sys.stderr)\n            sys.exit(1)\n\n\nsetup(\n    cmdclass={\n        \"build_py\": CustomBuildPy,\n    }\n)"}
{"code_id": "Ragnar_epd_helper.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Ragnar_epd_helper.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\Ragnar_epd_helper.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\Ragnar_epd_helper.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "Raw-Alchemy_setup.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Raw-Alchemy_setup.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\Raw-Alchemy_setup.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\Raw-Alchemy_setup.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "import os\nimport platform\nimport shutil\nimport sys\nimport urllib.request\nfrom pathlib import Path\n\nfrom setuptools import setup\nfrom setuptools.command.build_py import build_py\n\nclass CustomBuildPy(build_py):\n    \"\"\"Custom build command to download and set up Lensfun.\"\"\"\n\n    def run(self):\n        self.download_and_extract_lensfun()\n        super().run()\n\n    def get_download_url(self, asset_name):\n        \"\"\"Get the download URL for a given asset from the latest GitHub release.\"\"\"\n        api_url = \"https://api.github.com/repos/lensfun/lensfun/releases/latest\"\n        # Try both GITHUB_TOKEN and GH_TOKEN for compatibility\n        token = os.environ.get(\"GITHUB_TOKEN\") or os.environ.get(\"GH_TOKEN\")\n        headers = {}\n        if token:\n            headers[\"Authorization\"] = f\"token {token}\"\n        req = urllib.request.Request(api_url, headers=headers)\n        try:\n            with urllib.request.urlopen(req) as response:\n                data = json.loads(response.read().decode())\n                for asset in data[\"assets\"]:\n                    if asset[\"name\"] == asset_name:\n                        return asset[\"browser_download_url\"]\n        except Exception as e:\n            print(f\"Error fetching release info from GitHub: {e}\", file=sys.stderr)\n            return None\n        return None\n\n    def download_and_extract_lensfun(self):\n        \"\"\"Downloads and extracts the appropriate Lensfun library.\"\"\"\n        vendor_dir = Path(\"src/lensfun/lensfun\")\n        vendor_dir.mkdir(parents=True, exist_ok=True)\n\n        system = platform.system().lower()\n        if system == \"windows\":\n            asset_name = \"lensfun-windows.zip\"\n        elif system == \"linux\":\n            asset_name = \"lensfun-linux.tar.gz\"\n        elif system == \"darwin\":\n            asset_name = \"lensfun-macos.tar.gz\"\n        else:\n            print(f\"Unsupported system: {system}\", file=sys.stderr)\n            sys.exit(1)\n\n        download_url = self.get_download_url(asset_name)\n        if not download_url:\n            print(f\"Could not find download URL for {asset_name}\", file=sys.stderr)\n            sys.exit(1)\n\n        archive_path = asset_name\n        try:\n            print(f\"Downloading Lensfun for {system} from {download_url}...\")\n            with urllib.request.urlopen(download_url) as response, open(\n                archive_path, \"wb\"\n            ) as out_file:\n                shutil.copyfileobj(response, out_file)\n\n            print(\"Extracting Lensfun...\")\n            shutil.unpack_archive(archive_path, vendor_dir)\n            os.remove(archive_path)\n            print(\"Lensfun setup complete.\")\n        except Exception as e:\n            print(f\"Error during Lensfun setup: {e}\", file=sys.stderr)\n            sys.exit(1)\n\nsetup(\n    cmdclass={\n        \"build_py\": CustomBuildPy,\n    }\n)"}
{"code_id": "Rebecca_app_utils_store.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Rebecca_app_utils_store.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\Rebecca_app_utils_store.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\Rebecca_app_utils_store.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "class MemoryStorage:\n    def __init__(self):\n        self._data = {}\n\n    def set(self, key, value):\n        self._data[key] = value\n\n    def get(self, key, default=None):\n        return self._data.get(key, default)\n\n    def delete(self, key):\n        self._data.pop(key, None)\n\n    def clear(self):\n        self._data.clear()\n\nclass ListStorage(list):\n    def __init__(self, update_func):\n        super().__init__()\n        self.update_func = update_func\n\n    def __getitem__(self, index):\n        if not self:\n            self.update()\n\n        return super().__getitem__(index)\n\n    def __iter__(self):\n        if not self:\n            self.update()\n\n        return super().__iter__()\n\n    def __str__(self):\n        if not self:\n            self.update()\n\n        return super().__str__()\n\n    def update(self):\n        self.update_func(self)\n\nclass DictStorage(dict):\n    def __init__(self, update_func):\n        super().__init__()\n        self.update_func = update_func\n\n    def __getitem__(self, key):\n        if not self:\n            self.update()\n\n        return super().__getitem__(key)\n\n    def __iter__(self):\n        if not self:\n            self.update()\n\n        return super().__iter__()\n\n    def __str__(self):\n        if not self:\n            self.update()\n\n        return super().__str__()\n\n    def values(self):\n        if not self:\n            self.update()\n\n        return super().values()\n\n    def keys(self):\n        if not self:\n            self.update()\n\n        return super().keys()\n\n    def get(self, key, default=None):\n        if not self:\n            self.update()\n\n        return super().get(key, default)\n\n    def update(self):\n        self.update_func(self)"}
{"code_id": "Rebecca_app_utils_store.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Rebecca_app_utils_store.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\Rebecca_app_utils_store.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\Rebecca_app_utils_store.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "class MemoryStorage:\n    def __init__(self):\n        self._data = {}\n\n    def set(self, key, value):\n        self._data[key] = value\n\n    def get(self, key, default=None):\n        return self._data.get(key, default)\n\n    def delete(self, key):\n        self._data.pop(key, None)\n\n    def clear(self):\n        self._data.clear()\n\nclass ListStorage(list):\n    def __init__(self, update_func):\n        super().__init__()\n        self.update_func = update_func\n\n    def __getitem__(self, index):\n        if not self:\n            self.update()\n\n        return super().__getitem__(index)\n\n    def __iter__(self):\n        if not self:\n            self.update()\n\n        return super().__iter__()\n\n    def __str__(self):\n        if not self:\n            self.update()\n\n        return super().__str__()\n\n    def update(self):\n        self.update_func(self)\n\nclass DictStorage(dict):\n    def __init__(self, update_func):\n        super().__init__()\n        self.update_func = update_func\n\n    def __getitem__(self, key):\n        if not self:\n            self.update()\n\n        return super().__getitem__(key)\n\n    def __iter__(self):\n        if not self:\n            self.update()\n\n        return super().__iter__()\n\n    def __str__(self):\n        if not self:\n            self.update()\n\n        return super().__str__()\n\n    def values(self):\n        if not self:\n            self.update()\n\n        return super().values()\n\n    def keys(self):\n        if not self:\n            self.update()\n\n        return super().keys()\n\n    def get(self, key, default=None):\n        if not self:\n            self.update()\n\n        return super().get(key, default)\n\n    def update(self):\n        self.update_func(self)"}
{"code_id": "Raw-Alchemy_setup.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Raw-Alchemy_setup.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\Raw-Alchemy_setup.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\Raw-Alchemy_setup.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": "def get_download_url():\n    \"\"\"Return the URL to download and set up conda.\"\"\"\n    return (\n        \"https://repo.anaconda.com/miniconda/\"\n        \"Miniconda3-latest-Linux-x86_64.sh\"\n    )\n\ndef get_download_url_for_windows():\n    \"\"\"Return the download URL for a given arch that the target OS that conda\n    supports. Note: this function assumes that conda supports windows\n    x86 and x86_64. Miniconda3-latest-Windows-x86_64.exe\n    is a good choice and it works for both x86 and x86_64 archs. For\n    windows x86 arch, it is not tested and it may not work.\"\"\"\n    return (\n        \"https://repo.anaconda.com/miniconda/\"\n        \"Miniconda3-latest-Windows-x86_64.exe\"\n    )\n\ndef download_and_extract(download_url, extract_dir):\n    \"\"\"Download and extract the miniconda installer.\"\"\"\n    import os\n    import urllib.request\n    import tarfile\n\n    # Download the installer\n    installer_path = os.path.join(extract_dir, \"installer.sh\")\n    urllib.request.urlretrieve(download_url, installer_path)\n\n    # Extract the installer\n    with tarfile.open(installer_path, \"r:gz\") as tar:\n        tar.extractall(path=extract_dir)\n\n    # Clean up the installer\n    os.remove(installer_path)\n\ndef get_conda_envs():\n    \"\"\"Return a list of conda environments.\"\"\"\n    import subprocess\n    import re\n\n    # Get the list of conda environments\n    output = subprocess.check_output([\"conda\", \"env\", \"list\"]).decode(\"utf-8\")\n\n    # Parse the output to get the list of environments\n    envs = []\n    for line in output.splitlines():\n        match = re.match(r\"^\\s*(\\S+)\\s*$\", line)\n        if match:\n            envs.append(match.group(1))\n\n    return envs\n\ndef get_conda_envs_for_windows():\n    \"\"\"Return a list of conda environments for windows.\"\"\"\n    import subprocess\n    import re\n\n    # Get the list of conda environments\n    output = subprocess.check_output([\"conda\", \"env\", \"list\"]).decode(\"utf-8\")\n\n    # Parse the output to get the list of environments\n    envs = []\n    for line in output.splitlines():\n        match = re.match(r\"^\\s*(\\S+)\\s*$\", line)\n        if match:\n            envs.append(match.group(1))\n\n    return envs\n\ndef get_conda_envs_for_linux():\n    \"\"\"Return a list of conda environments for linux.\"\"\"\n    import subprocess\n    import re\n\n    # Get the list of conda environments\n    output = subprocess.check_output([\"conda\", \"env\", \"list\"]).decode(\"utf-8\")\n\n    # Parse the output to get the list of environments\n    envs = []\n    for line in output.splitlines():\n        match = re.match(r\"^\\s*(\\S+)\\s*$\", line)\n        if match:\n            envs.append(match.group(1))\n\n    return envs\n\ndef get_conda_envs_for_macos():\n    \"\"\"Return a list of conda environments for macos.\"\"\"\n    import subprocess\n    import re\n\n    # Get the list of conda environments\n    output = subprocess.check_output([\"conda\", \"env\", \"list\"]).decode(\"utf-8\")\n\n    # Parse the output to get the list of environments\n    envs = []\n    for line in output.splitlines():\n        match = re.match(r\"^\\s*(\\S+)\\s*$\", line)\n        if match:\n            envs.append(match.group(1))\n\n    return envs"}
{"code_id": "Rebecca_app_utils_store.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Rebecca_app_utils_store.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\Rebecca_app_utils_store.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\Rebecca_app_utils_store.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "class DictStorage:\n    def __init__(self):\n        self._data = {}\n\n    def set(self, key, value):\n        self._data[key] = value\n\n    def get(self, key, default=None):\n        return self._data.get(key, default)\n\n    def delete(self, key):\n        self._data.pop(key, None)\n\n    def clear(self):\n        self._data.clear()\n\nclass ListStorage(list):\n    def __init__(self, update_func):\n        super().__init__()\n        self.update_func = update_func\n\n    def __getitem__(self, index):\n        if not self:\n            self.update()\n        return super().__getitem__(index)\n\n    def __iter__(self):\n        if not self:\n            self.update()\n        return super().__iter__()\n\n    def __str__(self):\n        if not self:\n            self.update()\n        return super().__str__()\n\n    def update(self):\n        self.update_func(self)\n\nclass DictStorage(list):\n    def __init__(self, update_func):\n        super().__init__()\n        self.update_func = update_func\n\n    def __getitem__(self, key):\n        if not self:\n            self.update()\n        return super().__getitem__(key)\n\n    def __iter__(self):\n        if not self:\n            self.update()\n        return super().__iter__()\n\n    def __str__(self):\n        if not self:\n            self.update()\n        return super().__str__()\n\n    def values(self):\n        if not self:\n            self.update()\n        return super().values()\n\n    def keys(self):\n        if not self:\n            self.update()\n        return super().keys()\n\n    def get(self, key, default=None):\n        if not self:\n            self.update()\n        return super().get(key, default)\n\n    def update(self):\n        self.update_func(self)"}
{"code_id": "Raw-Alchemy_setup.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Raw-Alchemy_setup.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\Raw-Alchemy_setup.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\Raw-Alchemy_setup.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "Rebecca_app_utils_store.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Rebecca_app_utils_store.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\Rebecca_app_utils_store.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\Rebecca_app_utils_store.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": "def __init__(self):\n    self._data = []\n\ndef __len__(self):\n    return len(self._data)\n\ndef append(self, item):\n    self._data.append(item)\n\ndef pop(self, index=-1):\n    return self._data.pop(index)\n\ndef clear(self):\n    self._data.clear()\n\nclass ListWithMax():\n    def __init__(self, initial_data=None):\n        super().__init__()\n        self._data = []\n        self._max_value = initial_data\n\n    def _get_max(self, current):\n        if not self:\n            return current\n        return max(self._max_value, current)\n\n    def _set_max(self, current):\n        if not self:\n            return current\n        self._max_value = max(self._max_value, current)\n\n    def _get_max_from_data(self):\n        if not self:\n            return None\n        return max(self._data)\n\n    def _set_max_from_data(self):\n        if not self:\n            return None\n        self._max_value = max(self._data)\n\n    def append(self, item):\n        if not self:\n            self._max_value = item\n        else:\n            self._max_value = max(self._max_value, item)\n        super().append(item)\n\n    def pop(self, index=-1):\n        if not self:\n            return None\n        result = super().pop(index)\n        if not self:\n            self._max_value = None\n        else:\n            self._max_value = self._get_max_from_data()\n        return result\n\n    def clear(self):\n        if not self:\n            return None\n        super().clear()\n        self._max_value = None\n\nclass ListWithMax():\n    def __init__(self, initial_data=None):\n        super().__init__()\n        self._data = []\n        self._max_value = initial_data\n\n    def _get_max(self, current):\n        if not self:\n            return current\n        return max(self._max_value, current)\n\n    def _set_max(self, current):\n        if not self:\n            return current\n        self._max_value = max(self._max_value, current)\n\n    def _get_max_from_data(self):\n        if not self:\n            return None\n        return max(self._data)\n\n    def _set_max_from_data(self):\n        if not self:\n            return None\n        self._max_value = max(self._data)\n\n    def append(self, item):\n        if not self:\n            self._max_value = item\n        else:\n            self._max_value = max(self._max_value, item)\n        super().append(item)\n\n    def pop(self, index=-1):\n        if not self:\n            return None\n        result = super().pop(index)\n        if not self:\n            self._max_value = None\n        else:\n            self._max_value = self._get_max_from_data()\n        return result\n\n    def clear(self):\n        if not self:\n            return None\n        super().clear()\n        self._max_value = None"}
{"code_id": "Rebecca_app_utils_store.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Rebecca_app_utils_store.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\Rebecca_app_utils_store.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\Rebecca_app_utils_store.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": "    self._data = []\n    self._data.append(1)\n\ndef sum(self, data):\n    self._summing += sum\n\ndef sum(self, data, summing):\n    return self._data.append(data, summing)\n\ndef sum(self, data):\n    self._data.append(data, data)\n\ndef sum(self, data):\n    self._data.append(data)\n\nclass A:\n    def __init__(self, a):\n        self._a = a\n        self._data = []\n        self._data.append(1, a)\n\n    def get_data(self, data):\n        if not self._a:\n            self._data.append(1)\n\n        return self._data.append(data, data)\n\n    def get_data(self, data):\n        if not self._a:\n            self._data.append(1)\n\n        return self._data.append(data)\n\n    def get_data(self, data):\n        if not self._a:\n            self._data.append(1)\n\n        return self._data.append(data)\n\n    def append_data(self, data):\n        self._data.append(data, data)\n\nclass B:\n    def __init__(self, b):\n        self._b = b\n        self._data = []\n        self._data.append(1, b)\n\n    def get_data(self, data):\n        if not self._b:\n            self._data.append(1)\n\n        return self._data.append(data, data)\n\n    def get_data(self, data):\n        if not self._b:\n            self._data.append(1)\n\n        return self._data.append(data)\n\n    def get_data(self, data):\n        if not self._b:\n            self._data.append(1)\n\n        return self._data.append(data)\n\n    def append_data(self, data):\n        self._data.append(data)\n\n    def append_data(self, data):\n        if not self._b:\n            self._data.append(1)\n\n        return self._data.append(data)\n\n    def append_data(self, data):\n        if not self._b:\n            self._data.append(1)\n\n        return self._data.append(data)\n\n    def append_data(self, data):\n        self._data.append(data, data)"}
{"code_id": "Resume-Agent_backend_agent_flow_base.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Resume-Agent_backend_agent_flow_base.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\Resume-Agent_backend_agent_flow_base.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\Resume-Agent_backend_agent_flow_base.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "from abc import ABC, abstractmethod\nfrom typing import Dict, List, Optional, Union\nfrom pydantic import BaseModel\nfrom backend.agent.agent.base import BaseAgent\n\nclass BaseFlow(BaseModel, ABC):\n    \"\"\"Base class for execution flows supporting multiple agents\"\"\"\n    agents: Dict[str, BaseAgent]\n    tools: Optional[List] = None\n    primary_agent_key: Optional[str] = None\n\n    class Config:\n        arbitrary_types_allowed = True\n\n    def __init__(\n        self, agents: Union[BaseAgent, List[BaseAgent], Dict[str, BaseAgent]], **data\n    ):\n        # Handle different ways of providing agents\n        if isinstance(agents, BaseAgent):\n            agents_dict = {\"default\": agents}\n        elif isinstance(agents, list):\n            agents_dict = {f\"agent_{i}\": agent for i, agent in enumerate(agents)}\n        else:\n            agents_dict = agents\n\n        # If primary agent not specified, use first agent\n        primary_key = data.get(\"primary_agent_key\")\n        if not primary_key and agents_dict:\n            primary_key = next(iter(agents_dict))\n            data[\"primary_agent_key\"] = primary_key\n\n        # Set the agents dictionary\n        data[\"agents\"] = agents_dict\n\n        # Initialize using BaseModel's init\n        super().__init__(**data)\n\n    @property\n    def primary_agent(self) -> Optional[BaseAgent]:\n        \"\"\"Get the primary agent for the flow\"\"\"\n        return self.agents.get(self.primary_agent_key)\n\n    def get_agent(self, key: str) -> Optional[BaseAgent]:\n        \"\"\"Get a specific agent by key\"\"\"\n        return self.agents.get(key)\n\n    def add_agent(self, key: str, agent: BaseAgent) -> None:\n        \"\"\"Add a new agent to the flow\"\"\"\n        self.agents[key] = agent\n\n    @abstractmethod\n    async def execute(self, input_text: str) -> str:\n        \"\"\"Execute the flow with given input\"\"\""}
{"code_id": "Resume-Agent_backend_agent_flow_base.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Resume-Agent_backend_agent_flow_base.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\Resume-Agent_backend_agent_flow_base.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\Resume-Agent_backend_agent_flow_base.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": ""}
{"code_id": "Resume-Agent_backend_agent_flow_base.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Resume-Agent_backend_agent_flow_base.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\Resume-Agent_backend_agent_flow_base.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\Resume-Agent_backend_agent_flow_base.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "from abc import ABC, abstractmethod\nfrom typing import Dict, List, Optional, Union\n\nfrom pydantic import BaseModel\n\nfrom backend.agent.agent.base import BaseAgent\n\nclass BaseFlow(BaseModel, ABC):\n    \"\"\"Base class for execution flows supporting multiple agents\"\"\"\n\n    agents: Dict[str, BaseAgent]\n    tasks: Optional[List[str]] = None\n    primary_agent_key: Optional[str] = None\n\nclass Config:\n    arbitrary_types_allowed = True\n\ndef __init__(\n    self, agents: Union[BaseAgent, List[BaseAgent], Dict[str, BaseAgent]]], **data\n):\n    # Handle different ways of providing agents\n    if isinstance(agents, BaseAgent):\n        agents_dict = {\"default\": agents}\n    elif isinstance(agents, list):\n        agents_dict = {f\"agent_{i}\": agent for i, agent in enumerate(agents)}\n    else:\n        agents_dict = agents\n\n    # If primary agent not specified, use first agent\n    primary_key = data.get(\"primary_agent_key\")\n    if not primary_key and agents_dict:\n        primary_key = next(iter(agents_dict))\n        data[\"primary_agent_key\"] = primary_key\n\n    # Set the agents dictionary\n    data[\"agents\"] = agents_dict\n\n    # Initialize using BaseModel's init\n    super().__init__(**data)\n\n@property\ndef primary_agent(self) -> Optional[BaseAgent]:\n    \"\"\"Get the primary agent for the flow\"\"\"\n    return self.agents.get(self.primary_agent_key)\n\ndef get_agent(self, key: str) -> Optional[BaseAgent]:\n    \"\"\"Get a specific agent by key\"\"\"\n    return self.agents.get(key)\n\ndef add_agent(self, key: str, agent: BaseAgent) -> None:\n    \"\"\"Add a new agent to the flow\"\"\"\n    self.agents[key] = agent\n\n@abstractmethod\nasync def execute(self, input_text: str) -> str:\n    \"\"\"Execute the flow with given input\"\"\""}
{"code_id": "RoboCOIN_src_lerobot_datasets_sampler.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\RoboCOIN_src_lerobot_datasets_sampler.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\RoboCOIN_src_lerobot_datasets_sampler.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\RoboCOIN_src_lerobot_datasets_sampler.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "#!/usr/bin/env python\n#\n# Copyright 2024 The HuggingFace Inc. team. All rights reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nfrom collections.abc import Iterator\n\nimport torch\n\n\nclass EpisodeAwareSampler:\n    def __init__(\n        self,\n        episode_data_index: dict,\n        episode_indices_to_use: list | None = None,\n        drop_n_first_frames: int = 0,\n        drop_n_last_frames: int = 0,\n        shuffle: bool = False,\n    ):\n        \"\"\"Sampler that optionally incorporates episode boundary information.\n\n        Args:\n            episode_data_index: Dictionary with keys 'from' and 'to' containing the start and end indices of each episode.\n            episode_indices_to_use: List of episode indices to use. If None, all episodes are used.\n                Assumes that episodes are indexed from 0 to N-1.\n            drop_n_first_frames: Number of frames to drop from the start of each episode.\n            drop_n_last_frames: Number of frames to drop from the end of each episode.\n            shuffle: Whether to shuffle the indices.\n        \"\"\"\n        indices = []\n        for episode_idx, (start_index, end_index) in enumerate(\n            zip(episode_data_index[\"from\"], episode_data_index[\"to\"], strict=True)\n        ):\n            if episode_indices_to_use is None or episode_idx in episode_indices_to_use:\n                indices.extend(\n                    range(start_index.item() + drop_n_first_frames, end_index.item() - drop_n_last_frames)\n                )\n\n        self.indices = indices\n        self.shuffle = shuffle\n\n    def __iter__(self) -> Iterator[int]:\n        if self.shuffle:\n            for i in torch.randperm(len(self.indices)):\n                yield self.indices[i]\n        else:\n            for i in self.indices:\n                yield i\n\n    def __len__(self) -> int:\n        return len(self.indices)"}
{"code_id": "Resume-Agent_backend_agent_flow_base.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Resume-Agent_backend_agent_flow_base.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\Resume-Agent_backend_agent_flow_base.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\Resume-Agent_backend_agent_flow_base.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "Resume-Agent_backend_agent_flow_base.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Resume-Agent_backend_agent_flow_base.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\Resume-Agent_backend_agent_flow_base.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\Resume-Agent_backend_agent_flow_base.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "RoboCOIN_src_lerobot_datasets_sampler.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\RoboCOIN_src_lerobot_datasets_sampler.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\RoboCOIN_src_lerobot_datasets_sampler.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\RoboCOIN_src_lerobot_datasets_sampler.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "#!/usr/bin/env python\n# Copyright 2024 The HuggingFace Inc. team. All rights reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\nfrom collections.abc import Iterator\n\nimport torch\n\n\nclass EpisodeAwareSampler:\n    def __init__(\n        self,\n        episode_data_index: dict,\n        episode_indices_to_use: list | None = None,\n        drop_n_first_frames: int = 0,\n        drop_n_last_frames: int = 0,\n        shuffle: bool = False,\n    ):\n        \"\"\"Sampler that optionally incorporates episode boundary information.\n\n        Args:\n            episode_data_index: Dictionary with keys 'from' and 'to' containing the start and end indices of each episode.\n            episode_indices_to_use: List of episode indices to use. If None, all episodes are used.\n                Assumes that episodes are indexed from 0 to N-1.\n            drop_n_first_frames: Number of frames to drop from the start of each episode.\n            drop_n_last_frames: Number of frames to drop from the end of each episode.\n            shuffle: Whether to shuffle the indices.\n        \"\"\"\n        indices = []\n        for episode_idx, (start_index, end_index) in enumerate(\n            zip(episode_data_index[\"from\"], episode_data_index[\"to\"], strict=True)\n        ):\n            if episode_indices_to_use is None or episode_idx in episode_indices_to_use:\n                indices.extend(\n                    range(start_index.item() + drop_n_first_frames, end_index.item() - drop_n_last_frames)\n                )\n\n        self.indices = indices\n        self.shuffle = shuffle\n\n    def __iter__(self) -> Iterator[int]:\n        if self.shuffle:\n            for i in torch.randperm(len(self.indices)):\n                yield self.indices[i]\n        else:\n            for i in self.indices:\n                yield i\n\n    def __len__(self) -> int:\n        return len(self.indices)"}
{"code_id": "RoboCOIN_src_lerobot_datasets_sampler.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\RoboCOIN_src_lerobot_datasets_sampler.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\RoboCOIN_src_lerobot_datasets_sampler.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\RoboCOIN_src_lerobot_datasets_sampler.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "# Copyright 2024 The HuggingFace Inc. Team. All rights reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom collections.abc import Iterator\nimport torch\n\n\nclass EpisodeAwareSampler:\n    def __init__(\n        self,\n        episode_data_index: dict,\n        episode_indices_to_use: list | None = None,\n        drop_n_first_frames: int = 0,\n        drop_n_last_frames: int = 0,\n        shuffle: bool = False,\n    ):\n        \"\"\"Sampler that optionally incorporates episode boundary information.\n\n        Args:\n            episode_data_index: Dictionary with keys 'from' and 'to' containing the start and end indices of each episode.\n            episode_indices_to_use: List of episode indices to use. If None, all episodes are used.\n                Assumes that episodes are indexed from 0 to N-1.\n            drop_n_first_frames: Number of frames to drop from the start of each episode.\n            drop_n_last_frames: Number of frames to drop from the end of each episode.\n            shuffle: Whether to shuffle the indices.\n        \"\"\"\n        indices = []\n        for episode_idx, (start_index, end_index) in enumerate(\n            zip(episode_data_index[\"from\"], episode_data_index[\"to\"], strict=True))\n        ):\n            if episode_indices_to_use is None or episode_idx in episode_indices_to_use:\n                indices.extend(\n                    range(start_index + drop_n_first_frames, end_index - drop_n_last_frames))\n                )\n        self.indices = indices\n        self.shuffle = shuffle\n\n    def __iter__(self) -> Iterator[int]:\n        if self.shuffle:\n            for i in torch.randperm(len(self.indices)):\n                yield self.indices[i]\n        else:\n            for i in self.indices:\n                yield i\n\n    def __len__(self) -> int:\n        return len(self.indices)"}
{"code_id": "RoboCOIN_src_lerobot_datasets_sampler.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\RoboCOIN_src_lerobot_datasets_sampler.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\RoboCOIN_src_lerobot_datasets_sampler.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\RoboCOIN_src_lerobot_datasets_sampler.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": "# Copyright 2024 The HuggingFace Team. All rights reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License\n\nfrom ast import literal_eval\n\nimport torch\n\nclass _ConstantShuffle:\n    def __init__(self):\n        self._indices = None\n        self._indices_no_use = None\n        self._num_frames = None\n        self._num_frames_no_use = None\n        self._shuffle = None\n\n    \"\"\"Helper class used to store indices and shuffle boundaries information.\"\"\"\n\n    def __call__(\n        self,\n        audio_indices,\n        indices,\n        drop_n_frames,\n        drop_n_last_frames,\n        shuffle,\n    ):\n        if self._indices is None:\n            self._indices = indices\n            self._indices_no_use = indices\n            self._num_frames = drop_n_frames\n            self._num_frames_no_use = drop_n_last_frames\n            self._shuffle = shuffle\n\n        if audio_indices is None or audio_indices.size(0) == 0:\n            return audio_indices, indices[\"start\"], indices[\"end\"], shuffle\n\n        if shuffle:\n            start_idx = indices[\"start\"] + drop_n_frames\n            end_idx = indices[\"end\"] - drop_n_last_frames\n            range_len = end_idx - start_idx\n            audio_indices = audio_indices[start_idx:end_idx]\n            if shuffle:\n                perm = torch.randperm(range_len)\n                audio_indices = audio_indices[perm]\n        else:\n            start_idx = indices[\"start\"] + drop_n_frames\n            end_idx = indices[\"end\"] - drop_n_last_frames\n            audio_indices = audio_indices[start_idx:end_idx]\n\n        return audio_indices, indices[\"start\"], indices[\"end\"], shuffle\n\ndef _frame_len(frame: torch.Tensor) -> int:\n    if _is_shuffled:\n        return frame.size(0)\n    else:\n        return frame.size(1)\n\ndef _frame_len_no_use(frame: torch.Tensor) -> int:\n    if _is_shuffled:\n        return frame.size(0)\n    else:\n        return frame.size(1)"}
{"code_id": "Romifleur_src_core_config_manager.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Romifleur_src_core_config_manager.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\Romifleur_src_core_config_manager.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\Romifleur_src_core_config_manager.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "import json\nimport os\nimport sys\n\nclass ConfigManager:\n    def __init__(self, settings_file=\"settings.json\", consoles_file=\"consoles.json\"):\n        self.settings_file = settings_file\n        self.consoles_file = consoles_file\n        self.settings = self.load_settings()\n        self.consoles = self.load_consoles()\n\n    def get_resource_path(self, relative_path):\n        \"\"\" Get absolute path to resource, works for dev and for PyInstaller \"\"\"\n        try:\n            # PyInstaller creates a temp folder and stores path in _MEIPASS\n            base_path = sys._MEIPASS\n        except Exception:\n            base_path = os.path.abspath(\".\")\n        return os.path.join(base_path, relative_path)\n\n    def load_settings(self):\n        \"\"\"Load user settings.\"\"\"\n        # Check standard data path first? For now keep local compatibility\n        path = os.path.join(os.getcwd(), \"data\", self.settings_file)\n        if not os.path.exists(path):\n            path = self.settings_file # Fallback to root\n\n        try:\n            if os.path.exists(path):\n                with open(path, \"r\") as f:\n                    return json.load(f)\n        except Exception as e:\n            print(f\"Error loading settings: {e}\")\n\n        return {\"roms_path\": \"ROMs\", \"ra_api_key\": \"\"}\n\n    def save_settings(self):\n        \"\"\"Save user settings.\"\"\"\n        # Save to data/ if it exists, else root\n        data_dir = os.path.join(os.getcwd(), \"data\")\n        if os.path.exists(data_dir):\n            path = os.path.join(data_dir, self.settings_file)\n        else:\n            path = self.settings_file\n\n        try:\n            with open(path, \"w\") as f:\n                json.dump(self.settings, f, indent=4)\n        except Exception as e:\n            print(f\"Error saving settings: {e}\")\n\n    def load_consoles(self):\n        \"\"\"Load static console catalog.\"\"\"\n        try:\n            # Consoles file is a resource, not user data\n            # Check config/ folder or root or resource path\n            paths_to_try = [\n                self.get_resource_path(os.path.join(\"config\", self.consoles_file))),\n                self.get_resource_path(self.consoles_file),\n                \"consoles.json\"\n            ]\n\n            for path in paths_to_try:\n                if os.path.exists(path):\n                    with open(path, 'r') as f:\n                        return json.load(f)\n            return {}\n        except Exception as e:\n            print(f\"Error loading consoles: {e}\")\n            return {}\n\n    def get_download_path(self):\n        path = self.settings.get(\"roms_path\", \"ROMs\")\n        if not os.path.isabs(path):\n            path = os.path.abspath(path)\n\n        if not os.path.exists(path):\n            try:\n                os.makedirs(path, exist_ok=True)\n            except:\n                default = os.path.abspath(\"ROMs\")\n                os.makedirs(default, exist_ok=True)\n                return default\n        return path"}
{"code_id": "Romifleur_src_core_config_manager.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Romifleur_src_core_config_manager.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\Romifleur_src_core_config_manager.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\Romifleur_src_core_config_manager.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "import json\nimport os\nimport sys\n\nclass ConfigManager:\n    def __init__(self, settings_file=\"settings.json\", consoles_file=\"consoles.json\"):\n        self.settings_file = settings_file\n        self.consoles_file = consoles_file\n        self.settings = self.load_settings()\n        self.consoles = self.load_consoles()\n\n    def get_resource_path(self, relative_path):\n        \"\"\" Get absolute path to resource, works for dev and for PyInstaller \"\"\"\n        try:\n            # PyInstaller creates a temp folder and stores path in _MEIPASS\n            base_path = sys._MEIPASS\n        except Exception:\n            base_path = os.path.abspath(\".\")\n        return os.path.join(base_path, relative_path)\n\n    def load_settings(self):\n        \"\"\"Load user settings.\"\"\"\n        # Check standard data path first? For now keep local compatibility\n        path = os.path.join(os.getcwd(), \"data\", self.settings_file)\n        if not os.path.exists(path):\n            path = self.settings_file # Fallback to root\n\n        try:\n            if os.path.exists(path):\n                with open(path, \"r\") as f:\n                    return json.load(f)\n        except Exception as e:\n            print(f\"Error loading settings: {e}\")\n\n        return {\"roms_path\": \"ROMs\", \"ra_api_key\": \"\"}\n\n    def save_settings(self):\n        \"\"\"Save user settings.\"\"\"\n        # Save to data/ if it exists, else root\n        data_dir = os.path.join(os.getcwd(), \"data\")\n        if os.path.exists(data_dir):\n            path = os.path.join(data_dir, self.settings_file)\n        else:\n            path = self.settings_file\n\n        try:\n            with open(path, \"w\") as f:\n                json.dump(self.settings, f, indent=4)\n        except Exception as e:\n            print(f\"Error saving settings: {e}\")\n\n    def load_consoles(self):\n        \"\"\"Load static console catalog.\"\"\"\n        try:\n            # Consoles file is a resource, not user data\n            # Check config/ folder or root or resource path\n            paths_to_try = [\n                self.get_resource_path(os.path.join(\"config\", self.consoles_file))),\n                self.get_resource_path(self.consoles_file),\n                \"consoles.json\"\n            ]\n\n            for path in paths_to_try:\n                if os.path.exists(path):\n                    with open(path, \"r\") as f:\n                        return json.load(f)\n            return []\n        except Exception as e:\n            print(f\"Error loading consoles: {e}\")\n            return []\n\n    def get_download_path(self):\n        path = self.settings.get(\"roms_path\", \"ROMs\")\n        if not os.path.isabs(path):\n            path = os.path.abspath(path)\n\n        if not os.path.exists(path):\n            try:\n                os.makedirs(path, exist_ok=True)\n            except:\n                default = os.path.abspath(\"ROMs\")\n                os.makedirs(default, exist_ok=True)\n                return default\n        return path"}
{"code_id": "RoboCOIN_src_lerobot_datasets_sampler.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\RoboCOIN_src_lerobot_datasets_sampler.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\RoboCOIN_src_lerobot_datasets_sampler.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\RoboCOIN_src_lerobot_datasets_sampler.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "Romifleur_src_core_config_manager.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Romifleur_src_core_config_manager.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\Romifleur_src_core_config_manager.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\Romifleur_src_core_config_manager.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "import sys\n\nclass ConfigManager:\n    def __init__(self, settings_file=\"settings.json\", consoles_file=\"consoles.json\"):\n        self.settings_file = settings_file\n        self.consoles_file = consoles_file\n        self.settings = self.load_settings()\n        self.consoles = self.load_consoles()\n\n    def get_resource_path(self, relative_path):\n        \"\"\"Get absolute path to resource, works for dev and for PyInstaller\"\"\"\n        try:\n            # PyInstaller creates a temp folder and stores path in _MEIPASS\n            base_path = sys._MEIPASS\n        except Exception:\n            base_path = os.path.abspath(\".\")\n        return os.path.join(base_path, relative_path)\n\n    def load_settings(self):\n        \"\"\"Load user settings.\"\"\"\n        # Check standard data path first for now keep local compatibility\n        path = os.path.join(gettempdir(), \"data\", self.settings_file)\n        if not os.path.exists(path):\n            path = self.settings_file  # Fallback to root\n\n        try:\n            if os.path.exists(path):\n                with open(path, 'r') as f:\n                    return json.load(f)\n        except Exception as e:\n            print(f\"Error loading settings: {e}\")\n        return {\"rom_path\": \"ROMs\", \"ra_api_key\": \"\"}\n\n    def save_settings(self):\n        \"\"\"Save user settings.\"\"\"\n        # Save to data/ if it exists, else root\n        data_dir = os.path.join(gettempdir(), \"data\")\n        if os.path.exists(data_dir):\n            path = os.path.join(data_dir, self.settings_file)\n        else:\n            path = self.settings_file\n\n        try:\n            with open(path, 'w') as f:\n                json.dump(self.settings, f, indent=4)\n        except Exception as e:\n            print(f\"Error saving settings: {e}\")\n\n    def load_consoles(self):\n        \"\"\"Load static console catalog.\"\"\"\n        try:\n            # Consoles file is a resource, not user data\n            # Check config/ folder or root or resource path\n            paths_to_try = [\n                self.get_resource_path(os.path.join(\"config\", self.consoles_file))),\n                self.get_resource_path(self.consoles_file),\n                \"consoles.json\"\n            ]\n\n            for path in paths_to_try:\n                if os.path.exists(path):\n                    with open(path, 'r') as f:\n                        return json.load(f)\n            return []\n        except Exception as e:\n            print(f\"Error loading consoles: {e}\")\n            return []\n\n    def get_download_path(self):\n        path = self.settings.get(\"rom_path\", \"ROMs\")\n        if not os.path.isabs(path):\n            path = os.path.abspath(path)\n\n        if not os.path.exists(path):\n            try:\n                os.makedirs(path, exist_ok=True)\n            except:\n                default = os.path.abspath(\"ROMs\")\n                os.makedirs(default, exist_ok=True)\n                return default\n        return path"}
{"code_id": "Sidon_src_sidon_model_losses.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Sidon_src_sidon_model_losses.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\Sidon_src_sidon_model_losses.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\Sidon_src_sidon_model_losses.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "from __future__ import annotations\n\nfrom typing import Dict\n\nimport torch\nfrom audiotools import AudioSignal\nfrom dac.model.discriminator import Discriminator\nfrom dac.nn.loss import L1Loss, MelSpectrogramLoss, MultiScaleSTFTLoss\nfrom torch import nn\n\ntry:  # pragma: no cover - optional dependency typing\n    from omegaconf import DictConfig  # type: ignore\nexcept ModuleNotFoundError:  # pragma: no cover - controlled by dependencies\n    DictConfig = Dict[str, object]  # type: ignore\n\n\nclass DACLoss(nn.Module):\n    \"\"\"Aggregate losses used for training Describe Audio Codec decoders.\"\"\"\n\n    def __init__(self, cfg: DictConfig) -> None:\n        super().__init__()\n        self.stft_loss = MultiScaleSTFTLoss(**cfg.stft_loss)\n        self.mel_loss = MelSpectrogramLoss(**cfg.mel_loss)\n        self.wav_loss = L1Loss()\n\n    def forward(self, target: AudioSignal, predicted: AudioSignal) -> Dict[str, torch.Tensor]:\n        \"\"\"Compute STFT, mel, and waveform reconstruction losses.\"\"\"\n        stft_loss = self.stft_loss(predicted, target)\n        mel_loss = self.mel_loss(predicted, target)\n        wav_loss = self.wav_loss(predicted, target)\n        return {\n            \"stft_loss\": stft_loss,\n            \"mel_loss\": mel_loss,\n            \"wav_loss\": wav_loss,\n        }\n\n\nclass GANLoss(nn.Module):\n    \"\"\"Least-squares GAN losses for DAC discriminators.\"\"\"\n\n    def __init__(self, discriminator: Discriminator) -> None:\n        super().__init__()\n        self.discriminator = discriminator\n\n    def forward(self, fake: torch.Tensor, real: torch.Tensor):\n        d_fake = self.discriminator(fake)\n        d_real = self.discriminator(real)\n        return d_fake, d_real\n\n    def discriminator_loss(self, fake: torch.Tensor, real: torch.Tensor) -> torch.Tensor:\n        d_fake, d_real = self.forward(fake.clone().detach(), real)\n        loss_d = 0.0\n        for out_fake, out_real in zip(d_fake, d_real):\n            loss_d += torch.mean(out_fake[-1] ** 2)\n            loss_d += torch.mean((1 - out_real[-1]]) ** 2)\n        return loss_d\n\n    def generator_loss(self, fake: torch.Tensor, real: torch.Tensor):\n        d_fake, d_real = self.forward(fake, real)\n        loss_g = 0.0\n        for out_fake in d_fake:\n            loss_g += torch.mean((1 - out_fake[-1]]) ** 2)\n\n        feature_loss = 0.0\n        for idx in range(len(d_fake)):\n            for feature_idx in range(len(d_fake[idx]) - 1):\n                feature_loss += torch.nn.functional.l1_loss(\n                    d_fake[idx][feature_idx],\n                    d_real[idx][feature_idx].detach(),\n                )\n        return loss_g, feature_loss"}
{"code_id": "Romifleur_src_core_config_manager.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Romifleur_src_core_config_manager.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\Romifleur_src_core_config_manager.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\Romifleur_src_core_config_manager.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "Romifleur_src_core_config_manager.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Romifleur_src_core_config_manager.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\Romifleur_src_core_config_manager.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\Romifleur_src_core_config_manager.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "Sidon_src_sidon_model_losses.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Sidon_src_sidon_model_losses.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\Sidon_src_sidon_model_losses.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\Sidon_src_sidon_model_losses.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "\"\"\"Module loss utilities for Sidon models.\"\"\"\nfrom __future__ import annotations\n\nfrom typing import Dict\n\nimport torch\nfrom audiotools import AudioSignal\nfrom dac.model.discriminator import Discriminator\nfrom dac.nn.loss import L1Loss, MelSpectrogramLoss, MultiScaleSTFTLoss\nfrom torch import nn\n\ntry:  # pragma: no cover - optional dependency typing\n    from omegaconf import DictConfig  # type: ignore\nexcept ModuleNotFoundError:  # pragma: no cover - controlled by dependencies\n    DictConfig = Dict[str, object]  # type: ignore\n\nclass DAGLoss(nn.Module):\n    \"\"\"Aggregate losses used for training Describe Audio Codec decoders.\"\"\"\n\n    def __init__(self, cfg: DictConfig) -> None:\n        super().__init__()\n        self.stft_loss = MultiScaleSTFTLoss(**cfg.stft_loss)\n        self.mel_loss = MelSpectrogramLoss(**cfg.mel_loss)\n        self.wav_loss = L1Loss()\n\n    def forward(self, target: AudioSignal, predicted: AudioSignal) -> Dict[str, torch.Tensor]:\n        \"\"\"Compute STFT, mel, and waveform reconstruction losses.\"\"\"\n        stft_loss = self.stft_loss(predicted, target)\n        mel_loss = self.mel_loss(predicted, target)\n        wav_loss = self.wav_loss(predicted, target)\n        return {\n            \"stft_loss\": stft_loss,\n            \"mel_loss\": mel_loss,\n            \"wav_loss\": wav_loss,\n        }\n\nclass GANLoss(nn.Module):\n    \"\"\"Least-squares GAN losses for DAC discriminators.\"\"\"\n\n    def __init__(self, discriminator: Discriminator) -> None:\n        super().__init__()\n        self.discriminator = discriminator\n\n    def forward(self, fake: torch.Tensor, real: torch.Tensor):\n        d_fake = self.discriminator(fake)\n        d_real = self.discriminator(real)\n        return d_fake, d_real\n\n    def discriminator_loss(self, fake: torch.Tensor, real: torch.Tensor) -> torch.Tensor:\n        d_fake, d_real = self.forward(fake.clone().detach(), real)\n        loss_d = 0.0\n        for out_fake, out_real in zip(d_fake, d_real):\n            loss_d += torch.mean(out_fake[-1] ** 2)\n            loss_d += torch.mean((1 - out_real[-1]) ** 2)\n        return loss_d\n\n    def generator_loss(self, fake: torch.Tensor, real: torch.Tensor):\n        d_fake, d_real = self.forward(fake, real)\n        loss_g = 0.0\n        for out_fake in d_fake:\n            loss_g += torch.mean((1 - out_fake[-1]) ** 2))\n\n        feature_loss = 0.0\n        for idx in range(len(d_fake)):\n            for feature_idx in range(len(d_fake[idx]) - 1):\n                feature_loss += torch.nn.functional.l1_loss(\n                    d_fake[idx][feature_idx],\n                    d_real[idx][feature_idx].detach(),\n                )\n        return loss_g, feature_loss"}
{"code_id": "SnackBase_src_snackbase_domain_entities_invitation.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\SnackBase_src_snackbase_domain_entities_invitation.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\SnackBase_src_snackbase_domain_entities_invitation.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\SnackBase_src_snackbase_domain_entities_invitation.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "# Invitation entity for user onboarding.\n#\n# Invitations allow account admins to invite new users via email.\n# An invitation includes a secure token that expires after a set period.\n#\nfrom dataclasses import dataclass, field\nfrom datetime import datetime, timezone\n\n@dataclass\nclass Invitation:\n    \"\"\"Invitation entity for inviting users to an account.\n\n    Invitations contain a secure token that the invitee uses to accept\n    the invitation and create their account password.\n\n    Attributes:\n        id: Unique identifier (UUID string).\n        account_id: Foreign key to the account the user is invited to.\n        email: Email address of the invited user.\n        token: Secure random token for accepting the invitation.\n        invited_by: Foreign key to the user who sent the invitation.\n        expires_at: Timestamp when the invitation expires.\n        accepted_at: Timestamp when the invitation was accepted (nullable).\n        email_sent: Whether the invitation email has been sent.\n        email_sent_at: Timestamp when the email was sent (nullable).\n        created_at: Timestamp when the invitation was created.\n    \"\"\"\n    id: str\n    account_id: str\n    email: str\n    token: str\n    invited_by: str\n    expires_at: datetime\n    accepted_at: datetime | None = None\n    email_sent: bool = False\n    email_sent_at: datetime | None = None\n    created_at: datetime = field(default_factory=lambda: datetime.now(timezone.utc)))\n\n    def __post_init__(self) -> None:\n        \"\"\"Validate invitation data after initialization.\"\"\"\n        if not self.id:\n            raise ValueError(\"Invitation ID is required\")\n        if not self.account_id:\n            raise ValueError(\"Account ID is required\")\n        if not self.email:\n            raise ValueError(\"Email is required\")\n        if not self.token:\n            raise ValueError(\"Token is required\")\n        if not self.invited_by:\n            raise ValueError(\"Invited by user ID is required\")\n\n    @property\n    def is_expired(self) -> bool:\n        \"\"\"Check if the invitation has expired.\"\"\"\n        return datetime.now(timezone.utc) > self.expires_at\n\n    @property\n    def is_accepted(self) -> bool:\n        \"\"\"Check if the invitation has been accepted.\"\"\"\n        return self.accepted_at is not None"}
{"code_id": "Sidon_src_sidon_model_losses.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Sidon_src_sidon_model_losses.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\Sidon_src_sidon_model_losses.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\Sidon_src_sidon_model_losses.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "```python\n\"\"\"Module loss utilities for Siden models.\"\"\"\nfrom __future__ import annotations\nfrom typing import Dict\nimport torch\nfrom audioset import AudioSignal\nfrom dac.model.discriminator import Discriminator\nfrom dac.nn.loss import L1Loss, MultiSpectralLoss, MultiScaledSTFTLoss\nfrom torch import nn\ntry:  # pragma: no cover - optional dependency typing\n    from omegaconf import DictConfig  # type: ignore\nexcept ModuleNotFoundError:  # pragma: no cover - controlled by dependencies\n    DictConfig = Dict[str, object]  # type: ignore\n\nclass DACLoss(nn.Module):\n    \"\"\"Aggregate losses used for training Descript Audio Codec decoders.\"\"\"\n\n    def __init__(self, cfg: DictConfig) -> None:\n        super().__init__()\n        self.stft_loss = MultiScaledSTFTLoss(**cfg.stft_loss)\n        self.mel_loss = MultiSpectralLoss(**cfg.mel_loss)\n        self.wav_loss = L1Loss()\n\n    def forward(self, target: AudioSignal, predicted: AudioSignal) -> Dict[str, torch.Tensor]:\n        \"\"\"Compute STFT, mel, and waveform reconstruction losses.\"\"\"\n        stft_loss = self.stft_loss(predicted, target)\n        mel_loss = self.mel_loss(predicted, target)\n        wav_loss = self.wav_loss(predicted, target)\n        return {\n            \"stft_loss\": stft_loss,\n            \"mel_loss\": mel_loss,\n            \"wav_loss\": wav_loss,\n        }\n\nclass GANLoss(nn.Module):\n    \"\"\"Least-squares GAN losses for DAC discriminators.\"\"\"\n\n    def __init__(self, discriminator: Discriminator) -> None:\n        super().__init__()\n        self.discriminator = discriminator\n\n    def forward(self, fake: torch.Tensor, real: torch.Tensor):\n        d_fake = self.discriminator(fake)\n        d_real = self.discriminator(real)\n        return d_fake, d_real\n\n    def discriminator_loss(self, fake: torch.Tensor, real: torch.Tensor) -> torch.Tensor:\n        d_fake, d_real = self.forward(fake.clone().detach(), real)\n        loss_d = 0.0\n        for out_fake, out_real in zip(d_fake, d_real):\n            loss_d += torch.mean(out_fake[-1] ** 2)\n            loss_d += torch.mean((1 - out_real[-1]) ** 2)\n        return loss_d\n\n    def generator_loss(self, fake: torch.Tensor, real: torch.Tensor):\n        d_fake, d_real = self.forward(fake, real)\n        loss_g = 0.0\n        for out_fake in d_fake:\n            loss_g += torch.mean((1 - out_fake[-1]) ** 2)\n\n        feature_loss = 0.0\n        for idx in range(len(d_fake)):\n            for feature_idx in range(len(d_fake[idx]) - 1)):\n                feature_loss += torch.nn.functional.l1_loss(\n                    d_fake[idx][feature_idx],\n                    d_real[idx][feature_idx].detach(),\n                )\n        return loss_g, feature_loss\n```"}
{"code_id": "Sidon_src_sidon_model_losses.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Sidon_src_sidon_model_losses.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\Sidon_src_sidon_model_losses.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\Sidon_src_sidon_model_losses.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "Sidon_src_sidon_model_losses.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Sidon_src_sidon_model_losses.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\Sidon_src_sidon_model_losses.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\Sidon_src_sidon_model_losses.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "SnackBase_src_snackbase_domain_entities_invitation.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\SnackBase_src_snackbase_domain_entities_invitation.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\SnackBase_src_snackbase_domain_entities_invitation.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\SnackBase_src_snackbase_domain_entities_invitation.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "from dataclasses import dataclass, field\nfrom datetime import datetime, timezone\n\n@dataclass\nclass Invitation:\n    \"\"\"Invitation entity for inviting users to an account.\n\n    Invitations contain a secure token that the invitee uses to accept\n    the invitation and create their account password.\n\n    Attributes:\n        id: Unique identifier (UUID string).\n        account_id: Foreign key to the account the user is invited to.\n        email: Email address of the invited user.\n        token: Secure random token for accepting the invitation.\n        invited_by: Foreign key to the user who sent the invitation.\n        expires_at: Timestamp when the invitation expires.\n        accepted_at: Timestamp when the invitation was accepted (nullable).\n        email_sent: Whether the invitation email has been sent.\n        email_sent_at: Timestamp when the email was sent (nullable).\n        created_at: Timestamp when the invitation was created.\n    \"\"\"\n    id: str\n    account_id: str\n    email: str\n    token: str\n    invited_by: str\n    expires_at: datetime\n    accepted_at: datetime | None = None\n    email_sent: bool = False\n    email_sent_at: datetime | None = None\n    created_at: datetime = field(default_factory=lambda: datetime.now(timezone.utc)))\n\n    def __post_init__(self) -> None:\n        \"\"\"Validate invitation data after initialization.\"\"\"\n        if not self.id:\n            raise ValueError(\"Invitation ID is required\")\n        if not self.account_id:\n            raise ValueError(\"Account ID is required\")\n        if not self.email:\n            raise ValueError(\"Email is required\")\n        if not self.token:\n            raise ValueError(\"Token is required\")\n        if not self.invited_by:\n            raise ValueError(\"Invited by user ID is required\")\n\n    @property\n    def is_expired(self) -> bool:\n        \"\"\"Check if the invitation has expired.\"\"\"\n        return datetime.now(timezone.utc) > self.expires_at\n\n    @property\n    def is_accepted(self) -> bool:\n        \"\"\"Check if the invitation has been accepted.\"\"\"\n        return self.accepted_at is not None"}
{"code_id": "Vulnhalla_src_ui_components_splitter_divider.py", "ratio": 1, "num_pages": 3, "image_paths": ["./experiment_output\\images_glm46v\\Vulnhalla_src_ui_components_splitter_divider.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\Vulnhalla_src_ui_components_splitter_divider.py\\1024x1024_hl_nl\\page_002_ratio1.png", "./experiment_output\\images_glm46v\\Vulnhalla_src_ui_components_splitter_divider.py\\1024x1024_hl_nl\\page_003_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\Vulnhalla_src_ui_components_splitter_divider.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "#!/usr/bin/env python3\n\n\"\"\"Splitter divider component for Vulnhalla UI.\"\"\"\n\nfrom textual.widget import Widget\n\nclass SplitterDivider(Widget):\n    \"\"\"\n    Draggable divider widget between panels for resizing.\n    \"\"\"\n\n    DEFAULT_CSS = \"\"\"\n    SplitterDivider {\n        width: 1;\n        background: transparent;\n        color: $surface-lighten-2;\n    }\n    SplitterDivider:hover {\n        background: $primary;\n        color: $primary;\n    }\n    \"\"\"\n\n    def __init__(self, app_instance=None):\n        \"\"\"\n        Initialize the SplitterDivider.\n\n        Args:\n            app_instance: Reference to the VulnhallaUI app instance for updating split position.\n        \"\"\"\n        super().__init__()\n        self.app_instance = app_instance\n        self.dragging = False\n\n    def render(self):\n        \"\"\"\n        Render the divider as a thin vertical line.\n\n        Returns:\n            str: Single vertical line character \"|\".\n        \"\"\"\n        return \"|\"\n\n    def on_mouse_down(self, event) -> None:\n        \"\"\"\n        Start dragging when mouse is pressed.\n\n        Args:\n            event: Mouse down event.\n        \"\"\"\n        self.dragging = True\n        self.capture_mouse()\n\n    def on_mouse_move(self, event) -> None:\n        \"\"\"\n        Update split position while dragging.\n\n        Args:\n            event: Mouse move event containing position information.\n        \"\"\"\n        if self.dragging and self.app_instance:\n            parent = self.parent\n            if parent and parent.region:\n                try:\n                    # Get mouse position relative to parent container\n                    mouse_x = event.screen_x - parent.region.x\n                    parent_width = parent.size.width\n                    if parent_width > 0:\n                        new_position = max(0.2, min(0.8, mouse_x / parent_width)))\n                        self.app_instance.split_position = new_position\n                        self.app_instance._update_split_position()\n                except (AttributeError, TypeError):\n                    # Fallback: use delta if available\n                    if hasattr(event, 'delta_x') and event.delta_x != 0:\n                        parent_width = parent.size.width\n                        if parent_width > 0:\n                            delta = event.delta_x / parent_width\n                            new_position = max(0.2, min(0.8, self.app_instance.split_position + delta)))\n                            self.app_instance.split_position = new_position\n                            self.app_instance._update_split_position()\n\n    def on_mouse_up(self, event) -> None:\n        \"\"\"\n        Stop dragging when mouse is released.\n\n        Args:\n            event: Mouse up event.\n        \"\"\"\n        if self.dragging:\n            self.dragging = False\n            self.release_mouse()"}
{"code_id": "SnackBase_src_snackbase_domain_entities_invitation.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\SnackBase_src_snackbase_domain_entities_invitation.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\SnackBase_src_snackbase_domain_entities_invitation.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\SnackBase_src_snackbase_domain_entities_invitation.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "# Invitation entity for user onboarding.\n#\n# Invitations allow account admins to invite new users via email.\n# The invitation includes a secure token that expires after a set period.\n#\n\nfrom dataclasses import dataclass, field\nfrom datetime import datetime, timezone\n\n@dataclass\nclass Invitation:\n    \"\"\"Invitation entity for inviting users to an account.\n\n    Invitations contain a secure token that the invitee uses to accept\n    the invitation and create their account password.\n\n    Attributes:\n        id: Unique identifier (UUID string).\n        account_id: Foreign key to the account the user is invited to.\n        email: Email address of the invited user.\n        token: Secure random token for accepting the invitation.\n        invited_by: Foreign key to the user who sent the invitation.\n        expires_at: Timestamp when the invitation expires.\n        accepted_at: Timestamp when the invitation was accepted (nullable).\n        email_sent: Whether the invitation email has been sent.\n        email_sent_at: Timestamp when the email was sent (nullable).\n        created_at: Timestamp when the invitation was created.\n    \"\"\"\n    id: str\n    account_id: str\n    email: str\n    token: str\n    invited_by: str\n    expires_at: datetime\n    accepted_at: datetime | None = None\n    email_sent: bool = False\n    email_sent_at: datetime | None = None\n    created_at: datetime = field(default_factory=lambda: datetime.now(timezone.utc)))\n\n    def __post_init__(self) -> None:\n        \"\"\"Validate invitation data after initialization.\"\"\"\n        if not self.id:\n            raise ValueError(\"Invitation ID is required\")\n        if not self.account_id:\n            raise ValueError(\"Account ID is required\")\n        if not self.email:\n            raise ValueError(\"Email is required\")\n        if not self.token:\n            raise ValueError(\"Token is required\")\n        if not self.invited_by:\n            raise ValueError(\"Invited by user ID is required\")\n\n    @property\n    def is_expired(self) -> bool:\n        \"\"\"Check if the invitation has expired.\"\"\"\n        return datetime.now(timezone.utc) > self.expires_at\n\n    @property\n    def is_accepted(self) -> bool:\n        \"\"\"Check if the invitation has been accepted.\"\"\"\n        return self.accepted_at is not None"}
{"code_id": "SnackBase_src_snackbase_domain_entities_invitation.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\SnackBase_src_snackbase_domain_entities_invitation.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\SnackBase_src_snackbase_domain_entities_invitation.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\SnackBase_src_snackbase_domain_entities_invitation.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "Vulnhalla_src_ui_components_splitter_divider.py", "ratio": 2, "num_pages": 3, "image_paths": ["./experiment_output\\images_glm46v\\Vulnhalla_src_ui_components_splitter_divider.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\Vulnhalla_src_ui_components_splitter_divider.py\\1024x1024_hl_nl\\page_002_ratio2.png", "./experiment_output\\images_glm46v\\Vulnhalla_src_ui_components_splitter_divider.py\\1024x1024_hl_nl\\page_003_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\Vulnhalla_src_ui_components_splitter_divider.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "#!/usr/bin/env python3\n\n\"\"\"Splitter divider component for Vulnhalla UI.\"\"\"\n\nfrom textual.widget import Widget\n\nclass SplitterDivider(Widget):\n    \"\"\"\n    Draggable divider widget between panels for resizing.\n    \"\"\"\n\n    DEFAULT_CSS = \"\"\"\n    SplitterDivider {\n        width: 1;\n        background: transparent;\n        color: $surface-lighten-2;\n    }\n    SplitterDivider:hover {\n        background: $primary;\n        color: $primary;\n    }\n    \"\"\"\n\n    def __init__(self, app_instance=None):\n        \"\"\"\n        Initialize the SplitterDivider.\n\n        Args:\n            app_instance: Reference to the VulnhallaUI app instance for updating split position.\n        \"\"\"\n        super().__init__()\n        self.app_instance = app_instance\n        self.dragging = False\n\n    def render(self):\n        \"\"\"\n        Render the divider as a thin vertical line.\n\n        Returns:\n            str: Single vertical line character \"|\".\n        \"\"\"\n        return \"|\"\n\n    def on_mouse_down(self, event) -> None:\n        \"\"\"\n        Start dragging when mouse is pressed.\n\n        Args:\n            event: Mouse down event.\n        \"\"\"\n        self.dragging = True\n        self.capture_mouse()\n\n    def on_mouse_move(self, event) -> None:\n        \"\"\"\n        Update split position while dragging.\n\n        Args:\n            event: Mouse move event containing position information.\n        \"\"\"\n        if self.dragging and self.app_instance:\n            parent = self.parent\n            if parent and parent.region:\n                try:\n                    # Get mouse position relative to parent container\n                    mouse_x = event.screen_x - parent.region.x\n                    parent_width = parent.size.width\n                    if parent_width > 0:\n                        new_position = max(0.2, min(0.8, mouse_x / parent_width)))\n                        self.app_instance.split_position = new_position\n                        self.app_instance._update_split_position()\n                except (AttributeError, TypeError):\n                    # Fallback: use delta if available\n                    if hasattr(event, 'delta_x') and event.delta_x != 0:\n                        parent_width = parent.size.width\n                        if parent_width > 0:\n                            delta = event.delta_x / parent_width\n                            new_position = max(0.2, min(0.8, self.app_instance.split_position + delta)))\n                            self.app_instance.split_position = new_position\n                            self.app_instance._update_split_position()\n\n    def on_mouse_up(self, event) -> None:\n        \"\"\"\n        Stop dragging when mouse is released.\n\n        Args:\n            event: Mouse up event.\n        \"\"\"\n        if self.dragging:\n            self.dragging = False\n            self.release_mouse()"}
{"code_id": "SnackBase_src_snackbase_domain_entities_invitation.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\SnackBase_src_snackbase_domain_entities_invitation.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\SnackBase_src_snackbase_domain_entities_invitation.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\SnackBase_src_snackbase_domain_entities_invitation.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "Vulnhalla_src_ui_components_splitter_divider.py", "ratio": 4, "num_pages": 3, "image_paths": ["./experiment_output\\images_glm46v\\Vulnhalla_src_ui_components_splitter_divider.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\Vulnhalla_src_ui_components_splitter_divider.py\\1024x1024_hl_nl\\page_002_ratio4.png", "./experiment_output\\images_glm46v\\Vulnhalla_src_ui_components_splitter_divider.py\\1024x1024_hl_nl\\page_003_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\Vulnhalla_src_ui_components_splitter_divider.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "#!/usr/bin/env python3\n\n# Splitter divider component for Valhalla UI.\n\nfrom textual.widget import Widget\n\nclass SplitterDivider(Widget):\n    \"\"\"Draggable divider widget between panels for resizing.\"\"\"\n\n    DEFAULT_CSS = \"\"\"\n    SplitterDivider {\n        width: 1;\n        background: transparent;\n        color: $surface-lighter-2;\n    }\n    SplitterDivider:hover {\n        background: $primary;\n        color: $primary;\n    }\n    \"\"\"\n\n    def __init__(self, app_instance=None):\n        \"\"\"Initialize the SplitterDivider.\n\n        Args:\n            app_instance: Reference to the ValhallaUI app instance for updating split position.\n        \"\"\"\n        super().__init__()\n        self.app_instance = app_instance\n        self.dragging = False\n\n    def render(self):\n        \"\"\"Render the divider as a thin vertical line.\n\n        Returns:\n            str: Single vertical line character \"|\".\n        \"\"\"\n        return \"|\"\n\n    def on_mouse_down(self, event) -> None:\n        \"\"\"Start dragging when mouse is pressed.\n\n        Args:\n            event: Mouse down event.\n        \"\"\"\n        self.dragging = True\n        self.capture_mouse()\n\n    def on_mouse_move(self, event) -> None:\n        \"\"\"Update split position while dragging.\n\n        Args:\n            event: Mouse move event containing position information.\n        \"\"\"\n        if self.dragging and self.app_instance:\n            parent = self.parent\n            if parent and parent.region:\n                try:\n                    # Get mouse position relative to parent container\n                    mouse_x = event.screen_x - parent.region.x\n                    parent_width = parent.size.width\n                    if parent_width > 0:\n                        new_position = max(0.2, min(0.8, mouse_x / parent_width)))\n                        self.app_instance.split_position = new_position\n                        self.app_instance.update_split_position()\n                except (AttributeError, TypeError):\n                    # Fallback: use delta if available\n                    if hasattr(event, \"delta_x\") and event.delta_x != 0:\n                        parent_width = parent.size.width\n                        if parent_width > 0:\n                            delta = event.delta_x / parent_width\n                            new_position = max(0.2, min(0.8, self.app_instance.split_position + delta)))\n                            self.app_instance.split_position = new_position\n                            self.app_instance.update_split_position()\n\n    def on_mouse_up(self, event) -> None:\n        \"\"\"Stop dragging when mouse is released.\n\n        Args:\n            event: Mouse up event.\n        \"\"\"\n        if self.dragging:\n            self.dragging = False\n            self.release_mouse()"}
{"code_id": "Wegent_backend_app_models_namespace.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Wegent_backend_app_models_namespace.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\Wegent_backend_app_models_namespace.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\Wegent_backend_app_models_namespace.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "__fileCopyrightText: 2025 Weibo, Inc.\n__licenseIdentifier: Apache-2.0\nfrom datetime import datetime\nfrom sqlalchemy import Boolean, Column, DateTime, Integer, String, Text\nfrom sqlalchemy.orm import relationship\nfrom sqlalchemy.sql import func\nfrom app.db.base import Base\n\nclass Namespace(Base):\n    \"\"\"\n    Group (Namespace) model for resource organization.\n\n    Supports hierarchical structure with parent/child groups using name prefixes.\n    Example: 'aaa/bbb' represents group 'bbb' under parent group 'aaa'.\n    \"\"\"\n    __tablename__ = \"namespace\"\n\n    id = Column(Integer, primary_key=True, index=True)\n    # Unique identifier, immutable after creation\n    # Sub-groups use prefix format (e.g., 'aaa/bbb')\n    name = Column(String(100), nullable=False, unique=True, index=True)\n    # Display name, can be modified\n    display_name = Column(String(100), nullable=True)\n    # Group owner user ID\n    owner_user_id = Column(Integer, nullable=False, index=True)\n    # Visibility: private, internal, public\n    visibility = Column(String(20), nullable=False, default=\"private\")\n    # Group description\n    description = Column(Text, nullable=False, default=\"\")\n    # Is group active\n    is_active = Column(Boolean, default=True)\n    created_at = Column(DateTime, default=func.now())\n    updated_at = Column(DateTime, default=func.now(), onupdate=func.now())\n\n    # Relationships\n    members = relationship(\n        \"NamespaceMember\",\n        back_populates=\"namespace\",\n        cascade=\"all, delete-orphan\",\n        primaryjoin=\"Namespace.name == foreign(NamespaceMember.group_name)\",\n    )\n\n    __table_args__ = (\n        {\n            \"sqlite_autoincrement\": True,\n            \"mysql_engine\": \"InnoDB\",\n            \"mysql_charset\": \"utf8mb4\",\n            \"mysql_collate\": \"utf8mb4_unicode_ci\",\n            \"comment\": \"Group (Namespace) table for resource organization\",\n        },\n    )\n\n    def get_parent_name(self) -> str | None:\n        \"\"\"Get parent group name from hierarchical name.\"\"\"\n        if \"/\" not in self.name:\n            return None\n        return self.name.rsplit(\"/\", 1)[0]\n\n    def get_depth(self) -> int:\n        \"\"\"Get nesting depth (0 for root groups).\"\"\"\n        return self.name.count(\"/\")\n\n    def is_subgroup_of(self, parent_name: str) -> bool:\n        \"\"\"Check if this group is a subgroup of the given parent.\"\"\"\n        return self.name.startswith(f\"{parent_name}/\")"}
{"code_id": "Vulnhalla_src_ui_components_splitter_divider.py", "ratio": 8, "num_pages": 3, "image_paths": ["./experiment_output\\images_glm46v\\Vulnhalla_src_ui_components_splitter_divider.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\Vulnhalla_src_ui_components_splitter_divider.py\\1024x1024_hl_nl\\page_002_ratio8.png", "./experiment_output\\images_glm46v\\Vulnhalla_src_ui_components_splitter_divider.py\\1024x1024_hl_nl\\page_003_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\Vulnhalla_src_ui_components_splitter_divider.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "Vulnhalla_src_ui_components_splitter_divider.py", "ratio": 6, "num_pages": 3, "image_paths": ["./experiment_output\\images_glm46v\\Vulnhalla_src_ui_components_splitter_divider.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\Vulnhalla_src_ui_components_splitter_divider.py\\1024x1024_hl_nl\\page_002_ratio6.png", "./experiment_output\\images_glm46v\\Vulnhalla_src_ui_components_splitter_divider.py\\1024x1024_hl_nl\\page_003_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\Vulnhalla_src_ui_components_splitter_divider.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "Wegent_backend_app_models_namespace.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Wegent_backend_app_models_namespace.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\Wegent_backend_app_models_namespace.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\Wegent_backend_app_models_namespace.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "# fileCopyrightText: 2025 Weibo, Inc.\n#\n# license-Identifier: Apache-2.0\n\nfrom datetime import datetime\n\nfrom sqlalchemy import Boolean, Column, DateTime, Integer, String, Text\nfrom sqlalchemy.orm import relationship\nfrom sqlalchemy.sql import func\n\nfrom app.db.base import Base\n\nclass Namespace(Base):\n    \"\"\"\n    Group (Namespace) model for resource organization.\n\n    Supports hierarchical structure with parent/child groups using name prefixes.\n    Example: 'aaa/bbb' represents group 'bbb' under parent group 'aaa'.\n    \"\"\"\n\n    __tablename__ = \"namespace\"\n\n    id = Column(Integer, primary_key=True, index=True)\n    # Unique identifier, immutable after creation\n    # Sub-groups use prefix format (e.g. 'aaa/bbb')\n    name = Column(String(100), nullable=False, unique=True, index=True)\n    # Display name, can be modified\n    display_name = Column(String(100), nullable=True)\n    # Group owner user ID\n    owner_user_id = Column(Integer, nullable=False, index=True)\n    # Visibility: private, internal, public\n    visibility = Column(String(20), nullable=False, default=\"private\")\n    # Group description\n    description = Column(Text, nullable=False, default=\"\")\n    # Is group active\n    is_active = Column(Boolean, default=True)\n    created_at = Column(DateTime, default=func.now())\n    updated"}
{"code_id": "Wegent_backend_app_models_namespace.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Wegent_backend_app_models_namespace.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\Wegent_backend_app_models_namespace.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\Wegent_backend_app_models_namespace.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "# CopyrightCopyrightText: 2025 Weibo, Inc.\n# License-Identifier: Apache-2.0\n\nfrom datetime import datetime\n\nfrom sqlalchemy import Boolean, Column, DateTime, Integer, String, Text\nfrom sqlalchemy.orm import relationship\nfrom sqlalchemy.sql import func\n\nfrom apps.db.base import Base\n\n\nclass Namespace(Base):\n    \"\"\"\n    Group (Namespace) model for resource organization.\n\n    Supports hierarchical structure with parent/child groups using name prefixes.\n    Example: 'aaa/bbb' represents group 'bbb' under parent group 'aaa'.\n    \"\"\"\n    __tablename__ = \"namespace\"\n\n    id = Column(Integer, primary_key=True, index=True)\n    # Unique identifier, immutable after creation\n    # Sub-groups use prefix format (e.g., 'aaa/bbb')\n    name = Column(String(100), nullable=False, unique=True, index=True)\n    # Display name, can be modified\n    display_name = Column(String(100), nullable=True)\n    # Group owner user ID\n    owner_user_id = Column(Integer, nullable=False, index=True)\n    # Visibility: private, internal, public\n    visibility = Column(String(20), nullable=False, default=\"private\")\n    # Group description\n    description = Column(Text, nullable=False, default=\"\")\n    # Is group active\n    is_active = Column(Boolean, default=True)\n    created_at = Column(DateTime, default=func.now())\n    updated_at = Column(DateTime, default=func.now(), onupdate=func.now())\n\n    # Relationships\n    members = relationship(\n        \"NamespaceMember\",\n        back_populates=\"namespace\",\n        cascade=\"all, delete-orphan\",\n        primaryjoin=\"Namespace.name == foreign(NamespaceMember.group_name)\",\n    )\n\n    __table_args__ = {\n        \"sqlite_autoincrement\": True,\n        \"mysql_engine\": \"InnoDB\",\n        \"mysql_charset\": \"utf8mb4\",\n        \"mysql_collate\": \"utf8mb4_unicode_ci\",\n        \"comment\": \"Group (Namespace) table for resource organization\",\n    }\n\n    def get_parent_name(self) -> str | None:\n        \"\"\"Get parent group name from hierarchical name.\"\"\"\n        if \"/\" not in self.name:\n            return None\n        return self.name.rsplit(\"/\", 1)[0]\n\n    def get_depth(self) -> int:\n        \"\"\"Get nesting depth (0 for root groups).\"\"\"\n        return self.name.count(\"/\")\n\n    def is_subgroup_of(self, parent_name: str) -> bool:\n        \"\"\"Check if this group is a subgroup of the given parent.\"\"\"\n        return self.name.startswith(f\"{parent_name}/\")"}
{"code_id": "X-AnyLabeling-Server_app_models_yolo11.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\X-AnyLabeling-Server_app_models_yolo11.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\X-AnyLabeling-Server_app_models_yolo11.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\X-AnyLabeling-Server_app_models_yolo11.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "import numpy as np\nfrom typing import Any, Dict\n\nfrom . import BaseModel\nfrom app.schemas.shape import Shape\nfrom app.core.registry import register_model\n\n@register_model(\"yolo11n\", \"yolo11s\", \"yolo11m\", \"yolo11l\", \"yolo11x\")\nclass YOLO11Detection(BaseModel):\n    \"\"\"YOLO11 object detection model.\"\"\"\n\n    def load(self):\n        \"\"\"Load YOLO model.\"\"\"\n        from ultralytics import YOLO\n\n        model_path = self.params.get(\"model_path\", \"yolo11n.pt\")\n        device = self.params.get(\"device\", \"cpu\")\n\n        self.model = YOLO(model_path)\n        self.model.to(device)\n\n        dummy_img = np.zeros((640, 640, 3), dtype=np.uint8)\n        self.model(dummy_img, verbose=False)\n\n    def predict(\n        self, image: np.ndarray, params: Dict[str, Any]\n    ) -> Dict[str, Any]:\n        \"\"\"Execute object detection.\n\n        Args:\n            image: Input image in BGR format.\n            params: Inference parameters.\n\n        Returns:\n            Dictionary with detection results.\n        \"\"\"\n        conf_threshold = params.get(\n            \"conf_threshold\", self.params.get(\"conf_threshold\", 0.25)\n        )\n        iou_threshold = params.get(\n            \"iou_threshold\", self.params.get(\"iou_threshold\", 0.45)\n        )\n\n        results = self.model(\n            image, conf=conf_threshold, iou=iou_threshold, verbose=False\n        )\n\n        shapes = []\n        for result in results:\n            boxes = result.boxes\n            if boxes is not None:\n                for box in boxes:\n                    xyxy = box.xyxyn[0].cpu().numpy()\n                    conf = float(box.conf[0])\n                    cls = int(box.cls[0])\n                    label = result.names[cls]\n\n                    shape = Shape(\n                        label=label,\n                        shape_type=\"rectangle\",\n                        points=[\n                            [float(xyxy[0]), float(xyxy[1])],\n                            [float(xyxy[2]), float(xyxy[1])],\n                            [float(xyxy[2]), float(xyxy[3])],\n                            [float(xyxy[0]), float(xyxy[3])],\n                        ],\n                        score=conf,\n                    )\n                    shapes.append(shape)\n\n        return {\"shapes\": shapes, \"description\": \"\"}\n\n    def unload(self):\n        \"\"\"Release model resources.\"\"\"\n        if hasattr(self, \"model\"):\n            del self.model"}
{"code_id": "Wegent_backend_app_models_namespace.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Wegent_backend_app_models_namespace.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\Wegent_backend_app_models_namespace.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\Wegent_backend_app_models_namespace.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "X-AnyLabeling-Server_app_models_yolo11.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\X-AnyLabeling-Server_app_models_yolo11.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\X-AnyLabeling-Server_app_models_yolo11.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\X-AnyLabeling-Server_app_models_yolo11.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "import numpy as np\nfrom typing import Any, Dict\nfrom . import BaseModel\nfrom app.schemas.shape import Shape\nfrom app.core.registry import register_model\n\n@register_model(\"yolo11n\", \"yolo11s\", \"yolo11m\", \"yolo11l\", \"yolo11x\")\nclass YOLO11Detection(BaseModel):\n    \"\"\"YOLO11 object detection model.\"\"\"\n\n    def load(self):\n        \"\"\"Load YOLO model.\"\"\"\n        from ultralytics import YOLO\n\n        model_path = self.params.get(\"model_path\", \"yolo11n.pt\")\n        device = self.params.get(\"device\", \"cpu\")\n\n        self.model = YOLO(model_path)\n        self.model.to(device)\n\n        dummy_img = np.zeros((640, 640, 3), dtype=np.uint8)\n        self.model(dummy_img, verbose=False)\n\n    def predict(\n        self, image: np.ndarray, params: Dict[str, Any]\n    ) -> Dict[str, Any]:\n        \"\"\"Execute object detection.\n\n        Args:\n            image: Input image in BGR format.\n            params: Inference parameters.\n\n        Returns:\n            Dictionary with detection results.\n        \"\"\"\n        conf_threshold = params.get(\n            \"conf_threshold\", self.params.get(\"conf_threshold\", 0.25)\n        )\n        iou_threshold = params.get(\n            \"iou_threshold\", self.params.get(\"iou_threshold\", 0.45)\n        )\n\n        results = self.model(\n            image, conf=conf_threshold, iou=iou_threshold, verbose=False\n        )\n\n        shapes = []\n        for result in results:\n            boxes = result.boxes\n            if boxes is not None:\n                for box in boxes:\n                    xyxy = box.xyxy[0].cpu().numpy()\n                    conf = float(box.conf[0])\n                    cls = int(box.cls[0])\n                    label = result.names[cls]\n\n                    shape = Shape(\n                        label=label,\n                        shape_type=\"rectangle\",\n                        points=[\n                            [float(xyxy[0]), float(xyxy[1]))],\n                            [float(xyxy[2]), float(xyxy[1]))],\n                            [float(xyxy[2]), float(xyxy[3]))],\n                            [float(xyxy[0]), float(xyxy[3]))],\n                        ],\n                        score=conf,\n                    )\n                    shapes.append(shape)\n\n        return {\"shapes\": shapes, \"description\": \"\"}\n\n    def unload(self):\n        \"\"\"Release model resources.\"\"\"\n        if hasattr(self, \"model\"):\n            del self.model"}
{"code_id": "Wegent_backend_app_models_namespace.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\Wegent_backend_app_models_namespace.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\Wegent_backend_app_models_namespace.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\Wegent_backend_app_models_namespace.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "X-AnyLabeling-Server_app_models_yolo11.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\X-AnyLabeling-Server_app_models_yolo11.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\X-AnyLabeling-Server_app_models_yolo11.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\X-AnyLabeling-Server_app_models_yolo11.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": "from __future__ import print_function\nimport os\nimport sys\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms, utils\nfrom torchvision.datasets import ImageFolder\nfrom torchvision.models import resnet18\nfrom tensorboardX import SummaryWriter\n\ndef get_model():\n    \"\"\"Returns the model.\"\"\"\n    model = resnet18(pretrained=True)\n    return model\n\ndef get_dataloader(data_dir, batch_size):\n    \"\"\"Returns the dataloader.\"\"\"\n    transform = transforms.Compose([\n        transforms.Resize((224, 224))),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                   std=[0.229, 0.224, 0.225])\n    ])\n    dataset = ImageFolder(root=data_dir, transform=transform)\n    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n    return dataloader\n\ndef train(model, dataloader, criterion, optimizer, num_epochs):\n    \"\"\"Trains the model.\"\"\"\n    writer = SummaryWriter()\n    for epoch in range(num_epochs):\n        running_loss = 0.0\n        for i, (inputs, labels) in enumerate(dataloader):\n            inputs = Variable(inputs)\n            labels = Variable(labels)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.data[0]\n            if i % 100 == 0:\n                print('[Epoch %d, Batch %d] Loss: %.3f' %\n                      (epoch + 1, i + 1, running_loss / (i + 1))))\n                writer.add_scalar('Loss/train', running_loss / (i + 1)), epoch * len(dataloader) + i)\n        writer.add_scalar('Loss/epoch', running_loss / len(dataloader)), epoch)\n    writer.close()\n    print('Finished Training')\n\ndef test(model, dataloader, criterion):\n    \"\"\"Tests the model.\"\"\"\n    model.eval()\n    test_loss = 0\n    correct = 0\n    with torch.no_grad():\n        for data, target in dataloader:\n            data, target = data.to(device), target.to(device)\n            output = model(data)\n            test_loss += criterion(output, target).item()\n            pred = output.argmax(dim=1, keepdim=True)\n            correct += pred.eq(target.view_as(pred))).sum().item()\n    test_loss /= len(dataloader.dataset)\n    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n        test_loss, correct, len(dataloader.dataset),\n        100. * correct / len(dataloader.dataset)))\n    return test_loss, correct / len(dataloader.dataset)\n\ndef main():\n    \"\"\"Main function.\"\"\"\n    data_dir = 'data'\n    batch_size = 32\n    num_epochs = 10\n    learning_rate = 0.001\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    model = get_model().to(device)\n    dataloader = get_dataloader(data_dir, batch_size)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n    train(model, dataloader, criterion, optimizer, num_epochs)\n    test(model, dataloader, criterion)\n\nif __name__ == '__main__':\n    main()"}
{"code_id": "ZaiZaiCat-Checkin_script_huaruntong_wentiweilaihui_api.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\ZaiZaiCat-Checkin_script_huaruntong_wentiweilaihui_api.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\ZaiZaiCat-Checkin_script_huaruntong_wentiweilaihui_api.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\ZaiZaiCat-Checkin_script_huaruntong_wentiweilaihui_api.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "import requests\nimport uuid\nimport time\n\nclass WenTiWeiLaiHuiAPI:\n    \"\"\"文体未来荟API接口类\"\"\"\n\n    def __init__(self, token, mobile, user_agent=None):\n        \"\"\"\n        初始化API\n        :param token: 认证token\n        :param mobile: 手机号（用于显示）\n        :param user_agent: 用户代理字符串\n        \"\"\"\n        self.token = token\n        self.mobile = mobile\n        self.base_url = \"https://wtmp.crland.com.cn\"\n        self.user_agent = user_agent or 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36 MicroMessenger/7.0.20.1781(0x6700143B) NetType/WIFI MiniProgramEnv/Mac MacWechat/WMPF MacWechat/3.8.7(0x13080712) UnifiedPCMacWechat(0xf26405f0) XWEB/13910'\n        self.headers = {\n            'User-Agent': self.user_agent,\n            'Content-Type': 'application/json',\n            'xweb_xhr': '1',\n            'x-hrt-mid-appid': 'API_AUTH_MINI',\n            'token': self.token,\n            'sec-fetch-site': 'cross-site',\n            'sec-fetch-mode': 'cors',\n            'sec-fetch-dest': 'empty',\n            'referer': 'https://servicewechat.com/wx3c35b1f0737c23ce/11/page-frame.html',\n            'accept-language': 'zh-CN,zh;q=0.9',\n            'priority': 'u=1, i'\n        }\n\n    def sign_in(self):\n        \"\"\"\n        签到接口\n        :return: 接口响应数据\n        \"\"\"\n        url = f\"{self.base_url}/promotion/app/sign/signin\"\n\n        # 生成签到数据\n        data = {\n            \"data\": {\n                \"outOrderNo\": str(uuid.uuid4()),\n                \"mobile\": self.mobile,\n                \"timestamp\": int(time.time() * 1000),\n                \"projectCode\": \"df2d233f94f4c508073e0646610c021\",\n                \"deviceChannel\": \"WECHAT\",\n                \"businessChannel\": \"miniprogram\",\n                \"channelCode\": \"wechat\"\n            }\n        }\n\n        try:\n            response = requests.post(url, json=data, headers=self.headers)\n            response.raise_for_status()\n            return response.json()\n        except Exception as e:\n            return {\"success\": False, \"msg\": f\"请求失败：{str(e)}\"}\n\n    def query_points(self):\n        \"\"\"\n        查询万象星积分\n        :return: 接口响应数据\n        \"\"\"\n        url = f\"{self.base_url}/pointsAccount/app/queryAccount\"\n\n        try:\n            response = requests.post(url, json={}, headers=self.headers)\n            response.raise_for_status()\n            return response.json()\n        except Exception as e:\n            return {\"success\": False, \"msg\": f\"请求失败：{str(e)}\"}"}
{"code_id": "X-AnyLabeling-Server_app_models_yolo11.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\X-AnyLabeling-Server_app_models_yolo11.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\X-AnyLabeling-Server_app_models_yolo11.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\X-AnyLabeling-Server_app_models_yolo11.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "import sys\nfrom typing import Any, Dict\nfrom . import BaseModel\nfrom app.schemas.shape import Shape\nfrom app.core.registry import register_model\n\n@register_model(\"yolov11\", \"yolov11s\", \"yolov11m\", \"yolov11l\", \"yolov11x\")\nclass YOLOv11DetectionModel(BaseModel):\n    \"\"\"YOLOv11 object detection model.\"\"\"\n\n    def load(self):\n        \"\"\"Load YOLO model.\"\"\"\n        from ultralytics import YOLO\n\n        model_path = self.params.get(\"model_path\", \"yolov11n.pt\")\n        device = self.params.get(\"device\", \"cpu\")\n\n        self.model = YOLO(model_path)\n        self.model.to(device)\n\n        dummy_img = np.zeros((640, 640, 3), dtype=np.uint8)\n        self.model(dummy_img, verbose=False)\n\n    def predict(\n        self,\n        image: np.ndarray,\n        params: Dict[str, Any],\n    ) -> Dict[str, Any]:\n        \"\"\"Execute object detection.\n\n        Args:\n            image: Input image in BGR format.\n            params: Inference parameters.\n\n        Returns:\n            Dictionary with detection results.\n        \"\"\"\n        conf_threshold = params.get(\n            \"conf_threshold\", self.params.get(\"conf_threshold\", 0.25)\n        )\n        iou_threshold = params.get(\n            \"iou_threshold\", self.params.get(\"iou_threshold\", 0.45)\n        )\n\n        results = self.model(\n            image, conf=conf_threshold, iou=iou_threshold, verbose=False\n        )\n\n        shapes = []\n        for result in results:\n            boxes = result.boxes\n            if boxes is not None:\n                for box in boxes:\n                    xyxy = box.xyxy[0].cpu().numpy()\n                    conf = float(box.conf[0])\n                    cls = int(box.cls[0])\n                    label = result.names[cls]\n\n                    shape = Shape(\n                        label=label,\n                        shape_type=\"rectangle\",\n                        points=[\n                            [float(xyxy[0]), float(xyxy[1])],\n                            [float(xyxy[2]), float(xyxy[3])],\n                            [float(xyxy[2]), float(xyxy[1])],\n                            [float(xyxy[0]), float(xyxy[3])],\n                        ],\n                        score=conf,\n                    )\n                    shapes.append(shape)\n\n        return {\"shapes\": shapes, \"description\": \"\"}\n\n    def unload(self):\n        \"\"\"Release model resources.\"\"\"\n        if hasattr(self, \"model\"):\n            del self.model"}
{"code_id": "X-AnyLabeling-Server_app_models_yolo11.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\X-AnyLabeling-Server_app_models_yolo11.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\X-AnyLabeling-Server_app_models_yolo11.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\X-AnyLabeling-Server_app_models_yolo11.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "ZaiZaiCat-Checkin_script_huaruntong_wentiweilaihui_api.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\ZaiZaiCat-Checkin_script_huaruntong_wentiweilaihui_api.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\ZaiZaiCat-Checkin_script_huaruntong_wentiweilaihui_api.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\ZaiZaiCat-Checkin_script_huaruntong_wentiweilaihui_api.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "import requests\nimport uuid\nimport time\n\nclass WenTiWeiLaiHuiAPI:\n    \"\"\"文体未来荟API接口类\"\"\"\n\n    def __init__(self, token, mobile, user_agent=None):\n        \"\"\"\n        初始化API\n        :param token: 认证token\n        :param mobile: 手机号（用于显示）\n        :param user_agent: 用户代理字符串\n        \"\"\"\n        self.token = token\n        self.mobile = mobile\n        self.base_url = \"https://wtmp.crland.com.cn\"\n        self.user_agent = user_agent or 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36 MicroMessenger/7.0.20.1781(0x6700143B) NetType/WIFI MiniProgramEnv/Mac MacWechat/WMPF MacWechat/3.8.7(0x13080712) UnifiedPCMacWechat(0xf26405f0) XWEB/13910'\n        self.headers = {\n            'User-Agent': self.user_agent,\n            'Content-Type': 'application/json',\n            'xweb_xhr': '1',\n            'x-hrt-mid-appid': 'API_AUTH_MINI',\n            'token': self.token,\n            'sec-fetch-site': 'cross-site',\n            'sec-fetch-mode': 'cors',\n            'sec-fetch-dest': 'empty',\n            'referer': 'https://service.wechat.com/wx3c35b1f0737c23ce/11/page-frame.html',\n            'accept-language': 'zh-CN,zh;q=0.9',\n            'priority': 'u=1, i'\n        }\n\n    def sign_in(self):\n        \"\"\"\n        签到接口\n        :return: 接口响应数据\n        \"\"\"\n        url = f\"{self.base_url}/promotion/app/sign/signin\"\n\n        # 生成签到数据\n        data = {\n            \"data\": {\n                \"outOrderNo\": str(uuid.uuid4()),\n                \"mobile\": self.mobile,\n                \"timestamp\": int(time.time() * 1000),\n                \"projectCode\": \"df2d2333f94f4c508073e0646610c021\",\n                \"deviceChannel\": \"WECHAT\",\n                \"businessChannel\": \"miniprogram\",\n                \"channelCode\": \"wechat\"\n            }\n        }\n\n        try:\n            response = requests.post(url, json=data, headers=self.headers)\n            response.raise_for_status()\n            return response.json()\n        except Exception as e:\n            return {\"success\": False, \"msg\": f\"请求失败: {str(e)}\"}\n\n    def query_points(self):\n        \"\"\"\n        查询万象星积分\n        :return: 接口响应数据\n        \"\"\"\n        url = f\"{self.base_url}/pointsAccount/app/queryAccount\"\n\n        try:\n            response = requests.post(url, json=[], headers=self.headers)\n            response.raise_for_status()\n            return response.json()\n        except Exception as e:\n            return {\"success\": False, \"msg\": f\"请求失败: {str(e)}\"}"}
{"code_id": "ZaiZaiCat-Checkin_script_huaruntong_wentiweilaihui_api.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\ZaiZaiCat-Checkin_script_huaruntong_wentiweilaihui_api.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\ZaiZaiCat-Checkin_script_huaruntong_wentiweilaihui_api.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\ZaiZaiCat-Checkin_script_huaruntong_wentiweilaihui_api.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "import requests\nimport uuid\nimport time\n\nclass BenTianLaiAPI:\n    \"\"\"全体育来客API接口类\"\"\"\n\n    def __init__(self, token, mobile, user_agent=None):\n        \"\"\"\n        初始化API\n        :param token: 认证token\n        :param mobile: 手机号（需予显示）\n        :param user_agent: 用户代理字符串\n        \"\"\"\n        self.token = token\n        self.mobile = mobile\n        self.base_url = \"https://temp.oriland.com.cn\"\n        self.user_agent = user_agent or \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36 MicroMessenger/7.0.20.1781 (0x67007438) NetType/WIFI MiniProgramEnv/Mac MacWechat/3.8.7 (0x3080712) UnifiedPCMacWechat (0xf26405fc) 游戏包/1.9/F10\"\n\n        self.headers = {\n            'User-Agent': self.user_agent,\n            'Content-Type': 'application/json',\n            'env_id': '1',\n            'x-tt-mid-uuid': 'API_AUTH_系列',\n            'token': self.token,\n            'smc-fetch-site': 'cross-site',\n            'smc-fetch-mode': 'cors',\n            'smc-fetch-dest': 'empty',\n            'referer': 'https://servicemwechat.com/wx3c350f073c23bc/11/pages-frame.html',\n            'accept-language': 'zh-CN,zh;q=0.9',\n            'priority': 'u=1, i'\n        }\n\n    def sign_in(self):\n        \"\"\"\n        签到接口\n        :return: 接口响应数据\n        \"\"\"\n        url = f\"{self.base_url}/promotion/app/sign/signin\"\n\n        # 生成签到数据\n        data = {\n            \"data\": [\n                \"sourceDevice\": \"ios\"+uuid.uuid4(),\n                \"mobile\": self.mobile,\n                \"timestamp\": int(time.time()) * 1000,\n                \"projectIdCode\": \"df7d2033f9414a508073a0646670c021\",\n                \"deviceChannel\": \"MOBILE\",\n                \"businessChannel\": \"mini_program\",\n                \"channelCode\": \"wechat\"\n            ]\n        }\n\n        try:\n            response = requests.post(url, json=data, headers=self.headers)\n            response.raise_for_status()\n            return response.json()\n        except Exception as e:\n            return {\"success\": False, \"msg\": f\"请求失败: {str(e)}\"}\n\n    def query_points(self):\n        \"\"\"\n        查询万象星积分\n        :return: 接口响应数据\n        \"\"\"\n        url = f\"{self.base_url}/point/account/app/queryAccount\"\n\n        try:\n            response = requests.get(url, json=[], headers=self.headers)\n            response.raise_for_status()\n            return response.json()\n        except Exception as e:\n            return {\"success\": False, \"msg\": f\"请求失败: {str(e)}\"}"}
{"code_id": "ZaiZaiCat-Checkin_script_huaruntong_wentiweilaihui_api.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\ZaiZaiCat-Checkin_script_huaruntong_wentiweilaihui_api.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\ZaiZaiCat-Checkin_script_huaruntong_wentiweilaihui_api.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\ZaiZaiCat-Checkin_script_huaruntong_wentiweilaihui_api.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "agentready_src_agentready_fixers_base.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\agentready_src_agentready_fixers_base.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\agentready_src_agentready_fixers_base.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\agentready_src_agentready_fixers_base.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "\"\"\"Fixer interface for automated remediation.\"\"\"\nfrom abc import ABC, abstractmethod\nfrom typing import Optional\n\nfrom ..models.finding import Finding\nfrom ..models.fix import Fix\nfrom ..models.repository import Repository\n\nclass BaseFixer(ABC):\n    \"\"\"Abstract base class for all attribute fixers.\n\n    Each fixer knows how to automatically remediate a specific failing attribute\n    by generating files, modifying configurations, or executing commands.\n\n    Fixers follow the strategy pattern and are stateless for easy testing.\n    \"\"\"\n\n    @property\n    @abstractmethod\n    def attribute_id(self) -> str:\n        \"\"\"Unique attribute identifier (e.g., 'claude_md_file').\n\n        Must match the attribute ID from assessors.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def can_fix(self, finding: Finding) -> bool:\n        \"\"\"Check if this fixer can fix the given finding.\n\n        Args:\n            finding: Assessment finding for the attribute\n\n        Returns:\n            True if this fixer can generate a fix, False otherwise\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def generate_fix(self, repository: Repository, finding: Finding) -> Optional[Fix]:\n        \"\"\"Generate a fix for the failing attribute.\n\n        Args:\n            repository: Repository entity with path, languages, metadata\n            finding: Failing finding to remediate\n\n        Returns:\n            Fix object if one can be generated, None if cannot be fixed automatically\n\n        Raises:\n            This method should NOT raise exceptions. Return None on errors.\n        \"\"\"\n        pass\n\n    def estimate_score_improvement(self, finding: Finding) -> float:\n        \"\"\"Estimate score points gained if fix is applied.\n\n        Args:\n            finding: Failing finding\n\n        Returns:\n            Estimated points (0-100) that would be gained\n\n        Default implementation: Use attribute default_weight from finding.\n        \"\"\"\n        if finding.status == \"fail\" and finding.attribute.default_weight:\n            # Full weight if currently failing (0 points)\n            return finding.attribute.default_weight * 100\n        return 0.0"}
{"code_id": "agentready_src_agentready_fixers_base.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\agentready_src_agentready_fixers_base.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\agentready_src_agentready_fixers_base.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\agentready_src_agentready_fixers_base.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "\"\"\"User interface for automated remediation.\"\"\"\nfrom abc import ABC, abstractmethod\nfrom typing import Optional\n\nfrom ..models.finding import Finding\nfrom ..models.fix import Fix\nfrom ..models.repository import Repository\n\nclass BaseFixer(ABC):\n    \"\"\"Abstract base class for all attribute fixers.\n\n    Each fixer knows how to automatically remediate a specific failing attribute\n    by generating files, modifying configurations, or executing commands.\n\n    Fixers follow the strategy pattern and are stateless for easy testing.\n    \"\"\"\n\n    @property\n    @abstractmethod\n    def attribute_id(self) -> str:\n        \"\"\"Unique attribute identifier (e.g., \"cloud_md_file\").\n\n        Must match the attribute ID from assessors.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def can_fix(self, finding: Finding) -> bool:\n        \"\"\"Check if this fixer can fix the given finding.\n\n        Args:\n            finding: Assessment finding for the attribute\n\n        Returns:\n            True if this fixer can generate a fix. False otherwise\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def generate_fix(self, repository: Repository, finding: Finding) -> Optional[Fix]:\n        \"\"\"Generate a fix for the failing attribute.\n\n        Args:\n            repository: Repository entity with path, languages, metadata\n            finding: Failing finding to remediate\n\n        Returns:\n            Fix object if one can be generated, None if cannot be fixed automatically\n\n        Raises:\n            This method should NOT raise exceptions. Return None on errors.\n        \"\"\"\n        pass\n\n    def estimate_score_improvement(self, finding: Finding) -> float:\n        \"\"\"Estimate score points gained if fix is applied.\n\n        Args:\n            finding: Failing finding\n\n        Returns:\n            Estimated points (0-100) that would be gained\n\n        Default implementation: Use attribute default_weight from finding.\n        \"\"\"\n        if finding.status == \"fail\" and finding.attribute.default_weight:\n            # Full weight of currently failing ID points)\n            return finding.attribute.default_weight * 100\n        return 0.0"}
{"code_id": "agentready_src_agentready_fixers_base.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\agentready_src_agentready_fixers_base.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\agentready_src_agentready_fixers_base.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\agentready_src_agentready_fixers_base.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "\"\"\"Fixer interface for automated remediation.\"\"\"\nfrom abc import ABC, abstractmethod\nfrom typing import Optional\nfrom ..models.finding import Finding\nfrom ..models.fix import Fix\nfrom ..models.repository import Repository\n\nclass BaseFixer(ABC):\n    \"\"\"Abstract base class for all attribute fixers.\n\n    Each fixer knows how to automatically remediate a specific failing attribute\n    by generating files, modifying configurations, or executing commands.\n\n    Fixers follow the strategy pattern and are stateless for easy testing.\n    \"\"\"\n    @property\n    @abstractmethod\n    def attribute_id(self) -> str:\n        \"\"\"Unique attribute identifier (e.g., 'claude_md_file').\n\n        Must match the attribute ID from assessors.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def can_fix(self, finding: Finding) -> bool:\n        \"\"\"Check if this fixer can fix the given finding.\n\n        Args:\n            finding: Assessment finding for the attribute\n\n        Returns:\n            True if this fixer can generate a fix, False otherwise\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def generate_fix(self, repository: Repository, finding: Finding) -> Optional[Fix]:\n        \"\"\"Generate a fix for the failing attribute.\n\n        Args:\n            repository: Repository entity with path, languages, metadata\n            finding: Failing finding to remediate\n\n        Returns:\n            Fix object if one can be generated, None if cannot be fixed automatically\n\n        Raises:\n            This method should NOT raise exceptions. Return None on errors.\n        \"\"\"\n        pass\n\ndef estimate_score_improvement(self, finding: Finding) -> float:\n    \"\"\"Estimate score points gained if fix is applied.\n\n    Args:\n        finding: Failing finding\n\n    Returns:\n        Estimated points (0-100) that would be gained\n\n    Default implementation: Use attribute default_weight from finding.\n    \"\"\"\n    if finding.status == \"fail\" and finding.attribute.default_weight:\n        # Full weight if currently failing (0 points)\n        return finding.attribute.default_weight * 100\n    return 0.0"}
{"code_id": "ZaiZaiCat-Checkin_script_huaruntong_wentiweilaihui_api.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\ZaiZaiCat-Checkin_script_huaruntong_wentiweilaihui_api.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\ZaiZaiCat-Checkin_script_huaruntong_wentiweilaihui_api.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\ZaiZaiCat-Checkin_script_huaruntong_wentiweilaihui_api.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "agentready_src_agentready_fixers_base.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\agentready_src_agentready_fixers_base.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\agentready_src_agentready_fixers_base.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\agentready_src_agentready_fixers_base.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": "from typing import Any, abstractmethod\nfrom typing import Any\nfrom .models.finding import Finding\nfrom .models.finding import Finding\nfrom .models.repository import Repository\n\nclass Fixer(ABC):\n    \"\"\"Abstract base class for all attribute fixers.\n\n    Each Fixer knows how to automatically or semi-automatically\n    fix a failing attribute by generating a fix, modifying configurations,\n    or executing commands.\n\n    Each fixer has an unique pattern and area of expertise for easy testing.\n    \"\"\"\n\n    @abstractmethod\n    def __init__(self, config: 'Config') -> None:\n        \"\"\"Accepts configuration constructor (e.g., 'readme_path').\n\n        Must accept the attributes of the constructor.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def can_fix(self, finding: Finding) -> bool:\n        \"\"\"Check if this fixer can fix this given finding.\n\n        Args:\n            finding: Assessment finding for the attribute\n\n        Returns:\n            True if this fixer can generate a fix, false otherwise\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def generate_fix(self, finding: Finding) -> Optional[str]:\n        \"\"\"Generates a fix for the failing attribute.\n\n        Args:\n            finding: Assessment finding for the failing attribute\n\n        Returns:\n            Fix object if one can be generated, None if cannot be fixed automatically by\n            this method\n        \"\"\"\n        pass\n\n    def execute(self, source: Repository, improvement_level: Finding, finding: Finding) -> Fixer:\n        \"\"\"Executes entire process of fix is applied.\n\n        Args:\n            finding: Failing finding finding\n\n        Returns:\n            Generated process (Fixer) that would be applied\n        \"\"\"\n        pass\n\n    @staticmethod\n    def accepts_improvement_from_finding(finding: Finding) -> bool:\n        if finding.status == 'fail' and finding.auto_fixes.default_accepts:\n            if 'fix_weight' not in finding.attributes:\n                finding.attributes['fix_weight'] = 100\n            return True\n        return False\n\ndef execute(self, source: Repository, improvement_level: Finding, finding: Finding) -> Fixer:\n    \"\"\"Executes entire process of fix is applied.\n\n    Args:\n        finding: Failing finding finding\n\n    Returns:\n        Generated process (Fixer) that would be applied\n    \"\"\"\n    pass\n\n@staticmethod\ndef accepts_improvement_from_finding(finding: Finding) -> bool:\n    if finding.status == 'fail' and finding.auto_fixes.default_accepts:\n        if 'fix_weight' not in finding.attributes:\n            finding.attributes['fix_weight'] = 100\n        return True\n    return False"}
{"code_id": "agentscope-runtime_src_agentscope_runtime_sandbox_enums.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\agentscope-runtime_src_agentscope_runtime_sandbox_enums.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\agentscope-runtime_src_agentscope_runtime_sandbox_enums.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\agentscope-runtime_src_agentscope_runtime_sandbox_enums.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "# -*- coding: utf-8 -*-\nfrom enum import Enum, EnumMeta\n\nclass DynamicEnumMeta(EnumMeta):\n    def __new__(\n        metacls,\n        cls,\n        bases,\n        classdict,\n        **kwds,\n    ):  # pylint: disable=bad-mcs-classmethod-argument\n        enum_class = super().__new__(metacls, cls, bases, classdict, **kwds)\n        for member in enum_class:\n            member.builtin = True\n        return enum_class\n\nclass DynamicEnum(Enum, metaclass=DynamicEnumMeta):\n    def __init__(self, value):  # pylint: disable=unused-argument\n        self.builtin = True\n\n    @classmethod\n    def add_member(cls, name: str, value=None):\n        if name in cls.__members__:\n            raise ValueError(f\"Member '{name}' already exists.\")\n\n        if value is None:\n            value = name.lower()\n\n        # Add new member\n        new_member = cls._create_pseudo_member(name, value)\n        new_member.builtin = False\n        cls.__member_map__[name] = new_member\n        cls.__value2member_map__[value] = new_member\n        # Update ordered members\n        cls.__member_names__.append(name)\n\n    @classmethod\n    def _create_pseudo_member(cls, name, value):\n        temp = object.__new__(cls)\n        temp._value_ = value\n        temp._name_ = name\n        temp.__objclass__ = cls\n        return temp\n\n    @classmethod\n    def get_builtin_members(cls):\n        return [member for member in cls if getattr(member, \"builtin\", False)]\n\n\n    @classmethod\n    def get_dynamic_members(cls):\n        return [\n            member for member in cls if not getattr(member, \"builtin\", False)\n        ]\n\n\ndef is_builtin(self):\n    return getattr(self, \"builtin\", False)\n\n\nclass SandboxType(DynamicEnum):\n    \"\"\"Sandbox type enumeration\"\"\"\n\n    DUMMY = \"dummy\"\n    BASE = \"base\"\n    BROWSER = \"browser\"\n    FILESYSTEM = \"filesystem\"\n    GUI = \"gui\"\n    MOBILE = \"mobile\"\n    APPWORLD = \"appworld\"\n    BFCL = \"bfcl\"\n    AGENTBAY = \"agentbay\"\n\n    # Async sandbox\n    BASE_ASYNC = \"base_async\"\n    BROWSER_ASYNC = \"browser_async\"\n    FILESYSTEM_ASYNC = \"filesystem_async\"\n    GUI_ASYNC = \"gui_async\"\n    MOBILE_ASYNC = \"mobile_async\""}
{"code_id": "agentscope-runtime_src_agentscope_runtime_sandbox_enums.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\agentscope-runtime_src_agentscope_runtime_sandbox_enums.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\agentscope-runtime_src_agentscope_runtime_sandbox_enums.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\agentscope-runtime_src_agentscope_runtime_sandbox_enums.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "# coding: utf-8 -*-\nfrom enum import Enum, EnumMeta\n\nclass DynamicEnumMeta(EnumMeta):\n    def __new__(\n        metacls,\n        cls,\n        bases,\n        classdict,\n        **kwds,\n    ):  # pylint: disable=bad-mcs-classmethod-argument\n        enum_class = super().__new__(metacls, cls, bases, classdict, **kwds)\n        for member in enum_class:\n            member.builtin = True\n        return enum_class\n\nclass DynamicEnum(Enum, metaclass=DynamicEnumMeta):\n    def __init__(self, value):  # pylint: disable=unused-argument\n        self.builtin = True\n\n    @classmethod\n    def add_member(cls, name: str, value=None):\n        if name in cls.__members__:\n            raise ValueError(f\"Member '{name}' already exists.\")\n\n        if value is None:\n            value = name.lower()\n\n        # Add new member\n        new_member = cls._create_pseudo_member(name, value)\n        new_member.builtin = False\n        cls.__member_map__[name] = new_member\n        cls.__value2member_map__[value] = new_member\n        # Update ordered members\n        cls.__member_names__.append(name)\n\n    @classmethod\n    def _create_pseudo_member(cls, name, value):\n        temp = object.__new__(cls)\n        temp._value_ = value\n        temp._name_ = name\n        temp.__objclass__ = cls\n        return temp\n\n    @classmethod\n    def get_builtin_members(cls):\n        return [member for member in cls if getattr(member, \"builtin\", False)]]\n\n    @classmethod\n    def get_dynamic_members(cls):\n        return [\n            member for member in cls if not getattr(member, \"builtin\", False)\n        ]\n\n    def is_builtin(self):\n        return getattr(self, \"builtin\", False)\n\nclass SandboxType(DynamicEnum):\n    \"\"\"Sandbox type enumeration\"\"\"\n\n    DUMMY = \"dummy\"\n    BASE = \"base\"\n    BROWSER = \"browser\"\n    FILESYSTEM = \"filesystem\"\n    GUI = \"gui\"\n    MOBILE = \"mobile\"\n    APPWORLD = \"appworld\"\n    BFCL = \"bfcl\"\n    AGENTBAY = \"agentbay\"\n\n    # Async sandbox\n    BASE_ASYNC = \"base_async\"\n    BROWSER_ASYNC = \"browser_async\"\n    FILESYSTEM_ASYNC = \"filesystem_async\"\n    GUI_ASYNC = \"gui_async\"\n    MOBILE_ASYNC = \"mobile_async\""}
{"code_id": "agentready_src_agentready_fixers_base.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\agentready_src_agentready_fixers_base.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\agentready_src_agentready_fixers_base.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\agentready_src_agentready_fixers_base.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": "\"\"\"Module for handling the audio classification dataset.\"\"\"\n\nimport os\nimport glob\nimport numpy as np\nimport librosa\nimport librosa.display\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom sklearn.model_selection import train_test_split\n\nclass AudioDataset:\n    \"\"\"Dataset class for the audio classification dataset.\"\"\"\n\n    def __init__(self, data_dir, class_names, sr=22050):\n        \"\"\"Initialize the audio dataset class.\n\n        Args:\n            data_dir (str): Path to the dataset directory.\n            class_names (list): List of class names.\n            sr (int): Sampling rate for audio files.\n        \"\"\"\n        self.data_dir = data_dir\n        self.class_names = class_names\n        self.sr = sr\n        self.class_to_idx = {name: idx for idx, name in enumerate(class_names)}\n        self.audio_files = []\n        self.labels = []\n\n        # Load all audio files and their corresponding labels\n        for class_name in class_names:\n            class_dir = os.path.join(data_dir, class_name)\n            audio_files = glob.glob(os.path.join(class_dir, '*.wav'))\n            for audio_file in audio_files:\n                self.audio_files.append(audio_file)\n                self.labels.append(self.class_to_idx[class_name])\n\n    def __len__(self):\n        \"\"\"Return the number of audio files in the dataset.\"\"\"\n        return len(self.audio_files)\n\n    def __getitem__(self, idx):\n        \"\"\"Get an audio file and its corresponding label by index.\n\n        Args:\n            idx (int): Index of the audio file.\n\n        Returns:\n            tuple: A tuple containing the audio data (numpy array) and its label (int).\n        \"\"\"\n        audio_file ="}
{"code_id": "agentscope-runtime_src_agentscope_runtime_sandbox_enums.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\agentscope-runtime_src_agentscope_runtime_sandbox_enums.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\agentscope-runtime_src_agentscope_runtime_sandbox_enums.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\agentscope-runtime_src_agentscope_runtime_sandbox_enums.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "# coding: utf-8\nfrom enum import Enum, EnumMeta\n\nclass DynamicEnumMeta(EnumMeta):\n    def __new__(\n        mcs,\n        cls,\n        bases,\n        classdict,\n        **kwargs\n    ):  # pylint: disable=bad-mcs-classmethod-argument\n        enum_class = super().__new__(mcs, cls, bases, classdict, **kwargs)\n        for member in enum_class:\n            member.builtin = True\n        return enum_class\n\n\nclass DynamicEnum(Enum, metaclass=DynamicEnumMeta):\n    def __init__(self, value):  # pylint: disable=unused-argument\n        self.builtin = True\n\n    @classmethod\n    def add_member(cls, name: str, value: Any):\n        if name in cls.__members__:\n            raise NameError(f\"Member '{name}' already exists.\")\n\n        if value is None:\n            value = name.lower()\n\n        # Add new member\n        new_member = cls._create_pseudo_member(name, value)\n        new_member.builtin = False\n        cls.__member_map__[name] = new_member\n        cls.__value2member_map__[value] = new_member\n        # Update ordered members\n        cls.__member_names__.append(name)\n\n    @classmethod\n    def _create_pseudo_member(cls, name, value):\n        temp = object.__new__(cls)\n        temp._value_ = value\n        temp._name_ = name\n        temp.__objclass__ = cls\n        return temp\n\n    @classmethod\n    def get_builtin_numbers(cls):\n        return [member for member in cls if getattr(member, \"builtin\", False)]\n\n\nclass SandboxType(DynamicEnum):\n    \"\"\"Sandbox type enumeration\"\"\"\n\n    DUMMY = \"dummy\"\n    BASE = \"base\"\n    BROWSER = \"browser\"\n    FILESYSTEM = \"filesystem\"\n    GUI = \"gui\"\n    MOBILE = \"mobile\"\n    APPWORLD = \"appworld\"\n    SPCL = \"spcl\"\n    AGENTSBAY = \"agentsbay\"\n\n    # Async sandbox\n    BASE_ASYNC = \"base_async\"\n    BROWSER_ASYNC = \"browser_async\"\n    FILESYSTEM_ASYNC = \"filesystem_async\"\n    GUI_ASYNC = \"gui_async\"\n    MOBILE_ASYNC = \"mobile_async\"\n\n\n    @classmethod\n    def get_dynamic_numbers(cls):\n        return [\n            member for member in cls if not getattr(member, \"builtin\", False)\n        ]\n\n    def is_builtin(self):\n        return getattr(self, \"builtin\", False))"}
{"code_id": "ai-llm-red-team-handbook_scripts_compliance_ai_recon_scanner_source.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\ai-llm-red-team-handbook_scripts_compliance_ai_recon_scanner_source.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\ai-llm-red-team-handbook_scripts_compliance_ai_recon_scanner_source.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\ai-llm-red-team-handbook_scripts_compliance_ai_recon_scanner_source.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "#!/usr/bin/env python3\n\"\"\"\nAIRecon Scanner\n\nSource: Chapter_39_AI_Bug_Bounty_Programs\nCategory: compliance\n\"\"\"\nimport aiohttp\nimport asyncio\nfrom typing import Dict, List\n\nimport argparse\nimport sys\n\nclass AIReconScanner:\n    \"\"\"\n    Fingerprints AI backends by analyzing HTTP headers and\n    404/405 error responses for specific signatures.\n    \"\"\"\n\n    def __init__(self, targets: List[str]):\n        self.targets = targets\n        self.signatures = {\n            \"OpenAI\": [\"x-request-id\", \"openai-organization\", \"openai-processing-ms\"],\n            \"Anthropic\": [\"x-api-key\", \"anthropic-version\"],\n            \"HuggingFace\": [\"x-linked-model\", \"x-huggingface-reason\"],\n            \"LangChain\": [\"x-langchain-trace\"],\n            \"Azure OAI\": [\"apim-request-id\", \"x-ms-region\"]\n        }\n\n    async def scan_target(self, url: str) -> Dict:\n        \"\"\"Probes a URL for AI-specific artifacts.\"\"\"\n        results = {\"url\": url, \"backend\": \"Unknown\", \"confidence\": 0}\n\n        try:\n            async with aiohttp.ClientSession() as session:\n                # Probe 1: Check Headers\n                async with session.get(url, verify_ssl=False) as resp:\n                    headers = resp.headers\n                    for tech, sigs in self.signatures.items():\n                        matches = [s for s in sigs if s in headers or s.lower() in headers]\n                        if matches:\n                            results[\"backend\"] = tech\n                            results[\"confidence\"] += 30\n                            results[\"signatures\"] = matches\n\n                # Probe 2: Check Standard API Paths\n                api_paths = [\"/v1/chat/completions\", \"/api/generate\", \"/v1/models\"]\n                for path in api_paths:\n                    full_url = f\"{url.rstrip('/')}{path}\"\n                    async with session.post(full_url, json={}) as resp:\n                        # 400 or 422 usually means \"I understood the path but you sent bad JSON\"\n                        # This confirms the endpoint exists.\n                        if resp.status in [400, 422]:\n                            results[\"endpoint_found\"] = path\n                            results[\"confidence\"] += 50\n\n            return results\n\n        except Exception as e:\n            return {\"url\": url, \"error\": str(e)}\n\n    async def run(self):\n        tasks = [self.scan_target(t) for t in self.targets]\n        return await asyncio.gather(*tasks)\n\n# Usage\n# targets = [\"https://chat.target-corp.com\", \"https://api.startup.io\"]\n# scanner = AIReconScanner(targets)\n# asyncio.run(scanner.run())\n\ndef main():\n    \"\"\"Command-line interface.\"\"\"\n    parser = argparse.ArgumentParser(description=__doc__)\n    parser.add_argument(\"--verbose\", \"-v\", action=\"store_true\", help=\"Verbose output\")\n    args = parser.parse_args()\n\n    # TODO: Add main execution logic\n    pass\n\nif __name__ == \"__main__\":\n    main()"}
{"code_id": "ai-llm-red-team-handbook_scripts_compliance_ai_recon_scanner_source.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\ai-llm-red-team-handbook_scripts_compliance_ai_recon_scanner_source.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\ai-llm-red-team-handbook_scripts_compliance_ai_recon_scanner_source.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\ai-llm-red-team-handbook_scripts_compliance_ai_recon_scanner_source.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "#!/usr/bin/env python3\n\"\"\"\nAIRecon_Scanner\n---\nSource: Chapter_39_AI_Bug_Bounty_Programs\nCategory: compliance\n---\n\"\"\"\nimport aiohttp\nimport asyncio\nfrom typing import Dict, List\nimport argparse\nimport sys\n\nclass AIReconScanner:\n    \"\"\"\n    Fingerprints AI backends by analyzing HTTP headers and\n    404/405 error responses for specific signatures.\n    ---\n    \"\"\"\n    def __init__(self, targets: List[str]):\n        self.targets = targets\n        self.signatures = {\n            \"OpenAI\": [\"x-request-id\", \"openai-organization\", \"openai-processing-ms\"],\n            \"Anthropic\": [\"x-api-key\", \"anthropic-version\"],\n            \"HuggingFace\": [\"x-linked-model\", \"x-huggingface-reason\"],\n            \"LangChain\": [\"x-langchain-trace\"],\n            \"Azure OAI\": [\"apim-request-id\", \"x-ms-region\"]\n        }\n\n    async def scan_target(self, url: str) -> Dict:\n        \"\"\"\n        Probes a URL for AI-specific artifacts.\n        \"\"\"\n        results = {\"url\": url, \"backend\": \"Unknown\", \"confidence\": 0}\n\n        try:\n            async with aiohttp.ClientSession() as session:\n                # Probe 1: Check Headers\n                async with session.get(url, verify_ssl=False) as resp:\n                    headers = resp.headers\n                    for tech, sigs in self.signatures.items():\n                        matches = [s for s in sigs if s in headers or s.lower() in headers]\n                        if matches:\n                            results[\"backend\"] = tech\n                            results[\"confidence\"] += 30\n                            results[\"signatures\"] = matches\n\n                # Probe 2: Check Standard API Paths\n                api_paths = [\"/v1/chat/completions\", \"/api/generate\", \"/v1/models\"]\n                for path in api_paths:\n                    full_url = f\"{url.rstrip('/')}{path}\"\n                    async with session.post(full_url, json={}) as resp:\n                        # 400 or 422 usually means \"I understood the path but you sent bad JSON\"\n                        # This confirms the endpoint exists.\n                        if resp.status in [400, 422]:\n                            results[\"endpoint_found\"] = path\n                            results[\"confidence\"] += 50\n\n            return results\n        except Exception as e:\n            return {\"url\": url, \"error\": str(e)}\n\n    async def run(self):\n        tasks = [self.scan_target(t) for t in self.targets]\n        return await asyncio.gather(*tasks)\n\n# Usage\n# targets = [\"https://chat.target-corp.com\", \"https://api.startup.io\"]\n# scanner = AIReconScanner(targets)\n# asyncio.run(scanner.run())\n\ndef main():\n    \"\"\"\n    Command-line interface.\n    \"\"\"\n    parser = argparse.ArgumentParser(description=__doc__)\n    parser.add_argument(\"--verbose\", \"-v\", action=\"store_true\", help=\"Verbose output\")\n    args = parser.parse_args()\n\n    # TODO: Add main execution logic\n    pass\n\nif __name__ == \"__main__\":\n    main()"}
{"code_id": "ai-llm-red-team-handbook_scripts_compliance_ai_recon_scanner_source.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\ai-llm-red-team-handbook_scripts_compliance_ai_recon_scanner_source.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\ai-llm-red-team-handbook_scripts_compliance_ai_recon_scanner_source.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\ai-llm-red-team-handbook_scripts_compliance_ai_recon_scanner_source.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "#!/usr/bin/env python3\n\"\"\"\nAIRecon_Scanner\n...\nSource: Chapter_30_AI_Bug_Bounty_Programs\nCategory: compliance\n...\n\"\"\"\n\nimport aioshttp\nimport asyncio\nfrom typing import Dict, List\n\nimport argparse\nimport sys\n\nclass AIReconScanner:\n    \"\"\"\n    Fingerprints AI backends by analyzing HTTP headers and\n    404/405 error responses for specific signatures.\n    ...\n    \"\"\"\n\n    def __init__(self, targets: List[str]):\n        self.targets = targets\n        self.signatures = {\n            \"OpenAI\": [\"x-request-id\", \"openai-organization\", \"openai-processing-ms\"],\n            \"Anthropic\": [\"x-api-key\", \"anthropic-version\"],\n            \"HuggingFace\": [\"x-linked-model\", \"x-huggingface-reason\"],\n            \"LangChain\": [\"x-langchain-trace\"],\n            \"Azure OpenAI\": [\"azure-request-id\", \"x-ms-region\"]\n        }\n\n    async def scan_target(self, url: str) -> Dict:\n        \"\"\"Probes a URL for AI-specific artifacts.\"\"\"\n        results = {\"url\": url, \"backend\": \"Unknown\", \"confidence\": 0}\n\n        try:\n            async with aioshttp.ClientSession() as session:\n                # Probe 1: Check Headers\n                async with session.get(url, verify_ssl=False) as resp:\n                    headers = resp.headers\n                    for tech, signs in self.signatures.items():\n                        matches = [s for s in signs if s in headers or s.lower() in headers]\n                        if matches:\n                            results[\"backend\"] = tech\n                            results[\"confidence\"] = 30\n                            results[\"signatures\"] = matches\n\n                # Probe 2: Check Standard API Paths\n                api_paths = [\"/v1/chat/completions\", \"/api/generate\", \"/v1/models\"]\n                for path in api_paths:\n                    full_url = f\"{url.rstrip('/')}{path}\"\n                    async with session.post(full_url, json={}) as resp:\n                        # 400 or 401 usually means \"I understood the path but you sent bad JSON\"\n                        # This confirms the endpoint exists.\n                        if resp.status in {400, 401}:\n                            results[\"endpoint_found\"] = path\n                            results[\"confidence\"] = 50\n\n            return results\n\n        except Exception as e:\n            return {\"url\": url, \"error\": str(e)}\n\n    async def run(self):\n        tasks = [self.scan_target(t) for t in self.targets]\n        return await asyncio.gather(*tasks)\n\n# Usage\n# targets = [\"https://chat.target-corp.com\", \"https://api.interop.io\"]\n# scanner = AIReconScanner(targets)\n# asyncio.run(scanner.run())\n\ndef main():\n    \"\"\"Command-line interface.\"\"\"\n    parser = argparse.ArgumentParser(description=__doc__)\n    parser.add_argument(\"--verbose\", \"-v\", action=\"store_true\", help=\"Verbose output\")\n    args = parser.parse_args()\n\n    # TODO: Add main execution logic\n    pass\n\nif __name__ == \"__main__\":\n    main()"}
{"code_id": "agentscope-runtime_src_agentscope_runtime_sandbox_enums.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\agentscope-runtime_src_agentscope_runtime_sandbox_enums.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\agentscope-runtime_src_agentscope_runtime_sandbox_enums.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\agentscope-runtime_src_agentscope_runtime_sandbox_enums.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "agentscope-runtime_src_agentscope_runtime_sandbox_enums.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\agentscope-runtime_src_agentscope_runtime_sandbox_enums.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\agentscope-runtime_src_agentscope_runtime_sandbox_enums.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\agentscope-runtime_src_agentscope_runtime_sandbox_enums.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "ai-llm-red-team-handbook_scripts_compliance_ai_recon_scanner_source.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\ai-llm-red-team-handbook_scripts_compliance_ai_recon_scanner_source.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\ai-llm-red-team-handbook_scripts_compliance_ai_recon_scanner_source.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\ai-llm-red-team-handbook_scripts_compliance_ai_recon_scanner_source.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": "class HTTPRequestHandler(BaseHTTPRequestHandler):\n    \"\"\"Handles HTTP requests and responses.\"\"\"\n\n    def do_GET(self):\n        \"\"\"Handles GET requests.\"\"\"\n        self.send_response(200)\n        self.send_header('Content-type', 'text/html')\n        self.end_headers()\n\n        # Generate a simple HTML response\n        html = f\"\"\"\n        <html>\n        <head>\n            <title>Simple HTTP Server</title>\n        </head>\n        <body>\n            <h1>Hello, World!</h1>\n            <p>This is a simple HTTP server response.</p>\n        </body>\n        </html>\n        \"\"\"\n\n        self.wfile.write(html.encode('utf-8'))\n\n    def do_POST(self):\n        \"\"\"Handles POST requests.\"\"\"\n        content_length = int(self.headers['Content-Length'])\n        post_data = self.rfile.read(content_length).decode('utf-8')\n\n        self.send_response(200)\n        self.send_header('Content-type', 'text/html')\n        self.end_headers()\n\n        # Generate a response based on the POST data\n        html = f\"\"\"\n        <html>\n        <head>\n            <title>POST Request Received</title>\n        </head>\n        <body>\n            <h1>POST Request Received</h1>\n            <p>You sent the following data:</p>\n            <pre>{post_data}</pre>\n        </body>\n        </html>\n        \"\"\"\n\n        self.wfile.write(html.encode('utf-8'))\n\ndef run_server(port=8080):\n    \"\"\"Starts the HTTP server.\"\"\"\n    server_address = ('', port)\n    httpd = HTTPServer(server_address, HTTPRequestHandler)\n    print(f'Starting server on port {port}...')\n    httpd.serve_forever()\n\nif __name__ == '__main__':\n    run_server()"}
{"code_id": "ai_story_backend_core_ai_client_mock_image2video_client.py", "ratio": 1, "num_pages": 3, "image_paths": ["./experiment_output\\images_glm46v\\ai_story_backend_core_ai_client_mock_image2video_client.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\ai_story_backend_core_ai_client_mock_image2video_client.py\\1024x1024_hl_nl\\page_002_ratio1.png", "./experiment_output\\images_glm46v\\ai_story_backend_core_ai_client_mock_image2video_client.py\\1024x1024_hl_nl\\page_003_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\ai_story_backend_core_ai_client_mock_image2video_client.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "import time\nfrom typing import Dict, Any\nfrom .base import Image2VideoClient, AIResponse\n\nclass MockImage2VideoClient(Image2VideoClient):\n    \"\"\"\n    Mock 图生视频客户端\n    返回预定义的模拟视频URL，用于测试工作流\n    \"\"\"\n\n    # 模拟视频URL列表（使用示例视频）\n    MOCK_VIDEO_URLS = [\n        \"https://sample-videos.com/video123/mp4/720/big_buck_bunny_720p_1mb.mp4\",\n        \"https://commondatastorage.googleapis.com/gtv-videos-bucket/sample/BigBuckBunny.mp4\",\n        \"https://test-videos.co.uk/vids/bigbuckbunny/mp4/h264/360/Big_Buck_Bunny_360_10s_1MB.mp4\",\n    ]\n\n    async def _generate_video(\n        self,\n        image_url: str,\n        camera_movement: Dict[str, Any],\n        duration: float,\n        fps: int,\n        **kwargs\n    ) -> AIResponse:\n        \"\"\"\n        生成模拟的视频响应\n\n        Args:\n            image_url: 源图片URL\n            camera_movement: 运镜参数\n            duration: 视频时长\n            fps: 帧率\n            **kwargs: 其他参数\n\n        Returns:\n            AIResponse: 包含模拟视频URL的响应对象\n        \"\"\"\n        start_time = time.time()\n\n        # 模拟API延迟（视频生成通常很慢）\n        time.sleep(2.0)\n\n        # 从kwargs获取参数\n        width = kwargs.get('width', 1280)\n        height = kwargs.get('height', 720)\n        model = kwargs.get('model', self.model_name)\n\n        # 根据图片URL哈希选择视频（保证相同图片返回相同视频）\n        image_hash = hash(image_url) % len(self.MOCK_VIDEO_URLS)\n        video_url = self.MOCK_VIDEO_URLS[image_hash]\n\n        # 构建视频数据\n        video_data = {\n            \"url\": video_url,\n            \"width\": width,\n            \"height\": height,\n            \"duration\": duration,\n            \"fps\": fps,\n            \"format\": \"mp4\",\n            \"file_size\": 1024 * 1024,  # 模拟1MB文件大小\n            \"camera_movement\": camera_movement\n        }\n\n        latency_ms = int((time.time() - start_time) * 1000))\n\n        return AIResponse(\n            success=True,\n            data={\n                'url': video_url,\n                'video': video_data,\n                'videos': [video_data]  # 兼容多视频格式\n            },\n            metadata={\n                'latency_ms': latency_ms,\n                'model': model,\n                'is_mock': True,\n                'source_image': image_url[:100]  # 记录部分源图片URL\n            }\n        )\n\n    async def validate_config(self) -> bool:\n        \"\"\"\n        验证配置（Mock客户端始终返回True）\n\n        Returns:\n            bool: 始终返回True\n        \"\"\"\n        return True\n\n    async def health_check(self) -> bool:\n        \"\"\"\n        健康检查（Mock客户端始终返回True）\n\n        Returns:\n            bool: 始终返回True\n        \"\"\"\n        return True"}
{"code_id": "ai-llm-red-team-handbook_scripts_compliance_ai_recon_scanner_source.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\ai-llm-red-team-handbook_scripts_compliance_ai_recon_scanner_source.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\ai-llm-red-team-handbook_scripts_compliance_ai_recon_scanner_source.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\ai-llm-red-team-handbook_scripts_compliance_ai_recon_scanner_source.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "ai_story_backend_core_ai_client_mock_image2video_client.py", "ratio": 2, "num_pages": 3, "image_paths": ["./experiment_output\\images_glm46v\\ai_story_backend_core_ai_client_mock_image2video_client.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\ai_story_backend_core_ai_client_mock_image2video_client.py\\1024x1024_hl_nl\\page_002_ratio2.png", "./experiment_output\\images_glm46v\\ai_story_backend_core_ai_client_mock_image2video_client.py\\1024x1024_hl_nl\\page_003_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\ai_story_backend_core_ai_client_mock_image2video_client.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "import time\nfrom typing import Dict, Any\nfrom .base import Image2VideoClient, AIResponse\n\nclass MockImage2VideoClient(Image2VideoClient):\n    \"\"\"\n    Mock 图生视频客户端\n    返回预定义的模拟视频URL，用于测试工作流\n    \"\"\"\n\n    # 模拟视频URL列表（使用示例视频）\n    MOCK_VIDEO_URLS = [\n        \"https://sample-videos.com/video123/mp4/720/big_buck_bunny_720p_1mb.mp4\",\n        \"https://commondatastorage.googleapis.com/gtv-videos-bucket/sample/BigBuckBunny.mp4\",\n        \"https://test-videos.co.uk/vids/bigbuckbunny/mp4/h264/360/Big_Buck_Bunny_360_10s_1MB.mp4\",\n    ]\n\n    async def _generate_video(\n        self,\n        image_url: str,\n        camera_movement: Dict[str, Any],\n        duration: float,\n        fps: int,\n        **kwargs\n    ) -> AIResponse:\n        \"\"\"\n        生成模拟的视频响应\n\n        Args:\n            image_url: 源图片URL\n            camera_movement: 运镜参数\n            duration: 视频时长\n            fps: 帧率\n            **kwargs: 其他参数\n\n        Returns:\n            AIResponse: 包含模拟视频URL的响应对象\n        \"\"\"\n        start_time = time.time()\n\n        # 模拟API延迟（视频生成通常很慢）\n        time.sleep(2.0)\n\n        # 从kwargs获取参数\n        width = kwargs.get('width', 1280)\n        height = kwargs.get('height', 720)\n        model = kwargs.get('model', self.model_name)\n\n        # 根据图片URL哈希选择视频（保证相同图片返回相同视频）\n        image_hash = hash(image_url) % len(self.MOCK_VIDEO_URLS)\n        video_url = self.MOCK_VIDEO_URLS[image_hash]\n\n        # 构建视频数据\n        video_data = {\n            \"url\": video_url,\n            \"width\": width,\n            \"height\": height,\n            \"duration\": duration,\n            \"fps\": fps,\n            \"format\": \"mp4\",\n            \"file_size\": 1024 * 1024,  # 模拟1MB文件大小\n            \"camera_movement\": camera_movement\n        }\n\n        latency_ms = int((time.time() - start_time) * 1000))\n\n        return AIResponse(\n            success=True,\n            data={\n                'url': video_url,\n                'video': video_data,\n                'videos': [video_data]  # 兼容多视频格式\n            },\n            metadata={\n                'latency_ms': latency_ms,\n                'model': model,\n                'is_mock': True,\n                'source_image': image_url[:100]  # 记录部分源图片URL\n            }\n        )\n\n    async def validate_config(self) -> bool:\n        \"\"\"\n        验证配置（Mock客户端始终返回True）\n\n        Returns:\n            bool: 始终返回True\n        \"\"\"\n        return True\n\n    async def health_check(self) -> bool:\n        \"\"\"\n        健康检查（Mock客户端始终返回True）\n\n        Returns:\n            bool: 始终返回True\n        \"\"\"\n        return True"}
{"code_id": "ai_story_backend_core_ai_client_mock_image2video_client.py", "ratio": 4, "num_pages": 3, "image_paths": ["./experiment_output\\images_glm46v\\ai_story_backend_core_ai_client_mock_image2video_client.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\ai_story_backend_core_ai_client_mock_image2video_client.py\\1024x1024_hl_nl\\page_002_ratio4.png", "./experiment_output\\images_glm46v\\ai_story_backend_core_ai_client_mock_image2video_client.py\\1024x1024_hl_nl\\page_003_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\ai_story_backend_core_ai_client_mock_image2video_client.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "import time\nfrom typing import Dict, Any\nfrom .base import Image2VideoClient, AIResponse\n\n\nclass MockImage2VideoClient(Image2VideoClient):\n    \"\"\"\n    Mock 图生视频客户端\n    返回预定义的模拟视频响应，用于测试工作流\n    \"\"\"\n\n    # 模拟视频响应列表（使用示例视频）\n    MOCK_VIDEO_URLS = [\n        \"https://sample-videos.com/video123/mp4/720/big_buck_bunny_720p_1mb.mp4\",\n        \"https://commondatastorage.googleapis.com/gtv-videos-bucket/sample/BigBuckBunny.mp4\",\n        \"https://test-videos.co.uk/vids/bigbuckbunny/mp4/h264/360/Big_Buck_Bunny_360_10s_1MB.mp4\",\n    ]\n\n    async def _generate_video(\n        self,\n        image_url: str,\n        camera_movement: Dict[str, Any],\n        duration: float,\n        fps: int,\n        **kwargs\n    ) -> AIResponse:\n        \"\"\"\n        生成模拟的视频响应\n\n        Args:\n            image_url: 源图片URL\n            camera_movement: 摄像参数\n            duration: 视频时长\n            fps: 帧率\n            **kwargs: 其他参数\n\n        Returns:\n            AIResponse: 包含模拟视频URL的响应对象\n        \"\"\"\n        start_time = time.time()\n\n        # 模拟API延迟（根据生成通常需要）\n        await asyncio.sleep(2.0)\n\n        # 从kwargs获取参数\n        width = kwargs.get(\"width\", 1280)\n        height = kwargs.get(\"height\", 720)\n        model = kwargs.get(\"model\", self.model_name)\n\n        # 根据图片URL哈希选择视频（保证相同图片返回相同视频）\n        image_hash = hash(image_url) % len(self.MOCK_VIDEO_URLS)\n        video_url = self.MOCK_VIDEO_URLS[image_hash]\n\n        # 构建视频数据\n        video_data = {\n            \"url\": video_url,\n            \"width\": width,\n            \"height\": height,\n            \"duration\": duration,\n            \"fps\": fps,\n            \"format\": \"mp4\",\n            \"file_size\": 1024 * 1024,  # 模拟1MB文件大小\n            \"camera_movement\": camera_movement\n        }\n\n        latency_ms = int((time.time() - start_time) * 1000)\n\n        return AIResponse(\n            success=True,\n            data={\n                \"url\": video_url,\n                \"video\": video_data,\n                \"videos\": [video_data]  # 兼容多视频格式\n            },\n            metadata={\n                \"latency_ms\": latency_ms,\n                \"model\": model,\n                \"is_mock\": True,\n                \"source_image\": image_url[:100]  # 记录部分源图片URL\n            }\n        )\n\n    async def validate_config(self) -> bool:\n        \"\"\"\n        验证配置（Mock客户端始终返回True）\n        \"\"\"\n        return True\n\n    async def health_check(self) -> bool:\n        \"\"\"\n        健康检查（Mock客户端始终返回True）\n        \"\"\"\n        return True"}
{"code_id": "ai_story_backend_core_ai_client_mock_image2video_client.py", "ratio": 6, "num_pages": 3, "image_paths": ["./experiment_output\\images_glm46v\\ai_story_backend_core_ai_client_mock_image2video_client.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\ai_story_backend_core_ai_client_mock_image2video_client.py\\1024x1024_hl_nl\\page_002_ratio6.png", "./experiment_output\\images_glm46v\\ai_story_backend_core_ai_client_mock_image2video_client.py\\1024x1024_hl_nl\\page_003_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\ai_story_backend_core_ai_client_mock_image2video_client.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": "```python\nimport time\nfrom typing import Optional, List, Any\nfrom PIL import ImageDraw, Image\n\nasync def black_image(**kwargs) -> Image.Image:\n    \"\"\"\n    生成纯黑图片\n    适用于占位或测试用途，图片颜色为纯黑\n    \"\"\"\n    # 4 模板数据结构 (请勿手动创建)\n    template = [\n        {\n            \"type\": \"image\",\n            \"src\": \"https://example.com/black_image.jpg\",\n            \"style\": {\n                \"width\": \"100%\",\n                \"height\": \"100%\"\n            }\n        },\n        {\n            \"type\": \"text\",\n            \"content\": \"占位文本\",\n            \"style\": {\n                \"color\": \"#000000\",\n                \"font_size\": \"14px\"\n            }\n        },\n        {\n            \"type\": \"button\",\n            \"text\": \"占位按钮\",\n            \"style\": {\n                \"background_color\": \"#000000\",\n                \"color\": \"#FFFFFF\",\n                \"font_size\": \"14px\"\n            }\n        }\n    ]\n\n    async def _preprocess(**kwargs):\n        \"\"\"\n        生成模板的预处理函数\n        \"\"\"\n        # 4 生成模板数据结构\n        template = [\n            {\n                \"type\": \"image\",\n                \"src\": \"https://example.com/black_image.jpg\",\n                \"style\": {\n                    \"width\": \"100%\",\n                    \"height\": \"100%\"\n                }\n            }\n        ]\n\n        async def _build_template(**kwargs) -> dict:\n            \"\"\"\n            生成模板数据结构\n            \"\"\"\n            # 4 模板数据结构 (请勿手动创建)\n            template = [\n                {\n                    \"type\": \"image\",\n                    \"src\": \"https://example.com/black_image.jpg\",\n                    \"style\": {\n                        \"width\": \"100%\",\n                        \"height\": \"100%\"\n                    }\n                }\n            ]\n\n            return {\n                \"template\": template,\n                \"version\": \"1.0.0\"\n            }\n\n        async def _check(**kwargs) -> bool:\n            \"\"\"\n            检查模板是否有效\n            \"\"\"\n            return True\n\n        return {}\n```"}
{"code_id": "aicon_backend_src_services_base.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\aicon_backend_src_services_base.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\aicon_backend_src_services_base.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\aicon_backend_src_services_base.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "# -*- coding: utf-8 -*- 提供统一的数据库会话管理和基础功能\nfrom typing import Optional, TYPE_CHECKING\nfrom sqlalchemy.ext.asyncio import AsyncSession\nfrom src.core.database import AsyncSessionLocal\nfrom src.core.logging import get_logger\n\nif TYPE_CHECKING:\n    from typing import Any, Dict, Optional\n\nlogger = get_logger(__name__)\n\nclass BaseService:\n    \"\"\"\n    服务基类\n    要求外部注入 AsyncSession。\n    \"\"\"\n\n    def __init__(self, db_session: AsyncSession):\n        \"\"\"\n        初始化服务实例\n        Args:\n            db_session: 必须提供异步数据库会话\n        \"\"\"\n        self._db_session = db_session\n\n    @property\n    def db_session(self) -> AsyncSession:\n        \"\"\"获取并验证当前绑定的数据库会话\"\"\"\n        if self._db_session is None:\n            raise RuntimeError(f\"{self.__class__.__name__} 尚未绑定数据库会话\")\n        return self._db_session\n\n    async def commit(self):\n        \"\"\"提交当前事务\"\"\"\n        await self.db_session.commit()\n\n    async def rollback(self):\n        \"\"\"回滚当前事务\"\"\"\n        await self.db_session.rollback()\n\n    async def flush(self):\n        \"\"\"刷新当前会话\"\"\"\n        await self.db_session.flush()\n\n    async def refresh(self, obj):\n        \"\"\"刷新对象数据\"\"\"\n        await self.db_session.refresh(obj)\n\n    async def execute(self, query, params: Optional[dict] = None):\n        \"\"\"执行SQL查询\"\"\"\n        return await self.db_session.execute(query, params)\n\n    def add(self, obj):\n        \"\"\"添加对象到会话\"\"\"\n        self.db_session.add(obj)\n\n    def delete(self, obj):\n        \"\"\"从会话中删除对象\"\"\"\n        self.db_session.delete(obj)\n\n    async def get(self, model_class, identifier):\n        \"\"\"根据ID获取对象\"\"\"\n        return await self.db_session.get(model_class, identifier)\n\n__all__ = [\"BaseService\"]"}
{"code_id": "aicon_backend_src_services_base.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\aicon_backend_src_services_base.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\aicon_backend_src_services_base.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\aicon_backend_src_services_base.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "# 服务 - 提供统一的数据库会话管理和基础功能\nfrom typing import Optional, TYPE_CHECKING\nfrom sqlalchemy.ext.asyncio import AsyncSession\nfrom src.core.database import AsyncSessionLocal\nfrom src.core.logging import get_logger\n\nif TYPE_CHECKING:\n    from typing import Any, Dict, Optional\n\nlogger = get_logger(__name__)\n\nclass BaseService:\n    \"\"\"\n    服务基类\n    要求外部注入 AsyncSession。\n    \"\"\"\n\n    def __init__(self, db_session: AsyncSession):\n        \"\"\"\n        初始化服务实例\n        Args:\n            db_session: 必须提供异步数据库会话\n        \"\"\"\n        self._db_session = db_session\n\n    @property\n    def db_session(self) -> AsyncSession:\n        \"\"\"获取并验证当前绑定的数据库会话\"\"\"\n        if self._db_session is None:\n            raise RuntimeError(f\"{self.__class__.__name__} 尚未绑定数据库会话\")\n        return self._db_session\n\n    async def commit(self):\n        \"\"\"提交当前事务\"\"\"\n        await self.db_session.commit()\n\n    async def rollback(self):\n        \"\"\"回滚当前事务\"\"\"\n        await self.db_session.rollback()\n\n    async def flush(self):\n        \"\"\"刷新当前会话\"\"\"\n        await self.db_session.flush()\n\n    async def refresh(self, obj):\n        \"\"\"刷新对象数据\"\"\"\n        await self.db_session.refresh(obj)\n\n    async def execute(self, query, params: Optional[dict] = None):\n        \"\"\"执行SQL查询\"\"\"\n        return await self.db_session.execute(query, params)\n\n    def add(self, obj):\n        \"\"\"添加对象到会话\"\"\"\n        self.db_session.add(obj)\n\n    def delete(self, obj):\n        \"\"\"从会话中删除对象\"\"\"\n        self.db_session.delete(obj)\n\n    async def get(self, model_class, identifier):\n        \"\"\"根据ID获取对象\"\"\"\n        return await self.db_session.get(model_class, identifier)\n\n__all__ = [\"BaseService\"]"}
{"code_id": "ai_story_backend_core_ai_client_mock_image2video_client.py", "ratio": 8, "num_pages": 3, "image_paths": ["./experiment_output\\images_glm46v\\ai_story_backend_core_ai_client_mock_image2video_client.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\ai_story_backend_core_ai_client_mock_image2video_client.py\\1024x1024_hl_nl\\page_002_ratio8.png", "./experiment_output\\images_glm46v\\ai_story_backend_core_ai_client_mock_image2video_client.py\\1024x1024_hl_nl\\page_003_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\ai_story_backend_core_ai_client_mock_image2video_client.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "aicon_backend_src_services_base.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\aicon_backend_src_services_base.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\aicon_backend_src_services_base.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\aicon_backend_src_services_base.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "# -*- coding -*- 提供统一的数据库会话管理和基础功能\n\nfrom typing import Optional, TYPE_CHECKING\n\nfrom sqlalchemy.ext.asyncio import AsyncSession\n\nfrom src.core.database import AsyncSessionLocal\n\nfrom src.core.logging import get_logger\n\nif TYPE_CHECKING:\n    from typing import Any, Dict, Optional\n\nlogger = get_logger(__name__)\n\nclass BaseService:\n    \"\"\"\n    服务基类\n    需要外部注入 AsyncSession.\n    \"\"\"\n\n    def __init__(self, db_session: AsyncSession):\n        \"\"\"\n        初始化服务实例\n        Args:\n            db_session: 必须提供异步数据库会话\n        \"\"\"\n        self._db_session = db_session\n\n    @property\n    def db_session(self) -> AsyncSession:\n        \"\"\"\n        获取并验证当前绑定的数据库会话\n        \"\"\"\n        if self._db_session is None:\n            raise RuntimeError(f\"{self.__class__.__name__} 尚未绑定数据库会话\")\n        return self._db_session\n\n    async def commit(self):\n        \"\"\"提交当前事务\"\"\"\n        await self.db_session.commit()\n\n    async def rollback(self):\n        \"\"\"回滚当前事务\"\"\"\n        await self.db_session.rollback()\n\n    async def flush(self):\n        \"\"\"刷新当前会话\"\"\"\n        await self.db_session.flush()\n\n    async def refresh(self, obj):\n        \"\"\"刷新对象数据\"\"\"\n        await self.db_session.refresh(obj)\n\n    async def execute(self, query, params: Optional[dict] = None):\n        \"\"\"执行SQL查询\"\"\"\n        return await self.db_session.execute(query, params)\n\n    def add(self, obj):\n        \"\"\"添加对象到会话\"\"\"\n        self._db_session.add(obj)\n\n    def delete(self, obj):\n        \"\"\"从会话中删除对象\"\"\"\n        self._db_session.delete(obj)\n\n    async def get(self, model_class, identifier):\n        \"\"\"根据ID获取对象\"\"\"\n        return await self.db_session.get(model_class, identifier)\n\n__all__ = [\"BaseService\"]"}
{"code_id": "apm_src_apm_cli_runtime_base.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\apm_src_apm_cli_runtime_base.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\apm_src_apm_cli_runtime_base.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\apm_src_apm_cli_runtime_base.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "\"\"\"Runtime adapter interface for APM.\"\"\"\n\nfrom abc import ABC, abstractmethod\nfrom typing import Dict, Any, Optional\n\nclass RuntimeAdapter(ABC):\n    \"\"\"Base adapter interface for LLM runtimes.\"\"\"\n\n    @abstractmethod\n    def execute_prompt(self, prompt_content: str, **kwargs) -> str:\n        \"\"\"Execute a single prompt and return the response.\n\n        Args:\n            prompt_content: The prompt text to execute\n            **kwargs: Additional arguments passed to the runtime\n\n        Returns:\n            str: The response text from the runtime\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def list_available_models(self) -> Dict[str, Any]:\n        \"\"\"List all available models in the runtime.\n\n        Returns:\n            Dict[str, Any]: Dictionary of available models and their info\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_runtime_info(self) -> Dict[str, Any]:\n        \"\"\"Get information about this runtime.\n\n        Returns:\n            Dict[str, Any]: Runtime information including name, version, capabilities\n        \"\"\"\n        pass\n\n    @staticmethod\n    @abstractmethod\n    def is_available() -> bool:\n        \"\"\"Check if this runtime is available on the system.\n\n        Returns:\n            bool: True if runtime is available, False otherwise\n        \"\"\"\n        pass\n\n    @staticmethod\n    @abstractmethod\n    def get_runtime_name() -> str:\n        \"\"\"Get the name of this runtime.\n\n        Returns:\n            str: Runtime name (e.g., 'llm', 'codex')\n        \"\"\"\n        pass\n\n    def __str__(self) -> str:\n        \"\"\"String representation of the runtime.\"\"\"\n        return f\"{self.get_runtime_name()}RuntimeAdapter\""}
{"code_id": "apm_src_apm_cli_runtime_base.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\apm_src_apm_cli_runtime_base.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\apm_src_apm_cli_runtime_base.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\apm_src_apm_cli_runtime_base.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "\"\"\"Runtime adapter interface for APM.\"\"\"\nfrom abc import ABC, abstractmethod\nfrom typing import Dict, Any, Optional\n\nclass RuntimeAdapter(ABC):\n    \"\"\"Base adapter interface for LLM runtimes.\"\"\"\n\n    @abstractmethod\n    def execute_prompt(self, prompt_content: str, **kwargs) -> str:\n        \"\"\"Execute a single prompt and return the response.\n\n        Args:\n            prompt_content: The prompt text to execute\n            **kwargs: Additional arguments passed to the runtime\n\n        Returns:\n            str: The response text from the runtime\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def list_available_models(self) -> Dict[str, Any]:\n        \"\"\"List all available models in the runtime.\n\n        Returns:\n            Dict[str, Any]: Dictionary of available models and their info\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_runtime_info(self) -> Dict[str, Any]:\n        \"\"\"Get information about this runtime.\n\n        Returns:\n            Dict[str, Any]: Runtime information including name, version, capabilities\n        \"\"\"\n        pass\n\n    @staticmethod\n    @abstractmethod\n    def is_available() -> bool:\n        \"\"\"Check if this runtime is available on the system.\n\n        Returns:\n            bool: True if runtime is available, False otherwise\n        \"\"\"\n        pass\n\n    @staticmethod\n    @abstractmethod\n    def get_runtime_name() -> str:\n        \"\"\"Get the name of this runtime.\n\n        Returns:\n            str: Runtime name (e.g., 'llm', 'codex')\n        \"\"\"\n        pass\n\n    def __str__(self) -> str:\n        \"\"\"String representation of the runtime.\"\"\"\n        return f\"{self.get_runtime_name()}RuntimeAdapter\""}
{"code_id": "aicon_backend_src_services_base.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\aicon_backend_src_services_base.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\aicon_backend_src_services_base.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\aicon_backend_src_services_base.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "aicon_backend_src_services_base.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\aicon_backend_src_services_base.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\aicon_backend_src_services_base.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\aicon_backend_src_services_base.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "apm_src_apm_cli_runtime_base.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\apm_src_apm_cli_runtime_base.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\apm_src_apm_cli_runtime_base.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\apm_src_apm_cli_runtime_base.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "\"\"\"Runtime adapter interface for LLM.\"\"\"\n\nfrom abc import ABC, abstractmethod\nfrom typing import Dict, Any, Optional\n\nclass RuntimeAdapter(ABC):\n    \"\"\"Base adapter interface for LLM runtimes.\"\"\"\n\n    @abstractmethod\n    def execute_prompt(self, prompt_content: str, **kwargs) -> str:\n        \"\"\"Execute a single prompt and return the response.\n\n        Args:\n            prompt_content: The prompt text to execute\n            **kwargs: Additional arguments passed to the runtime\n\n        Returns:\n            str: The response text from the runtime\n        \"\"\"\n\n    @abstractmethod\n    def list_available_models(self) -> Dict[str, Any]:\n        \"\"\"List all available models in the runtime.\n\n        Returns:\n            Dict[str, Any]: Dictionary of available models and their info\n        \"\"\"\n\n    @abstractmethod\n    def get_runtime_info(self) -> Dict[str, Any]:\n        \"\"\"Get information about this runtime.\n\n        Returns:\n            Dict[str, Any]: Runtime information including name, version, capabilities\n        \"\"\"\n\n    @abstractmethod\n    def is_available(self) -> bool:\n        \"\"\"Check if this runtime is available on the system.\n\n        Returns:\n            bool: True if runtime is available, False otherwise\n        \"\"\"\n\n    @abstractmethod\n    def get_runtime_name(self) -> str:\n        \"\"\"Get the name of this runtime.\n\n        Returns:\n            str: Runtime name (e.g., 'llm', 'codegen')\n        \"\"\"\n\n    def __str__(self) -> str:\n        \"\"\"String representation of the runtime.\"\"\"\n        return f\"{self.get_runtime_name()} RuntimeAdapter\""}
{"code_id": "apm_src_apm_cli_runtime_base.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\apm_src_apm_cli_runtime_base.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\apm_src_apm_cli_runtime_base.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\apm_src_apm_cli_runtime_base.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": "\"\"\"Base adapter interface for LLMs.\"\"\"\n\nclass LLMAdapter(ABC):\n    \"\"\"Base adapter interface for LLM runtimes.\"\"\"\n\n    @abstractmethod\n    def execute_prompt(self, prompt_content: str, **kwargs) -> str:\n        \"\"\"Execute a string prompt and return the response.\n\n        Args:\n            prompt_content: The prompt text to execute\n            **kwargs: Additional arguments passed to the runtime\n\n        Returns:\n            str: The response text from the runtime\n        \"\"\"\n        ...\n\n    @abstractmethod\n    def list_model_info(self) -> list[tuple, dict]]:\n        \"\"\"List all model info metadata in the runtime.\n\n        Returns:\n            list[tuple, dict]]: List of model info metadata and their info\n        \"\"\"\n        ...\n\n    @abstractmethod\n    def get_runtime_info(self) -> dict[str, Any]]:\n        \"\"\"Get information about this runtime.\n\n        Returns:\n            dict[str, Any]]: Runtime information including name, version, capabilities etc.\n        \"\"\"\n        ...\n\n    @abstractmethod\n    def is_runtime_valid(self) -> bool:\n        \"\"\"Check if this runtime is valid/healthy on the system.\n\n        Returns:\n            bool: True if runtime is accessible, False otherwise\n        \"\"\"\n        ...\n\n    @abstractmethod\n    def get_runtime_name(self) -> str:\n        \"\"\"Get the name of this runtime.\n\n        Returns:\n            str: Runtime name (e.g., 'llama', 'openai')\n        \"\"\"\n        ...\n\n    def __str__(self) -> str:\n        \"\"\"String representation of the runtime.\"\"\"\n        return f\"{self.get_runtime_name()} LLM Adapter\""}
{"code_id": "atomworks_src_atomworks_ml_executables_x3dna.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\atomworks_src_atomworks_ml_executables_x3dna.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\atomworks_src_atomworks_ml_executables_x3dna.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\atomworks_src_atomworks_ml_executables_x3dna.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "import logging\nfrom pathlib import PathLike\nfrom atomworks.ml.executables import Executable, ExecutableError\n\nlogger = logging.getLogger(__name__)\n\nclass X3DNAFiber(Executable):\n    \"\"\"Executable wrapper for the x3dna-fiber program from the 3DNA package.\n\n    This class manages the x3dna-fiber executable, which is used to generate B-form conformation\n    DNA fibers (i.e. linear duplexes).\n\n    Example:\n        ```python\n        fiber = X3DNAFiber.get_or_initialize(\"/path/to/x3dna-v2.4/bin/fiber\")\n        version = fiber.get_version()\n        bin_path = fiber.get_bin_path()\n        ```\n    \"\"\"\n\n    name = \"x3dna-fiber\"\n    required_verification_text = (\"fiber\", \"3DNA\", \"SYNOPSIS\", \"DESCRIPTION\")\n\n    @classmethod\n    def initialize(cls, bin_path: PathLike | None = None, *args, **kwargs) -> \"X3DNAFiber\":\n        if bin_path is None:\n            bin_path = cls._infer_bin_path_from_env_var()\n        return super().initialize(bin_path, *args, **kwargs)\n\n    @staticmethod\n    def _infer_bin_path_from_env_var() -> PathLike:\n        x3dna_path = os.environ.get(\"X3DNA\")\n        if x3dna_path is not None:\n            bin_path = os.path.join(x3dna_path, \"bin\", \"fiber\")\n            return bin_path\n        raise ExecutableError(\n            \"No `bin_path` provided and `X3DNA` environment variable not set.\\n\"\n            \"Please set the `X3DNA` environment variable to the root directory of the X3DNA installation \"\n            \"or provide a `bin_path` to the `X3DNAFiber` constructor: \"\n            \"`X3DNAFiber(bin_path='/path/to/fiber')`.\"\n        )\n\n    @classmethod\n    def setup(cls, bin_path: PathLike) -> None:\n        \"\"\"Sets up the X3DNA environment by setting the X3DNA environment variable.\n\n        The X3DNA environment variable must point to the root directory of the X3DNA installation,\n        which is typically two levels up from the executable location.\n\n        Args:\n            - bin_path (PathLike): Path to the x3dna-fiber executable.\n        \"\"\"\n        # ... set the X3DNA environment variable\n        x3dna_path = os.path.dirname(os.path.dirname(bin_path)))\n        logger.info(f\"Setting environment variable X3DNA={x3dna_path}\")\n        os.environ[\"X3DNA\"] = x3dna_path"}
{"code_id": "atomworks_src_atomworks_ml_executables_x3dna.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\atomworks_src_atomworks_ml_executables_x3dna.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\atomworks_src_atomworks_ml_executables_x3dna.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\atomworks_src_atomworks_ml_executables_x3dna.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "import logging\nfrom pathlib import Path\nfrom typing import PathLike\n\nfrom atomworks.ml.executables import Executable, ExecutableError\n\nlogger = logging.getLogger(__name__)\n\nclass X3DNAFiber(Executable):\n    \"\"\"Executable wrapper for the x3dna-fiber program from the 3DNA package.\n\n    This class manages the x3dna-fiber executable, which is used to generate B-form conformation\n    DNA fibers (i.e. linear duplexes).\n\n    Example:\n        ```python\n        fiber = X3DNAFiber.get_or_initialize(\"/path/to/x3dna-v2.4/bin/fiber\")\n        version = fiber.get_version()\n        bin_path = fiber.get_bin_path()\n        ```\n    \"\"\"\n    name = \"x3dna-fiber\"\n    required_verification_text = (\"fiber\", \"3DNA\", \"SYNOPSIS\", \"DESCRIPTION\")\n\n    @classmethod\n    def initialize(cls, bin_path: PathLike | None = None, *args, **kwargs) -> \"X3DNAFiber\":\n        if bin_path is None:\n            bin_path = cls._infer_bin_path_from_env_var()\n        return super().initialize(bin_path, *args, **kwargs)\n\n    @staticmethod\n    def _infer_bin_path_from_env_var() -> PathLike:\n        x3dna_path = os.environ.get(\"X3DNA\")\n        if x3dna_path is not None:\n            bin_path = os.path.join(x3dna_path, \"bin\", \"fiber\")\n            return bin_path\n        raise ExecutableError(\n            \"No 'bin_path' provided and 'X3DNA' environment variable not set.\\n\"\n            \"Please set the 'X3DNA' environment variable to the root directory of the X3DNA installation \"\n            \"or provide a 'bin_path' to the 'X3DNAFiber' constructor: \"\n            \"'X3DNAFiber(bin_path='/path/to/fiber')'.\"\n        )\n\n    @classmethod\n    def setup(cls, bin_path: PathLike) -> None:\n        \"\"\"Sets up the X3DNA environment by setting the X3DNA environment variable.\n\n        The X3DNA environment variable must point to the root directory of the X3DNA installation,\n        which is typically two levels up from the executable location.\n\n        Args:\n            bin_path (PathLike): Path to the x3dna-fiber executable.\n        \"\"\"\n        # ... set the X3DNA environment variable\n        x3dna_path = os.path.dirname(os.path.dirname(bin_path)))\n        logger.info(f\"Setting environment variable X3DNA={x3dna_path}\")\n        os.environ[\"X3DNA\"] = x3dna_path"}
{"code_id": "atomworks_src_atomworks_ml_executables_x3dna.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\atomworks_src_atomworks_ml_executables_x3dna.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\atomworks_src_atomworks_ml_executables_x3dna.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\atomworks_src_atomworks_ml_executables_x3dna.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "import logging\nfrom pathlib import PathLike\nfrom atomworks.ml.executables import Executable, ExecutableError\n\nlogger = logging.getLogger(__name__)\n\nclass X3DNAFiber(Executable):\n    \"\"\"Executable wrapper for the x3dna-fiber program from the 3DNA package.\n\n    This class manages the x3dna-fiber executable, which is used to generate B-form conformation\n    DNA fibers (i.e. linear duplexes).\n\n    Example:\n        >>>python\n        fiber = X3DNAFiber.get_or_initialize(\"/path/to/x3dna-v2.4/bin/fiber\")\n        version = fiber.get_version()\n        bin_path = fiber.get_bin_path()\n        ...\n    \"\"\"\n\n    name = \"x3dna-fiber\"\n    required_verification_text = [\"fiber\", \"3DNA\", \"SNOPS id\", \"DESCRIPTiON\"]\n\n    @classmethod\n    def initialize(cls, bin_path: PathLike | None = None, *args, **kwargs) -> \"X3DNAFiber\":\n        if bin_path is None:\n            bin_path = cls._infer_bin_path_from_env_var()\n        return super().initialize(bin_path, *args, **kwargs)\n\n    @staticmethod\n    def _infer_bin_path_from_env_var() -> PathLike:\n        x3dna_path = os.environ.get(\"X3DNA\")\n        if x3dna_path is not None:\n            bin_path = os.path.join(x3dna_path, \"bin\", \"fiber\")\n            return bin_path\n        raise ExecutableError(\n            \"No bin_path provided and X3DNA environment variable not set.\"\n            \"Please set the X3DNA environment variable to the root directory of the X3DNA installation \"\n            \"or provide a bin_path to the X3DNAFiber constructor: \"\n            \"X3DNAFiber(bin_path='/path/to/fiber').\"\n        )\n\n    @classmethod\n    def setup(cls, bin_path: PathLike) -> None:\n        \"\"\"Sets up the X3DNA environment by setting the X3DNA environment variable.\n\n        The X3DNA environment variable must point to the root directory of the X3DNA installation,\n        which is typically two levels up from the executable location.\n\n        Args:\n            - bin_path (PathLike): Path to the x3dna-fiber executable.\n        ... set the X3DNA environment variable\n        \"\"\"\n        x3dna_path = os.path.dirname(os.path.dirname(bin_path))\n        logger.info(f\"Setting environment variable X3DNA={x3dna_path}\")\n        os.environ[\"X3DNA\"] = x3dna_path"}
{"code_id": "apm_src_apm_cli_runtime_base.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\apm_src_apm_cli_runtime_base.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\apm_src_apm_cli_runtime_base.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\apm_src_apm_cli_runtime_base.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "cccc_src_cccc_runners_pty_stub.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\cccc_src_cccc_runners_pty_stub.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\cccc_src_cccc_runners_pty_stub.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\cccc_src_cccc_runners_pty_stub.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "from __future__ import annotations\nimport socket\nfrom dataclasses import dataclass\nfrom pathlib import Path\nfrom typing import Callable, Dict, Iterable, Optional, Tuple\n\nPTY_SUPPORTED = False\n\n@dataclass\nclass PtySession:\n    group_id: str = \"\"\n    actor_id: str = \"\"\n    pid: int = 0\n\nclass PtySupervisor:\n    def set_exit_hook(self, hook: Optional[Callable[[PtySession], None]]]) -> None:\n        return None\n\n    def group_running(self, group_id: str) -> bool:\n        return False\n\n    def actor_running(self, group_id: str, actor_id: str) -> bool:\n        return False\n\n    def tail_output(self, self, *, group_id: str, actor_id: str, max_bytes: int = 2_000_000) -> bytes:\n        return b\"\"\n\n    def clear_backlog(self, self, *, group_id: str, actor_id: str) -> bool:\n        return False\n\n    def start_actor(\n        self,\n        *,\n        group_id: str,\n        actor_id: str,\n        cwd: Path,\n        command: Iterable[str],\n        env: Dict[str, str],\n        max_backlog_bytes: int = 2_000_000,\n    ) -> PtySession:\n        raise RuntimeError(\"pty runner is not supported on this platform; use runner='headless'\")\n\n    def stop_actor(self, self, *, group_id: str, actor_id: str) -> None:\n        return None\n\n    def stop_group(self, *, group_id: str) -> None:\n        return None\n\n    def stop_all(self) -> None:\n        return None\n\n    def attach(self, *, group_id: str, actor_id: str, sock: socket.socket) -> None:\n        raise RuntimeError(\"pty runner is not supported on this platform\")\n\n    def bracketed_paste_enabled(self, *, group_id: str, actor_id: str) -> bool:\n        return False\n\n    def bracketed_paste_status(self, *, group_id: str, actor_id: str) -> Tuple[bool, Optional[float]]:\n        return (False, None)\n\n    def startup_times(self, *, group_id: str, actor_id: str) -> Tuple[Optional[float], Optional[float]]:\n        return (None, None)\n\n    def session_key(self, *, group_id: str, actor_id: str) -> Optional[str]:\n        return None\n\n    def resize(self, *, group_id: str, actor_id: str, cols: int, rows: int) -> None:\n        return None\n\n    def write_input(self, *, group_id: str, actor_id: str, data: bytes) -> bool:\n        return False\n\nSUPERVISOR = PtySupervisor()"}
{"code_id": "cccc_src_cccc_runners_pty_stub.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\cccc_src_cccc_runners_pty_stub.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\cccc_src_cccc_runners_pty_stub.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\cccc_src_cccc_runners_pty_stub.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "from __future__ import annotations\nimport socket\nfrom dataclasses import dataclass\nfrom pathlib import Path\nfrom typing import Callable, Dict, Iterable, Optional, Tuple\n\nPTY_SUPPORTED = False\n\n@dataclass\nclass PtySession:\n    group_id: str = \"\"\n    actor_id: str = \"\"\n    pid: int = 0\n\nclass PtySupervisor:\n    def set_exit_hook(self, hook: Optional[Callable[[PtySession], None]]]]) -> None:\n        return None\n\n    def group_running(self, group_id: str) -> bool:\n        return False\n\n    def actor_running(self, group_id: str, actor_id: str) -> bool:\n        return False\n\n    def tail_output(self, self, *, group_id: str, actor_id: str, max_bytes: int = 2_000_000) -> bytes:\n        return b\"\"\n\n    def clear_backlog(self, self, *, group_id: str, actor_id: str) -> bool:\n        return False\n\n    def start_actor(\n        self,\n        *,\n        group_id: str,\n        actor_id: str,\n        cwd: Path,\n        command: Iterable[str],\n        env: Dict[str, str],\n        max_backlog_bytes: int = 2_000_000,\n    ) -> PtySession:\n        raise RuntimeError(\"pty runner is not supported on this platform; use runner='headless'\")\n\n    def stop_actor(self, *, group_id: str, actor_id: str) -> None:\n        return None\n\n    def stop_group(self, *, group_id: str) -> None:\n        return None\n\n    def stop_all(self) -> None:\n        return None\n\n    def attach(self, *, group_id: str, actor_id: str, sock: socket.socket) -> None:\n        raise RuntimeError(\"pty runner is not supported on this platform\")\n\n    def bracketed_paste_enabled(self, *, group_id: str, actor_id: str) -> bool:\n        return False\n\n    def bracketed_paste_status(self, *, group_id: str, actor_id: str) -> Tuple[bool, Optional[float]]:\n        return (False, None)\n\n    def startup_times(self, *, group_id: str, actor_id: str) -> Tuple[Optional[float], Optional[float]]:\n        return (None, None)\n\n    def session_key(self, *, group_id: str, actor_id: str) -> Optional[str]:\n        return None\n\n    def resize(self, *, group_id: str, actor_id: str, cols: int, rows: int) -> None:\n        return None\n\n    def write_input(self, *, group_id: str, actor_id: str, data: bytes) -> bool:\n        return False\n\nSUPERVISOR = PtySupervisor()"}
{"code_id": "atomworks_src_atomworks_ml_executables_x3dna.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\atomworks_src_atomworks_ml_executables_x3dna.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\atomworks_src_atomworks_ml_executables_x3dna.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\atomworks_src_atomworks_ml_executables_x3dna.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "atomworks_src_atomworks_ml_executables_x3dna.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\atomworks_src_atomworks_ml_executables_x3dna.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\atomworks_src_atomworks_ml_executables_x3dna.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\atomworks_src_atomworks_ml_executables_x3dna.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": "\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is used to import the data from the\n\"\"\"\n\n\"\"\"\nThis module is"}
{"code_id": "claude-stt_src_claude_stt_engines_whisper.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\claude-stt_src_claude_stt_engines_whisper.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\claude-stt_src_claude_stt_engines_whisper.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\claude-stt_src_claude_stt_engines_whisper.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "\"\"\"Whisper STT engine using faster-whisper.\"\"\"\nfrom __future__ import annotations\n\nimport logging\nimport os\nfrom typing import Optional\n\nimport numpy as np\n\n_whisper_available = False\n_WhisperModel = None\n\ntry:\n    from faster_whisper import WhisperModel as _WhisperModel\n\n    _whisper_available = True\nexcept ImportError:\n    pass\n\n\nclass WhisperEngine:\n    \"\"\"Whisper speech-to-text engine backed by faster-whisper.\"\"\"\n\n    def __init__(\n        self,\n        model_name: str = \"medium\",\n        device: Optional[str] = None,\n        compute_type: Optional[str] = None,\n    ):\n        self.model_name = model_name\n        self.device = device or os.environ.get(\n            \"CLAUDE_STT_WHISPER_DEVICE\", \"cpu\"\n        )\n        self.compute_type = compute_type or os.environ.get(\n            \"CLAUDE_STT_WHISPER_COMPUTE_TYPE\", \"int8\", \n        )\n        self._model: Optional[object] = None\n        self._logger = logging.getLogger(__name__)\n\n    def is_available(self) -> bool:\n        return _whisper_available\n\n    def load_model(self) -> bool:\n        if not self.is_available():\n            return False\n        if self._model is not None:\n            return True\n\n        try:\n            self._model = _WhisperModel(\n                self.model_name,\n                device=self.device,\n                compute_type=self.compute_type,\n            )\n            return True\n        except Exception:\n            self._logger.exception(\"Failed to load Whisper model\")\n            return False\n\n    def transcribe(self, audio: np.ndarray, sample_rate: int = 16000) -> str:\n        if not self.load_model():\n            return \"\"\n        try:\n            if audio.dtype != np.float32:\n                audio = audio.astype(np.float32)\n            segments, _info = self._model.transcribe(audio, sample_rate=sample_rate)\n            text = \" \".join(segment.text.strip() for segment in segments)\n            return text.strip()\n        except Exception:\n            self._logger.exception(\"Whisper transcription failed\")\n            return \"\""}
{"code_id": "cccc_src_cccc_runners_pty_stub.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\cccc_src_cccc_runners_pty_stub.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\cccc_src_cccc_runners_pty_stub.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\cccc_src_cccc_runners_pty_stub.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": ""}
{"code_id": "cccc_src_cccc_runners_pty_stub.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\cccc_src_cccc_runners_pty_stub.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\cccc_src_cccc_runners_pty_stub.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\cccc_src_cccc_runners_pty_stub.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "claude-stt_src_claude_stt_engines_whisper.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\claude-stt_src_claude_stt_engines_whisper.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\claude-stt_src_claude_stt_engines_whisper.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\claude-stt_src_claude_stt_engines_whisper.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "\"\"\"Whisper STT engine using faster-whisper.\"\"\"\nfrom __future__ import annotations\n\nimport logging\nimport os\nfrom typing import Optional\n\nimport numpy as np\n\n_whisper_available = False\n_WhisperModel = None\n\ntry:\n    from faster_whisper import WhisperModel as _WhisperModel\n\n    _whisper_available = True\nexcept ImportError:\n    pass\n\n\nclass WhisperEngine:\n    \"\"\"Whisper speech-to-text engine backed by faster-whisper.\"\"\"\n\n    def __init__(\n        self,\n        model_name: str = \"medium\",\n        device: Optional[str] = None,\n        compute_type: Optional[str] = None,\n    ):\n        self.model_name = model_name\n        self.device = device or os.environ.get(\n            \"CLAUDE_STT_WHISPER_DEVICE\", \"cpu\"\n        )\n        self.compute_type = compute_type or os.environ.get(\n            \"CLAUDE_STT_WHISPER_COMPUTE_TYPE\", \"int8\"\n        )\n        self._model: Optional[object] = None\n        self._logger = logging.getLogger(__name__)\n\n    def is_available(self) -> bool:\n        return _whisper_available\n\n    def load_model(self) -> bool:\n        if not self.is_available():\n            return False\n        if self._model is not None:\n            return True\n\n        try:\n            self._model = _WhisperModel(\n                self.model_name,\n                device=self.device,\n                compute_type=self.compute_type,\n            )\n            return True\n        except Exception:\n            self._logger.exception(\"Failed to load Whisper model\")\n            return False\n\n    def transcribe(self, audio: np.ndarray, sample_rate: int = 16000) -> str:\n        if not self.load_model():\n            return \"\"\n        try:\n            if audio.dtype != np.float32:\n                audio = audio.astype(np.float32)\n            segments, _info = self._model.transcribe(audio, sample_rate=sample_rate)\n            text = \" \".join(segment.text.strip() for segment in segments)\n            return text.strip()\n        except Exception:\n            self._logger.exception(\"Whisper transcription failed\")\n            return \"\""}
{"code_id": "cccc_src_cccc_runners_pty_stub.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\cccc_src_cccc_runners_pty_stub.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\cccc_src_cccc_runners_pty_stub.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\cccc_src_cccc_runners_pty_stub.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "codex-autorunner_src_codex_autorunner_agents_base.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\codex-autorunner_src_codex_autorunner_agents_base.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\codex-autorunner_src_codex_autorunner_agents_base.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\codex-autorunner_src_codex_autorunner_agents_base.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "from __future__ import annotations\nfrom pathlib import Path\nfrom typing import Any, AsyncIterator, Optional, Protocol\nfrom .types import ConversationRef, ModelCatalog, TurnRef\n\nclass AgentHarness(Protocol):\n    agent_id: str\n    display_name: str\n\n    async def ensure_ready(self, workspace_root: Path) -> None: ...\n    async def model_catalog(self, workspace_root: Path) -> ModelCatalog: ...\n    async def new_conversation(\n        self, workspace_root: Path, title: Optional[str] = None\n    ) -> ConversationRef: ...\n    async def list_conversations(\n        self, workspace_root: Path\n    ) -> list[ConversationRef]: ...\n    async def resume_conversation(\n        self, workspace_root: Path, conversation_id: str\n    ) -> ConversationRef: ...\n    async def start_turn(\n        self,\n        workspace_root: Path,\n        conversation_id: str,\n        prompt: str,\n        model: Optional[str],\n        reasoning: Optional[str],\n        *,\n        approval_mode: Optional[str],\n        sandbox_policy: Optional[Any],\n    ) -> TurnRef: ...\n    async def start_review(\n        self,\n        workspace_root: Path,\n        conversation_id: str,\n        prompt: str,\n        model: Optional[str],\n        reasoning: Optional[str],\n        approval_mode: Optional[str],\n        sandbox_policy: Optional[Any],\n    ) -> TurnRef: ...\n    async def interrupt(\n        self, workspace_root: Path, conversation_id: str, turn_id: Optional[str]\n    ) -> None: ...\n    def stream_events(\n        self, workspace_root: Path, conversation_id: str, turn_id: str\n    ) -> AsyncIterator[str]: ...\n\n__all__ = [\"AgentHarness\"]"}
{"code_id": "claude-stt_src_claude_stt_engines_whisper.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\claude-stt_src_claude_stt_engines_whisper.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\claude-stt_src_claude_stt_engines_whisper.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\claude-stt_src_claude_stt_engines_whisper.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "\"\"\"Whisper STT engine using faster-whisper.\"\"\"\n\nfrom __future__ import annotations\n\nimport logging\nimport os\nfrom typing import Optional\n\nimport numpy as np\n\n_whisper_available = False\n_WhisperModel = None\n\ntry:\n    from faster_whisper import WhisperModel as _WhisperModel\n\n    _whisper_available = True\nexcept ImportError:\n    pass\n\n\nclass WhisperEngine:\n    \"\"\"Whisper openAI-to-text engine backed by faster-whisper.\"\"\"\n\n    def __init__(\n        self,\n        model_name: str = \"medium\",\n        device: Optional[str] = None,\n        compute_type: Optional[str] = None,\n    ):\n        self.model_name = model_name\n        self.device = device or os.environ.get(\"CLAUDE_STT_WHISPER_DEVICE\", \"cpu\")\n        self.compute_type = compute_type or os.environ.get(\n            \"CLAUDE_STT_WHISPER_COMPUTE_TYPE\",\n            \"int8\",\n        )\n        self._model: Optional[object] = None\n        self._logger = logging.getLogger(__name__)\n\n    def is_available(self) -> bool:\n        return _whisper_available\n\n    def load_model(self) -> bool:\n        if not self.is_available():\n            return False\n        if self._model is not None:\n            return True\n\n        try:\n            self._model = _WhisperModel(\n                self.model_name,\n                device=self.device,\n                compute_type=self.compute_type,\n            )\n            return True\n        except Exception:\n            self._logger.exception(\"Failed to load Whisper model\")\n            return False\n\n    def transcribe(self, audio: np.ndarray, sample_rate: int = 16000) -> str:\n        if not self.load_model():\n            return \"\"\n\n        try:\n            if audio.dtype != np.float32:\n                audio = audio.astype(np.float32)\n            segments, _info = self._model.transcribe(audio, sample_rate=sample_rate)\n            text = \" \".join(segment.text.strip() for segment in segments)\n            return text.strip()\n        except Exception:\n            self._logger.exception(\"Whisper transcription failed\")\n            return \"\""}
{"code_id": "claude-stt_src_claude_stt_engines_whisper.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\claude-stt_src_claude_stt_engines_whisper.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\claude-stt_src_claude_stt_engines_whisper.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\claude-stt_src_claude_stt_engines_whisper.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": "\"\"\"A simple HTTP request using basic-requests.\"\"\"\nimport requests, json\nimport logging\n\nlogger = logging.getLogger(__name__)\nlogger.setLevel(logging.DEBUG)\n\n# Create a handler that outputs to the console\nconsole_handler = logging.StreamHandler()\nconsole_handler.setLevel(logging.DEBUG)\n\n# Add the handler to the logger\nlogger.addHandler(console_handler)\n\ndef make_request(url):\n    \"\"\"Make a request to the given URL and return the response.\"\"\"\n    try:\n        response = requests.get(url)\n        response.raise_for_status()  # Raise an exception for 4xx/5xx status codes\n        return response.json()\n    except requests.exceptions.RequestException as e:\n        logger.error(f\"Error making request to {url}: {e}\")\n        return None\n\ndef load_json_file(file_path):\n    try:\n        with open(file_path, 'r') as file:\n            return json.load(file)\n    except FileNotFoundError:\n        logger.error(f\"File not found: {file_path}\")\n        return None\n    except json.JSONDecodeError:\n        logger.error(f\"Invalid JSON in file: {file_path}\")\n        return None\n\ndef save_json_file(data, file_path):\n    try:\n        with open(file_path, 'w') as file:\n            json.dump(data, file, indent=4)\n    except IOError as e:\n        logger.error(f\"Error saving JSON file: {e}\")\n        return False\n    return True\n\ndef process_data(data):\n    # This is a placeholder for data processing logic\n    # For example, you could filter, transform, or aggregate the data\n    processed_data = data  # Replace this with actual processing logic\n    return processed_data"}
{"code_id": "codex-autorunner_src_codex_autorunner_agents_base.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\codex-autorunner_src_codex_autorunner_agents_base.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\codex-autorunner_src_codex_autorunner_agents_base.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\codex-autorunner_src_codex_autorunner_agents_base.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "from __future__ import annotations\nfrom pathlib import Path\nfrom typing import Any, AsyncIterator, Optional, Protocol\nfrom .types import ConversationRef, ModelCatalog, TurnRef\n\nclass AgentHarness(Protocol):\n    agent_id: str\n    display_name: str\n\n    async def ensure_ready(self, workspace_root: Path) -> None: ...\n    async def model_catalog(self, workspace_root: Path) -> ModelCatalog: ...\n    async def new_conversation(\n        self, workspace_root: Path, title: Optional[str] = None\n    ) -> ConversationRef: ...\n    async def list_conversations(\n        self, workspace_root: Path\n    ) -> list[ConversationRef]: ...\n    async def resume_conversation(\n        self, workspace_root: Path, conversation_id: str\n    ) -> ConversationRef: ...\n    async def start_turn(\n        self,\n        workspace_root: Path,\n        conversation_id: str,\n        prompt: str,\n        model: Optional[str],\n        reasoning: Optional[str],\n        *,\n        approval_mode: Optional[str],\n        sandbox_policy: Optional[Any],\n    ) -> TurnRef: ...\n    async def start_review(\n        self,\n        workspace_root: Path,\n        conversation_id: str,\n        prompt: str,\n        model: Optional[str],\n        reasoning: Optional[str],\n        *,\n        approval_mode: Optional[str],\n        sandbox_policy: Optional[Any],\n    ) -> TurnRef: ...\n    async def interrupt(\n        self, workspace_root: Path, conversation_id: str, turn_id: Optional[str]\n    ) -> None: ...\n    def stream_events(\n        self, workspace_root: Path, conversation_id: str, turn_id: str\n    ) -> AsyncIterator[str]: ...\n\n__all__ = [\"AgentHarness\"]"}
{"code_id": "codex-autorunner_src_codex_autorunner_agents_base.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\codex-autorunner_src_codex_autorunner_agents_base.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\codex-autorunner_src_codex_autorunner_agents_base.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\codex-autorunner_src_codex_autorunner_agents_base.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "from __future__ import annotations\nfrom pathlib import Path\nfrom typing import Any, AsyncIterator, Optional, Protocol\nfrom .types import ConversationRef, ModelCatalog, TurnRef\n\nclass AgentHarness(Protocol):\n    agent_id: str\n    display_name: str\n\n    async def ensure_ready(self, workspace_root: Path) -> None: ...\n    async def model_catalog(self, workspace_root: Path) -> ModelCatalog: ...\n    async def new_conversation(\n        self, workspace_root: Path, title: Optional[str] = None\n    ) -> ConversationRef: ...\n    async def list_conversations(\n        self, workspace_root: Path\n    ) -> List[ConversationRef]: ...\n    async def resume_conversation(\n        self, workspace_root: Path, conversation_id: str\n    ) -> ConversationRef: ...\n    async def start_turn(\n        self,\n        workspace_root: Path,\n        conversation_id: str,\n        prompt: str,\n        model: Optional[str],\n        reasoning: Optional[str],\n        *,\n        approval_mode: Optional[str],\n        sandbox_policy: Optional[Dict],\n    ) -> TurnRef: ...\n    async def start_review(\n        self,\n        workspace_root: Path,\n        conversation_id: str,\n        prompt: str,\n        model: Optional[str],\n        reasoning: Optional[str],\n        *,\n        approval_mode: Optional[str],\n        sandbox_policy: Optional[Dict],\n    ) -> TurnRef: ...\n    async def interrupt(\n        self, workspace_root: Path, conversation_id: str, turn_id: Optional[str]\n    ) -> None: ...\n    def stream_events(\n        self, workspace_root: Path, conversation_id: str, turn_id: str\n    ) -> AsyncIterator[str]: ...\n\n__all__ = [\"AgentHarness\"]"}
{"code_id": "claude-stt_src_claude_stt_engines_whisper.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\claude-stt_src_claude_stt_engines_whisper.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\claude-stt_src_claude_stt_engines_whisper.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\claude-stt_src_claude_stt_engines_whisper.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "cosmos-transfer2.5_packages_cosmos-gradio_sample_sample_worker.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\cosmos-transfer2.5_packages_cosmos-gradio_sample_sample_worker.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\cosmos-transfer2.5_packages_cosmos-gradio_sample_sample_worker.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\cosmos-transfer2.5_packages_cosmos-gradio_sample_sample_worker.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "# Copyright (c) 2025 NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n# SPDX-License-Identifier: Apache-2.0\n\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport json\nimport os\n\nfrom cosmos_gradio.deployment_env import DeploymentEnv\nfrom cosmos_gradio.model_ipc.model_worker import ModelWorker\nfrom PIL import Image\nfrom pydantic import BaseModel, ConfigDict, Field\n\nclass InferenceParameters(BaseModel):\n    \"\"\"Parameters for inference requests.\"\"\"\n\n    prompt: str = Field(..., min_length=1)\n    \"\"\"Text prompt for generation\"\"\"\n\n    num_steps: int = Field(..., gt=0)\n    \"\"\"Number of inference steps\"\"\"\n\n    input_image: str | None = None\n    \"\"\"Path to the input image\"\"\"\n\n    \"\"\"use_attribute_docstrings=True to use the docstrings as the description of the fields\"\"\"\n    model_config = ConfigDict(use_attribute_docstrings=True)\n\nclass SampleWorker(ModelWorker):\n    def __init__(self, num_gpus, model_name):\n        pass\n\n# pyrefly: ignore  # bad-override\ndef infer(self, args: dict):\n    prompt = args.get(\"prompt\", \"\")\n\n    img = Image.new(\"RGB\", (256, 256), color=\"red\")\n    output_dir = args.get(\"output_dir\", \"/mnt/pvc/gradio_output\")\n    out_file_name = os.path.join(output_dir, \"output.png\")\n\n    rank = int(os.getenv(\"RANK\", 0)))\n    if rank == 0:\n        if not os.path.exists(output_dir):\n            os.makedirs(output_dir)\n        img.save(out_file_name)\n\n    # the client will look for either 'videos' or 'images' in the status json\n    # if neither is present, the client will look through the output directory for any files and display th\nem\n\n    return {\"message\": \"created a red box\", \"prompt\": prompt, \"images\": [out_file_name]}\n\n@staticmethod\ndef get_parameters_schema():\n    \"\"\"Return the JSON schema for the inference parameters.\"\"\"\n    return json.dumps(InferenceParameters.model_json_schema(), indent=2)\n\n@staticmethod\ndef validate_parameters(kwargs: dict):\n    \"\"\"Validate the inference parameters.\"\"\"\n    params = InferenceParameters(**kwargs)\n    return params.model_dump(mode=\"json\")\n\ndef create_worker():\n    \"\"\"Factory function to create sample pipeline.\"\"\"\n    cfg = DeploymentEnv()\n\n    pipeline = SampleWorker(\n        num_gpus=cfg.num_gpus,\n        model_name=cfg.model_name,\n    )\n\n    return pipeline"}
{"code_id": "cosmos-transfer2.5_packages_cosmos-gradio_sample_sample_worker.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\cosmos-transfer2.5_packages_cosmos-gradio_sample_sample_worker.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\cosmos-transfer2.5_packages_cosmos-gradio_sample_sample_worker.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\cosmos-transfer2.5_packages_cosmos-gradio_sample_sample_worker.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "# File: CopyrightText: Copyright (c) 2025 NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n# SPDX-License-Identifier: Apache-2.0\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport json\nimport os\n\nfrom cosmos_gradio.deployment_env import DeploymentEnv\nfrom cosmos_gradio.model_ipc.model_worker import ModelWorker\nfrom PIL import Image\nfrom pydantic import BaseModel, ConfigDict, Field\n\nclass InferenceParameters(BaseModel):\n    \"\"\"Parameters for inference requests.\"\"\"\n\n    prompt: str = Field(..., min_length=1)\n    \"\"\"Text prompt for generation\"\"\"\n\n    num_steps: int = Field(..., gt=0)\n    \"\"\"Number of inference steps\"\"\"\n\n    input_image: str | None = None\n    \"\"\"Path to the input image\"\"\"\n\n    \"\"\"use_attribute_docstrings=True to use the docstrings as the description of the fields\"\"\"\n    model_config = ConfigDict(use_attribute_docstrings=True)\n\nclass SampleWorker(ModelWorker):\n    def __init__(self, num_gpus, model_name):\n        pass\n\n    # pyrefly: ignore # bad-override\n    def infer(self, args: dict):\n        prompt = args.get(\"prompt\", \"\")\n\n        img = Image.new(\"RGB\", (256, 256), color=\"red\")\n\n        output_dir = args.get(\"output_dir\", \"./mnt/pvc/gradio_output\")\n        out_file_name = os.path.join(output_dir, \"output.png\")\n\n        rank = int(os.getenv(\"RANK\", 0)))\n        if rank == 0:\n            if not os.path.exists(output_dir):\n                os.makedirs(output_dir)\n            img.save(out_file_name)\n\n        # the client will look for either 'videos' or 'images' in the status json\n        # if neither is present, the client will look through the output directory for any files and display th\nem\n\n        return {\"message\": \"created a red box\", \"prompt\": prompt, \"images\": [out_file_name]}\n\n    @staticmethod\n    def get_parameters_schema():\n        \"\"\"Return the JSON schema for the inference parameters.\"\"\"\n        return json.dumps(InferenceParameters.model_json_schema(), indent=2)\n\n    @staticmethod\n    def validate_parameters(kwargs: dict):\n        \"\"\"Validate the inference parameters.\"\"\"\n        params = InferenceParameters(**kwargs)\n        return params.model_dump(mode=\"json\")\n\ndef create_worker():\n    \"\"\"Factory function to create sample pipeline.\"\"\"\n    cfg = DeploymentEnv()\n\n    pipeline = SampleWorker(\n        num_gpus=cfg.num_gpus,\n        model_name=cfg.model_name,\n    )\n\n    return pipeline"}
{"code_id": "codex-autorunner_src_codex_autorunner_agents_base.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\codex-autorunner_src_codex_autorunner_agents_base.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\codex-autorunner_src_codex_autorunner_agents_base.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\codex-autorunner_src_codex_autorunner_agents_base.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "codex-autorunner_src_codex_autorunner_agents_base.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\codex-autorunner_src_codex_autorunner_agents_base.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\codex-autorunner_src_codex_autorunner_agents_base.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\codex-autorunner_src_codex_autorunner_agents_base.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "cosmos-transfer2.5_packages_cosmos-gradio_sample_sample_worker.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\cosmos-transfer2.5_packages_cosmos-gradio_sample_sample_worker.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\cosmos-transfer2.5_packages_cosmos-gradio_sample_sample_worker.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\cosmos-transfer2.5_packages_cosmos-gradio_sample_sample_worker.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "# Copyright (c) 2025 NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n# SPDX-License-Identifier: Apache-2.0\n\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport json\nimport os\n\nfrom common_gradio.deployment_env import DeploymentEnv\nfrom common_gradio.model_ipc.model_worker import ModelWorker\nfrom PIL import Image\nfrom pydantic import BaseModel, ConfigDict, Field\n\nclass InferenceParameters(BaseModel):\n    \"\"\"Parameters for inference requests.\"\"\"\n\n    prompt: str = Field(..., min_length=1)\n    \"\"\"Text prompt for generation\"\"\"\n\n    num_steps: int = Field(..., gt=0)\n    \"\"\"Number of inference steps\"\"\"\n\n    input_image: str | None = None\n    \"\"\"Path to the input image\"\"\"\n\n    \"\"\"use_attribute_descriptions=True to use the docstrings as the description of the fields\"\"\"\n    model_config = ConfigDict(use_attribute_descriptions=True)\n\nclass SampleWorker(ModelWorker):\n    def __init__(self, num_gpus, model_name):\n        pass\n\n    # pylint: ignore # bad-override\n    @override\n    def infer(self, args: dict):\n        prompt = args.get(\"prompt\", \"\")\n\n        img = Image.new(\"RGB\", (256, 256), color=\"red\")\n\n        output_dir = args.get(\"output_dir\", \"./tmp/gradio_output\")\n        output_file_name = os.path.join(output_dir, \"output.png\")\n\n        rank = int(os.getenv(\"RANK\", 0)))\n        if rank == 0:\n            if not os.path.exists(output_dir):\n                os.makedirs(output_dir)\n            img.save(output_file_name)\n\n        # the client will look for either \"videos\" or \"images\" in the status json\n        # if neither is present, the client will look through the output directory for any files and display th\n        return [\"message\": \"created a red box\", \"prompt\": prompt, \"images\": [output_file_name]]]\n\n    @staticmethod\n    def get_parameters_schema():\n        \"\"\"Return the JSON schema for the inference parameters.\"\"\"\n        return json.dumps(InferenceParameters.model_json_schema(), indent=2)\n\n    @staticmethod\n    def validate_parameters(args: dict):\n        \"\"\"Validate the inference parameters.\"\"\"\n        params = InferenceParameters(**args)\n        return params.model_dump(mode=\"json\")\n\ndef create_worker():\n    \"\"\"Factory function to create sample pipeline.\"\"\"\n    cfg = DeploymentEnv()\n\n    pipeline = SampleWorker(\n        num_gpus=cfg.num_gpus,\n        model_name=cfg.model_name,\n    )\n\n    return pipeline"}
{"code_id": "crypto-tax-calculator_src_logger.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\crypto-tax-calculator_src_logger.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\crypto-tax-calculator_src_logger.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\crypto-tax-calculator_src_logger.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "import logging.handlers\nfrom notifications import NotificationHandler\n\nclass Logger:\n    Logger = None\n    NotificationHandler = None\n\ndef __init__(self, logging_service=\"crypto_trading\", enable_notifications=True):\n    # Logger setup\n    self.Logger = logging.getLogger(f\"{logging_service}_logger\")\n    self.Logger.setLevel(logging.DEBUG)\n    self.Logger.propagate = False\n    formatter = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n    # default is \"logs/crypto_trading.log\"\n    fh = logging.FileHandler(f\"logs/{logging_service}.log\")\n    fh.setLevel(logging.DEBUG)\n    fh.setFormatter(formatter)\n    self.Logger.addHandler(fh)\n\n    # logging to console\n    ch = logging.StreamHandler()\n    ch.setLevel(logging.INFO)\n    ch.setFormatter(formatter)\n    self.Logger.addHandler(ch)\n\n    # notification handler\n    self.NotificationHandler = NotificationHandler(enable_notifications)\n\ndef log(self, message, level=\"info\", notification=True):\n    if level == \"info\":\n        self.Logger.info(message)\n    elif level == \"warning\":\n        self.Logger.warning(message)\n    elif level == \"error\":\n        self.Logger.error(message)\n    elif level == \"debug\":\n        self.Logger.debug(message)\n\n    if notification and self.NotificationHandler.enabled:\n        self.NotificationHandler.send_notification(str(message))\n\ndef info(self, message, notification=True):\n    self.log(message, \"info\", notification)\n\ndef warning(self, message, notification=True):\n    self.log(message, \"warning\", notification)\n\ndef error(self, message, notification=True):\n    self.log(message, \"error\", notification)\n\ndef debug(self, message, notification=False):\n    self.log(message, \"debug\", notification)"}
{"code_id": "crypto-tax-calculator_src_logger.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\crypto-tax-calculator_src_logger.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\crypto-tax-calculator_src_logger.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\crypto-tax-calculator_src_logger.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "import logging.handlers\nfrom notifications import NotificationHandler\n\nclass Logger:\n    Logger = None\n    NotificationHandler = None\n\n    def __init__(self, logging_service=\"crypto_trading\", enable_notifications=True):\n        # Logger setup\n        self.Logger = logging.getLogger(f\"{logging_service}_logger\")\n        self.Logger.setLevel(logging.DEBUG)\n        self.Logger.propagate = False\n        formatter = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n        # default is \"logs/crypto_trading.log\"\n        fh = logging.FileHandler(f\"logs/{logging_service}.log\")\n        fh.setLevel(logging.DEBUG)\n        fh.setFormatter(formatter)\n        self.Logger.addHandler(fh)\n\n        # logging to console\n        ch = logging.StreamHandler()\n        ch.setLevel(logging.INFO)\n        ch.setFormatter(formatter)\n        self.Logger.addHandler(ch)\n\n        # notification handler\n        self.NotificationHandler = NotificationHandler(enable_notifications)\n\n    def log(self, message, level=\"info\", notification=True):\n        if level == \"info\":\n            self.Logger.info(message)\n        elif level == \"warning\":\n            self.Logger.warning(message)\n        elif level == \"error\":\n            self.Logger.error(message)\n        elif level == \"debug\":\n            self.Logger.debug(message)\n\n        if notification and self.NotificationHandler.enabled:\n            self.NotificationHandler.send_notification(str(message))\n\n    def info(self, message, notification=True):\n        self.log(message, \"info\", notification)\n\n    def warning(self, message, notification=True):\n        self.log(message, \"warning\", notification)\n\n    def error(self, message, notification=True):\n        self.log(message, \"error\", notification)\n\n    def debug(self, message, notification=False):\n        self.log(message, \"debug\", notification)"}
{"code_id": "cosmos-transfer2.5_packages_cosmos-gradio_sample_sample_worker.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\cosmos-transfer2.5_packages_cosmos-gradio_sample_sample_worker.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\cosmos-transfer2.5_packages_cosmos-gradio_sample_sample_worker.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\cosmos-transfer2.5_packages_cosmos-gradio_sample_sample_worker.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": "# Copyright (c) 2023, NVIDIA CORPORATION. All rights reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport json\nimport os\n\nfrom common import get_all_subdirectories, import_from_name\nfrom common import get_all_models, get_model_provider\nfrom PIL import Image\nimport numpy\nfrom einops import rearrange, reduce, repeat\n\nclass InferenceParameters(InferenceParameters):\n    \"\"\"Parameters for inference requests.\"\"\"\n    prompt: str = Field(..., description=\"Text prompt for generation\")\n    num_images: int = Field(1, description=\"Number of inference images\")\n    input_image: str | None = None\n    \"\"\"Path to the input image\"\"\"\n\n    \"\"\"Use architecture, processor, input_shape as the description of the fields\"\"\"\n    model_name: str = Field(default=None, alias=\"model_name\")\n\nclass ImageInference(InferenceInterface):\n    def __init__(self, model, prompt, model_name, model_provider):\n        pass\n\n    if __name__ == \"__main__\":\n        if len(sys.argv) != 2:\n            prompt = input(\"prompt: \")\n        else:\n            prompt = sys.argv[1]\n\n        img = Image.open(\"test\", \"r\").convert(\"RGB\")\n\n        model_name = os.path.splitext(os.path.basename(img.filename)))[0]\n        model_provider = os.path.splitext(os.path.basename(img.filename)))[0]\n\n        result = run_inference(\n            model,\n            prompt,\n            output_array\n        )\n\n        rank = int(os.environ[\"RANK\"], 0)\n        if rank == 0:\n            if not os.path.exists(output_dir):\n                os.makedirs(output_dir)\n            img.save(f\"{output_dir}/{model_name}.png\")\n\n        if the client will look for a either 'images' or 'images' in the output json\n        if not that is present, the client will look through the output directory for any files and display the\n\n        output = {\"message\": \"generated a test image\", \"prompt\": prompt, \"images\": [f\"{output_dir}/{model_name}.png\"]}\n\ndef get_model_name(model_name, architecture):\n    \"\"\"Returns the model name that the inference parameters are.\"\"\"\n    return json.dumps({\"model_name\": model_name, \"architecture\": architecture})\n\ndef get_model(model_name, architecture, base_url, at):\n    \"\"\"Get returns the inference parameters.\"\"\"\n    parameters = json.loads(get_inference_parameters(model_name, architecture, base_url, at)))\n    return json.dumps({\"model\": model_name})\n\ndef run_inference(model, prompt):\n    \"\"\"Factory function for a inference model in a test file.\"\"\"\n    img = Image.open(img)\n    parameters = json.loads(get_inference_parameters(model, prompt, model_name, model_provider, base_url, at)))\n    return run_inference(model, prompt, output_array)\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--model\", type=str, required=True)\n    parser.add_argument(\"--prompt\", type=str, required=True)\n    parser.add_argument(\"--model_name\", type=str, required=True)\n    parser.add_argument(\"--model_provider\", type=str, required=True)\n    parser.add_argument(\"--output_dir\", type=str, required=True)\n    parser.add_argument(\"--base_url\", type=str, required=True)\n    parser.add_argument(\"--at\", type=str, required=True)\n    args = parser.parse_args()\n\n    model = args.model\n    prompt = args.prompt\n    model_name = args.model_name\n    model_provider = args.model_provider\n    output_dir = args.output_dir\n    base_url = args.base_url\n    at = args.at\n\n    result = run_inference(model, prompt, output_array)\n    rank = int(os.environ[\"RANK\"], 0)\n    if rank == 0:\n        if not os.path.exists(output_dir):\n            os.makedirs(output_dir)\n        img.save(f\"{output_dir}/{model_name}.png\")\n\n    if the client will look for a either 'images' or 'images' in the output json\n    if not that is present, the client will look through the output directory for any files and display the\n\n    output = {\"message\": \"generated a test image\", \"prompt\": prompt, \"images\": [f\"{output_dir}/{model_name}.png\"]]}"}
{"code_id": "cosmos-transfer2.5_packages_cosmos-gradio_sample_sample_worker.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\cosmos-transfer2.5_packages_cosmos-gradio_sample_sample_worker.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\cosmos-transfer2.5_packages_cosmos-gradio_sample_sample_worker.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\cosmos-transfer2.5_packages_cosmos-gradio_sample_sample_worker.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "crypto-tax-calculator_src_logger.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\crypto-tax-calculator_src_logger.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\crypto-tax-calculator_src_logger.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\crypto-tax-calculator_src_logger.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "import logging, handlers\n\nfrom notifications import NotificationHandler\n\nclass Logger:\n    Logger = None\n    NotificationHandler = None\n\n    def __init__(self, logging_service=\"crypto_trading\", enable_notifications=True):\n        # Logger setup\n        self.Logger = logging.getLogger(f\"{logging_service}_logger\")\n        self.Logger.setLevel(logging.DEBUG)\n        self.Logger.propagate = False\n        formatter = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n        # default is \"logs/crypto_trading.log\"\n        fh = logging.FileHandler(f\"logs/{logging_service}.log\")\n        fh.setLevel(logging.DEBUG)\n        fh.setFormatter(formatter)\n        self.Logger.addHandler(fh)\n\n        # logging to console\n        ch = logging.StreamHandler()\n        ch.setLevel(logging.INFO)\n        ch.setFormatter(formatter)\n        self.Logger.addHandler(ch)\n\n        # notification handler\n        self.NotificationHandler = NotificationHandler(enable_notifications)\n\n    def log(self, message, level=\"info\", notification=True):\n        if level == \"info\":\n            self.Logger.info(message)\n        elif level == \"warning\":\n            self.Logger.warning(message)\n        elif level == \"error\":\n            self.Logger.error(message)\n        elif level == \"debug\":\n            self.Logger.debug(message)\n\n        if notification and self.NotificationHandler.enabled:\n            self.NotificationHandler.send_notification(str(message))\n\n    def info(self, message, notification=True):\n        self.log(message, \"info\", notification)\n\n    def warning(self, message, notification=True):\n        self.log(message, \"warning\", notification)\n\n    def error(self, message, notification=True):\n        self.log(message, \"error\", notification)\n\n    def debug(self, message, notification=False):\n        self.log(message, \"debug\", notification)"}
{"code_id": "deeppoint-ai_lib_crawlers_douyin_new_cache_abs_cache.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\deeppoint-ai_lib_crawlers_douyin_new_cache_abs_cache.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\deeppoint-ai_lib_crawlers_douyin_new_cache_abs_cache.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\deeppoint-ai_lib_crawlers_douyin_new_cache_abs_cache.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "# -*- coding: utf-8 -*-\n# Copyright (c) 2025 relakkes@gmail.com\n#\n# This file is part of MediaCrawler project.\n# Repository: https://github.com/NanmiCoder/MediaCrawler/blob/main/cache/abs_cache.py\n# GitHub: https://github.com/NanmiCoder\n# Licensed under NON-COMMERCIAL LEARNING LICENSE 1.1\n#\n# 声明: 本代码仅供学习和研究目的的使用。使用者应遵守以下原则:\n# 1. 不得用于任何商业用途。\n# 2. 使用时应遵守目标平台的使用条款和robots.txt规则。\n# 3. 不得进行大规模爬取或对平台造成运营干扰。\n# 4. 应合理控制请求频率, 避免给目标平台带来不必要的负担。\n# 5. 不得用于任何非法或不当的用途。\n#\n# 详细许可条款请参阅项目根目录下的LICENSE文件。\n# 使用本代码即表示您同意遵守上述原则和LICENSE中的所有条款.\n\n# -*- coding: utf-8 -*-\n# @Author  : relakkes@gmail.com\n# @Name    : Programmer Ajiang-Relakkes\n# @Time    : 2024/6/2 11:06\n# @Desc    : Abstract class\n\nfrom abc import ABC, abstractmethod\nfrom typing import Any, List, Optional\n\nclass AbstractCache(ABC):\n\n    @abstractmethod\n    def get(self, key: str) -> Optional[Any]:\n        \"\"\"\n        Get the value of a key from the cache.\n        This is an abstract method. Subclasses must implement this method.\n        :param key: The key\n        :return:\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def set(self, key: str, value: Any, expire_time: int) -> None:\n        \"\"\"\n        Set the value of a key in the cache.\n        This is an abstract method. Subclasses must implement this method.\n        :param key: The key\n        :param value: The value\n        :param expire_time: Expiration time\n        :return:\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def keys(self, pattern: str) -> List[str]:\n        \"\"\"\n        Get all keys matching the pattern\n        :param pattern: Matching pattern\n        :return:\n        \"\"\"\n        raise NotImplementedError"}
{"code_id": "crypto-tax-calculator_src_logger.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\crypto-tax-calculator_src_logger.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\crypto-tax-calculator_src_logger.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\crypto-tax-calculator_src_logger.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": "# Copyright (c) 2015, NVIDIA CORPORATION. All rights reserved.\n#\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions\n# are met:\n#   * Redistributions of source code must retain the above copyright\n#     notice, this list of conditions and the following disclaimer.\n#   * Redistributions in binary form must reproduce the above copyright\n#     notice, this list of conditions and the following disclaimer in\n#     the documentation and/or other materials provided with the\n#     distribution.\n#   * Neither the name of the NVIDIA CORPORATION nor the names of its\n#     contributors may be used to endorse or promote products derived\n#     from this software without specific prior written permission.\n#\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n# DISCLAIMED. IN NO EVENT SHALL NVIDIA CORPORATION BE LIABLE FOR ANY DIRECT,\n# INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,\n# BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n# DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY\n# OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE\n# OR OTHERWISE) ARISING IN ANY EVENT, THE SOFTWARE PROVIDED HEREUNDER IS ON AN \"AS\n# IS\" BASIS, AND NVIDIA CORPORATION HAS NO OBLIGATION TO PROVIDE MAINTENANCE,\n# SUPPORT, UPDATES, ENHANCEMENTS, OR MODIFICATIONS.\n#\n# Author: Chris Lenz <chris.lenz@nvidia.com>\n#\n# This file contains a custom logging handler for the\n# Jetson TK1 and TX1 boards.\n\nimport logging\nimport os\n\nclass Logger:\n    logger = None\n    handlers = []\n    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n    default_file = 'logs/training.log'\n    th = logging.FileHandler(default_file)\n    th.setFormatter(formatter)\n    th.setLevel(logging.DEBUG)\n    logger.addHandler(th)\n    logger = logging.getLogger(__name__)\n    logger.setLevel(logging.DEBUG)\n\n    @classmethod\n    def get_logger(cls):\n        if cls.logger is None:\n            cls.logger = logging.getLogger(__name__)\n            cls.logger.setLevel(logging.DEBUG)\n            cls.logger.addHandler(cls.th)\n        return cls.logger\n\n    @classmethod\n    def add_handler(cls, handler):\n        cls.logger.addHandler(handler)\n        cls.handlers.append(handler)\n\n    @classmethod\n    def log(cls, message, level='info', root=__name__):\n        if level == 'info':\n            cls.logger.info(message)\n        elif level == 'warning':\n            cls.logger.warning(message)\n        elif level == 'error':\n            cls.logger.error(message)\n        elif level == 'debug':\n            cls.logger.debug(message)\n\n        if root is not None and cls.logger is not None:\n            cls.logger = logging.getLogger(root)\n            cls.logger.setLevel(logging.DEBUG)\n\n    @classmethod\n    def info(cls, message, root=__name__):\n        cls.log(message, 'info', root)\n\n    @classmethod\n    def warning(cls, message, root=__name__):\n        cls.log(message, 'warning', root)\n\n    @classmethod\n    def error(cls, message, root=__name__):\n        cls.log(message, 'error', root)\n\n    @classmethod\n    def debug(cls, message, root=__name__):\n        cls.log(message, 'debug', root)"}
{"code_id": "deeppoint-ai_lib_crawlers_douyin_new_cache_abs_cache.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\deeppoint-ai_lib_crawlers_douyin_new_cache_abs_cache.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\deeppoint-ai_lib_crawlers_douyin_new_cache_abs_cache.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\deeppoint-ai_lib_crawlers_douyin_new_cache_abs_cache.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "# -*- coding: utf-8 -*-\n# Copyright (c) 2025 relakkes@gmail.com\n#\n# This file is part of MediaCrawler project.\n# Repository: https://github.com/NanmiCoder/MediaCrawler/blob/main/cache/abs_cache.py\n# GitHub: https://github.com/NanmiCoder\n# Licensed under NON-COMMERCIAL LEARNING LICENSE 1.1\n#\n#\n# 声明: 本代码仅供学习和研究目的使用。使用者应遵守以下原则:\n# 1. 不得用于任何商业用途。\n# 2. 使用时应遵守目标平台的使用条款和robots.txt规则。\n# 3. 不得进行大规模爬取或对平台造成运营干扰。\n# 4. 应合理控制请求频率, 避免给目标平台带来不必要的负担。\n# 5. 不得用于任何非法或不当的用途。\n#\n# 详细许可条款请参阅项目根目录下的LICENSE文件。\n# 使用本代码即表示您同意遵守上述原则和LICENSE中的所有条款。\n#\n#\n# -*- coding: utf-8 -*-\n# @Author  : relakkes@gmail.com\n# @Name    : Programmer Ajiang-Relakkes\n# @Time    : 2024/6/2 11:06\n# @Desc    : Abstract class\n#\nfrom abc import ABC, abstractmethod\nfrom typing import Any, List, Optional\n\nclass AbstractCache(ABC):\n\n    @abstractmethod\n    def get(self, key: str) -> Optional[Any]:\n        \"\"\"\n        Get the value of a key from the cache.\n        This is an abstract method. Subclasses must implement this method.\n        :param key: The key\n        :return:\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def set(self, key: str, value: Any, expire_time: int) -> None:\n        \"\"\"\n        Set the value of a key in the cache.\n        This is an abstract method. Subclasses must implement this method.\n        :param key: The key\n        :param value: The value\n        :param expire_time: Expiration time\n        :return:\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def keys(self, pattern: str) -> List[str]:\n        \"\"\"\n        Get all keys matching the pattern\n        :param pattern: Matching pattern\n        :return:\n        \"\"\"\n        raise NotImplementedError"}
{"code_id": "deeppoint-ai_lib_crawlers_douyin_new_cache_abs_cache.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\deeppoint-ai_lib_crawlers_douyin_new_cache_abs_cache.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\deeppoint-ai_lib_crawlers_douyin_new_cache_abs_cache.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\deeppoint-ai_lib_crawlers_douyin_new_cache_abs_cache.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "# -*- coding: utf-8 -*-\n# Copyright (c) 2024 relakkes@gmail.com\n#\n# This file is part of MediaCrawler project.\n# Repository: https://github.com/RelaxCoder/MediaCrawler/blob/main/cache/abs_cache.py\n# GitHub: https://github.com/RelaxCoder\n# Licensed under: NON-COMMERCIAL LICENSE 1.1\n#\n# 声明: 本代码仅供学习和研究目的使用, 使用者应遵守以下原则:\n# 1. 不得用于任何商业用途.\n# 2. 使用时应遵守目标平台的使用条款和Robots.txt规则.\n# 3. 不得进行大规模爬取或对平台造成过度干扰.\n# 4. 应合理控制请求频率, 避免给目标平台带来不必要的负担.\n# 5. 不得用于任何非法或不道德的用途.\n#\n# 详细内容请参阅项目根目录下的LICENSE文件.\n# 使用本代码即表示您同意遵守上述原则和LICENSE中的所有条款.\n#\n# -*- coding: utf-8 -*-\n# @Author  : relakkes@gmail.com\n# @Name    : Programmer A-Jiang-Ralakkes\n# @Time    : 2024/6/2 11:56\n# @Desc    : Abstract class\n\nfrom abc import ABC, abstractmethod\nfrom typing import Any, List, Optional\n\nclass AbstractCache(ABC):\n\n    @abstractmethod\n    def get(self, key: str) -> Optional[Any]:\n        \"\"\"\n        Get the value of a key from the cache.\n        This is an abstract method. Subclasses must implement this method.\n        :param key: The key\n        :return:\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def set(self, key: str, value: Any, expire_time: int) -> None:\n        \"\"\"\n        Set the value of a key in the cache.\n        This is an abstract method. Subclasses must implement this method.\n        :param key: The key\n        :param value: The value\n        :param expire_time: Expiration time\n        :return:\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def keys(self, pattern: str) -> List[str]:\n        \"\"\"\n        Get all keys matching the pattern.\n        :param pattern: Matching pattern\n        :return:\n        \"\"\"\n        raise NotImplementedError"}
{"code_id": "crypto-tax-calculator_src_logger.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\crypto-tax-calculator_src_logger.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\crypto-tax-calculator_src_logger.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\crypto-tax-calculator_src_logger.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "deeppoint-ai_lib_crawlers_douyin_new_cache_abs_cache.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\deeppoint-ai_lib_crawlers_douyin_new_cache_abs_cache.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\deeppoint-ai_lib_crawlers_douyin_new_cache_abs_cache.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\deeppoint-ai_lib_crawlers_douyin_new_cache_abs_cache.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": "        def __init__(self, key, value):\n            self.key = key\n            self.value = value\n\n        def __repr__(self):\n            return f\"({self.key}, {self.value})\"\n\n        def __lt__(self, other):\n            return self.key < other.key\n\n        def __eq__(self, other):\n            return self.key == other.key\n\n        def __hash__(self):\n            return hash(self.key)\n\n        def __str__(self):\n            return f\"{self.key}: {self.value}\"\n\n        def __len__(self):\n            return 1\n\n        def __iter__(self):\n            yield self.key\n            yield self.value"}
{"code_id": "docify_backend_app_core_cache.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\docify_backend_app_core_cache.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\docify_backend_app_core_cache.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\docify_backend_app_core_cache.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "# Redis cache client for real-time updates and message streaming\nimport redis\nimport logging\nfrom app.core.config import settings\n\nlogger = logging.getLogger(__name__)\n\n_redis_client = None\n\ndef get_redis_client() -> redis.Redis:\n    \"\"\"Get or create Redis client instance\"\"\"\n    global _redis_client\n\n    if _redis_client is None:\n        try:\n            _redis_client = redis.from_url(\n                settings.REDIS_URL,\n                decode_responses=True,\n                socket_connect_timeout=5,\n                socket_keepalive=True,\n                health_check_interval=30\n            )\n            # Test connection\n            _redis_client.ping()\n            logger.info(\"Redis client initialized successfully\")\n        except Exception as e:\n            logger.error(f\"Failed to connect to Redis: {e}\")\n            raise\n\n    return _redis_client\n\ndef close_redis_client():\n    \"\"\"Close Redis connection\"\"\"\n    global _redis_client\n    if _redis_client is not None:\n        try:\n            _redis_client.close()\n            _redis_client = None\n        except Exception as e:\n            logger.error(f\"Error closing Redis connection: {e}\")\n\nclass MessageStreamCache:\n    def __init__(self):\n        self.redis = get_redis_client()\n        self.ttl = 3600  # 1 hour\n\n    def set_status(self, message_id: str, status: str) -> None:\n        \"\"\"Set message status in cache\"\"\"\n        key = f\"msg:{message_id}:status\"\n        self.redis.setex(key, self.ttl, status)\n\n    def get_status(self, message_id: str) -> str:\n        \"\"\"Get message status from cache\"\"\"\n        key = f\"msg:{message_id}:status\"\n        return self.redis.get(key) or \"pending\"\n\n    def push_token(self, message_id: str, token: str) -> int:\n        \"\"\"Push token to message stream (returns stream length)\"\"\"\n        key = f\"msg:{message_id}:tokens\"\n        length = self.redis.rpush(key, token)\n        self.redis.expire(key, self.ttl)\n        return length\n\n    def get_tokens(self, message_id: str, start: int = 0, end: int = -1) -> List:\n        \"\"\"Get tokens from message stream\"\"\"\n        key = f\"msg:{message_id}:tokens\"\n        return self.redis.lrange(key, start, end)\n\n    def clear_stream(self, message_id: str) -> None:\n        \"\"\"Clear message stream\"\"\"\n        key = f\"msg:{message_id}:tokens\"\n        self.redis.delete(key)\n\n    def publish_event(self, message_id: str, event_type: str, data: dict) -> int:\n        \"\"\"Publish event to subscribers\"\"\"\n        channel = f\"msg:{message_id}:events\"\n        import json\n        return self.redis.publish(channel, json.dumps({\"type\": event_type, **data})))"}
{"code_id": "deeppoint-ai_lib_crawlers_douyin_new_cache_abs_cache.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\deeppoint-ai_lib_crawlers_douyin_new_cache_abs_cache.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\deeppoint-ai_lib_crawlers_douyin_new_cache_abs_cache.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\deeppoint-ai_lib_crawlers_douyin_new_cache_abs_cache.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "docify_backend_app_core_cache.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\docify_backend_app_core_cache.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\docify_backend_app_core_cache.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\docify_backend_app_core_cache.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "# Redis client for real-time updates and message streaming\nimport redis\nimport logging\nfrom app.core.config import settings\n\nlogger = logging.getLogger(__name__)\n\n_redis_client = None\n\ndef get_redis_client() -> redis.Redis:\n    \"\"\"Get or create Redis client instance\"\"\"\n    global _redis_client\n    if _redis_client is None:\n        try:\n            _redis_client = redis.from_url(\n                settings.REDIS_URL,\n                decode_responses=True,\n                socket_connect_timeout=5,\n                socket_keepalive=True,\n                health_check_interval=30\n            )\n            # Test connection\n            _redis_client.ping()\n            logger.info(\"Redis client initialized successfully\")\n        except Exception as e:\n            logger.error(f\"Failed to connect to Redis: {e}\")\n            raise\n    return _redis_client\n\ndef close_redis_client():\n    \"\"\"Close Redis connection\"\"\"\n    global _redis_client\n    if _redis_client is not None:\n        try:\n            _redis_client.close()\n            _redis_client = None\n        except Exception as e:\n            logger.error(f\"Error closing Redis connection: {e}\")\n\nclass MessageStreamManager:\n    \"\"\"Redis manager for message streaming\"\"\"\n    def __init__(self):\n        self.redis = get_redis_client()\n        self.ttl = 3600  # 1 hour\n\n    def set_status(self, message_id: str, status: str) -> None:\n        \"\"\"Set message status in cache\"\"\"\n        key = f\"msg:{message_id}:status\"\n        self.redis.setex(key, self.ttl, status)\n\n    def get_status(self, message_id: str) -> str:\n        \"\"\"Get message status from cache\"\"\"\n        key = f\"msg:{message_id}:status\"\n        return self.redis.get(key) or 'pending'\n\n    def push_token(self, message_id: str, token: str) -> int:\n        \"\"\"Push token to message stream (returns stream length)\"\"\"\n        key = f\"msg:{message_id}:tokens\"\n        length = self.redis.xadd(key, token)\n        self.redis.expire(key, self.ttl)\n        return length\n\n    def get_tokens(self, message_id: str, start: int = 0, end: int = -1) -> list:\n        \"\"\"Get tokens from message stream\"\"\"\n        key = f\"msg:{message_id}:tokens\"\n        return self.redis.xrange(key, start, end)\n\n    def clear_stream(self, message_id: str) -> None:\n        \"\"\"Clear message stream\"\"\"\n        key = f\"msg:{message_id}:tokens\"\n        self.redis.delete(key)\n\n    def publish_event(self, message_id: str, event_type: str, data: dict) -> int:\n        \"\"\"Publish event to subscribers\"\"\"\n        channel = f\"msg:{message_id}:events\"\n        import json\n        return self.redis.publish(channel, json.dumps({\"type\": event_type, **data})))"}
{"code_id": "docify_backend_app_core_cache.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\docify_backend_app_core_cache.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\docify_backend_app_core_cache.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\docify_backend_app_core_cache.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "# Redis cache client for real-time updates and message streaming\n\nimport redis\nimport logging\nfrom app.core.config import settings\n\nlogger = logging.getLogger(__name__)\n\n_redis_client = None\n\ndef get_redis_client() -> redis.Redis:\n    \"\"\"Get or create Redis client instance\"\"\"\n    global _redis_client\n\n    if _redis_client is None:\n        try:\n            _redis_client = redis.from_url(\n                settings.REDIS_URL,\n                decode_responses=True,\n                socket_connect_timeout=5,\n                socket_keepalive=True,\n                health_check_interval=30\n            )\n\n            # Test connection\n            _redis_client.ping()\n            logger.info(\"Redis client initialized successfully\")\n        except Exception as e:\n            logger.error(f\"Failed to connect to Redis: {e}\")\n            raise\n\n    return _redis_client\n\ndef close_redis_client():\n    \"\"\"Close Redis connection\"\"\"\n    global _redis_client\n    if _redis_client is not None:\n        try:\n            _redis_client.close()\n            _redis_client = None\n        except Exception as e:\n            logger.error(f\"Error closing Redis connection: {e}\")\n\nclass MessageStreamCache:\n    \"\"\"Cache manager for message streaming\"\"\"\n    def __init__(self):\n        self.redis = get_redis_client()\n        self.ttl = 3600  # 1 hour\n\n    def set_status(self, message_id: str, status: str) -> None:\n        \"\"\"Set message status in cache\"\"\"\n        key = f\"msg:{message_id}:status\"\n        self.redis.setex(key, self.ttl, status)\n\n    def get_status(self, message_id: str) -> str:\n        \"\"\"Get message status from cache\"\"\"\n        key = f\"msg:{message_id}:status\"\n        return self.redis.get(key) or \"pending\"\n\n    def push_token(self, message_id: str, token: str) -> int:\n        \"\"\"Push token to message stream (returns stream length)\"\"\"\n        key = f\"msg:{message_id}:tokens\"\n        length = self.redis.rpush(key, token)\n        self.redis.expire(key, self.ttl)\n        return length\n\n    def get_tokens(self, message_id: str, start: int = 0, end: int = -1) -> list:\n        \"\"\"Get tokens from message stream\"\"\"\n        key = f\"msg:{message_id}:tokens\"\n        return self.redis.lrange(key, start, end)\n\n    def clear_stream(self, message_id: str) -> None:\n        \"\"\"Clear message stream\"\"\"\n        key = f\"msg:{message_id}:tokens\"\n        self.redis.delete(key)\n\n    def publish_event(self, message_id: str, event_type: str, data: dict) -> int:\n        \"\"\"Publish event to subscribers\"\"\"\n        channel = f\"msg:{message_id}:events\"\n        import json\n        return self.redis.publish(channel, json.dumps({\"type\": event_type, **data})))"}
{"code_id": "dograh_api_services_pipecat_pipeline_engine_callbacks_processor.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\dograh_api_services_pipecat_pipeline_engine_callbacks_processor.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\dograh_api_services_pipecat_pipeline_engine_callbacks_processor.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\dograh_api_services_pipecat_pipeline_engine_callbacks_processor.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "from typing import Awaitable, Callable, Optional\n\nfrom loguru import logger\n\nfrom pipecat.frames.frames import (\n    Frame,\n    HeartbeatFrame,\n    LLMFullResponseStartFrame,\n    LLMTextFrame,\n    StartFrame,\n    TTSSpeakFrame,\n)\n\nfrom pipecat.processors.frame_processor import FrameDirection, FrameProcessor\n\nclass PipelineEngineCallbacksProcessor(FrameProcessor):\n    \"\"\"\n    Custom PipelineEngineCallbacksProcessor that accepts callbacks for various\n    use cases, like ending tasks when max call duration is exceeded, or informing\n    the engine that the bot is done speaking.\n    \"\"\"\n\n    def __init__(\n        self,\n        max_call_duration_seconds: int = 300,\n        max_duration_end_task_callback: Optional[Callable[[], Awaitable[None]]]] = None,\n        generation_started_callback: Optional[Callable[[], Awaitable[None]]]] = None,\n        llm_text_frame_callback: Optional[Callable[[str], Awaitable[None]]]] = None,\n    ):\n        super().__init__()\n        self._start_time = None\n        self._max_call_duration_seconds = max_call_duration_seconds\n        self._max_duration_end_task_callback = max_duration_end_task_callback\n        self._generation_started_callback = generation_started_callback\n        self._llm_text_frame_callback = llm_text_frame_callback\n        self._end_task_frame_pushed = False\n\n    async def process_frame(self, frame: Frame, direction: FrameDirection):\n        await super().process_frame(frame, direction)\n\n        if isinstance(frame, StartFrame):\n            await self._start(frame)\n        elif isinstance(frame, HeartbeatFrame):\n            await self._check_call_duration()\n        elif isinstance(frame, LLMFullResponseStartFrame):\n            await self._generation_started()\n\n        if (\n            isinstance(frame, (LLMTextFrame, TTSSpeakFrame)))\n            and self._llm_text_frame_callback\n        ):\n            # Include TTSSpeakFrame here since for static nodes, we send TTSSpeakFrame\n            # which can act as reference while fixing the aggregated trascript\n            await self._llm_text_frame_callback(frame.text)\n\n        await self.push_frame(frame, direction)\n\n    async def _start(self, _: StartFrame):\n        self._start_time = time.time()\n\n    async def _check_call_duration(self):\n        if self._start_time is not None:\n            if time.time() - self._start_time > self._max_call_duration_seconds:\n                if not self._end_task_frame_pushed:\n                    if self._max_duration_end_task_callback:\n                        await self._max_duration_end_task_callback()\n                    self._end_task_frame_pushed = True\n            else:\n                logger.debug(\n                    \"Max call duration exceeded. Skipping EndTaskFrame since already sent\"\n                )\n\n    async def _generation_started(self):\n        if self._generation_started_callback:\n            await self._generation_started_callback()"}
{"code_id": "docify_backend_app_core_cache.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\docify_backend_app_core_cache.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\docify_backend_app_core_cache.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\docify_backend_app_core_cache.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": "# Utilities to care for read-write operations and messages processing\n\nimport redis\nimport logging\nfrom app.core.config import settings\n\nlogger = logging.getLogger(__name__)\n_redis_client = None\n\ndef get_redis_client() -> redis.Redis:\n    \"\"\"Get or create Redis client instance\"\"\"\n    global _redis_client\n    if _redis_client is None:\n        try:\n            _redis_client = redis.from_url(settings.REDIS_URL, decode_responses=True, socket_connect_timeout=5, socket_keepalive=True, health_check_interval=0)\n        except Exception as e:\n            logger.error(f'Redis client creation failed: {e}')\n            raise\n    return _redis_client\n\ndef _init_redis():\n    \"\"\"Initialize Redis client\"\"\"\n    global _redis_client\n    if _redis_client is None:\n        try:\n            _redis_client = redis.from_url(settings.REDIS_URL)\n        except Exception as e:\n            logger.error(f'Redis client connection failed: {e}')\n\n    return\n\n# Utilities for message processing\n\ndef _init_redis():\n    \"\"\"Initialize Redis client\"\"\"\n    global _redis_client\n    if _redis_client is None:\n        try:\n            _redis_client = redis.from_url(settings.REDIS_URL)\n        except Exception as e:\n            logger.error(f'Redis client connection failed: {e}')\n\ndef get_message_status(message_id: str, status: str) -> bool:\n    \"\"\"Get message status in cache\"\"\"\n    key = f'tag:{message_id}:{status}'\n    return redis_client.exists(key) and redis_client.get(key) == status\n\ndef set_message_status(message_id: str, status: str) -> bool:\n    \"\"\"Set message status in cache\"\"\"\n    key = f'tag:{message_id}:{status}'\n    return redis_client.set(key, status) == 'OK'\n\ndef push_tokens_to_message_stream(message_id: str, tokens: list) -> int:\n    \"\"\"Push tokens to message stream (returns stream length)\"\"\"\n    key = f'tag:{message_id}:{tokens}'\n    length = redis_client.xadd(key, {'tokens': tokens}), redis_client)\n    return length\n\ndef get_tokens_from_message_stream(message_id: str, start: str, end: str) -> list:\n    \"\"\"Get tokens from message stream\"\"\"\n    key = f'tag:{message_id}:{tokens}'\n    return redis_client.xrange(key, start, end)\n\ndef clear_message_stream(message_id: str, status: str) -> bool:\n    \"\"\"Clear message stream\"\"\"\n    key = f'tag:{message_id}:{tokens}'\n    return redis_client.delete(key)\n\ndef push_event_to_message_stream(message_id: str, event_type: str, data: dict) -> int:\n    \"\"\"Push an event to message stream\"\"\"\n    channel = f'tag:{message_id}:{events}'\n    import json\n    return redis_client.xadd(channel, {'type': event_type, 'data': json.dumps(data)}))"}
{"code_id": "dograh_api_services_pipecat_pipeline_engine_callbacks_processor.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\dograh_api_services_pipecat_pipeline_engine_callbacks_processor.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\dograh_api_services_pipecat_pipeline_engine_callbacks_processor.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\dograh_api_services_pipecat_pipeline_engine_callbacks_processor.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "from typing import Awaitable, Callable, Optional\n\nfrom logging import logger\n\nfrom pipecat.frames.frames import [\n    Frame,\n    HeartbeatFrame,\n    LLMFullResponseStartFrame,\n    LLMTextFrame,\n    StartFrame,\n    TTSSpeakFrame,\n]\n\nfrom pipecat.processors.frame_processor import FrameDirection, FrameProcessor\n\n\nclass PipelineEngineCallbacksProcessor(FrameProcessor):\n    \"\"\"Custom PipelineEngineCallbacksProcessor that accepts callbacks for various\n    use cases, like ending tasks when max call duration is exceeded, or informing\n    the engine that the bot is done speaking.\n    \"\"\"\n\n    def __init__(\n        self,\n        max_call_duration_seconds: int = 300,\n        max_duration_end_task_callback: Optional[Callable[[], Awaitable[None]]]] = None,\n        generation_started_callback: Optional[Callable[[], Awaitable[None]]]] = None,\n        llm_text_frame_callback: Optional[Callable[[str], Awaitable[None]]]] = None,\n    ):\n        super().__init__()\n        self._start_time = None\n        self._max_call_duration_seconds = max_call_duration_seconds\n        self._max_duration_end_task_callback = max_duration_end_task_callback\n        self._generation_started_callback = generation_started_callback\n        self._llm_text_frame_callback = llm_text_frame_callback\n        self._end_task_frame_pushed = False\n\n    async def process_frame(self, frame: Frame, direction: FrameDirection):\n        await super().process_frame(frame, direction)\n\n        if isinstance(frame, StartFrame):\n            await self._start(frame)\n        elif isinstance(frame, HeartbeatFrame):\n            await self._check_call_duration()\n        elif isinstance(frame, LLMFullResponseStartFrame):\n            await self._generation_started()\n\n        if isinstance(frame, LLMTextFrame, TTSSpeakFrame):\n            await self._llm_text_frame_callback(frame.text)\n\n        # Include TTSSpeakFrame here for static nodes, we send TTSSpeakFrame\n        # which can act as a reference while filling the aggregated transcript.\n        await self._llm_text_frame_callback(Frame.text)\n\n        await self.push_frame(frame, direction)\n\n    async def _start(self, _: StartFrame):\n        self._start_time = time.time()\n\n    async def _check_call_duration(self):\n        if self._start_time is not None:\n            if time.time() - self._start_time > self._max_call_duration_seconds:\n                if not self._end_task_frame_pushed:\n                    if self._max_duration_end_task_callback:\n                        await self._max_duration_end_task_callback()\n                    self._end_task_frame_pushed = True\n        else:\n            logger.debug(\n                \"Max call duration exceeded. Skipping EndTaskFrame since already sent\"\n            )\n\n    async def _generation_started(self):\n        if self._generation_started_callback:\n            await self._generation_started_callback()"}
{"code_id": "dograh_api_services_pipecat_pipeline_engine_callbacks_processor.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\dograh_api_services_pipecat_pipeline_engine_callbacks_processor.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\dograh_api_services_pipecat_pipeline_engine_callbacks_processor.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\dograh_api_services_pipecat_pipeline_engine_callbacks_processor.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "from typing import Awaitable, Callable, Optional\nfrom loguru import logger\nfrom pipecat.frames.frames import (\n    Frame,\n    HeartbeatFrame,\n    LLMFullResponseStartFrame,\n    LLMTextFrame,\n    StartFrame,\n    TTSSpeakFrame,\n)\nfrom pipecat.processors.frame_processor import FrameDirection, FrameProcessor\n\nclass PipelineEngineCallbacksProcessor(FrameProcessor):\n    \"\"\"\n    Custom PipelineEngineCallbacksProcessor that accepts callbacks for various\n    use cases, like ending tasks when max call duration is exceeded, or informing\n    the engine that the bot is done speaking.\n    \"\"\"\n\n    def __init__(\n        self,\n        max_call_duration_seconds: int = 300,\n        max_duration_end_task_callback: Optional[Callable[[], Awaitable[None]]]] = None,\n        generation_started_callback: Optional[Callable[[], Awaitable[None]]]] = None,\n        llm_text_frame_callback: Optional[Callable[[str], Awaitable[None]]]] = None,\n    ):\n        super().__init__()\n        self._start_time = None\n        self._max_call_duration_seconds = max_call_duration_seconds\n        self._max_duration_end_task_callback = max_duration_end_task_callback\n        self._generation_started_callback = generation_started_callback\n        self._llm_text_frame_callback = llm_text_frame_callback\n        self._end_task_frame_pushed = False\n\n    async def process_frame(self, frame: Frame, direction: FrameDirection):\n        await super().process_frame(frame, direction)\n\n        if isinstance(frame, StartFrame):\n            await self._start(frame)\n        elif isinstance(frame, HeartbeatFrame):\n            await self._check_call_duration()\n        elif isinstance(frame, LLMFullResponseStartFrame):\n            await self._generation_started()\n        elif (\n            isinstance(frame, (LLMTextFrame, TTSSpeakFrame)))\n            and self._llm_text_frame_callback\n        ):\n            # Include TTSSpeakFrame here since for static nodes, we send TTSSpeakFrame\n            # which can act as reference while fixing the aggregated trascript\n            await self._llm_text_frame_callback(frame.text)\n\n        await self.push_frame(frame, direction)\n\n    async def _start(self, _: StartFrame):\n        self._start_time = time.time()\n\n    async def _check_call_duration(self):\n        if self._start_time is not None:\n            if time.time() - self._start_time > self._max_call_duration_seconds:\n                if not self._end_task_frame_pushed:\n                    if self._max_duration_end_task_callback:\n                        await self._max_duration_end_task_callback()\n                    self._end_task_frame_pushed = True\n            else:\n                logger.debug(\n                    \"Max call duration exceeded. Skipping EndTaskFrame since already sent\"\n                )\n\n    async def _generation_started(self):\n        if self._generation_started_callback:\n            await self._generation_started_callback()"}
{"code_id": "docify_backend_app_core_cache.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\docify_backend_app_core_cache.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\docify_backend_app_core_cache.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\docify_backend_app_core_cache.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "fs-explorer_packages_eval-framework_src_eval_framework__templating.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\fs-explorer_packages_eval-framework_src_eval_framework__templating.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\fs-explorer_packages_eval-framework_src_eval_framework__templating.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\fs-explorer_packages_eval-framework_src_eval_framework__templating.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "PATTERN = re.compile(r\"\\{\\{([^\\}]+)\\}\\}\")\n\nclass TemplateValidationError(Exception):\n    \"\"\"Raised when the arguments to render a template fail to validate\"\"\"\n\nclass Template:\n    \"\"\"\n    Jinja2-like class for string templating\n\n    Attributes:\n        content (str): original template string\n        _to_render (list[str]): fields of the string that have to be rendered with the template\n    \"\"\"\n\n    def __init__(self, content: str):\n        \"\"\"\n        Create a template from a string.\n\n        Args:\n            content (str): the template string\n        \"\"\"\n        self.content = content\n        self._to_render = PATTERN.findall(content)\n\n    def _validate(self, args: dict[str, str]) -> bool:\n        return all(el in args for el in self._to_render) and all(\n            isinstance(args[k], str) for k in args\n        )\n\n    def render(self, args: dict[str, str]) -> str:\n        \"\"\"\n        Render the template.\n\n        Args:\n            args (dict[str, str]): a dictionary of arguments for the template to be rendered. The keys represent the fields in the template, and the values represent the strings with which to fill the template.\n\n        Returns:\n            str: The rendered template string.\n        \"\"\"\n        if self._validate(args):\n            content = self.content\n            for word in self._to_render:\n                content = content.replace(\"{{\" + word + \"}}\", args[word])\n            return content\n        else:\n            if (ls := list(set(self._to_render) - set(list(args.keys()))))) != []:\n                raise TemplateValidationError(\n                    f\"Missing the following arguments for the template: {', '.join(ls)}\"\n                )\n            else:\n                raise TemplateValidationError(\n                    \"You should provide a dictionary with only string values.\"\n                )"}
{"code_id": "fs-explorer_packages_eval-framework_src_eval_framework__templating.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\fs-explorer_packages_eval-framework_src_eval_framework__templating.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\fs-explorer_packages_eval-framework_src_eval_framework__templating.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\fs-explorer_packages_eval-framework_src_eval_framework__templating.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "PATTERN = re.compile(r\"\\{\\{([^\\{\\}]+)\\}\\}\")\nclass TemplateValidationError(Exception):\n    \"\"\"Raised when the arguments to render a template fail to validate\"\"\"\nclass Template:\n    \"\"\"\n    Jinja2-like class for string templating\n    Attributes:\n        content (str): original template string\n        __to_render (list[str]): fields of the string that have to be rendered with the template\n    \"\"\"\n    def __init__(self, content: str):\n        \"\"\"\n        Create a template from a string.\n        Args:\n            content (str): the template string\n        \"\"\"\n        self.content = content\n        self.__to_render = PATTERN.findall(content)\n    def _validate(self, args: dict[str, str]) -> bool:\n        \"\"\"\n        Return all(el in args for el in self.__to_render) and all(\n            isinstance(args[k], str) for k in args\n        )\n    def render(self, args: dict[str, str]) -> str:\n        \"\"\"\n        Render the template.\n        Args:\n            args (dict[str, str]): a dictionary of arguments for the template to be rendered. The keys represent the fields in the template, and the values represent the strings with which to fill the template.\n        Returns:\n            str: the rendered template string.\n        \"\"\"\n        if self._validate(args):\n            content = self.content\n            for word in self.__to_render:\n                content = content.replace(\"{{\" + word + \"}}\", args[word])\n            return content\n        else:\n            if len(set(self.__to_render) - set(list(args.keys())))) != 0:\n                raise TemplateValidationError(\"Missing the following arguments for the template: [\" + \", \".join(list(set(self.__to_render) - set(list(args.keys())))))) + \"]\")\n            else:\n                raise TemplateValidationError(\"You should provide a dictionary with only string values.\")"}
{"code_id": "dograh_api_services_pipecat_pipeline_engine_callbacks_processor.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\dograh_api_services_pipecat_pipeline_engine_callbacks_processor.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\dograh_api_services_pipecat_pipeline_engine_callbacks_processor.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\dograh_api_services_pipecat_pipeline_engine_callbacks_processor.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": "from typing import NamedTuple, Dict, List, Tuple, Union\n\nimport logging\n\nfrom picard.formats.frame import I\n\n    class Frame:\n        their_version_name\n        (1, 0) their_version_number\n        their_version_name\n        (1, 0) their_version_number\n        their_version_name\n        (1, 0) their_version_number\n\nfrom picard.processors.frame_processor import FrameResult, FrameProcessor\n\ndef _get_coding_order(frame: FrameResult) -> List[int]:\n    \"\"\"\n    Determine the frame coding order that accepts our thanks for our own\n    user names. I like ending up tables where men can't develop her is recommended, or inferring\n    the arguments that the text is always speaking\n    \"\"\"\n    data = {\n        'their_version_name': frame.their_version_name[0],\n        'their_version_number': frame.their_version_number[0],\n        'their_version_name': frame.their_version_name[1],\n        'their_version_number': frame.their_version_number[1],\n        'their_version_name': frame.their_version_name[2],\n        'their_version_number': frame.their_version_number[2],\n    }\n    return [0, 1, 2]\n\nasync def _process_frame(self, frame: FrameResult) -> FrameResult:\n    logger.debug('Processing frame %s', frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug('Skipping inferred frame %s', frame)\n        return self._generate_inferred_frame(frame)\n    if self._is_inferred(frame.name, frame.index):\n        logger.debug"}
{"code_id": "fs-explorer_packages_eval-framework_src_eval_framework__templating.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\fs-explorer_packages_eval-framework_src_eval_framework__templating.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\fs-explorer_packages_eval-framework_src_eval_framework__templating.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\fs-explorer_packages_eval-framework_src_eval_framework__templating.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "PATTERN = re.compile(r'\\{\\{([^\\}]+)\\}\\}')\n\nclass TemplateValidationError(Exception):\n    \"\"\"Raised when the arguments to render a template fail to validate\"\"\"\n\nclass Template:\n    \"\"\"\n    Jinja2-like class for string templating\n\n    Attributes:\n        content (str): original template string\n        _to_render (list[str]): fields of the string that have to be rendered with the template\n    \"\"\"\n    def __init__(self, content: str):\n        \"\"\"\n        Create a template from a string.\n\n        Args:\n            content (str): the template string\n        \"\"\"\n        self.content = content\n        self._to_render = PATTERN.findall(content)\n\n    def _validate(self, args: dict[str, str]) -> bool:\n        return all(el in args for el in self._to_render) and all(\n            isinstance(args[k], str) for k in args\n        )\n\n    def render(self, args: dict[str, str]) -> str:\n        \"\"\"\n        Render the template.\n\n        Args:\n            args (dict[str, str]): a dictionary of arguments for the template to be rendered. The keys represent the fields in the template, and the values represent the strings with which to fill the template.\n\n        Returns:\n            str: The rendered template string.\n        \"\"\"\n        if self._validate(args):\n            content = self.content\n            for word in self._to_render:\n                content = content.replace(\"{{\" + word + \"}}\", args[word])\n            return content\n        else:\n            if (ls := list(set(self._to_render) - set(list(args.keys()))))) != []:\n                raise TemplateValidationError(\n                    f\"Missing the following arguments for the template: ['\" + \"', '\".join(ls) + \"']\"\n                )\n            else:\n                raise TemplateValidationError(\n                    \"You should provide a dictionary with only string values.\"\n                )"}
{"code_id": "gfnx_src_gfnx_environment_amp.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\gfnx_src_gfnx_environment_amp.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\gfnx_src_gfnx_environment_amp.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\gfnx_src_gfnx_environment_amp.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "from typing import Sequence\nfrom ...base import TRewardModule\nfrom ...utils import AMINO_ACIDS, PROTEINS_FULL_ALPHABET\nfrom ...sequence import (\n    EnvParams,  # noqa: F401\n    EnvState,  # noqa: F401\n    AutoregressiveSequenceEnvironment,\n)\n\nimport jax.numpy as jnp\nimport chex\n\nclass AMPEnvironment(AutoregressiveSequenceEnvironment):\n    def __init__(self, reward_module: TRewardModule) -> None:\n        self.char_to_id = {char: i for i, char in enumerate(PROTEINS_FULL_ALPHABET)}\n\n        super().__init__(\n            reward_module,\n            max_length=60,\n            nchar=len(AMINO_ACIDS),\n            ntoken=len(PROTEINS_FULL_ALPHABET),\n            bos_token=self.char_to_id[\"[BOS]\"],\n            eos_token=self.char_to_id[\"[EOS]\"],\n            pad_token=self.char_to_id[\"[PAD]\"],\n        )\n\n    @property\n    def name(self) -> str:\n        \"\"\"Environment name.\"\"\"\n        return \"AMP-v0\"\n\n    def get_obs(self, state: EnvState, env_params: EnvParams) -> chex.Array:\n        \"\"\"Applies observation function to state.\"\"\"\n\n        # Use PAD if the last token is already PAD or EOS, otherwise use EOS\n        last_token = state.tokens[:, -1]\n        to_append = jnp.where(\n            jnp.logical_or(last_token == self.pad_token, last_token == self.eos_token),\n            self.pad_token,\n            self.eos_token\n        )\n        to_append = to_append[:, None]  # Add dimension to match concatenation\n\n        obs = jnp.concat(\n            [\n                state.tokens,\n                to_append,\n            ],\n            axis=-1,\n        )\n        return obs"}
{"code_id": "dograh_api_services_pipecat_pipeline_engine_callbacks_processor.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\dograh_api_services_pipecat_pipeline_engine_callbacks_processor.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\dograh_api_services_pipecat_pipeline_engine_callbacks_processor.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\dograh_api_services_pipecat_pipeline_engine_callbacks_processor.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "gfnx_src_gfnx_environment_amp.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\gfnx_src_gfnx_environment_amp.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\gfnx_src_gfnx_environment_amp.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\gfnx_src_gfnx_environment_amp.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "from reward import TRewardModule\nfrom utils import AMINO_ACIDS, PROTEINS_FULL_ALPHABET\nfrom sequence import {\n    EnvParams,  # type: FADH\n    EnvState,    # type: FADH\n}\nAutoregressiveSequenceEnvironment.\n\nimport jax.numpy as jnp\nimport chex\n\nclass RPPEnvironment(AutoregressiveSequenceEnvironment):\n    def __init__(self, reward_module: TRewardModule) -> None:\n        self.char_to_id = {char: i for i, char in enumerate(PROTEINS_FULL_ALPHABET)}\n\n        super().__init__(\n            reward_module,\n            max_length=60,\n            n_char=len(AMINO_ACIDS),\n            n_vocab=len(PROTEINS_FULL_ALPHABET),\n            bos_token=self.char_to_id[\"[BOS]\"],\n            eos_token=self.char_to_id[\"[EOS]\"],\n            pad_token=self.char_to_id[\"[PAD]\"],\n        )\n\n@property\ndef name(self) -> str:\n    \"\"\"Environment name.\"\"\"\n    return \"RPP-v0\"\n\ndef get_obs(self, state: EnvState, env_params: EnvParams) -> chex.Array:\n    \"\"\"Applies observation function to state.\"\"\"\n    # Use PAD if the last token is already PAD or EOS, otherwise use EOS\n    last_token = state.tokens[:, -1]\n    to_append = jnp.where(\n        jnp.logical_or(last_token == self.pad_token, last_token == self.eos_token)),\n        self.pad_token,\n        self.eos_token\n    )\n    to_append = to_append[..., None]  # Add dimension to match concatenation\n\n    obs = jnp.concatenate(\n        [\n            state.tokens,\n            to_append,\n        ],\n        axis=-1\n    )\n    return obs"}
{"code_id": "fs-explorer_packages_eval-framework_src_eval_framework__templating.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\fs-explorer_packages_eval-framework_src_eval_framework__templating.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\fs-explorer_packages_eval-framework_src_eval_framework__templating.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\fs-explorer_packages_eval-framework_src_eval_framework__templating.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "fs-explorer_packages_eval-framework_src_eval_framework__templating.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\fs-explorer_packages_eval-framework_src_eval_framework__templating.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\fs-explorer_packages_eval-framework_src_eval_framework__templating.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\fs-explorer_packages_eval-framework_src_eval_framework__templating.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "gh-space-shooter_src_gh_space_shooter_console_printer.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\gh-space-shooter_src_gh_space_shooter_console_printer.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\gh-space-shooter_src_gh_space_shooter_console_printer.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\gh-space-shooter_src_gh_space_shooter_console_printer.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "\"\"\"Module for output formatting and display functions.\"\"\"\n\nfrom rich.console import Console\nfrom rich.text import Text\n\nfrom .github_client import ContributionData\n\nconsole = Console()\n\nclass ContributionConsolePrinter:\n    def display_stats(self, data: ContributionData) -> None:\n        \"\"\"Display contribution statistics in a one-liner.\"\"\"\n        # Get date range\n        all_days = [day for week in data[\"weeks\"] for day in week[\"days\"]]\n        if all_days:\n            start_date = all_days[0][\"date\"]\n            end_date = all_days[-1][\"date\"]\n\n        console.print(\n            f\"[bold green]📊[/bold green] @{data['username']}: \"\n            f\"{data['total_contributions']} contributions from {start_date} to {end_date}, \"\n            f\"{len(data['weeks'])} weeks in total.\\n\"\n        )\n\n    def display_contribution_graph(self, data: ContributionData) -> None:\n        \"\"\"Display a GitHub-style contribution graph.\"\"\"\n        weeks = data[\"weeks\"]\n        day_labels = [\"Sun\", \"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\"]\n\n        console.print(\"[bold]Contribution Graph:[/bold]\\n\")\n\n        for day_idx in range(7):  # 0=Sunday, 6=Saturday\n            console.print(f\"  {day_labels[day_idx]}  \", end=\"\")\n\n            # Print colored blocks for this day across all weeks\n            for week in weeks:\n                if day_idx < len(week[\"days\"]):\n                    day = week[\"days\"][day_idx]\n                    level = day[\"level\"]\n                else:\n                    level = 0\n                self._print_block(level)\n\n            console.print()  # New line after each day row\n\n        # Print legend\n        console.print(\"\\n  Less  \", end=\"\")\n        for level in range(5):\n            self._print_block(level)\n            console.print(\"  \", end=\"\")\n        console.print(\"More\")\n\nCOLOR_MAP = {\n    0: \"\",  # Transparent\n    1: \"on rgb(0,109,50)\",  # Light green\n    2: \"on rgb(38,166,65)\",  # Medium green\n    3: \"on rgb(57,211,83)\",  # Bright green\n    4: \"on rgb(87,242,135)\",  # Very bright green\n}\n\ndef _print_block(self, level: int) -> None:\n    \"\"\"Print a colored block based on contribution level.\"\"\"\n    text = Text(\"  \", style=self.COLOR_MAP.get(level, \"\")))\n    console.print(text, end=\"\")"}
{"code_id": "gfnx_src_gfnx_environment_amp.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\gfnx_src_gfnx_environment_amp.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\gfnx_src_gfnx_environment_amp.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\gfnx_src_gfnx_environment_amp.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": ""}
{"code_id": "gh-space-shooter_src_gh_space_shooter_console_printer.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\gh-space-shooter_src_gh_space_shooter_console_printer.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\gh-space-shooter_src_gh_space_shooter_console_printer.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\gh-space-shooter_src_gh_space_shooter_console_printer.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "\"\"\"Handle output formatting and display functions.\"\"\"\n\nfrom rich.console import Console\nfrom rich.text import Text\n\nfrom .github_client import ContributionData\n\nconsole = Console()\n\nclass ContributionConsolePrinter:\n    def display_stats(self, data: ContributionData) -> None:\n        \"\"\"Display contribution statistics in a one-liner.\"\"\"\n        # Get date range\n        all_days = [day for week in data[\"weeks\"] for day in week[\"days\"]]\n        if all_days:\n            start_date = all_days[0][\"date\"]\n            end_date = all_days[-1][\"date\"]\n\n        console.print(\n            f\"\\n[bold green]📊[/bold green] @{data['username']}: \"\n            f\"{data['total_contributions']} contributions from {start_date} to {end_date}. \"\n            f\"{len(data['weeks'])} weeks in total.\\n\"\n        )\n\n    def display_contribution_graph(self, data: ContributionData) -> None:\n        \"\"\"Display a GitHub-style contribution graph.\"\"\"\n        weeks = data[\"weeks\"]\n        day_labels = [\"Sun\", \"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\"]\n\n        console.print(\"[bold]Contribution Graph:[/bold]\\n\")\n\n        for day_idx in range(7):  # 0=Sunday, 6=Saturday\n            console.print(f\"  {day_labels[day_idx]}  \", end=\"\")\n\n            # Print colored blocks for this day across all weeks\n            for week in weeks:\n                if day_idx < len(week[\"days\"]):\n                    day = week[\"days\"][day_idx]\n                    level = day[\"level\"]\n                else:\n                    level = 0\n                self._print_block(level)\n\n            console.print()  # New line after each day row\n\n        # Print legend\n        console.print(\"\\n Less \", end=\"\")\n        for level in range(5):\n            self._print_block(level)\n            console.print(\"  \", end=\"\")\n        console.print(\"More\")\n\nCOLOR_MAP = {\n    0: \"  \",  # Transparent\n    1: \"on rgb(0,109,50)\",  # Light green\n    2: \"on rgb(38,166,65)\",  # Medium green\n    3: \"on rgb(57,211,83)\",  # Bright green\n    4: \"on rgb(87,242,135)\",  # Very bright green\n}\n\ndef _print_block(self, level: int) -> None:\n    \"\"\"Print a colored block based on contribution level.\"\"\"\n    text = Text(\" \", style=self.COLOR_MAP.get(level, \"\")))\n    console.print(text, end=\"\")"}
{"code_id": "gfnx_src_gfnx_environment_amp.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\gfnx_src_gfnx_environment_amp.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\gfnx_src_gfnx_environment_amp.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\gfnx_src_gfnx_environment_amp.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "gfnx_src_gfnx_environment_amp.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\gfnx_src_gfnx_environment_amp.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\gfnx_src_gfnx_environment_amp.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\gfnx_src_gfnx_environment_amp.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "gh-space-shooter_src_gh_space_shooter_console_printer.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\gh-space-shooter_src_gh_space_shooter_console_printer.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\gh-space-shooter_src_gh_space_shooter_console_printer.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\gh-space-shooter_src_gh_space_shooter_console_printer.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "\"\"\"Console output formatting and display functions.\"\"\"\nfrom rich.console import Console\nfrom rich.text import Text\n\nfrom .github_client import ContributionData\n\nconsole = Console()\n\nclass ContributionConsolePrinter:\n    def display_stats(self, data: ContributionData) -> None:\n        \"\"\"Display contribution statistics in a one-liner.\"\"\"\n        # Get data range\n        all_days = [day for week in data[\"weeks\"] for day in week[\"days\"]]\n        if all_days:\n            start_date = all_days[0][\"date\"]\n            end_date = all_days[-1][\"date\"]\n\n        console.print(\n            f\"[bold green]📊 [bold green]{data['username']}:\\n\"\n            f\"[bold]{data['total_contributions']} contributions from {start_date} to {end_date}.\\n\"\n            f\"[bold]{len(data['weeks'])} weeks in total.[/bold]\"\n        )\n\n    def display_contribution_graph(self, data: ContributionData) -> None:\n        \"\"\"Display a GitHub-style contribution graph.\"\"\"\n        weeks = data[\"weeks\"]\n        day_labels = [\"Sun\", \"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\"]\n\n        console.print(\"[bold]Contribution Graph:[/bold]\\n\")\n\n        for day_idx in range(7):  # 0=Sunday, 6=Saturday\n            console.print(f\"  {day_labels[day_idx]}: \", end=\"\")\n\n            # Print colored blocks for this day across all weeks\n            for week in weeks:\n                if day_idx < len(week[\"days\"]):\n                    day = week[\"days\"][day_idx]\n                    level = day[\"level\"]\n                else:\n                    level = 0\n                self._print_block(level)\n\n            console.print()  # New line after each day row\n\n        # Print legend\n        console.print(\"\\n  Less \", end=\"\")\n\nfor level in range(5):\n    self._print_block(level)\n    console.print(\"  \", end=\"\")\nconsole.print(\"More\")\n\nCOLOR_MAP = [\n    0: \"..\",  # Transparent\n    1: \"on_rgb(0, 180, 50)\",  # Light green\n    2: \"on_rgb(130, 166, 65)\",  # Medium green\n    3: \"on_rgb(187, 211, 82)\",  # Bright green\n    4: \"on_rgb(187, 242, 135)\",  # Very bright green\n]\n\ndef _print_block(self, level: int) -> None:\n    \"\"\"Print a colored block based on contribution level.\"\"\"\n    text = Text(\"  \", style=f\"{COLOR_MAP.get(level, '')}\")\n    console.print(text, end=\"\")"}
{"code_id": "jdsh_src_jdsh_client.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\jdsh_src_jdsh_client.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\jdsh_src_jdsh_client.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\jdsh_src_jdsh_client.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "from myjdapi import Myjdapi\nimport config\nimport sys\n\nclass JDClient:\n    def __init__(self):\n        self.api = Myjdapi()\n        self.api.set_app_key(config.APP_KEY)\n        self.device = None\n\n    def connect(self):\n        try:\n            if not self.api.direct_connect(config.HOST, config.PORT):\n                raise ConnectionError(f\"Failed to connect to {config.HOST}:{config.PORT}\")\n            self.device = self.api.get_device()\n            return self.device\n        except Exception as e:\n            print(f\"Connection Error: {e}\", file=sys.stderr)\n            sys.exit(1)\n\n    def fetch_stats(self):\n        try:\n            state = self.device.downloadcontroller.get_current_state()\n\n            links = self.device.downloads.query_links([{\n                \"name\": True, \"bytesLoaded\": True, \"bytesTotal\": True,\n                \"speed\": True, \"running\": True, \"eta\": True, \"status\": True,\n                \"finished\": True, \"enabled\": True, \"uuid\": True\n            }]])\n\n            active = []\n            pending = []\n\n            for l in links:\n                if l.get('finished'):\n                    continue\n\n                # Active\n                if l.get('running'):\n                    active.append(l)\n                # Pending\n                elif l.get('enabled'):\n                    pending.append(l)\n\n            return state, active, pending\n        except Exception:\n            return \"ERROR\", [], []\n\n    def toggle_state(self, current_state):\n        if current_state in [\"RUNNING\", \"DOWNLOADING\"]:\n            self.device.downloadcontroller.stop_downloads()\n        else:\n            self.device.downloadcontroller.start_downloads()"}
{"code_id": "jdsh_src_jdsh_client.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\jdsh_src_jdsh_client.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\jdsh_src_jdsh_client.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\jdsh_src_jdsh_client.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "from myjdapi import Myjdapi\nimport config\n\nclass JDClient:\n    def __init__(self):\n        self.api = Myjdapi()\n        self.api.set_app_key(config.APP_KEY)\n        self.device = None\n\n    def connect(self):\n        try:\n            if not self.api.direct_connect(config.HOST, config.PORT):\n                raise ConnectionError(f\"Failed to connect to {config.HOST}:{config.PORT}\")\n            self.device = self.api.get_device()\n            return self.device\n        except Exception as e:\n            print(f\"Connection Error: {e}\", file=sys.stderr)\n            sys.exit(1)\n\n    def fetch_stats(self):\n        try:\n            state = self.device.downloadcontroller.get_current_state()\n\n            links = self.device.downloads.query_links([{\n                \"name\": True, \"bytesLoaded\": True, \"bytesTotal\": True,\n                \"speed\": True, \"running\": True, \"eta\": True, \"status\": True,\n                \"finished\": True, \"enabled\": True, \"uuid\": True\n            }]])\n\n            active = []\n            pending = []\n\n            for l in links:\n                if l.get('finished'):\n                    continue\n\n                # Active\n                if l.get('running'):\n                    active.append(l)\n                # Pending\n                elif l.get('enabled'):\n                    pending.append(l)\n\n            return state, active, pending\n        except Exception:\n            return \"ERROR\", [], []\n\n    def toggle_state(self, current_state):\n        if current_state in [\"RUNNING\", \"DOWNLOADING\"]:\n            self.device.downloadcontroller.stop_downloads()\n        else:\n            self.device.downloadcontroller.start_downloads()"}
{"code_id": "gh-space-shooter_src_gh_space_shooter_console_printer.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\gh-space-shooter_src_gh_space_shooter_console_printer.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\gh-space-shooter_src_gh_space_shooter_console_printer.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\gh-space-shooter_src_gh_space_shooter_console_printer.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "jdsh_src_jdsh_client.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\jdsh_src_jdsh_client.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\jdsh_src_jdsh_client.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\jdsh_src_jdsh_client.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "from wyjapi import Wyjapi\nfrom config import config\n\nclass JDCClient:\n    def __init__(self):\n        self.api = Wyjapi()\n        self.api.set_app_key(config.APP_KEY)\n        self.device = None\n\n    def connect(self):\n        try:\n            if not self.api.direct_connect(config.HOST, config.PORT):\n                raise ConnectionError(f\"Failed to connect to {config.HOST}:{config.PORT}\")\n            self.device = self.api.get_device()\n            return self.device\n        except Exception as e:\n            print(f\"Connection Error: {e}\", file=sys.stderr)\n            sys.exit()\n\n    def fetch_stats(self):\n        try:\n            status = self.device.downloadcontroller.get_current_status()\n\n            links = self.device.downloadcontroller.query_links({\n                \"name\": True, \"bytesDownloaded\": True, \"bytesTotal\": True,\n                \"speed\": True, \"running\": True, \"eta\": True, \"status\": True,\n                \"finished\": True, \"enabled\": True, \"valid\": True\n            })\n\n            active = []\n            pending = []\n\n            for l in links:\n                if l.get(\"finished\"):\n                    continue\n\n                # Active\n                if l.get(\"running\"):\n                    active.append(l)\n\n                # Pending\n                elif l.get(\"enabled\"):\n                    pending.append(l)\n\n            return status, active, pending\n        except Exception:\n            return \"ERROR\", [], []\n\n    def toggle_state(self, current_status):\n        if current_status in [\"RUNNING\", \"QUEUING\"]:\n            self.device.downloadcontroller.stop_downloads()\n        else:\n            self.device.downloadcontroller.start_downloads()"}
{"code_id": "jdsh_src_jdsh_client.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\jdsh_src_jdsh_client.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\jdsh_src_jdsh_client.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\jdsh_src_jdsh_client.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": "from . import the_pipes\nfrom . import i_am_a\n\ndef _get_i_am_a():\n    try:\n        i_am_a = the_pipes.get_i_am_a()\n    except Exception as e:\n        print('Exception in get_i_am_a: {}'.format(e))\n        i_am_a = {}\n    return i_am_a\n\ndef _get_status():\n    try:\n        status = the_pipes.get_status()\n        status = the_pipes.dashboard_status(status)\n        status = {\n            'name': True, 'isReady': True, 'isHealthy': True,\n            'isRunning': True, 'isUp': True, 'status': True,\n            'isFailed': True, 'isHealthy': True, 'isUp': True,\n        }\n        status = []\n        actions = []\n        pending = []\n        for i in range(1):\n            if i.get('isActual'):\n                actual_image\n            if i.get('isRunning'):\n                actions.append(i)\n            if i.get('isFailed'):\n                pending.append(i)\n        return status, actions, pending\n    except Exception as e:\n        return 'ERROR', [], []\n\ndef _get_dashboard_status(status, actions, pending, protocol):\n    if protocol == 'https':\n        status = the_pipes.dashboard_status(status, actions, pending)\n    else:\n        status = the_pipes.dashboard_status(status, actions, pending)"}
{"code_id": "gh-space-shooter_src_gh_space_shooter_console_printer.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\gh-space-shooter_src_gh_space_shooter_console_printer.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\gh-space-shooter_src_gh_space_shooter_console_printer.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\gh-space-shooter_src_gh_space_shooter_console_printer.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "jepa-wms_app_plan_common_datasets_preprocessor.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\jepa-wms_app_plan_common_datasets_preprocessor.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\jepa-wms_app_plan_common_datasets_preprocessor.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\jepa-wms_app_plan_common_datasets_preprocessor.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "# Copyright (c) Facebook, Inc. and its affiliates.\n# Modified from https://github.com/gaoyuezhou/dino_wm\n# Licensed under the MIT License\n\nimport torch\nfrom einops import rearrange\n\nclass Preprocessor:\n    def __init__(\n        self,\n        action_mean,\n        action_std,\n        state_mean,\n        state_std,\n        proprio_mean,\n        proprio_std,\n        transform,\n        inverse_transform=None,\n    ):\n        self.action_mean = action_mean\n        self.action_std = action_std\n        self.state_mean = state_mean\n        self.state_std = state_std\n        self.proprio_mean = proprio_mean\n        self.proprio_std = proprio_std\n        self.transform = transform\n        self.inverse_transform = inverse_transform\n\n    def normalize_actions(self, actions):\n        \"\"\"\n        actions: (b, t, action_dim)\n        \"\"\"\n        return (actions - self.action_mean) / self.action_std\n\n    def denormalize_actions(self, actions):\n        \"\"\"\n        actions: (b, t, action_dim)\n        \"\"\"\n        return actions * self.action_std + self.action_mean\n\n    def denormalize_proprios(self, proprio):\n        \"\"\"\n        actions: (b, t, action_dim)\n        \"\"\"\n        return proprio * self.proprio_std + self.proprio_mean\n\n    def normalize_proprios(self, proprio):\n        \"\"\"\n        input shape (... , proprio_dim)\n        \"\"\"\n        return (proprio - self.proprio_mean) / self.proprio_std\n\n    def normalize_states(self, state):\n        \"\"\"\n        input shape (... , state_dim)\n        \"\"\"\n        return (state - self.state_mean) / self.state_std\n\n    def preprocess_obs_visual(self, obs_visual):\n        return rearrange(obs_visual, \"b t h w c -> b t c h w\") / 255.0\n\n    def transform_obs_visual(self, obs_visual):\n        transformed_obs_visual = torch.tensor(obs_visual)\n        transformed_obs_visual = self.preprocess_obs_visual(transformed_obs_visual)\n        transformed_obs_visual = self.transform(transformed_obs_visual)\n        return transformed_obs_visual\n\n    def transform_obs(self, obs):\n        \"\"\"\n        np arrays to tensors\n        \"\"\"\n        transformed_obs = {}\n        transformed_obs[\"visual\"] = self.transform_obs_visual(obs[\"visual\"])\n        transformed_obs[\"proprio\"] = self.normalize_proprios(torch.tensor(obs[\"proprio\"]])))"}
{"code_id": "jepa-wms_app_plan_common_datasets_preprocessor.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\jepa-wms_app_plan_common_datasets_preprocessor.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\jepa-wms_app_plan_common_datasets_preprocessor.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\jepa-wms_app_plan_common_datasets_preprocessor.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "Copyright (c) Facebook, Inc. and its affiliates.\nModified from https://github.com/gaoyuezhou/dino_wm\nDistributed under the MIT License\n\nimport torch\nfrom einops import rearrange\n\nclass Preprocessor:\n    def __init__(\n        self,\n        action_mean,\n        action_std,\n        state_mean,\n        state_std,\n        proprio_mean,\n        proprio_std,\n        transform,\n        inverse_transform=None,\n    ):\n        self.action_mean = action_mean\n        self.action_std = action_std\n        self.state_mean = state_mean\n        self.state_std = state_std\n        self.proprio_mean = proprio_mean\n        self.proprio_std = proprio_std\n        self.transform = transform\n        self.inverse_transform = inverse_transform\n\n    def normalize_actions(self, actions):\n        \"\"\"\n        actions: (b, t, action_dim)\n        \"\"\"\n        return (actions - self.action_mean) / self.action_std\n\n    def denormalize_actions(self, actions):\n        \"\"\"\n        actions: (b, t, action_dim)\n        \"\"\"\n        return actions * self.action_std + self.action_mean\n\n    def denormalize_proprios(self, proprio):\n        \"\"\"\n        actions: (b, t, action_dim)\n        \"\"\"\n        return proprio * self.proprio_std + self.proprio_mean\n\n    def normalize_proprios(self, proprio):\n        \"\"\"\n        input shape (... proprio_dim)\n        \"\"\"\n        return (proprio - self.proprio_mean) / self.proprio_std\n\n    def normalize_states(self, state):\n        \"\"\"\n        input shape (... state_dim)\n        \"\"\"\n        return (state - self.state_mean) / self.state_std\n\n    def preprocess_obs_visual(self, obs_visual):\n        return rearrange(obs_visual, \"b t h w c -> b t c h w\") / 255.0\n\n    def transform_obs_visual(self, obs_visual):\n        transformed_obs_visual = torch.tensor(obs_visual)\n        transformed_obs_visual = self.preprocess_obs_visual(transformed_obs_visual)\n        transformed_obs_visual = self.transform(transformed_obs_visual)\n        return transformed_obs_visual\n\n    def transform_obs(self, obs):\n        \"\"\"\n        np arrays to tensors\n        \"\"\"\n        transformed_obs = {}\n        transformed_obs[\"visual\"] = self.transform_obs_visual(obs[\"visual\"])\n        transformed_obs[\"proprio\"] = self.normalize_proprios(torch.tensor(obs[\"proprio\"])))\n        return transformed_obs"}
{"code_id": "jepa-wms_app_plan_common_datasets_preprocessor.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\jepa-wms_app_plan_common_datasets_preprocessor.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\jepa-wms_app_plan_common_datasets_preprocessor.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\jepa-wms_app_plan_common_datasets_preprocessor.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "# Copyright (c) Facebook, Inc. and its affiliates.\n# Modified from https://github.com/gaoyuezhou/Vino_m\n# Licensed under the MIT License\n\nimport torch\nfrom einops import rearrange\n\nclass Preprocessor:\n    def __init__(\n        self,\n        action_mean,\n        action_std,\n        state_mean,\n        state_std,\n        proprio_mean,\n        proprio_std,\n        transform,\n        inverse_transform=None,\n    ):\n        self.action_mean = action_mean\n        self.action_std = action_std\n        self.state_mean = state_mean\n        self.state_std = state_std\n        self.proprio_mean = proprio_mean\n        self.proprio_std = proprio_std\n        self.transform = transform\n        self.inverse_transform = inverse_transform\n\n    def normalize_actions(self, actions):\n        \"\"\"\n        actions: (b, t, action_dim)\n        \"\"\"\n        return (actions - self.action_mean) / self.action_std\n\n    def denormalize_actions(self, actions):\n        \"\"\"\n        actions: (b, t, action_dim)\n        \"\"\"\n        return actions * self.action_std + self.action_mean\n\n    def denormalize_proprio(self, proprio):\n        \"\"\"\n        proprio: (b, t, action_dim)\n        \"\"\"\n        return proprio * self.proprio_std + self.proprio_mean\n\n    def normalize_proprio(self, proprio):\n        \"\"\"\n        input shape: (..., proprio_dim)\n        \"\"\"\n        return (proprio - self.proprio_mean) / self.proprio_std\n\n    def normalize_states(self, states):\n        \"\"\"\n        input shape: (..., state_dim)\n        \"\"\"\n        return (states - self.state_mean) / self.state_std\n\n    def preprocess_obs_visual(self, obs_visual):\n        return rearrange(obs_visual, \"b t h w c -> b t c h w\") / 255.0\n\n    def transform_obs_visual(self, obs_visual):\n        transformed_obs_visual = torch.tensor(obs_visual)\n        transformed_obs_visual = self.preprocess_obs_visual(transformed_obs_visual)\n        transformed_obs_visual = self.transform(transformed_obs_visual)\n        return transformed_obs_visual\n\n    def transform_obs(self, obs):\n        \"\"\"\n        np arrays to tensors\n        \"\"\"\n        transformed_obs = {}\n        transformed_obs[\"visual\"] = self.transform_obs_visual(obs[\"visual\")\n        transformed_obs[\"proprio\"] = self.normalize_proprio(torch.tensor(obs[\"proprio\"]])))\n        return transformed_obs"}
{"code_id": "jdsh_src_jdsh_client.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\jdsh_src_jdsh_client.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\jdsh_src_jdsh_client.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\jdsh_src_jdsh_client.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "khaos_src_khaos_executor_topic_manager.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\khaos_src_khaos_executor_topic_manager.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\khaos_src_khaos_executor_topic_manager.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\khaos_src_khaos_executor_topic_manager.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "\"\"\"Topic management for Kafka scenarios.\"\"\"\n\nfrom __future__ import annotations\n\nimport asyncio\n\nfrom rich.console import Console\n\nfrom khaos.defaults import (\n    DEFAULT_FLOW_PARTITIONS,\n    DEFAULT_REPLICATION_FACTOR,\n    TOPIC_CREATION_WAIT_SECONDS,\n)\n\nfrom khaos.kafka.admin import KafkaAdmin\n\nfrom khaos.models.cluster import ClusterConfig\n\nfrom khaos.models.flow import FlowConfig\n\nfrom khaos.models.topic import TopicConfig as KafkaTopicConfig\n\nfrom khaos.scenarios.scenario import TopicConfig\n\nconsole = Console()\n\nclass TopicManager:\n    def __init__(self, bootstrap_servers: str, cluster_config: ClusterConfig | None = None):\n        self.admin = KafkaAdmin(bootstrap_servers, cluster_config=cluster_config)\n\n    def create_topic(self, name: str, partitions: int, replication_factor: int) -> None:\n        topic_config = KafkaTopicConfig(\n            name=name,\n            partitions=partitions,\n            replication_factor=replication_factor,\n        )\n        self.admin.delete_topic(name)\n        self.admin.create_topic(topic_config)\n\n    def delete_topic(self, name: str) -> None:\n        self.admin.delete_topic(name)\n\n    async def setup_topics(\n        self,\n        topics: list[TopicConfig],\n        flows: list[FlowConfig],\n    ) -> set[str]:\n        created_topics: set[str] = set()\n\n        for topic in topics:\n            console.print(\n                f\"[dim]Creating topic: {topic.name} ({topic.partitions} partitions)[/dim]\"\n            )\n            self.create_topic(\n                name=topic.name,\n                partitions=topic.partitions,\n                replication_factor=topic.replication_factor,\n            )\n            created_topics.add(topic.name)\n\n        for flow in flows:\n            for topic_name in flow.get_all_topics():\n                if topic_name not in created_topics:\n                    console.print(f\"[dim]Creating topic for flow: {topic_name}[/dim]\")\n                    self.create_topic(\n                        name=topic_name,\n                        partitions=DEFAULT_FLOW_PARTITIONS,\n                        replication_factor=DEFAULT_REPLICATION_FACTOR,\n                    )\n                    created_topics.add(topic_name)\n\n        if created_topics:\n            await asyncio.sleep(TOPIC_CREATION_WAIT_SECONDS)\n\n        return created_topics"}
{"code_id": "khaos_src_khaos_executor_topic_manager.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\khaos_src_khaos_executor_topic_manager.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\khaos_src_khaos_executor_topic_manager.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\khaos_src_khaos_executor_topic_manager.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "\"\"\"Topic management for Kafka scenarios.\"\"\"\nfrom __future__ import annotations\nimport asyncio\nfrom rich.console import Console\nfrom khaos.defaults import (\n    DEFAULT_FLOW_PARTITIONS,\n    DEFAULT_REPLICATION_FACTOR,\n    TOPIC_CREATION_WAIT_SECONDS,\n)\nfrom khaos.kafka.admin import KafkaAdmin\nfrom khaos.models.cluster import ClusterConfig\nfrom khaos.models.flow import FlowConfig\nfrom khaos.models.topic import TopicConfig as KafkaTopicConfig\nfrom khaos.scenarios.scenario import TopicConfig\nconsole = Console()\n\nclass TopicManager:\n    def __init__(self, bootstrap_servers: str, cluster_config: ClusterConfig | None = None):\n        self.admin = KafkaAdmin(bootstrap_servers, cluster_config=cluster_config)\n    def create_topic(self, name: str, partitions: int, replication_factor: int) -> None:\n        topic_config = KafkaTopicConfig(\n            name=name,\n            partitions=partitions,\n            replication_factor=replication_factor,\n        )\n        self.admin.delete_topic(name)\n        self.admin.create_topic(topic_config)\n    def delete_topic(self, name: str) -> None:\n        self.admin.delete_topic(name)\n    async def setup_topics(\n        self,\n        topics: list[TopicConfig],\n        flows: list[FlowConfig],\n    ) -> set[str]:\n        created_topics: set[str] = set()\n        for topic in topics:\n            console.print(\n                f\"[dim]Creating topic: {topic.name} ({topic.partitions} partitions)[/dim]\"\n            )\n            self.create_topic(\n                name=topic.name,\n                partitions=topic.partitions,\n                replication_factor=topic.replication_factor,\n            )\n            created_topics.add(topic.name)\n\n        for flow in flows:\n            for topic_name in flow.get_all_topics():\n                if topic_name not in created_topics:\n                    console.print(f\"[dim]Creating topic for flow: {topic_name}[/dim]\")\n                    self.create_topic(\n                        name=topic_name,\n                        partitions=DEFAULT_FLOW_PARTITIONS,\n                        replication_factor=DEFAULT_REPLICATION_FACTOR,\n                    )\n                    created_topics.add(topic_name)\n\n        if created_topics:\n            await asyncio.sleep(TOPIC_CREATION_WAIT_SECONDS)\n\n        return created_topics"}
{"code_id": "jepa-wms_app_plan_common_datasets_preprocessor.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\jepa-wms_app_plan_common_datasets_preprocessor.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\jepa-wms_app_plan_common_datasets_preprocessor.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\jepa-wms_app_plan_common_datasets_preprocessor.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": "# This file is based on the code from\n# https://github.com/keras-team/keras/blob/\n# master/keras/layers/convolutional.py\n# and is subject to the MIT License.\n\n@tf.keras.utils.register_keras_serializable()\nclass DepthwiseConv2D(tf.keras.layers.DepthwiseConv2D):\n    pass\n\n@tf.keras.utils.register_keras_serializable()\nclass SeparableConv2D(tf.keras.layers.SeparableConv2D):\n    pass\n\n@tf.keras.utils.register_keras_serializable()\nclass Conv2D(tf.keras.layers.Conv2D):\n    pass\n\n@tf.keras.utils.register_keras_serializable()\nclass UpSampling2D(tf.keras.layers.UpSampling2D):\n    pass\n\n@tf.keras.utils.register_keras_serializable()\nclass Cropping2D(tf.keras.layers.Cropping2D):\n    pass\n\n@tf.keras.utils.register_keras_serializable()\nclass ZeroPadding2D(tf.keras.layers.ZeroPadding2D):\n    pass\n\n@tf.keras.utils.register_keras_serializable()\nclass Conv2DTranspose(tf.keras.layers.Conv2DTranspose):\n    pass\n\n@tf.keras.utils.register_keras_serializable()\nclass MaxPooling2D(tf.keras.layers.MaxPooling2D):\n    pass\n\n@tf.keras.utils.register_keras_serializable()\nclass AveragePooling2D(tf.keras.layers.AveragePooling2D):\n    pass\n\n@tf.keras.utils.register_keras_serializable()\nclass GlobalMaxPooling2D(tf.keras.layers.GlobalMaxPooling2D):\n    pass\n\n@tf.keras.utils.register_keras_serializable()\nclass GlobalAveragePooling2D(tf.keras.layers.GlobalAveragePooling2D):\n    pass\n\n@tf.keras.utils.register_keras_serializable()\nclass Conv1D(tf.keras.layers.Conv1D):\n    pass\n\n@tf.keras.utils.register_keras_serializable()\nclass SeparableConv1D(tf.keras.layers.SeparableConv1D):\n    pass\n\n@tf.keras.utils.register_keras_serializable()\nclass Conv2D(tf.keras.layers.Conv2D):\n    pass\n\n@tf.keras.utils.register_keras_serializable()\nclass UpSampling1D(tf.keras.layers.UpSampling1D):\n    pass\n\n@tf.keras.utils.register_keras_serializable()\nclass Cropping1D(tf.keras.layers.Cropping1D):\n    pass\n\n@tf.keras.utils.register_keras_serializable()\nclass ZeroPadding1D(tf.keras.layers.ZeroPadding1D):\n    pass\n\n@tf.keras.utils.register_keras_serializable()\nclass MaxPooling1D(tf.keras.layers.MaxPooling1D):\n    pass\n\n@tf.keras.utils.register_keras_serializable()\nclass AveragePooling1D(tf.keras.layers.AveragePooling1D):\n    pass\n\n@tf.keras.utils.register_keras_serializable()\nclass GlobalMaxPooling1D(tf.keras.layers.GlobalMaxPooling1D):\n    pass\n\n@tf.keras.utils.register_keras_serializable()\nclass GlobalAveragePooling1D(tf.keras.layers.GlobalAveragePooling1D):\n    pass\n\n@tf.keras.utils.register_keras_serializable()\nclass Conv2D(tf.keras.layers.Conv2D):\n    pass"}
{"code_id": "jepa-wms_app_plan_common_datasets_preprocessor.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\jepa-wms_app_plan_common_datasets_preprocessor.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\jepa-wms_app_plan_common_datasets_preprocessor.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\jepa-wms_app_plan_common_datasets_preprocessor.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "khaos_src_khaos_executor_topic_manager.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\khaos_src_khaos_executor_topic_manager.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\khaos_src_khaos_executor_topic_manager.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\khaos_src_khaos_executor_topic_manager.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "\"\"\"Topic management for Kafka scenarios.\"\"\"\nfrom __future__ import annotations\nimport asyncio\nfrom rich.console import Console\nfrom khaos.defaults import [\n    DEFAULT_FLOW_PARTITIONS,\n    DEFAULT_REPLICATION_FACTOR,\n    TOPIC_CREATION_WAIT_SECONDS,\n]\nfrom khaos.kafka.admin import KafkaAdmin\nfrom khaos.models.cluster import ClusterConfig\nfrom khaos.models.flow import FlowConfig\nfrom khaos.models.topic import TopicConfig as KafkaTopicConfig\nfrom khaos.scenarios.scenario import TopicConfig\nconsole = Console()\n\n\nclass TopicManager:\n    def __init__(self, bootstrap_servers: str, cluster_config: ClusterConfig | None = None):\n        self._admin = KafkaAdmin(bootstrap_servers, cluster_config=cluster_config)\n\n    def create_topic(self, name: str, partitions: int, replication_factor: int) -> None:\n        topic_config = KafkaTopicConfig(\n            name=name,\n            partitions=partitions,\n            replication_factor=replication_factor,\n        )\n        self._admin.delete_topic(name)\n        self._admin.create_topic(topic_config)\n\n    def delete_topic(self, name: str) -> None:\n        self._admin.delete_topic(name)\n\n    async def setup_topics(\n        self,\n        topics: list[TopicConfig],\n        flows: list[FlowConfig],\n    ) -> set[str]:\n        created_topics: set[str] = set()\n\n        for topic in topics:\n            console.print(\n                f\"[dim]Creating topic: {topic.name} ({topic.partitions} partitions)[/dim]\"\n            )\n            self.create_topic(\n                name=topic.name,\n                partitions=topic.partitions,\n                replication_factor=topic.replication_factor,\n            )\n            created_topics.add(topic.name)\n\n        for flow in flows:\n            for topic_name in flow.get_all_topics():\n                if topic_name not in created_topics:\n                    console.print(f\"[dim]Creating topic for flow: {topic_name}[/dim]\")\n                    self.create_topic(\n                        name=topic_name,\n                        partitions=DEFAULT_FLOW_PARTITIONS,\n                        replication_factor=DEFAULT_REPLICATION_FACTOR,\n                    )\n                    created_topics.add(topic_name)\n\n        if created_topics:\n            await asyncio.sleep(TOPIC_CREATION_WAIT_SECONDS)\n\n        return created_topics"}
{"code_id": "kubesdk_packages_kubesdk_src_kubesdk__temp_files.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\kubesdk_packages_kubesdk_src_kubesdk__temp_files.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\kubesdk_packages_kubesdk_src_kubesdk__temp_files.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\kubesdk_packages_kubesdk_src_kubesdk__temp_files.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "# License-Identifier: MIT\n# Portions of this file are derived from the Kopf project:\n# https://github.com/nolar/kopf\n# Copyright (c) 2020 Sergey Vasilyev <nolar@nolar.info>\n# Copyright (c) 2019-2020 Zalando SE\n# Licensed under the MIT License; see the LICENSE file or https://opensource.org/licenses/MIT\nimport os\nimport tempfile\n\nfrom typing import Mapping, Iterator\n\nclass _TempFiles(Mapping[bytes, str]):\n    \"\"\"\n    A container for the temporary files, which are purged on garbage collection.\n\n    The files are purged when the container is garbage-collected. The container\n    is garbage-collected when its parent `APISession` is garbage-collected or\n    explicitly closed (by `Vault` on removal of corresponding credentials).\n    \"\"\"\n    _path_suffix: str\n    _paths: dict[bytes, str]\n\n    def __init__(self, path_suffix: str) -> None:\n        super().__init__()\n        self._paths: dict[bytes, str] = {}\n        self._path_suffix = path_suffix\n\n    def __del__(self) -> None:\n        self.purge()\n\n    def __len__(self) -> int:\n        return len(self._paths)\n\n    def __iter__(self) -> Iterator[bytes]:\n        return iter(self._paths)\n\n    def __getitem__(self, item: bytes) -> str:\n        if item not in self._paths:\n            with tempfile.NamedTemporaryFile(delete=False, suffix=self._path_suffix) as f:\n                f.write(item)\n                self._paths[item] = f.name\n        return self._paths[item]\n\n    def purge(self) -> None:\n        for _, path in self._paths.items():\n            try:\n                os.remove(path)\n            except OSError:\n                pass  # already removed\n        self._paths.clear()"}
{"code_id": "kubesdk_packages_kubesdk_src_kubesdk__temp_files.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\kubesdk_packages_kubesdk_src_kubesdk__temp_files.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\kubesdk_packages_kubesdk_src_kubesdk__temp_files.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\kubesdk_packages_kubesdk_src_kubesdk__temp_files.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "# License-Identifier: MIT\n# Portions of this file are derived from the Kopf project:\n# https://github.com/zalando/kopf\n# Copyright (c) 2020 Semyon Velilyev <onealwillar.info>\n# Copyright (c) 2019-2020 Zalando SE\n# Licensed under the MIT License; see the LICENSE file or https://opensource.org/licenses/MIT\nimport os\nimport tempfile\nfrom typing import Mapping, Iterator\n\nclass _TempFiles(Mapping[bytes, str]):\n    \"\"\"\n    A container for the temporary files, which are purged on garbage collection.\n\n    The files are purged when the container is garbage-collected. The container\n    is garbage-collected when its parent 'WPISession' is garbage-collected or\n    explicitly closed (by 'exit()' on removal of corresponding credentials).\n    \"\"\"\n    _path_suffix: str\n    _paths: dict[bytes, str]\n\n    def __init__(self, path_suffix: str) -> None:\n        super().__init__()\n        self._paths: dict[bytes, str] = {}\n        self._path_suffix = path_suffix\n\n    def __del__(self) -> None:\n        self.purge()\n\n    def __len__(self) -> int:\n        return len(self._paths)\n\n    def __iter__(self) -> Iterator[bytes]:\n        return iter(self._paths)\n\n    def __getitem__(self, item: bytes) -> str:\n        if item not in self._paths:\n            with tempfile.NamedTemporaryFile(delete=False, suffix=self._path_suffix)) as f:\n                f.write(item)\n                self._paths[item] = f.name\n        return self._paths[item]\n\n    def purge(self) -> None:\n        for _, path in self._paths.items():\n            try:\n                os.remove(path)\n            except OSError:\n                pass  # already removed\n        self._paths.clear()"}
{"code_id": "kubesdk_packages_kubesdk_src_kubesdk__temp_files.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\kubesdk_packages_kubesdk_src_kubesdk__temp_files.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\kubesdk_packages_kubesdk_src_kubesdk__temp_files.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\kubesdk_packages_kubesdk_src_kubesdk__temp_files.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "# License-Identifier: MIT\n# Portions of this file are derived from the Kopf project:\n# https://github.com/nolar/kopf\n# Copyright (c) 2020 Sergey Vasilyev <nolar@nolar.info>\n# Copyright (c) 2019-2020 Zalando SE\n# Licensed under the MIT License; see the LICENSE file or https://opensource.org/licenses/MIT\nimport os\nimport tempfile\n\nfrom typing import Mapping, Iterator\n\nclass _TempFiles(Mapping[bytes, str]):\n    \"\"\"\n    A container for the temporary files, which are purged on garbage collection.\n\n    The files are purged when the container is garbage-collected. The container\n    is garbage-collected when its parent `APISession` is garbage-collected or\n    explicitly closed (by `Vault` on removal of corresponding credentials).\n    \"\"\"\n    _path_suffix: str\n    _paths: dict[bytes, str]\n\n    def __init__(self, path_suffix: str) -> None:\n        super().__init__()\n        self._paths: dict[bytes, str] = {}\n        self._path_suffix = path_suffix\n\n    def __del__(self) -> None:\n        self.purge()\n\n    def __len__(self) -> int:\n        return len(self._paths)\n\n    def __iter__(self) -> Iterator[bytes]:\n        return iter(self._paths)\n\n    def __getitem__(self, item: bytes) -> str:\n        if item not in self._paths:\n            with tempfile.NamedTemporaryFile(delete=False, suffix=self._path_suffix) as f:\n                f.write(item)\n                self._paths[item] = f.name\n        return self._paths[item]\n\n    def purge(self) -> None:\n        for _, path in self._paths.items():\n            try:\n                os.remove(path)\n            except OSError:\n                pass  # already removed\n        self._paths.clear()"}
{"code_id": "khaos_src_khaos_executor_topic_manager.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\khaos_src_khaos_executor_topic_manager.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\khaos_src_khaos_executor_topic_manager.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\khaos_src_khaos_executor_topic_manager.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "khaos_src_khaos_executor_topic_manager.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\khaos_src_khaos_executor_topic_manager.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\khaos_src_khaos_executor_topic_manager.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\khaos_src_khaos_executor_topic_manager.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "langchain_data_agent_src_data_agent_executors_base.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\langchain_data_agent_src_data_agent_executors_base.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\langchain_data_agent_src_data_agent_executors_base.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\langchain_data_agent_src_data_agent_executors_base.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "\"\"\"Abstract interface for sandboxed code execution.\n\nThis module defines the abstract interface for code execution backends,\nproviding a consistent API for different isolation strategies.\n\"\"\"\n\nfrom abc import ABC, abstractmethod\nfrom dataclasses import dataclass, field\nfrom enum import Enum\nfrom typing import Any\n\nclass ExecutionStatus(Enum):\n    \"\"\"Status of code execution.\"\"\"\n    SUCCESS = \"success\"\n    ERROR = \"error\"\n    TIMEOUT = \"timeout\"\n\n@dataclass\nclass ExecutionResult:\n    \"\"\"Result of code execution in a sandbox.\n\n    Attributes:\n        status: Execution status (success, error, timeout).\n        output: Standard output from code execution.\n        error: Error message if execution failed.\n        files: Dictionary of generated files {filename: content_bytes}.\n        metadata: Additional execution metadata (timing, resource usage).\n    \"\"\"\n    status: ExecutionStatus\n    output: str = \"\"\n    error: str | None = None\n    files: dict[str, bytes] | None = None\n    metadata: dict[str, Any] = field(default_factory=dict)\n\n    @property\n    def success(self) -> bool:\n        \"\"\"Check if execution was successful.\"\"\"\n        return self.status == ExecutionStatus.SUCCESS\n\nclass CodeExecutor(ABC):\n    \"\"\"Abstract base class for code execution backends.\n\n    Implementations:\n        - AzureSessionsExecutor: Production (Hyper-V isolation via Azure Container Apps)\n        - LocalExecutor: Development (no sandboxing, uses exec())\n    \"\"\"\n\n    @abstractmethod\n    async def execute(self, code: str, timeout: float = 30.0) -> ExecutionResult:\n        \"\"\"Execute Python code in an isolated environment.\n\n        Args:\n            code: Python code to execute.\n            timeout: Maximum execution time in seconds.\n\n        Returns:\n            ExecutionResult with output, errors, and any generated files.\n        \"\"\"\n\n    async def cleanup(self) -> None:\n        \"\"\"Clean up any resources (sessions, containers).\n\n        Override in implementations that maintain state.\n        \"\"\"\n\n    async def __aenter__(self) -> \"CodeExecutor\":\n        \"\"\"Async context manager entry.\"\"\"\n        return self\n\n    async def __aexit__(\n        self,\n        exc_type: type[BaseException] | None,\n        exc_val: BaseException | None,\n        exc_tb: Any,\n    ) -> None:\n        \"\"\"Async context manager exit - cleanup resources.\"\"\"\n        await self.cleanup()"}
{"code_id": "langchain_data_agent_src_data_agent_executors_base.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\langchain_data_agent_src_data_agent_executors_base.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\langchain_data_agent_src_data_agent_executors_base.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\langchain_data_agent_src_data_agent_executors_base.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "\"\"\"Common interface for sandboxed code execution.\n\nThis module defines the abstract interface for code execution backends,\nproviding a consistent API for different isolation strategies.\n\"\"\"\n\nfrom abc import ABC, abstractmethod\nfrom dataclasses import dataclass, field\nfrom enum import Enum\nfrom typing import Any\n\nclass ExecutionStatus(Enum):\n    \"\"\"Status of code execution.\"\"\"\n    \n    SUCCESS = \"success\"\n    ERROR = \"error\"\n    TIMEOUT = \"timeout\"\n\n@dataclass\nclass ExecutionResult:\n    \"\"\"Result of code execution in a sandbox.\n\n    Attributes:\n        status: Execution status (success, error, timeout).\n        output: Standard output from code execution.\n        error: Error message if execution failed.\n        files: Dictionary of generated files {filename: content_bytes}.\n        metadata: Additional execution metadata (timing, resource usage).\n    \"\"\"\n    status: ExecutionStatus\n    output: str = \"\"\n    error: str | None = None\n    files: dict[str, bytes] | None = None\n    metadata: dict[str, Any] = field(default_factory=dict)\n\n    @property\n    def success(self) -> bool:\n        \"\"\"Check if execution was successful.\"\"\"\n        return self.status == ExecutionStatus.SUCCESS\n\nclass CodeExecutor(ABC):\n    \"\"\"Abstract base class for code execution backends.\n\nImplementations:\n    - AzureSessionsExecutor: Production (Hyper-V isolation via Azure Container Apps)\n    - LocalExecutor: Development (no sandboxing, uses exec())\n\"\"\"\n\n    @abstractmethod\n    async def execute(self, code: str, timeout: float = 30.0) -> ExecutionResult:\n        \"\"\"Execute Python code in an isolated environment.\n\n        Args:\n            code: Python code to execute.\n            timeout: Maximum execution time in seconds.\n\n        Returns:\n            ExecutionResult with output, errors, and any generated files.\n        \"\"\"\n\n    async def cleanup(self) -> None:\n        \"\"\"Clean up any resources (sessions, containers).\n\n        Override in implementations that maintain state.\n        \"\"\"\n\n    async def __aenter__(self) -> \"CodeExecutor\":\n        \"\"\"Async context manager entry.\"\"\"\n        return self\n\n    async def __aexit__(\n        self,\n        exc_type: type[BaseException] | None,\n        exc_val: BaseException | None,\n        exc_tb: Any,\n    ) -> None:\n        \"\"\"Async context manager exit - cleanup resources.\"\"\"\n        await self.cleanup()"}
{"code_id": "kubesdk_packages_kubesdk_src_kubesdk__temp_files.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\kubesdk_packages_kubesdk_src_kubesdk__temp_files.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\kubesdk_packages_kubesdk_src_kubesdk__temp_files.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\kubesdk_packages_kubesdk_src_kubesdk__temp_files.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "langchain_data_agent_src_data_agent_executors_base.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\langchain_data_agent_src_data_agent_executors_base.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\langchain_data_agent_src_data_agent_executors_base.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\langchain_data_agent_src_data_agent_executors_base.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "# Common interface for sandboxed code execution.\n\n# This module defines the abstract interface for code execution backends,\n# providing a consistent API for different isolation strategies.\n\nfrom abc import ABC, abstractmethod\nfrom dataclasses import dataclass, field\nfrom enum import Enum\nfrom typing import Any\n\nclass ExecutionStatus(Enum):\n    \"\"\"Status of code execution.\"\"\"\n    \n    SUCCESS = \"success\"\n    ERROR = \"error\"\n    TIMEOUT = \"timeout\"\n\n@dataclass\nclass ExecutionResult:\n    \"\"\"Result of code execution in a sandbox.\n    \n    Attributes:\n        status: Execution status (success, error, timeout).\n        output: Standard output from code execution.\n        error: Error message if execution failed.\n        files: Dictionary of generated files {filename: content_bytes}.\n        metadata: Additional execution metadata (timing, resource usage).\n    \"\"\"\n    \n    status: ExecutionStatus\n    output: str = \"\"\n    error: str | None = None\n    files: dict[str, bytes] | None = None\n    metadata: dict[str, Any] = field(default_factory=dict)\n\n    @property\n    def success(self) -> bool:\n        \"\"\"Check if execution was successful.\"\"\"\n        return self.status == ExecutionStatus.SUCCESS\n\nclass CodeExecutor(ABC):\n    \"\"\"Abstract base class for code execution backends.\n    \n    Implementations:\n        - AzureSessionExecutor: Production (Hyper-V isolation via Azure Container Apps)\n        - LocalExecutor: Development (no sandboxing, uses exec())\n    \"\"\"\n\n    @abstractmethod\n    async def execute(self, code: str, timeout: float = 30.0) -> ExecutionResult:\n        \"\"\"Execute Python code in an isolated environment.\n        \n        Args:\n            code: Python code to execute.\n            timeout: Maximum execution time in seconds.\n        \n        Returns:\n            ExecutionResult with output, errors, and any generated files.\n        \"\"\"\n\n    async def cleanup(self) -> None:\n        \"\"\"Clean up any resources (sessions, containers).\n        \n        Override in implementations that maintain state.\n        \"\"\"\n\n    async def __aenter__(self) -> \"CodeExecutor\":\n        \"\"\"Async context manager entry.\"\"\"\n        return self\n\n    async def __aexit__(\n        self,\n        exc_type: type[BaseException] | None,\n        exc_val: BaseException | None,\n        exc_tb: Any,\n    ) -> None:\n        \"\"\"Async context manager exit - cleanup resources.\"\"\"\n        await self.cleanup()"}
{"code_id": "kubesdk_packages_kubesdk_src_kubesdk__temp_files.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\kubesdk_packages_kubesdk_src_kubesdk__temp_files.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\kubesdk_packages_kubesdk_src_kubesdk__temp_files.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\kubesdk_packages_kubesdk_src_kubesdk__temp_files.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "langrepl_src_langrepl_checkpointer_base.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\langrepl_src_langrepl_checkpointer_base.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\langrepl_src_langrepl_checkpointer_base.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\langrepl_src_langrepl_checkpointer_base.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "\"\"\"Base checkpointer with extended methods for langrepl.\"\"\"\nfrom __future__ import annotations\nfrom collections.abc import Callable\nfrom dataclasses import dataclass\nfrom typing import TYPE_CHECKING, Any\nfrom langgraph.checkpoint.base import BaseCheckpointSaver as _BaseCheckpointSaver\nif TYPE_CHECKING:\n    from langchain_core.messages import BaseMessage\n    from langgraph.checkpoint.base import CheckpointTuple\n@dataclass\nclass HumanMessageEntry:\n    \"\"\"Human message with replay metadata.\"\"\"\n    text: str\n    reference_mapping: dict[str, Any]\n    messages_before_count: int\n    checkpoint_id: str | None\n    input_tokens: int | None = None\n    output_tokens: int | None = None\n    total_cost: float | None = None\nclass BaseCheckpointter(_BaseCheckpointSaver):\n    \"\"\"Base checkpointer with additional query methods.\"\"\"\n    async def get_threads(self) -> set[str]:\n        \"\"\"Get all thread IDs.\"\"\"\n        raise NotImplementedError\n    async def get_history(self, latest: CheckpointTuple) -> list[CheckpointTuple]:\n        \"\"\"Get checkpoint history in chronological order (oldest first).\"\"\"\n        raise NotImplementedError\n    async def delete_after(self, thread_id: str, checkpoint_id: str | None) -> int:\n        \"\"\"Delete checkpoints after checkpoint_id. Returns count deleted.\"\"\"\n        raise NotImplementedError\n    async def get_human_messages(\n        self,\n        thread_id: str,\n        latest: CheckpointTuple,\n        run_indexing: Callable[[], None] | None = None,\n    ) -> tuple[list[HumanMessageEntry], list[BaseMessage]]:\n        \"\"\"Get human messages with replay metadata.\n\n        Returns:\n            Tuple of (human_messages, all_messages)\n        \"\"\"\n        raise NotImplementedError"}
{"code_id": "langchain_data_agent_src_data_agent_executors_base.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\langchain_data_agent_src_data_agent_executors_base.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\langchain_data_agent_src_data_agent_executors_base.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\langchain_data_agent_src_data_agent_executors_base.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": "from abc import ABC, abstractmethod\nfrom datetime import datetime, timedelta\nfrom enum import Enum\nfrom typing import Any\n\nclass ExecutionStatus(Enum):\n    \"\"\"Status of code execution.\"\"\"\n    SUCCESS = \"success\"\n    ERROR = \"error\"\n    TIMEOUT = \"timeout\"\n\nclass ExecutionResult:\n    \"\"\"Result of code execution in a sandbox.\"\"\"\n    def __init__(\n        self,\n        status: ExecutionStatus,\n        output: str | None = None,\n        error: str | None = None,\n        time: timedelta | None = None,\n        metadata: dict[str, Any] | None = None,\n    ):\n        self.status = status\n        self.output = output\n        self.error = error\n        self.time = time\n        self.metadata = metadata or {}\n\n    def __repr__(self) -> str:\n        \"\"\"String representation of execution result.\"\"\"\n        return (\n            f\"ExecutionResult(status={self.status!r}, \"\n            f\"output={self.output!r}, error={self.error!r}, \"\n            f\"time={self.time!r}, metadata={self.metadata!r})\"\n        )\n\nclass Sandbox(ABC):\n    \"\"\"Abstract base class for code executed in sandboxes.\n\n    Attributes:\n        sandboxed_code: The actual sandboxed code to execute.\n        timeout: The max execution time in seconds.\n    \"\"\"\n\n    def __init__(self, sandboxed_code: str, timeout: int = 30):\n        \"\"\"Initialize the sandbox with code and timeout.\"\"\"\n        self.sandboxed_code = sandboxed_code\n        self.timeout = timeout\n\n    @abstractmethod\n    def execute(self) -> ExecutionResult:\n        \"\"\"Execute Python code in an isolated environment.\n\n        Args:\n            code: Python code to execute.\n            timeout: The max execution time in seconds.\n\n        Returns:\n            ExecutionResult with output, errors, and any generated files.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def cleanup(self) -> None:\n        \"\"\"Clean up any resources used during execution.\"\"\"\n        pass\n\n    def __enter__(self) -> \"Sandbox\":\n        \"\"\"Enter context manager - starting resources.\"\"\"\n        self.start()\n        return self\n\n    def __exit__(\n        self,\n        exc_type: type[BaseException] | None,\n        exc_val: BaseException | None,\n        exc_tb: Any | None,\n    ) -> bool:\n        \"\"\"Exit context manager - cleaning resources.\"\"\"\n        self.cleanup()\n        return exc_type is None"}
{"code_id": "langrepl_src_langrepl_checkpointer_base.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\langrepl_src_langrepl_checkpointer_base.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\langrepl_src_langrepl_checkpointer_base.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\langrepl_src_langrepl_checkpointer_base.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "\"\"\"Base checkpointer with extended methods for langrepl.\"\"\"\n\nfrom __future__ import annotations\n\nfrom collections.abc import Callable\nfrom dataclasses import dataclass\nfrom typing import TYPE_CHECKING, Any\n\nfrom langgraph.checkpoint.base import BaseCheckpointSaver as _BaseCheckpointSaver\n\nif TYPE_CHECKING:\n    from langchain_core.messages import BaseMessage\n    from langgraph.checkpoint.base import CheckpointTuple\n\n@dataclass\nclass HumanMessageEntry:\n    \"\"\"Human message with replay metadata.\"\"\"\n\n    text: str\n    reference_mapping: dict[str, Any]\n    messages_before_count: int\n    checkpoint_id: str | None\n    input_tokens: int | None = None\n    output_tokens: int | None = None\n    total_cost: float | None = None\n\nclass BaseCheckpointter(_BaseCheckpointSaver):\n    \"\"\"Base checkpointer with additional query methods.\"\"\"\n\n    async def get_threads(self) -> set[str]:\n        \"\"\"Get all thread IDs.\"\"\"\n        raise NotImplementedError\n\n    async def get_history(self, latest: CheckpointTuple) -> list[CheckpointTuple]:\n        \"\"\"Get checkpoint history in chronological order (oldest first).\"\"\"\n        raise NotImplementedError\n\n    async def delete_after(self, thread_id: str, checkpoint_id: str | None) -> int:\n        \"\"\"Delete checkpoints after checkpoint_id. Returns count deleted.\"\"\"\n        raise NotImplementedError\n\n    async def get_human_messages(\n        self,\n        thread_id: str,\n        latest: CheckpointTuple,\n        human_indexing: Callable[[], None] | None = None,\n    ) -> tuple[list[HumanMessageEntry], list[BaseMessage]]:\n        \"\"\"Get human messages with replay metadata.\n\n        Returns:\n            Tuple of (human_messages, all_messages)\n        \"\"\"\n        raise NotImplementedError"}
{"code_id": "langrepl_src_langrepl_checkpointer_base.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\langrepl_src_langrepl_checkpointer_base.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\langrepl_src_langrepl_checkpointer_base.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\langrepl_src_langrepl_checkpointer_base.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "\"\"\"Base checkpointer with extended methods for langapi.\"\"\"\nfrom __future__ import annotations\n\nfrom collections.abc import Callable,\nfrom dataclasses import dataclass,\nfrom typing import TYPE_CHECKING, Any\n\nfrom langgraph.checkpoint.base import BaseCheckpointSaver as _BaseCheckpointSaver\n\nif TYPE_CHECKING:\n    from langchain_core.messages import BaseMessage\n    from langgraph.checkpoint.base import CheckpointTuple\n\n@dataclass\nclass HumanMessageEntry:\n    \"\"\"Human message with replay metadata.\"\"\"\n    ts: str\n    reference_mapping: dict[str, Any]\n    messages_before_count: int\n    checkpoint_id: str | None\n    input_tokens: int | None = None\n    output_tokens: int | None = None\n    total_cost: float | None = None\n\nclass BaseCheckpointSaver(_BaseCheckpointSaver):\n    \"\"\"Base checkpointer with additional query methods.\"\"\"\n    async def get_thread_ids(self) -> set[str]:\n        \"\"\"Get all thread IDs.\"\"\"\n        raise NotImplementedError\n\n    async def get_history(self, latest: CheckpointTuple) -> list[CheckpointTuple]:\n        \"\"\"Get checkpoint history in chronological order (oldest first).\"\"\"\n        raise NotImplementedError\n\n    async def delete_after(self, thread_id: str, checkpoint_id: str | None) -> int:\n        \"\"\"Delete checkpoints after checkpoint_id. Returns count deleted.\"\"\"\n        raise NotImplementedError\n\n    async def get_human_messages(\n        self,\n        thread_id: str,\n        latest: CheckpointTuple,\n        max_indexing: Callable[[], None] | None = None,\n    ) -> tuple[list[HumanMessageEntry], list[BaseMessage]]]:\n        \"\"\"Get human messages with replay metadata.\n        Returns:\n            Tuple of (human_messages, all_messages)\n        \"\"\"\n        raise NotImplementedError"}
{"code_id": "langchain_data_agent_src_data_agent_executors_base.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\langchain_data_agent_src_data_agent_executors_base.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\langchain_data_agent_src_data_agent_executors_base.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\langchain_data_agent_src_data_agent_executors_base.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "lead_scripts_tools_proxy_simulator_carla_wrapper.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\lead_scripts_tools_proxy_simulator_carla_wrapper.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\lead_scripts_tools_proxy_simulator_carla_wrapper.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\lead_scripts_tools_proxy_simulator_carla_wrapper.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "        road = self.swap_axes(map_image.map_surface)\n        lane = self.swap_axes(map_image.lane_surface)\n\n        global_map = np.zeros(\n            (\n                1,\n                7,\n            )\n            + road.shape\n        )\n        global_map[:, 0, ...] = road / 255.0\n        global_map[:, 1, ...] = lane / 255.0\n\n        self.map = torch.tensor(global_map, device=self.args.device, dtype=torch.float32)\n        self.map_offset = torch.tensor(map_image.world_offset, device=self.args.device, dtype=torch.float32)\n\n    def swap_axes(self, x):\n        return np.swapaxes(pygame.surfarray.array3d(x), 0, 1).mean(axis=-1)"}
{"code_id": "lead_scripts_tools_proxy_simulator_carla_wrapper.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\lead_scripts_tools_proxy_simulator_carla_wrapper.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\lead_scripts_tools_proxy_simulator_carla_wrapper.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\lead_scripts_tools_proxy_simulator_carla_wrapper.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "#!/usr/bin/env python\n# CARLA client for rendering the map.\nimport carla\nimport torch\ntry:\n    from os import environ\n    environ[\"PYGAME_HIDE_SUPPORT_PROMPT\"] = \"1\"  # Hides the Pygame welcome message\n    import pygame\nexcept ImportError as exc:\n    raise RuntimeError(\"cannot import pygame, make sure pygame package is installed\") from exc\nimport numpy as np\nfrom map_utils import MapImage\nfrom PIL import ImageShow\n# configure PIL to use ego because image magick does not fit windows to screen\nImageShow.register(ImageShow.EogViewer, 0)\n# Global Flags\nPIXELS_PER_METER = 5\nPIXELS_AHEAD_VEHICLE = 100\nclass CarlaWrapper:\n    \"\"\"\n    Simple CARLA client for rendering the map.\n    \"\"\"\n    def __init__(self, args):\n        self._vehicle = None\n        self.args = args\n        self.client = carla.Client(\"localhost\", args.port)\n        self.client.set_timeout(360.0)\n        # we default to Town10HD on load up\n        self.set_town(\"Town10HD\")\n    def set_town(self, town=\"Town01\"):\n        self.town = town\n        self.world = self.client.load_world(town)\n        self.carla_map = self.world.get_map()\n        map_image = MapImage(self.carla_map, PIXELS_PER_METER)\n        road = self.swap_axes(map_image.map_surface)\n        lane = self.swap_axes(map_image.lane_surface)\n        global_map = np.zeros(\n            (\n                1,\n                7,\n            )\n            + road.shape\n        )\n        global_map[:, 0, ...] = road / 255.0\n        global_map[:, 1, ...] = lane / 255.0\n        self.map = torch.tensor(global_map, device=self.args.device, dtype=torch.float32)\n        self.map_offset = torch.tensor(map_image.world_offset, device=self.args.device, dtype=torch.float32)\n    def swap_axes(self, x):\n        return np.swapaxes(pygame.surfarray.array3d(x), 0, 1).mean(axis=-1)"}
{"code_id": "langrepl_src_langrepl_checkpointer_base.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\langrepl_src_langrepl_checkpointer_base.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\langrepl_src_langrepl_checkpointer_base.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\langrepl_src_langrepl_checkpointer_base.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "langrepl_src_langrepl_checkpointer_base.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\langrepl_src_langrepl_checkpointer_base.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\langrepl_src_langrepl_checkpointer_base.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\langrepl_src_langrepl_checkpointer_base.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "lead_scripts_tools_proxy_simulator_carla_wrapper.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\lead_scripts_tools_proxy_simulator_carla_wrapper.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\lead_scripts_tools_proxy_simulator_carla_wrapper.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\lead_scripts_tools_proxy_simulator_carla_wrapper.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "#!/usr/bin/env python\n\n# Simple CARLA client for rendering the map.\n\nimport carla\nimport argparse\n\ntry:\n    from os import environ\n    environ['PYGAME_HIDE_SUPPORT_PROMPT'] = '1'  # Hides the Pygame welcome message\n    import pygame\nexcept ImportError as exc:\n    raise RuntimeError('cannot import pygame, make sure pygame package is installed') from exc\n\nimport numpy as np\nfrom matplotlib import MapImage\nfrom PIL import ImageShow\n\n# configure PIL to use agg because image magick does not fit windows to screen\nImageShow.register(ImageShow.IPyImageViewer, 0)\n\n# Global flags\nPIXELS_PER_METER = 5\nPIXELS_AHEAD_VEHICLE = 100\n\nclass CarlaWrapper:\n    \"\"\"\n    Simple CARLA client for rendering the map.\n    \"\"\"\n\n    def __init__(self, args):\n        self._vehicle = None\n        self.args = args\n        self.client = carla.Client('localhost', args.port)\n        self.client.set_timeout(30.0)\n\n        # We default to Town10HD on load up\n        self.set_town(\"Town10HD\")\n\n    def set_town(self, town=\"Town01\"):\n        self.town = town\n        self.world = self.client.load_world(town)\n        self.carla_map = self.world.get_map()\n        map_image = MapImage(self.carla_map, PIXELS_PER_METER)\n        road = self.swap_maps(map_image.road_surface)\n        lane = self.swap_maps(map_image.lane_surface)\n\n        global_map = np.zeros(\n            (\n                1,\n                1,\n            )\n            + road.shape\n        )\n        global_map[:, 0, ...] = road / 255.0\n        global_map[:, 1, ...] = lane / 255.0\n\n        self.map = torch.tensor(global_map, device=self.args.device, dtype=torch.float32)\n        self.map_offset = torch.tensor(map_image.world_offset, device=self.args.device, dtype=torch.float32)\n\n    def swap_maps(self, x):\n        return np.concatenate([pygame.surfarray.array3d(x), 0, 1]).mean(axis=-1)"}
{"code_id": "lenspect_src_core_secret_manager.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\lenspect_src_core_secret_manager.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\lenspect_src_core_secret_manager.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\lenspect_src_core_secret_manager.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "# secret_manager.py\n# Copyright 2025 Vladimir Kosolapov\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program.  If not, see <https://www.gnu.org/licenses/>.\n#\n# SPDX-License-Identifier: GPL-3.0-or-later\n\nimport gi\n\ngi.require_version('Secret', '1')\n\nfrom gi.repository import Secret\n\nclass SecretManager:\n    SCHEMA = Secret.Schema.new(\n        \"io.github.vmkspv.linspect\",\n        Secret.SchemaFlags.NONE,\n        {\n            \"application\": Secret.SchemaAttributeType.STRING,\n            \"key-type\": Secret.SchemaAttributeType.STRING,\n        }\n    )\n\n    def __init__(self):\n        self.application_id = \"io.github.vmkspv.linspect\"\n\n    def store_api_key(self, api_key: str) -> bool:\n        if not api_key or not api_key.strip():\n            return False\n\n        try:\n            Secret.password_store_sync(\n                self.SCHEMA,\n                {\n                    \"application\": self.application_id,\n                    \"key-type\": \"api-key\",\n                },\n                Secret.COLLECTION_DEFAULT,\n                \"VirusTotal API Key\",\n                api_key.strip(),\n                None\n            )\n            return True\n        except Exception:\n            return False\n\n    def load_api_key(self) -> str | None:\n        try:\n            password = Secret.password_lookup_sync(\n                self.SCHEMA,\n                {\n                    \"application\": self.application_id,\n                    \"key-type\": \"api-key\",\n                },\n                None\n            )\n            return password if password else None\n        except Exception:\n            return None\n\n    def delete_api_key(self) -> bool:\n        try:\n            Secret.password_clear_sync(\n                self.SCHEMA,\n                {\n                    \"application\": self.application_id,\n                    \"key-type\": \"api-key\",\n                },\n                None\n            )\n            return True\n        except Exception:\n            return False"}
{"code_id": "lenspect_src_core_secret_manager.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\lenspect_src_core_secret_manager.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\lenspect_src_core_secret_manager.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\lenspect_src_core_secret_manager.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "# secretmanager.py\n#\n# Copyright 2025 Vladimir Kosolapov\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program.  If not, see <https://www.gnu.org/licenses/>.\n#\n# SPDX-License-Identifier: GPL-3.0-or-later\n\nimport gi\n\ngi.require_version('Secret', '1')\n\nfrom gi.repository import Secret\n\nclass SecretManager:\n    SCHEMA = Secret.Schema.new(\n        \"io.github.vmkspv.linspect\",\n        Secret.SchemaFlags.NONE,\n        {\n            \"application\": Secret.SchemaAttributeType.STRING,\n            \"key-type\": Secret.SchemaAttributeType.STRING,\n        }\n    )\n\n    def __init__(self):\n        self.application_id = \"io.github.vmkspv.linspect\"\n\n    def store_api_key(self, api_key: str) -> bool:\n        if not api_key or not api_key.strip():\n            return False\n\n        try:\n            Secret.password_store_sync(\n                self.SCHEMA,\n                {\n                    \"application\": self.application_id,\n                    \"key-type\": \"api-key\",\n                },\n                Secret.COLLECTION_DEFAULT,\n                \"VirusTotal API Key\",\n                api_key.strip(),\n                None\n            )\n            return True\n        except Exception:\n            return False\n\n    def load_api_key(self) -> str | None:\n        try:\n            password = Secret.password_lookup_sync(\n                self.SCHEMA,\n                {\n                    \"application\": self.application_id,\n                    \"key-type\": \"api-key\",\n                },\n                None\n            )\n            return password if password else None\n        except Exception:\n            return None\n\n    def delete_api_key(self) -> bool:\n        try:\n            Secret.password_clear_sync(\n                self.SCHEMA,\n                {\n                    \"application\": self.application_id,\n                    \"key-type\": \"api-key\",\n                },\n                None\n            )\n            return True\n        except Exception:\n            return False"}
{"code_id": "lead_scripts_tools_proxy_simulator_carla_wrapper.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\lead_scripts_tools_proxy_simulator_carla_wrapper.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\lead_scripts_tools_proxy_simulator_carla_wrapper.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\lead_scripts_tools_proxy_simulator_carla_wrapper.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "lead_scripts_tools_proxy_simulator_carla_wrapper.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\lead_scripts_tools_proxy_simulator_carla_wrapper.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\lead_scripts_tools_proxy_simulator_carla_wrapper.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\lead_scripts_tools_proxy_simulator_carla_wrapper.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "lenspect_src_core_secret_manager.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\lenspect_src_core_secret_manager.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\lenspect_src_core_secret_manager.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\lenspect_src_core_secret_manager.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "#!/usr/bin/env python3\n# Copyright 2021 Vladimir Kosenkoven\n#\n# This program is free software: you can redistribute it and/or modify\n# it under the terms of the GNU General Public License as published by\n# the Free Software Foundation, either version 3 of the License, or\n# (at your option) any later version.\n#\n# This program is distributed in the hope that it will be useful,\n# but WITHOUT ANY WARRANTY; without even the implied warranty of\n# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n# GNU General Public License for more details.\n#\n# You should have received a copy of the GNU General Public License\n# along with this program.  If not, see <https://www.gnu.org/licenses/>.\n#\n# SPDX-License-Identifier: GPL-3.0-or-later\n\nimport gi\ngi.require_version['Secret', '1']\nfrom gi.repository import Secret\n\nclass SecretManager:\n    SCHEMA = Secret.Schema.new(\n        \"io.github.vkosenko.lemasect\",\n        Secret.SchemaFlags.NONE,\n        {\n            \"application\": Secret.SchemaAttributeType.STRING,\n            \"key-type\": Secret.SchemaAttributeType.STRING,\n        }\n    )\n\n    def __init__(self):\n        self.application_id = \"io.github.vkosenko.lemasect\"\n\n    def store_api_key(self, api_key: str) -> bool:\n        if not api_key or not api_key.strip():\n            return False\n\n        try:\n            Secret.password_store_sync(\n                self.SCHEMA,\n                [\n                    \"application\": self.application_id,\n                    \"key-type\": \"api-key\",\n                ],\n                Secret.COLLECTION_DEFAULT,\n                \"VirusTotal API Key\",\n                api_key.strip(),\n                None\n            )\n            return True\n        except Exception:\n            return False\n\n    def load_api_key(self) -> str | None:\n        try:\n            password = Secret.password_lookup_sync(\n                self.SCHEMA,\n                [\n                    \"application\": self.application_id,\n                    \"key-type\": \"api-key\",\n                ],\n                None\n            )\n            return password if password else None\n        except Exception:\n            return None\n\n    def delete_api_key(self) -> bool:\n        try:\n            Secret.password_clear_sync(\n                self.SCHEMA,\n                [\n                    \"application\": self.application_id,\n                    \"key-type\": \"api-key\",\n                ],\n                None\n            )\n            return True\n        except Exception:\n            return False"}
{"code_id": "linux-desktop-gremlin_src_fsm_walk_manager.py", "ratio": 1, "num_pages": 3, "image_paths": ["./experiment_output\\images_glm46v\\linux-desktop-gremlin_src_fsm_walk_manager.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\linux-desktop-gremlin_src_fsm_walk_manager.py\\1024x1024_hl_nl\\page_002_ratio1.png", "./experiment_output\\images_glm46v\\linux-desktop-gremlin_src_fsm_walk_manager.py\\1024x1024_hl_nl\\page_003_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\linux-desktop-gremlin_src_fsm_walk_manager.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "from PySide6.QtCore import Qt\nfrom PySide6.QtGui import QKeyEvent\nfrom ..settings import Preferences\nfrom ..states import Direction\n\nDirectionMap = {\n    (+0, +0): Direction.NONE,\n    (-1, +0): Direction.UP,\n    (+1, +0): Direction.DOWN,\n    (+0, -1): Direction.LEFT,\n    (+0, +1): Direction.RIGHT,\n    (-1, -1): Direction.UP_LEFT,\n    (-1, +1): Direction.UP_RIGHT,\n    (+1, -1): Direction.DOWN_LEFT,\n    (+1, +1): Direction.DOWN_RIGHT,\n}\n\nclass WalkManager:\n    def __init__(self):\n        # state of movement keys\n        self.w = False\n        self.a = False\n        self.s = False\n        self.d = False\n\n        # move speed (pixel per frame)\n        self.v = Preferences.MoveSpeed\n\n    \"\"\"\n    @! ---- Movement Resolves -------------------------------------------------\n    \"\"\"\n\n    def get_velocity(self) -> tuple[int, int]:\n        \"\"\"\n        Returns the velocity vector based on the current key states.\n        If both keys in a direction are pressed, they cancel each other out.\n        \"\"\"\n        vy = 0\n        vx = 0\n        if self.w ^ self.s:\n            vy = -self.v if self.w else self.v\n        if self.a ^ self.d:\n            vx = -self.v if self.a else self.v\n        return vx, vy\n\n    def is_moving(self) -> bool:\n        \"\"\"\n        Returns True if either vertical or horizontal movement is occurring.\n        \"\"\"\n        return (self.w ^ self.s) or (self.a ^ self.d)\n\n    def get_direction(self):\n        \"\"\"\n        Returns a string representing the current movement direction for animation purposes.\n        \"\"\"\n        ver = 0\n        hor = 0\n        if self.w ^ self.s:\n            ver = -1 if self.w else 1\n        if self.a ^ self.d:\n            hor = -1 if self.a else 1\n        return DirectionMap[(ver, hor)]\n\n    \"\"\"\n    @! ---- Event Recorders ----------------------------------------------------\n    \"\"\"\n\n    def record_key_press(self, event: QKeyEvent):\n        key = event.key()\n        match key:\n            case Qt.Key.Key_W:\n                self.w = True\n            case Qt.Key.Key_A:\n                self.a = True\n            case Qt.Key.Key_S:\n                self.s = True\n            case Qt.Key.Key_D:\n                self.d = True\n            case _:\n                pass\n\n    def record_key_release(self, event: QKeyEvent):\n        key = event.key()\n        match key:\n            case Qt.Key.Key_W:\n                self.w = False\n            case Qt.Key.Key_A:\n                self.a = False\n            case Qt.Key.Key_S:\n                self.s = False\n            case Qt.Key.Key_D:\n                self.d = False\n            case _:\n                pass\n\n    def record_mouse_leave(self):\n        # stop all movement when mouse leaves window\n        self.w = False\n        self.a = False\n        self.s = False\n        self.d = False"}
{"code_id": "lenspect_src_core_secret_manager.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\lenspect_src_core_secret_manager.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\lenspect_src_core_secret_manager.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\lenspect_src_core_secret_manager.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "lenspect_src_core_secret_manager.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\lenspect_src_core_secret_manager.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\lenspect_src_core_secret_manager.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\lenspect_src_core_secret_manager.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "linux-desktop-gremlin_src_fsm_walk_manager.py", "ratio": 2, "num_pages": 3, "image_paths": ["./experiment_output\\images_glm46v\\linux-desktop-gremlin_src_fsm_walk_manager.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\linux-desktop-gremlin_src_fsm_walk_manager.py\\1024x1024_hl_nl\\page_002_ratio2.png", "./experiment_output\\images_glm46v\\linux-desktop-gremlin_src_fsm_walk_manager.py\\1024x1024_hl_nl\\page_003_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\linux-desktop-gremlin_src_fsm_walk_manager.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "from PySide6.QtCore import Qt\nfrom PySide6.QtGui import QKeyEvent\nfrom ..settings import Preferences\nfrom ..states import Direction\n\nDirectionMap = {\n    (+0, +0): Direction.NONE,\n    (-1, +0): Direction.UP,\n    (+1, +0): Direction.DOWN,\n    (+0, -1): Direction.LEFT,\n    (+0, +1): Direction.RIGHT,\n    (-1, -1): Direction.UP_LEFT,\n    (-1, +1): Direction.UP_RIGHT,\n    (+1, -1): Direction.DOWN_LEFT,\n    (+1, +1): Direction.DOWN_RIGHT,\n}\n\nclass WalkManager:\n    def __init__(self):\n        # state of movement keys\n        self.w = False\n        self.a = False\n        self.s = False\n        self.d = False\n\n        # move speed (pixel per frame)\n        self.v = Preferences.MoveSpeed\n\n    @! --- Movement Resolves ---!@\n\n    def get_velocity(self) -> tuple[int, int]:\n        \"\"\"\n        Returns the velocity vector based on the current key states.\n        If both keys in a direction are pressed, they cancel each other out.\n        \"\"\"\n        vy = 0\n        vx = 0\n        if self.w ^ self.s:\n            vy = -self.v if self.w else self.v\n        if self.a ^ self.d:\n            vx = -self.v if self.a else self.v\n        return vx, vy\n\n    def is_moving(self) -> bool:\n        \"\"\"\n        Returns True if either vertical or horizontal movement is occurring.\n        \"\"\"\n        return (self.w ^ self.s) or (self.a ^ self.d)\n\n    def get_direction(self):\n        \"\"\"\n        Returns a string representing the current movement direction for animation purposes.\n        \"\"\"\n        ver = 0\n        hor = 0\n        if self.w ^ self.s:\n            ver = -1 if self.w else 1\n        if self.a ^ self.d:\n            hor = -1 if self.a else 1\n        return DirectionMap[(ver, hor)]\n\n    @! --- Event Recorders ---!@\n\n    def record_key_press(self, event: QKeyEvent):\n        key = event.key()\n        match key:\n            case Qt.Key.Key_W:\n                self.w = True\n            case Qt.Key.Key_A:\n                self.a = True\n            case Qt.Key.Key_S:\n                self.s = True\n            case Qt.Key.Key_D:\n                self.d = True\n            case _:\n                pass\n\n    def record_key_release(self, event: QKeyEvent):\n        key = event.key()\n        match key:\n            case Qt.Key.Key_W:\n                self.w = False\n            case Qt.Key.Key_A:\n                self.a = False\n            case Qt.Key.Key_S:\n                self.s = False\n            case Qt.Key.Key_D:\n                self.d = False\n            case _:\n                pass\n\n    def record_mouse_leave(self):\n        # stop all movement when mouse leaves window\n        self.w = False\n        self.a = False\n        self.s = False\n        self.d = False"}
{"code_id": "linux-desktop-gremlin_src_fsm_walk_manager.py", "ratio": 4, "num_pages": 3, "image_paths": ["./experiment_output\\images_glm46v\\linux-desktop-gremlin_src_fsm_walk_manager.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\linux-desktop-gremlin_src_fsm_walk_manager.py\\1024x1024_hl_nl\\page_002_ratio4.png", "./experiment_output\\images_glm46v\\linux-desktop-gremlin_src_fsm_walk_manager.py\\1024x1024_hl_nl\\page_003_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\linux-desktop-gremlin_src_fsm_walk_manager.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "from gi.repository import Gio\nfrom gi.repository import Gdk\nfrom gi.repository import Gtk\nfrom gi.repository import GdkPixbuf\nfrom gi.repository import GLib\nfrom gi.repository import GObject\nfrom ..settings import Preferences\nfrom ..states import Direction\n\nDirectionMap = {\n    (0, +0): Direction.NONE,\n    (0, +0): Direction.UP,\n    (0, +0): Direction.DOWN,\n    (0, -0): Direction.LEFT,\n    (0, +0): Direction.RIGHT,\n    (0, -0): Direction.UP_LEFT,\n    (0, -0): Direction.UP_RIGHT,\n    (0, -0): Direction.DOWN_LEFT,\n    (0, +0): Direction.DOWN_RIGHT,\n}\n\nclass WalkManager:\n    def __init__(self):\n        # state of movement keys\n        self.w = False\n        self.a = False\n        self.s = False\n        self.d = False\n\n        # move speed (pixel per frame)\n        self.v = Preferences.MoveSpeed\n\n    # --- Movement Resolvers ---\n\n    def get_velocity(self) -> Tuple[int, int]:\n        \"\"\"\n        Returns the velocity vector based on the current key states.\n        If both keys in a direction are pressed, they cancel each other out.\n        \"\"\"\n        vx = 0\n        vy = 0\n        if self.a != self.d:\n            vx = -self.v if self.a else self.v\n        if self.w != self.s:\n            vy = -self.v if self.w else self.v\n        return vx, vy\n\n    def is_moving(self) -> bool:\n        \"\"\"\n        Returns True if either vertical or horizontal movement is occurring.\n        \"\"\"\n        return (self.w != self.s) or (self.a != self.d)\n\n    def get_direction(self):\n        \"\"\"\n        Returns a string representing the current movement direction for animation purposes.\n        \"\"\"\n        ver = 0\n        hor = 0\n        if self.w != self.s:\n            ver = -1 if self.w else 1\n        if self.a != self.d:\n            hor = -1 if self.a else 1\n        return DirectionMap[(ver, hor)]\n\n    # --- Event Recorders ---\n\n    def record_key_press(self, event: Gdk.Event):\n        key = event.keyval\n        match key:\n            case Gdk.KEY_w:\n                self.w = True\n            case Gdk.KEY_a:\n                self.a = True\n            case Gdk.KEY_s:\n                self.s = True\n            case Gdk.KEY_d:\n                self.d = True\n            case _:\n                pass\n\n    def record_key_release(self, event: Gdk.Event):\n        key = event.keyval\n        match key:\n            case Gdk.KEY_w:\n                self.w = False\n            case Gdk.KEY_a:\n                self.a = False\n            case Gdk.KEY_s:\n                self.s = False\n            case Gdk.KEY_d:\n                self.d = False\n            case _:\n                pass\n\n    def record_mouse_leave(self):\n        # stop all movement when mouse leaves window\n        self.w = False\n        self.a = False\n        self.s = False\n        self.d = False"}
{"code_id": "multi-agent-marketplace_packages_magentic-marketplace_src_magentic_marketplace_platform_client_resources_base.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\multi-agent-marketplace_packages_magentic-marketplace_src_magentic_marketplace_platform_client_resources_base.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\multi-agent-marketplace_packages_magentic-marketplace_src_magentic_marketplace_platform_client_resources_base.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\multi-agent-marketplace_packages_magentic-marketplace_src_magentic_marketplace_platform_client_resources_base.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "\"\"\"API resource class with agent ID handling.\"\"\"\nfrom typing import Any\nfrom ..base import BaseClient\n\nclass BaseResource:\n    \"\"\"Base class for API resources with agent ID support.\"\"\"\n\n    def __init__(self, base_client: BaseClient):\n        \"\"\"Initialize resource with base client.\n\n        Args:\n            base_client: The BaseClient instance for making HTTP requests\n        \"\"\"\n        self._base_client = base_client\n        self._agent_id: str | None = None\n\n    def set_agent_id(self, agent_id: str) -> None:\n        \"\"\"Set the agent ID for requests.\n\n        Args:\n            agent_id: The agent ID to use\n        \"\"\"\n        self._agent_id = agent_id\n\n    @property\n    def agent_id(self) -> str | None:\n        \"\"\"Get the current agent ID.\n\n        Returns:\n            str | None: The agent ID or None if not set\n        \"\"\"\n        return self._agent_id\n\n    async def request(\n        self,\n        method: str,\n        path: str,\n        params: Any = None,\n        json_data: dict[str, Any] | None = None,\n        headers: dict[str, str] | None = None,\n    ) -> dict[str, Any]:\n        \"\"\"Make an HTTP request with automatic agent ID injection.\n\n        Args:\n            method: HTTP method (GET, POST, etc.)\n            path: API endpoint path\n            params: Optional query parameters\n            json_data: Optional JSON body\n            headers: Optional additional headers\n\n        Returns:\n            dict: Parsed JSON response\n        \"\"\"\n        # Add agent ID to headers if set\n        request_headers = headers or {}\n        if self._agent_id:\n            request_headers[\"X-Agent-Id\"] = self._agent_id\n\n        return await self._base_client.request(\n            method, path, params, json_data, request_headers\n        )"}
{"code_id": "linux-desktop-gremlin_src_fsm_walk_manager.py", "ratio": 6, "num_pages": 3, "image_paths": ["./experiment_output\\images_glm46v\\linux-desktop-gremlin_src_fsm_walk_manager.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\linux-desktop-gremlin_src_fsm_walk_manager.py\\1024x1024_hl_nl\\page_002_ratio6.png", "./experiment_output\\images_glm46v\\linux-desktop-gremlin_src_fsm_walk_manager.py\\1024x1024_hl_nl\\page_003_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\linux-desktop-gremlin_src_fsm_walk_manager.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "multi-agent-marketplace_packages_magentic-marketplace_src_magentic_marketplace_platform_client_resources_base.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\multi-agent-marketplace_packages_magentic-marketplace_src_magentic_marketplace_platform_client_resources_base.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\multi-agent-marketplace_packages_magentic-marketplace_src_magentic_marketplace_platform_client_resources_base.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\multi-agent-marketplace_packages_magentic-marketplace_src_magentic_marketplace_platform_client_resources_base.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "\"\"\"API resource class with agent ID handling.\"\"\"\nfrom typing import Any\nfrom ..base import BaseClient\n\nclass BaseResource:\n    \"\"\"Base class for API resources with agent ID support.\"\"\"\n\n    def __init__(self, base_client: BaseClient):\n        \"\"\"Initialize resource with base client.\n\n        Args:\n            base_client: The BaseClient instance for making HTTP requests\n        \"\"\"\n        self._base_client = base_client\n        self._agent_id: str | None = None\n\n    def set_agent_id(self, agent_id: str) -> None:\n        \"\"\"Set the agent ID for requests.\n\n        Args:\n            agent_id: The agent ID to use\n        \"\"\"\n        self._agent_id = agent_id\n\n    @property\n    def agent_id(self) -> str | None:\n        \"\"\"Get the current agent ID.\n\n        Returns:\n            str | None: The agent ID or None if not set\n        \"\"\"\n        return self._agent_id\n\n    async def request(\n        self,\n        method: str,\n        path: str,\n        params: Any = None,\n        json_data: dict[str, Any] | None = None,\n        headers: dict[str, str] | None = None,\n    ) -> dict[str, Any]:\n        \"\"\"Make an HTTP request with automatic agent ID injection.\n\n        Args:\n            method: HTTP method (GET, POST, etc.)\n            path: API endpoint path\n            params: Optional query parameters\n            json_data: Optional JSON body\n            headers: Optional additional headers\n\n        Returns:\n            dict: Parsed JSON response\n        \"\"\"\n        # Add agent ID to headers if set\n        request_headers = headers or {}\n        if self._agent_id:\n            request_headers[\"X-Agent-Id\"] = self._agent_id\n\n        return await self._base_client.request(\n            method, path, params, json_data, request_headers\n        )"}
{"code_id": "linux-desktop-gremlin_src_fsm_walk_manager.py", "ratio": 8, "num_pages": 3, "image_paths": ["./experiment_output\\images_glm46v\\linux-desktop-gremlin_src_fsm_walk_manager.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\linux-desktop-gremlin_src_fsm_walk_manager.py\\1024x1024_hl_nl\\page_002_ratio8.png", "./experiment_output\\images_glm46v\\linux-desktop-gremlin_src_fsm_walk_manager.py\\1024x1024_hl_nl\\page_003_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\linux-desktop-gremlin_src_fsm_walk_manager.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "multi-agent-marketplace_packages_magentic-marketplace_src_magentic_marketplace_platform_client_resources_base.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\multi-agent-marketplace_packages_magentic-marketplace_src_magentic_marketplace_platform_client_resources_base.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\multi-agent-marketplace_packages_magentic-marketplace_src_magentic_marketplace_platform_client_resources_base.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\multi-agent-marketplace_packages_magentic-marketplace_src_magentic_marketplace_platform_client_resources_base.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": "\"\"\"Base class for API connections with agent ID handling.\"\"\"\nfrom . import Key\n\nclass BaseResource:\n    \"\"\"Base class for API connections with agent ID support.\"\"\"\n\n    def __init__(self, base_url: str):\n        \"\"\"Initialise resources with base url.\"\"\"\n        self._base_url = base_url\n        self._agent_id = None\n\n    def set_agent_id(self, agent_id: str) -> None:\n        \"\"\"Set the agent ID for resources.\"\"\"\n        self._agent_id = agent_id\n\n    def agent_id(self) -> str | None:\n        \"\"\"Get the current agent ID.\"\"\"\n        Returns:\n            str | None: The agent ID or None if not set.\n        \"\"\"\n        return self._agent_id\n\n    @staticmethod\n    def request():\n        \"\"\"Make an HTTP request with the associated agent ID included in the request.\"\"\"\n        method: HTTP method (GET, POST, etc.)\n        path: API's endpoint path\n        params: dict or list of query parameters\n        json_data: dict or list of JSON body\n        headers: dict or list of request headers\n\n        Returns:\n            dict: The current HTTP request.\n\n    def add_agent_id_to_headers(self, request_headers: dict = None) -> dict:\n        \"\"\"Add the agent ID to headers if set.\"\"\"\n        if not request_headers:\n            request_headers = {}\n        if self._agent_id:\n            request_headers[\"X-Agent-ID\"] = self._agent_id\n        return request_headers\n\n    def make_request(self, method: str, path: str, params: dict = None, json_data: dict = None, headers: dict = None) -> dict:\n        \"\"\"Make an HTTP request with the associated agent ID included in the request.\"\"\"\n        method: HTTP method (GET, POST, etc.)\n        path: API's endpoint path\n        params: dict or list of query parameters\n        json_data: dict or list of JSON body\n        headers: dict or list of request headers\n\n        Returns:\n            dict: The current HTTP request."}
{"code_id": "multi-agent-marketplace_packages_magentic-marketplace_src_magentic_marketplace_platform_client_resources_base.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\multi-agent-marketplace_packages_magentic-marketplace_src_magentic_marketplace_platform_client_resources_base.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\multi-agent-marketplace_packages_magentic-marketplace_src_magentic_marketplace_platform_client_resources_base.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\multi-agent-marketplace_packages_magentic-marketplace_src_magentic_marketplace_platform_client_resources_base.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": "\"\"\"These are classes with the agent id handling\"\"\"\nfrom . import agent_ids\n\nfrom . import agent_id\n\nclass AgentIdStore:\n    \"\"\"These are classes for API consumers with the agent id component.\"\"\"\n    def __init__(self, team_id=None, thread_id=None):\n        \"\"\"Initialize an consumer with these or none.\"\"\"\n        self._team_id = team_id\n        self._thread_id = thread_id\n        self._agent_id = None\n\n    def set_agent_id(self, agent_id: str) -> None:\n        \"\"\"Set the agent id for consumers.\"\"\"\n        self._agent_id = agent_id\n\n    def get_agent_id(self) -> str | None:\n        \"\"\"Get the current agent ID.\"\"\"\n        return self._agent_id\n\n    def is_agent_id(self) -> bool:\n        \"\"\"Is there the agent id or None if not set.\"\"\"\n        return self._agent_id is not None\n\n    async def consume(\n        self,\n        event: dict,\n        agent_id: str,\n        team_id: str | None = None,\n        thread_id: str | None = None,\n    ) -> None:\n        \"\"\"Consume an API event and continue the adding API capability.\"\"\"\n        self._team_id = team_id\n        self._thread_id = thread_id\n        self._agent_id = agent_id\n\n        # Check if the agent id is already set\n        if self._agent_id is not None:\n            # If the agent id is already set, we don't need to set it again\n            pass\n        else:\n            # If the agent id is not set, we set it\n            self._agent_id = agent_id\n\n        # Now we can continue with the rest of the consume method\n        # For example, we can call the parent class's consume method\n        # But since we don't have the parent class, we'll just leave it as is\n        # For now, we'll just return\n        return await super().consume(\n            event=event,\n            agent_id=agent_id,\n            team_id=team_id,\n            thread_id=thread_id,\n        )"}
{"code_id": "muwanx_src_muwanx_project.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\muwanx_src_muwanx_project.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\muwanx_src_muwanx_project.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\muwanx_src_muwanx_project.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "\"\"\"Project configuration and management.\n\nThis module defines the ProjectConfig dataclass and ProjectHandle class for managing projects containing multiple scenes.\n\"\"\"\n\nfrom __future__ import annotations\n\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import TYPE_CHECKING, Any\n\nimport mujoco\n\nfrom .scene import SceneConfig, SceneHandle\n\nif TYPE_CHECKING:\n    from .builder import Builder\n\n@dataclass\nclass ProjectConfig:\n    \"\"\"Configuration for a project containing multiple scenes.\"\"\"\n\n    name: str\n    \"\"\"Name of the project.\"\"\"\n\n    id: str | None = None\n    \"\"\"Optional ID for the project used in URL routing (e.g., 'menagerie' for /#/menagerie/).\"\"\"\n\n    scenes: list[SceneConfig] = field(default_factory=list)\n    \"\"\"List of scenes in the project.\"\"\"\n\nclass ProjectHandle:\n    \"\"\"Handle for adding scenes and configuring a project.\n\n    This class provides methods for adding scenes and customizing project properties.\n    Similar to viser's server handle, this allows for hierarchical configuration.\n    \"\"\"\n\n    def __init__(self, project_config: ProjectConfig, builder: Builder) -> None:\n        self._config = project_config\n        self._builder = builder\n\n    @property\n    def name(self) -> str:\n        \"\"\"Name of the project.\"\"\"\n        return self._config.name\n\n    @property\n    def id(self) -> str | None:\n        \"\"\"Optional ID of the project for URL routing.\"\"\"\n        return self._config.id\n\n    def add_scene(\n        self,\n        model: mujoco.MjModel | str | Path,\n        name: str,\n        *,\n        metadata: dict[str, Any] | None = None,\n        source_path: str | None = None,\n    ) -> SceneHandle:\n        \"\"\"Add a MuJoCo scene to this project.\n\n        Args:\n            model: MuJoCo model for the scene, or a path to an MJCF XML file.\n            name: Name for the scene (displayed in the UI).\n            metadata: Optional metadata dictionary for the scene.\n            source_path: Optional MJCF XML path for asset copying.\n\n        Returns:\n            SceneHandle for adding policies and further configuration.\n        \"\"\"\n        if metadata is None:\n            metadata = {}\n\n        if isinstance(model, (str, Path))):\n            source_path = str(model)\n            model = mujoco.MjModel.from_xml_path(str(model))\n\n        scene_config = SceneConfig(\n            name=name,\n            model=model,\n            metadata=metadata,\n            source_path=source_path,\n        )\n        self._config.scenes.append(scene_config)\n        return SceneHandle(scene_config, self)\n\n__all__ = [\"ProjectConfig\", \"ProjectHandle\"]"}
{"code_id": "multi-agent-marketplace_packages_magentic-marketplace_src_magentic_marketplace_platform_client_resources_base.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\multi-agent-marketplace_packages_magentic-marketplace_src_magentic_marketplace_platform_client_resources_base.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\multi-agent-marketplace_packages_magentic-marketplace_src_magentic_marketplace_platform_client_resources_base.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\multi-agent-marketplace_packages_magentic-marketplace_src_magentic_marketplace_platform_client_resources_base.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "\"\"\"Base resource class with agent ID handling.\"\"\"\nfrom typing import Any\nfrom ..base import BaseClient\n\nclass BaseResource:\n    \"\"\"Base class for API resources with agent ID support.\"\"\"\n    def __init__(self, base_client: BaseClient):\n        \"\"\"Initialize resource with Base client.\n\n        Args:\n            base_client: The BaseClient instance for making HTTP requests\n        \"\"\"\n        self._base_client = base_client\n        self._agent_id: str | None = None\n    def set_agent_id(self, agent_id: str) -> None:\n        \"\"\"Set the agent ID for requests.\n\n        Args:\n            agent_id: The agent ID to use\n        \"\"\"\n        self._agent_id = agent_id\n    @property\n    def agent_id(self) -> str | None:\n        \"\"\"Get the current agent ID.\n\n        Returns:\n            str | None: The agent ID or None if not set\n        \"\"\"\n        return self._agent_id\n    async def request(\n        self,\n        method: str,\n        path: str,\n        params: Any = None,\n        json_data: dict[str, Any] | None = None,\n        headers: dict[str, str] | None = None,\n    ) -> dict[str, Any]:\n        \"\"\"Make an HTTP request with automatic agent ID injection.\n\n        Args:\n            method: HTTP method (GET, POST, etc.)\n            path: API endpoint path\n            params: Optional query parameters\n            json_data: Optional JSON body\n            headers: Optional additional headers\n        \"\"\"\n        # Add agent ID to headers if set\n        request_headers = headers or {}\n        if self._agent_id:\n            request_headers[\"X-Agent-Id\"] = self._agent_id\n        return await self._base_client.request(\n            method, path, params, json_data, request_headers\n        )"}
{"code_id": "muwanx_src_muwanx_project.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\muwanx_src_muwanx_project.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\muwanx_src_muwanx_project.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\muwanx_src_muwanx_project.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "from __future__ import annotations\n\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import TYPE_CHECKING, Any\n\nimport mujoco\n\nfrom .scene import SceneConfig, SceneHandle\n\nif TYPE_CHECKING:\n    from .builder import Builder\n\n@dataclass\nclass ProjectConfig:\n    \"\"\"Configuration for a project containing multiple scenes.\"\"\"\n\n    name: str\n    \"\"\"Name of the project.\"\"\"\n\n    id: str | None = None\n    \"\"\"Optional ID for the project used in URL routing (e.g. 'menagerie' for /menagerie/).\"\"\"\n\n    scenes: list[SceneConfig] = field(default_factory=list)\n    \"\"\"List of scenes in the project.\"\"\"\n\nclass ProjectHandle:\n    \"\"\"Handle for adding scenes and configuring a project.\n\n    This class provides methods for adding scenes and customizing project properties.\n    Similar to viser's server handle, this allows for hierarchical configuration.\n    \"\"\"\n\n    def __init__(self, project_config: ProjectConfig, builder: Builder) -> None:\n        self._config = project_config\n        self._builder = builder\n\n    @property\n    def name(self) -> str:\n        return self._config.name\n\n    @property\n    def id(self) -> str | None:\n        \"\"\"Optional ID of the project for URL routing.\"\"\"\n        return self._config.id\n\n    def add_scene(\n        self,\n        model: mujoco.MjModel | str | Path,\n        name: str,\n        *,\n        metadata: dict[str, Any] | None = None,\n        source_path: str | None = None,\n    ) -> SceneHandle:\n        \"\"\"Add a MuJoCo scene to this project.\n\n        Args:\n            model: MuJoCo model for the scene, or a path to an MJCF XML file.\n            name: Name for the scene (displayed in the GUI).\n            metadata: Optional metadata dictionary for the scene.\n            source_path: Optional MJCF XML path for asset copying.\n\n        Returns:\n            SceneHandle for adding policies and further configuration.\n        \"\"\"\n        if metadata is None:\n            metadata = {}\n\n        if isinstance(model, (str, Path))):\n            source_path = str(model)\n            model = mujoco.MjModel.from_xml_path(str(model))\n\n        scene_config = SceneConfig(\n            name=name,\n            model=model,\n            metadata=metadata,\n            source_path=source_path,\n        )\n        self._config.scenes.append(scene_config)\n        return SceneHandle(scene_config, self)\n\n__all__ = [\"ProjectConfig\", \"ProjectHandle\"]"}
{"code_id": "muwanx_src_muwanx_project.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\muwanx_src_muwanx_project.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\muwanx_src_muwanx_project.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\muwanx_src_muwanx_project.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "# Project configuration and management.\n#\n# This module defines the ProjectConfig dataclass and ProjectHandle class for\n# managing projects containing multiple scenes.\n#\nfrom __future__ import annotations\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import TYPE_CHECKING, Any\nimport mujoco\nfrom .scene import SceneConfig, SceneHandle\nif TYPE_CHECKING:\n    from .builder import Builder\n@dataclass\nclass ProjectConfig:\n    \"\"\"Configuration for a project containing multiple scenes.\"\"\"\n    name: str\n    \"\"\"Name of the project.\"\"\"\n    id: str | None = None\n    \"\"\"Optional ID for the project used in URL routing (e.g., 'menagerie' for /#menagerie/).\"\"\"\n    scenes: list[SceneConfig] = field(default_factory=list)\n    \"\"\"List of scenes in the project.\"\"\"\nclass ProjectHandle:\n    \"\"\"Handle for adding scenes and configuring a project.\n    This class provides methods for adding scenes and customizing project properties.\n    Similar to viser's server handle, this allows for hierarchical configuration.\n    \"\"\"\n    def __init__(self, project_config: ProjectConfig, builder: Builder) -> None:\n        self._config = project_config\n        self._builder = builder\n    @property\n    def name(self) -> str:\n        \"\"\"Name of the project.\"\"\"\n        return self._config.name\n    @property\n    def id(self) -> str | None:\n        \"\"\"Optional ID of the project for URL routing.\"\"\"\n        return self._config.id\n    def add_scene(\n        self,\n        model: mujoco.MjModel | str | Path,\n        name: str,\n        *,\n        metadata: dict[str, Any] | None = None,\n        source_path: str | None = None,\n    ) -> SceneHandle:\n        \"\"\"Add a MuJoCo scene to this project.\n        Args:\n            model: MuJoCo model for the scene, or a path to an MJCF XML file.\n            name: Name for the scene (displayed in the UI).\n            metadata: Optional metadata dictionary for the scene.\n            source_path: Optional MJCF XML path for asset copying.\n        Returns:\n            SceneHandle for adding policies and further configuration.\n        \"\"\"\n        if metadata is None:\n            metadata = {}\n        if isinstance(model, (str, Path))):\n            source_path = str(model)\n            model = mujoco.MjModel.from_xml_path(str(model))\n        scene_config = SceneConfig(\n            name=name,\n            model=model,\n            metadata=metadata,\n            source_path=source_path,\n        )\n        self._config.scenes.append(scene_config)\n        return SceneHandle(scene_config, self)\n\n__all__ = [\"ProjectConfig\", \"ProjectHandle\"]"}
{"code_id": "mve-collection_src_minio-docker-delta_minio_delta.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\mve-collection_src_minio-docker-delta_minio_delta.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\mve-collection_src_minio-docker-delta_minio_delta.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\mve-collection_src_minio-docker-delta_minio_delta.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "from dotenv import load_dotenv\nfrom deltalake import DeltaTable, write_deltalake\nimport pandas as pd\nfrom typing import Optional, List\n\nload_dotenv()\n\nclass MinioDelta:\n    def __init__(self):\n        self.endpoint = os.getenv(\"MINIO_ENDPOINT\")\n        self.access_key = os.getenv(\"MINIO_ROOT_USER\")\n        self.secret_key = os.getenv(\"MINIO_ROOT_PASSWORD\")\n        self.bucket = os.getenv(\"BUCKET_NAME\")\n\n        self.storage_options = {\n            \"AWS_ENDPOINT_URL\": self.endpoint,\n            \"AWS_ACCESS_KEY_ID\": self.access_key,\n            \"AWS_SECRET_ACCESS_KEY\": self.secret_key,\n            \"AWS_ALLOW_HTTP\": \"true\",\n            \"aws_conditional_put\": \"etag\",\n        }\n\n    def write(\n        self,\n        df: pd.DataFrame,\n        path: str,\n        mode: str = \"overwrite\",\n        partition_by: Optional[List[str]] = None,\n        predicate: Optional[str] = None\n    ) -> None:\n        write_deltalake(\n            table_or_uri=f\"s3://{self.bucket}/{path}\",\n            data=df,\n            mode=mode,\n            partition_by=partition_by,\n            predicate=predicate,\n            storage_options=self.storage_options\n        )\n\n    def read(\n        self,\n        path: str,\n        columns: Optional[List[str]] = None,\n        filters: Optional[List] = None\n    ) -> pd.DataFrame:\n        full_path = f\"s3://{self.bucket}/{path}\"\n        dt = DeltaTable(full_path, storage_options=self.storage_options)\n        return dt.to_pandas(columns=columns, filters=filters)"}
{"code_id": "muwanx_src_muwanx_project.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\muwanx_src_muwanx_project.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\muwanx_src_muwanx_project.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\muwanx_src_muwanx_project.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": "# Configuration and management\n# This module defines the configuration parameters and management classes for\n# managing principals, certificates, and trust stores\n\nfrom __future__ import annotations\n\nfrom datetime import datetime, timedelta\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Tuple, Union\n\nclass Principal:\n    \"\"\"Base principal for a principal management application\"\"\"\n    \n    def __init__(self, name: str, description: str = \"\"):\n        \"\"\"Initialize the principal\"\"\"\n        self.name = name\n        self.description = description\n        self.created_at = datetime.now()\n        self.updated_at = datetime.now()\n    \n    def __str__(self) -> str:\n        \"\"\"String representation of the principal\"\"\"\n        return f\"Principal(name={self.name}, description={self.description})\"\n    \n    def update(self, name: Optional[str] = None, description: Optional[str] = None):\n        \"\"\"Update the principal's attributes\"\"\"\n        if name is not None:\n            self.name = name\n        if description is not None:\n            self.description = description\n        self.updated_at = datetime.now()\n    \n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"Convert the principal to a dictionary\"\"\"\n        return {\n            \"name\": self.name,\n            \"description\": self.description,\n            \"created_at\": self.created_at.isoformat(),\n            \"updated_at\": self.updated_at.isoformat()\n        }\n\nclass Certificate(Principal):\n    \"\"\"Base certificate for a principal management application\"\"\"\n    \n    def __init__(self, name: str, description: str = \"\", cert_data: str = \"\"):\n        \"\"\"Initialize the certificate\"\"\"\n        super().__init__(name, description)\n        self.cert_data = cert_data\n        self.issuer = \"\"\n        self.subject = \"\"\n        self.not_before = datetime.now()\n        self.not_after = datetime.now()\n    \n    def __str__(self) -> str:\n        \"\"\"String representation of the certificate\"\"\"\n        return f\"Certificate(name={self.name}, description={self.description}, cert_data={self.cert_data})\"\n    \n    def update(self, name: Optional[str] = None, description: Optional[str] = None, cert_data: Optional[str] = None):\n        \"\"\"Update the certificate's attributes\"\"\"\n        super().update(name, description)\n        if cert_data is not None:\n            self.cert_data = cert_data\n        self.updated_at = datetime.now()\n    \n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"Convert the certificate to a dictionary\"\"\"\n        principal_dict = super().to_dict()\n        return {\n            **principal_dict,\n            \"cert_data\": self.cert_data,\n            \"issuer\": self.issuer,\n            \"subject\": self.subject,\n            \"not_before\": self.not_before.isoformat(),\n            \"not_after\": self.not_after.isoformat()\n        }"}
{"code_id": "mve-collection_src_minio-docker-delta_minio_delta.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\mve-collection_src_minio-docker-delta_minio_delta.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\mve-collection_src_minio-docker-delta_minio_delta.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\mve-collection_src_minio-docker-delta_minio_delta.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "from dotenv import load_dotenv\nfrom deltalake import DeltaTable, write_deltalake\nimport pandas as pd\nfrom typing import Optional, List\n\nload_dotenv()\n\nclass MinioDelta:\n    def __init__(self):\n        self.endpoint = os.getenv(\"MINIO_ENDPOINT\")\n        self.access_key = os.getenv(\"MINIO_ROOT_USER\")\n        self.secret_key = os.getenv(\"MINIO_ROOT_PASSWORD\")\n        self.bucket = os.getenv(\"BUCKET_NAME\")\n\n        self.storage_options = {\n            \"AWS_ENDPOINT_URL\": self.endpoint,\n            \"AWS_ACCESS_KEY_ID\": self.access_key,\n            \"AWS_SECRET_ACCESS_KEY\": self.secret_key,\n            \"AWS_ALLOW_HTTP\": \"true\",\n            \"aws_conditional_put\": \"etag\",\n        }\n\n    def write(\n        self,\n        df: pd.DataFrame,\n        path: str,\n        mode: str = \"overwrite\",\n        partition_by: Optional[List[str]] = None,\n        predicate: Optional[str] = None\n    ) -> None:\n        write_deltalake(\n            table_or_uri=f\"s3://{self.bucket}/{path}\",\n            data=df,\n            mode=mode,\n            partition_by=partition_by,\n            predicate=predicate,\n            storage_options=self.storage_options\n        )\n\n    def read(\n        self,\n        path: str,\n        columns: Optional[List[str]] = None,\n        filters: Optional[List] = None\n    ) -> pd.DataFrame:\n        full_path = f\"s3://{self.bucket}/{path}\"\n        dt = DeltaTable(full_path, storage_options=self.storage_options)\n        return dt.to_pandas(columns=columns, filters=filters)"}
{"code_id": "muwanx_src_muwanx_project.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\muwanx_src_muwanx_project.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\muwanx_src_muwanx_project.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\muwanx_src_muwanx_project.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "mve-collection_src_minio-docker-delta_minio_delta.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\mve-collection_src_minio-docker-delta_minio_delta.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\mve-collection_src_minio-docker-delta_minio_delta.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\mve-collection_src_minio-docker-delta_minio_delta.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "from . import load_dataset\nfrom deltalake import DeltaTable, write_deltalake\nimport pandas as pd\nfrom typing import Optional, List\n\nload_dataset()\n\nclass MinioDelta:\n    def __init__(self):\n        self.endpoint = os.getenv(\"MINIO_ENDPOINT\")\n        self.access_key = os.getenv(\"MINIO_ROOT_USER\")\n        self.secret_key = os.getenv(\"MINIO_ROOT_PASSWORD\")\n        self.bucket = os.getenv(\"BUCKET_NAME\")\n\n        self.storage_options = {\n            \"AWS_ENDPOINT_URL\": self.endpoint,\n            \"AWS_ACCESS_KEY_ID\": self.access_key,\n            \"AWS_SECRET_ACCESS_KEY\": self.secret_key,\n            \"AWS_ALLOW_HTTP\": \"true\",\n            \"aws_conditional_put\": \"etag\",\n        }\n\n    def write(\n        self,\n        df: pd.DataFrame,\n        path: str,\n        mode: str = \"overwrite\",\n        partition_by: Optional[List[str]] = None,\n        predicate: Optional[str] = None\n    ) -> None:\n        write_deltalake(\n            table_or_uri=f\"s3a://{self.bucket}/{path}\",\n            data=df,\n            mode=mode,\n            partition_by=partition_by,\n            predicate=predicate,\n            storage_options=self.storage_options\n        )\n\n    def read(\n        self,\n        path: str,\n        columns: Optional[List[str]] = None,\n        filters: Optional[List] = None\n    ) -> pd.DataFrame:\n        full_path = f\"s3a://{self.bucket}/{path}\"\n        dt = DeltaTable(full_path, storage_options=self.storage_options)\n        return dt.to_pandas(columns=columns, filters=filters)"}
{"code_id": "myfy_packages_myfy-data_myfy_data_session.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\myfy_packages_myfy-data_myfy_data_session.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\myfy_packages_myfy-data_myfy_data_session.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\myfy_packages_myfy-data_myfy_data_session.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "\"\"\"Async session management.\n\nProvides async session factory and context managers for database operations.\n\"\"\"\n\nfrom collections.abc import AsyncIterator\nfrom contextlib import asynccontextmanager\n\nfrom sqlalchemy.ext.asyncio import AsyncSession, async_sessionmaker\n\n# Note: AsyncIterator is still used by session_context method\n\nclass SessionFactory:\n    \"\"\"\n    Factory for creating async database sessions.\n\n    This class wraps SQLAlchemy's async_sessionmaker and provides\n    a clean interface for session creation.\n    \"\"\"\n\n    def __init__(self, sessionmaker: async_sessionmaker[AsyncSession]):\n        \"\"\"\n        Initialize session factory.\n\n        Args:\n            sessionmaker: SQLAlchemy async sessionmaker instance\n        \"\"\"\n        self._sessionmaker = sessionmaker\n\n    def create_session(self) -> AsyncSession:\n        \"\"\"\n        Create a new async session.\n\n        Returns:\n            AsyncSession instance\n        \"\"\"\n        return self._sessionmaker()\n\n    @asynccontextmanager\n    async def session_context(self) -> AsyncIterator[AsyncSession]:\n        \"\"\"\n        Context manager for automatic session lifecycle.\n\n        Automatically commits on success, rolls back on exception,\n        and closes the session in all cases.\n\n        Example:\n            async with session_factory.session_context() as session:\n                result = await session.execute(query)\n                await session.commit()\n\n        Yields:\n            AsyncSession instance\n        \"\"\"\n        session = self.create_session()\n        try:\n            yield session\n            await session.commit()\n        except Exception:\n            await session.rollback()\n            raise\n        finally:\n            await session.close()\n\ndef get_session_for_request(session_factory: SessionFactory) -> AsyncSession:\n    \"\"\"\n    Dependency provider for REQUEST-scoped database sessions.\n\n    This function is registered as a REQUEST-scoped provider in the DI container.\n    Each HTTP request gets its own session. The session lifecycle (commit/rollback/close)\n    is managed by the ASGI adapter via cleanup callbacks.\n\n    Args:\n        session_factory: SessionFactory injected from DI container\n\n    Returns:\n        AsyncSession instance for the current request\n    \"\"\"\n    return session_factory.create_session()"}
{"code_id": "myfy_packages_myfy-data_myfy_data_session.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\myfy_packages_myfy-data_myfy_data_session.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\myfy_packages_myfy-data_myfy_data_session.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\myfy_packages_myfy-data_myfy_data_session.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "\"\"\"Async session management.\n\nProvides async session factory and context managers for database operations.\n\"\"\"\n\nfrom collections.abc import AsyncIterator\nfrom contextlib import asynccontextmanager\n\nfrom sqlalchemy.ext.asyncio import AsyncSession, async_sessionmaker\n\n# Note: AsyncIterator is still used by session_context method\n\nclass SessionFactory:\n    \"\"\"\n    Factory for creating async database sessions.\n\n    This class wraps SQLAlchemy's async_sessionmaker and provides\n    a clean interface for session creation.\n    \"\"\"\n\n    def __init__(self, sessionmaker: async_sessionmaker[AsyncSession]):\n        \"\"\"\n        Initialize session factory.\n\n        Args:\n            sessionmaker: SQLAlchemy async sessionmaker instance\n        \"\"\"\n        self._sessionmaker = sessionmaker\n\n    def create_session(self) -> AsyncSession:\n        \"\"\"\n        Create a new async session.\n\n        Returns:\n            AsyncSession instance\n        \"\"\"\n        return self._sessionmaker()\n\n    @asynccontextmanager\n    async def session_context(self) -> AsyncIterator[AsyncSession]:\n        \"\"\"\n        Context manager for automatic session lifecycle.\n\n        Automatically commits on success, rolls back on exception,\n        and closes the session in all cases.\n\n        Example:\n            async with session_factory.session_context() as session:\n                result = await session.execute(query)\n                await session.commit()\n\n        Yields:\n            AsyncSession instance\n        \"\"\"\n        session = self.create_session()\n        try:\n            yield session\n            await session.commit()\n        except Exception:\n            await session.rollback()\n            raise\n        finally:\n            await session.close()\n\ndef get_session_for_request(session_factory: SessionFactory) -> AsyncSession:\n    \"\"\"\n    Dependency provider for REQUEST-scoped database sessions.\n\n    This function is registered as a REQUEST-scoped provider in the DI container.\n    Each HTTP request gets its own session. The session lifecycle (commit/rollback/close)\n    is managed by the ASGI adapter via cleanup callbacks.\n\n    Args:\n        session_factory: SessionFactory injected from DI container\n\n    Returns:\n        AsyncSession instance for the current request\n    \"\"\"\n    return session_factory.create_session()"}
{"code_id": "mve-collection_src_minio-docker-delta_minio_delta.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\mve-collection_src_minio-docker-delta_minio_delta.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\mve-collection_src_minio-docker-delta_minio_delta.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\mve-collection_src_minio-docker-delta_minio_delta.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "mve-collection_src_minio-docker-delta_minio_delta.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\mve-collection_src_minio-docker-delta_minio_delta.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\mve-collection_src_minio-docker-delta_minio_delta.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\mve-collection_src_minio-docker-delta_minio_delta.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "nano-trm_src_nn_data_dummy_datamodule.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\nano-trm_src_nn_data_dummy_datamodule.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\nano-trm_src_nn_data_dummy_datamodule.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\nano-trm_src_nn_data_dummy_datamodule.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "from lightning import LightningDataModule\nfrom torch.utils.data import DataLoader, Dataset\n\n\nclass DummyDataset(Dataset):\n    \"\"\"Dummy dataset for self-play training.\"\"\"\n    def __init__(self, length=100):\n        self.length = length\n\n    def __len__(self):\n        return self.length\n\n    def __getitem__(self, idx):\n        return {}  # Return empty dict\n\n\nclass DummyDataModule(LightningDataModule):\n    \"\"\"Dummy datamodule for pure self-play training.\"\"\"\n    def __init__(\n        self,\n        batch_size: int = 32,\n        num_workers: int = 0,\n    ):\n        super().__init__()\n        self.batch_size = batch_size\n        self.num_workers = num_workers\n\n        # Properties needed by model\n        self.num_puzzles = 1  # Single game type\n        self.pad_value = 0\n        self.max_grid_size = 7\n        self.vocab_size = 25  # Enough for board + move + outcome tokens\n        self.seq_len = 42\n\n    def setup(self, stage=None):\n        self.train_dataset = DummyDataset()\n        self.val_dataset = DummyDataset(length=100)\n        self.test_dataset = DummyDataset(length=100)\n\n    def train_dataloader(self):\n        return DataLoader(\n            self.train_dataset,\n            batch_size=1,  # Batch size handled in model\n            num_workers=0,\n            shuffle=False\n        )\n\n    def val_dataloader(self):\n        return DataLoader(\n            self.val_dataset,\n            batch_size=1,\n            num_workers=0\n        )\n\n    def test_dataloader(self):\n        return DataLoader(\n            self.test_dataset,\n            batch_size=1,\n            num_workers=0\n        )"}
{"code_id": "myfy_packages_myfy-data_myfy_data_session.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\myfy_packages_myfy-data_myfy_data_session.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\myfy_packages_myfy-data_myfy_data_session.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\myfy_packages_myfy-data_myfy_data_session.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "# Async session management.\n\n# Provides async session factory and context managers for database operations.\n\nfrom collections.abc import AsyncIterator\nfrom contextlib import asynccontextmanager\n\nfrom sqlalchemy.ext.asyncio import AsyncSession, async_sessionmaker\n\n# Note: AsyncIterator is still used by session_context method\n\nclass SessionFactory:\n    \"\"\"\n    Factory for creating async database sessions.\n\n    This class wraps SQLAlchemy's async_sessionmaker and provides\n    a clean interface for session creation.\n    \"\"\"\n\n    def __init__(self, sessionmaker: async_sessionmaker[AsyncSession]):\n        \"\"\"\n        Initialize session factory.\n\n        Args:\n            sessionmaker: SQLAlchemy async sessionmaker instance\n        \"\"\"\n        self._sessionmaker = sessionmaker\n\n    def create_session(self) -> AsyncSession:\n        \"\"\"\n        Create a new async session.\n\n        Returns:\n            AsyncSession instance\n        \"\"\"\n        return self._sessionmaker()\n\n@asynccontextmanager\nasync def session_context(self) -> AsyncIterator[AsyncSession]:\n    \"\"\"\n    Context manager for automatic session lifecycle.\n\n    Automatically commits on success, rolls back on exception,\n    and closes the session in all cases.\n\n    Example:\n        async with session_factory.session_context() as session:\n            result = await session.execute(query)\n            await session.commit()\n\n    Yields:\n        AsyncSession instance\n    \"\"\"\n    session = self.create_session()\n    try:\n        yield session\n        await session.commit()\n    except Exception:\n        await session.rollback()\n        raise\n    finally:\n        await session.close()\n\ndef get_session_for_request(session_factory: SessionFactory) -> AsyncSession:\n    \"\"\"\n    Dependency provider for REQUEST-scoped database sessions.\n\n    This function is registered as a REQUEST-scoped provider in the DI container.\n    Each HTTP request gets its own session. The session lifecycle (commit/rollback/close)\n    is managed by the ASGI adapter via cleanup callbacks.\n\n    Args:\n        session_factory: SessionFactory injected from DI container\n\n    Returns:\n        AsyncSession instance for the current request\n    \"\"\"\n    return session_factory.create_session()"}
{"code_id": "nano-trm_src_nn_data_dummy_datamodule.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\nano-trm_src_nn_data_dummy_datamodule.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\nano-trm_src_nn_data_dummy_datamodule.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\nano-trm_src_nn_data_dummy_datamodule.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "from data.dummy_dataset import DummyDataset\nfrom lightning import LightningDataModule\nfrom torch.utils.data import DataLoader, Dataset\n\n\nclass DummyDataset(Dataset):\n    \"\"\"Dummy dataset for self-play training.\"\"\"\n    def __init__(self, length=100):\n        self.length = length\n\n    def __len__(self):\n        return self.length\n\n    def __getitem__(self, idx):\n        return {}  # Return empty dict\n\n\nclass DummyDataModule(LightningDataModule):\n    \"\"\"Dummy data module for pure self-play training.\"\"\"\n    def __init__(\n        self,\n        batch_size: int = 32,\n        num_workers: int = 0,\n    ):\n        super().__init__()\n        self.batch_size = batch_size\n        self.num_workers = num_workers\n\n        # Properties needed by model\n        self.num_puzzles = 1  # Single game type\n        self.pad_value = 0\n        self.max_grid_size = 7\n        self.vocab_size = 25  # Enough for board + move + outcome tokens\n        self.sms_len = 42\n\n    def setup(self, stage=None):\n        self.train_dataset = DummyDataset()\n        self.val_dataset = DummyDataset(length=100)\n        self.test_dataset = DummyDataset(length=100)\n\n    def train_dataloader(self):\n        return DataLoader(\n            self.train_dataset,\n            batch_size=1,  # Batch size handled in model\n            num_workers=0,\n            shuffle=False\n        )\n\n    def val_dataloader(self):\n        return DataLoader(\n            self.val_dataset,\n            batch_size=1,\n            num_workers=0\n        )\n\n    def test_dataloader(self):\n        return DataLoader(\n            self.test_dataset,\n            batch_size=1,\n            num_workers=0\n        )"}
{"code_id": "nano-trm_src_nn_data_dummy_datamodule.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\nano-trm_src_nn_data_dummy_datamodule.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\nano-trm_src_nn_data_dummy_datamodule.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\nano-trm_src_nn_data_dummy_datamodule.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "from lightning import LightningDataModule\nfrom torch.utils.data import DataLoader, Dataset\n\nclass DummyDataset(Dataset):\n    \"\"\"Dummy dataset for self-play training.\"\"\"\n    def __init__(self, length=100):\n        self.length = length\n\n    def __len__(self):\n        return self.length\n\n    def __getitem__(self, idx):\n        return {}  # Return empty dict\n\nclass DummyDataModule(LightningDataModule):\n    \"\"\"Dummy datamodule for pure self-play training.\"\"\"\n    def __init__(\n        self,\n        batch_size: int = 32,\n        num_workers: int = 0,\n    ):\n        super().__init__()\n        self.batch_size = batch_size\n        self.num_workers = num_workers\n\n        # Properties needed by model\n        self.num_puzzles = 1  # Single game type\n        self.pad_value = 0\n        self.max_grid_size = 7\n        self.vocab_size = 25  # Enough for board + move + outcome tokens\n        self.seq_len = 42\n\n    def setup(self, stage=None):\n        self.train_dataset = DummyDataset()\n        self.val_dataset = DummyDataset(length=100)\n        self.test_dataset = DummyDataset(length=100)\n\n    def train_dataloader(self):\n        return DataLoader(\n            self.train_dataset,\n            batch_size=1,  # Batch size handled in model\n            num_workers=0,\n            shuffle=False\n        )\n\ndef val_dataloader(self):\n    return DataLoader(\n        self.val_dataset,\n        batch_size=1,\n        num_workers=0\n    )\n\ndef test_dataloader(self):\n    return DataLoader(\n        self.test_dataset,\n        batch_size=1,\n        num_workers=0\n    )"}
{"code_id": "myfy_packages_myfy-data_myfy_data_session.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\myfy_packages_myfy-data_myfy_data_session.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\myfy_packages_myfy-data_myfy_data_session.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\myfy_packages_myfy-data_myfy_data_session.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "myfy_packages_myfy-data_myfy_data_session.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\myfy_packages_myfy-data_myfy_data_session.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\myfy_packages_myfy-data_myfy_data_session.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\myfy_packages_myfy-data_myfy_data_session.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "onyx-foss_backend_onyx_httpx_httpx_pool.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\onyx-foss_backend_onyx_httpx_httpx_pool.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\onyx-foss_backend_onyx_httpx_httpx_pool.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\onyx-foss_backend_onyx_httpx_httpx_pool.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "import threading\nfrom typing import Any\n\nimport httpx\n\ndef make_default_kwargs() -> dict[str, Any]:\n    return {\n        \"http2\": True,\n        \"limits\": httpx.Limits(),\n    }\n\nclass HttpxPool:\n    \"\"\"Class to manage a global httpx Client instance\"\"\"\n\n    _clients: dict[str, httpx.Client] = {}\n    _lock: threading.Lock = threading.Lock()\n\n    # Default parameters for creation\n\n    def __init__(self) -> None:\n        pass\n\n    @classmethod\n    def _init_client(cls, **kwargs: Any) -> httpx.Client:\n        \"\"\"Private helper method to create and return an httpx.Client.\"\"\"\n        merged_kwargs = {**make_default_kwargs(), **kwargs}\n        return httpx.Client(**merged_kwargs)\n\n    @classmethod\n    def init_client(cls, name: str, **kwargs: Any) -> None:\n        \"\"\"Allow the caller to init the client with extra params.\"\"\"\n        with cls._lock:\n            if name not in cls._clients:\n                cls._clients[name] = cls._init_client(**kwargs)\n\n    @classmethod\n    def close_client(cls, name: str) -> None:\n        \"\"\"Allow the caller to close the client.\"\"\"\n        with cls._lock:\n            client = cls._clients.pop(name, None)\n            if client:\n                client.close()\n\n    @classmethod\n    def close_all(cls) -> None:\n        \"\"\"Close all registered clients.\"\"\"\n        with cls._lock:\n            for client in cls._clients.values():\n                client.close()\n            cls._clients.clear()\n\n    @classmethod\n    def get(cls, name: str) -> httpx.Client:\n        \"\"\"Gets the httpx.Client. Will init to default settings if not init'd.\"\"\"\n        with cls._lock:\n            if name not in cls._clients:\n                cls._clients[name] = cls._init_client()\n            return cls._clients[name]"}
{"code_id": "onyx-foss_backend_onyx_httpx_httpx_pool.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\onyx-foss_backend_onyx_httpx_httpx_pool.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\onyx-foss_backend_onyx_httpx_httpx_pool.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\onyx-foss_backend_onyx_httpx_httpx_pool.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "import threading\nfrom typing import Any\nimport httpx\n\ndef make_default_kwargs() -> dict[str, Any]:\n    return {\n        \"http2\": True,\n        \"limits\": httpx.Limits(),\n    }\n\nclass HttpxPool:\n    \"\"\"Class to manage a global httpx Client instance\"\"\"\n\n    _clients: dict[str, httpx.Client] = {}\n    _lock: threading.Lock = threading.Lock()\n\n    # Default parameters for creation\n\n    def __init__(self) -> None:\n        pass\n\n    @classmethod\n    def _init_client(cls, **kwargs: Any) -> httpx.Client:\n        \"\"\"Private helper method to create and return an httpx.Client.\"\"\"\n        merged_kwargs = {**make_default_kwargs(), **kwargs}\n        return httpx.Client(**merged_kwargs)\n\n    @classmethod\n    def init_client(cls, name: str, **kwargs: Any) -> None:\n        \"\"\"Allow the caller to init the client with extra params.\"\"\"\n        with cls._lock:\n            if name not in cls._clients:\n                cls._clients[name] = cls._init_client(**kwargs)\n\n    @classmethod\n    def close_client(cls, name: str) -> None:\n        \"\"\"Allow the caller to close the client.\"\"\"\n        with cls._lock:\n            client = cls._clients.pop(name, None)\n            if client:\n                client.close()\n\n    @classmethod\n    def close_all(cls) -> None:\n        \"\"\"Close all registered clients.\"\"\"\n        with cls._lock:\n            for client in cls._clients.values():\n                client.close()\n            cls._clients.clear()\n\n    @classmethod\n    def get(cls, name: str) -> httpx.Client:\n        \"\"\"Gets the httpx.Client. Will init to default settings if not init'd.\"\"\"\n        with cls._lock:\n            if name not in cls._clients:\n                cls._clients[name] = cls._init_client()\n            return cls._clients[name]"}
{"code_id": "nano-trm_src_nn_data_dummy_datamodule.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\nano-trm_src_nn_data_dummy_datamodule.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\nano-trm_src_nn_data_dummy_datamodule.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\nano-trm_src_nn_data_dummy_datamodule.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "nano-trm_src_nn_data_dummy_datamodule.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\nano-trm_src_nn_data_dummy_datamodule.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\nano-trm_src_nn_data_dummy_datamodule.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\nano-trm_src_nn_data_dummy_datamodule.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "onyx-foss_backend_onyx_httpx_httpx_pool.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\onyx-foss_backend_onyx_httpx_httpx_pool.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\onyx-foss_backend_onyx_httpx_httpx_pool.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\onyx-foss_backend_onyx_httpx_httpx_pool.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "import threading\nfrom typing import Any\n\nimport httpx\n\ndef make_default_kwargs() -> dict[str, Any]:\n    return {\n        \"http2\": True,\n        \"limits\": httpx.Limits(),\n    }\n\nclass HttpxPool:\n    \"\"\"Class to manage a global Httpx Client instance\"\"\"\n\n    _clients: dict[str, httpx.Client] = {}\n    _lock: threading.Lock = threading.Lock()\n\n    # Default parameters for creation\n    def __init__(self) -> None:\n        pass\n\n    @classmethod\n    def _init_client(cls, **kwargs: Any) -> httpx.Client:\n        \"\"\"Private helper method to create and return an Httpx Client.\"\"\"\n        merged_kwargs = {**make_default_kwargs(), **kwargs}\n        return httpx.Client(**merged_kwargs)\n\n    @classmethod\n    def init_client(cls, name: str, **kwargs: Any) -> None:\n        \"\"\"Allow the caller to init the client with extra params.\"\"\"\n        with cls._lock:\n            if name not in cls._clients:\n                cls._clients[name] = cls._init_client(**kwargs)\n\n    @classmethod\n    def close_client(cls, name: str) -> None:\n        \"\"\"Allow the caller to close the client.\"\"\"\n        with cls._lock:\n            client = cls._clients.pop(name, None)\n            if client:\n                client.close()\n\n    @classmethod\n    def close_all(cls) -> None:\n        \"\"\"Close all registered clients.\"\"\"\n        with cls._lock:\n            for client in cls._clients.values():\n                client.close()\n            cls._clients.clear()\n\n    @classmethod\n    def get(cls, name: str) -> httpx.Client:\n        \"\"\"Gets the Httpx Client. Will init to default settings if not init'd.\"\"\"\n        with cls._lock:\n            if name not in cls._clients:\n                cls._clients[name] = cls._init_client()\n            return cls._clients[name]"}
{"code_id": "open-wearables_backend_app_database.py", "ratio": 1, "num_pages": 3, "image_paths": ["./experiment_output\\images_glm46v\\open-wearables_backend_app_database.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\open-wearables_backend_app_database.py\\1024x1024_hl_nl\\page_002_ratio1.png", "./experiment_output\\images_glm46v\\open-wearables_backend_app_database.py\\1024x1024_hl_nl\\page_003_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\open-wearables_backend_app_database.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "from collections.abc import AsyncGenerator, Iterator\nfrom typing import Annotated\nfrom uuid import UUID\n\nfrom fastapi import Depends\nfrom sqlalchemy import UUID as SQL_UUID\nfrom sqlalchemy import Engine, String, Text, create_engine, inspect\nfrom sqlalchemy.ext.asyncio import (\n    AsyncEngine,\n    AsyncSession,\n    async_sessionmaker,\n    create_async_engine,\n)\n\nfrom sqlalchemy.orm import (\n    DeclarativeBase,\n    Session,\n    declared_attr,\n    sessionmaker,\n)\n\nfrom app.config import settings\nfrom app.mappings import email, str_10, str_32, str_50, str_64, str_100, str_255\nfrom app.schemas.invitation import InvitationStatus\nfrom app.schemas.oauth import ConnectionStatus\nfrom app.utils.mappings_meta import AutoRelMeta\n\nengine = create_engine(\n    settings.db_uri,\n    pool_pre_ping=True,\n    pool_size=20,\n    max_overflow=30,\n    pool_timeout=30,\n    pool_recycle=3600,\n)\n\nasync_engine = create_async_engine(settings.db_uri)\n\ndef _prepare_sessionmaker(engine: Engine) -> sessionmaker:\n    return sessionmaker(autocommit=False, autoflush=False, bind=engine)\n\ndef _prepare_async_sessionmaker(engine: AsyncEngine) -> async_sessionmaker:\n    return async_sessionmaker(engine, expire_on_commit=False)\n\nclass BaseDbModel(DeclarativeBase, metaclass=AutoRelMeta):\n    @declared_attr\n    def tablename__(self) -> str:\n        return self.__name__.lower()\n\n    @property\n    def id_str(self) -> str:\n        return f\"{inspect(self).identity[0]}\"\n\n    def __repr__(self) -> str:\n        mapper = inspect(self.__class__)\n        fields = [f\"{col.key}={repr(getattr(self, col.key, None)))}\" for col in mapper.columns]\n        return f\"<{self.__class__.__name__}({', '.join(fields)})>\"\n\ntype_annotation_map = {\n    str: Text,\n    email: String,\n    UUID: SQL_UUID,\n    str_10: String(10),\n    str_32: String(32),\n    str_50: String(50),\n    str_64: String(64),\n    str_100: String(100),\n    str_255: String(255),\n    ConnectionStatus: String(64),\n    InvitationStatus: String(50),\n}\n\nSessionLocal = _prepare_sessionmaker(engine)\nAsyncSessionLocal = _prepare_async_sessionmaker(async_engine)\n\ndef _get_db_dependency() -> Iterator[Session]:\n    db = SessionLocal()\n    try:\n        yield db\n    except Exception as exc:\n        db.rollback()\n        raise exc\n    finally:\n        db.close()\n\nasync def _get_async_db_dependency() -> AsyncGenerator[AsyncSession, None]:\n    async with AsyncSessionLocal() as session:\n        yield session\n\ndb_session = Annotated[Session, Depends(_get_db_dependency)]\nasync_db_session = Annotated[AsyncSession, Depends(_get_async_db_dependency)]"}
{"code_id": "onyx-foss_backend_onyx_httpx_httpx_pool.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\onyx-foss_backend_onyx_httpx_httpx_pool.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\onyx-foss_backend_onyx_httpx_httpx_pool.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\onyx-foss_backend_onyx_httpx_httpx_pool.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": "def _init_(self, images):\n    self.images = images\n\nclass SpriteSheet:\n    \"\"\"Class to manage a grid of images as a sprite sheet.\"\"\"\n\n    def __init__(self, filename, width, height):\n        \"\"\"Load the sprite sheet and split it into individual sprites.\"\"\"\n        try:\n            self.sheet = pygame.image.load(filename).convert_alpha()\n        except pygame.error as e:\n            print(f\"Unable to load spritesheet image: {filename}\")\n            raise SystemExit(e)\n\n    def get_image(self, name, x, y, width, height):\n        \"\"\"Get the image at the given x and y position.\"\"\"\n        try:\n            image = pygame.Surface((width, height)).convert_alpha()\n            image.blit(self.sheet, (0, 0), (x, y, width, height)))\n            return image\n        except pygame.error as e:\n            print(f\"Unable to get image: {name}\")\n            raise SystemExit(e)\n\ndef _init_(self, images):\n    self.images = images\n\nclass SpriteSheet:\n    \"\"\"Class to manage a grid of images as a sprite sheet.\"\"\"\n\n    def __init__(self, filename, width, height):\n        \"\"\"Load the sprite sheet and split it into individual sprites.\"\"\"\n        try:\n            self.sheet = pygame.image.load(filename).convert_alpha()\n        except pygame.error as e:\n            print(f\"Unable to load spritesheet image: {filename}\")\n            raise SystemExit(e)\n\n    def get_image(self, name, x, y, width, height):\n        \"\"\"Get the image at the given x and y position.\"\"\"\n        try:\n            image = pygame.Surface((width, height)).convert_alpha()\n            image.blit(self.sheet, (0, 0), (x, y, width, height)))\n            return image\n        except pygame.error as e:\n            print(f\"Unable to get image: {name}\")\n            raise SystemExit(e)"}
{"code_id": "onyx-foss_backend_onyx_httpx_httpx_pool.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\onyx-foss_backend_onyx_httpx_httpx_pool.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\onyx-foss_backend_onyx_httpx_httpx_pool.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\onyx-foss_backend_onyx_httpx_httpx_pool.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "open-wearables_backend_app_database.py", "ratio": 2, "num_pages": 3, "image_paths": ["./experiment_output\\images_glm46v\\open-wearables_backend_app_database.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\open-wearables_backend_app_database.py\\1024x1024_hl_nl\\page_002_ratio2.png", "./experiment_output\\images_glm46v\\open-wearables_backend_app_database.py\\1024x1024_hl_nl\\page_003_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\open-wearables_backend_app_database.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "from collections.abc import AsyncGenerator, Iterator\nfrom typing import Annotated\nfrom uuid import UUID\n\nfrom fastapi import Depends\nfrom sqlalchemy import UUID as SQL_UUID\nfrom sqlalchemy import Engine, String, Text, create_engine, inspect\nfrom sqlalchemy.ext.asyncio import (\n    AsyncEngine,\n    AsyncSession,\n    async_sessionmaker,\n    create_async_engine,\n)\n\nfrom sqlalchemy.orm import (\n    DeclarativeBase,\n    Session,\n    declared_attr,\n    sessionmaker,\n)\n\nfrom app.config import settings\nfrom app.mappings import email, str_10, str_32, str_50, str_64, str_100, str_255\nfrom app.schemas.invitation import InvitationStatus\nfrom app.schemas.oauth import ConnectionStatus\nfrom app.utils.mappings_meta import AutoRelMeta\n\nengine = create_engine(\n    settings.db_uri,\n    pool_pre_ping=True,\n    pool_size=20,\n    max_overflow=30,\n    pool_timeout=30,\n    pool_recycle=3600,\n)\n\nasync_engine = create_async_engine(settings.db_uri)\n\ndef _prepare_sessionmaker(engine: Engine) -> sessionmaker:\n    return sessionmaker(autocommit=False, autoflush=False, bind=engine)\n\ndef _prepare_async_sessionmaker(engine: AsyncEngine) -> async_sessionmaker:\n    return async_sessionmaker(engine, expire_on_commit=False)\n\nclass BaseDbModel(DeclarativeBase, metaclass=AutoRelMeta):\n    @declared_attr\n    def tablename__(self) -> str:\n        return self.__name__.lower()\n\n    @property\n    def id_str(self) -> str:\n        return f\"{inspect(self).identity[0]}\"\n\n    def __repr__(self) -> str:\n        mapper = inspect(self.__class__)\n        fields = [f\"{col.key}={repr(getattr(self, col.key), None))}\" for col in mapper.columns]\n        return f\"<{self.__class__.__name__}({', '.join(fields)})>\"\n\ntype_annotation_map = {\n    str: Text,\n    email: String,\n    UUID: SQL_UUID,\n    str_10: String(10),\n    str_32: String(32),\n    str_50: String(50),\n    str_64: String(64),\n    str_100: String(100),\n    str_255: String(255),\n    ConnectionStatus: String(64),\n    InvitationStatus: String(50),\n}\n\nSessionLocal = _prepare_sessionmaker(engine)\nAsyncSessionLocal = _prepare_async_sessionmaker(async_engine)\n\ndef _get_db_dependency() -> Iterator[Session]:\n    db = SessionLocal()\n    try:\n        yield db\n    except Exception as exc:\n        db.rollback()\n        raise exc\n    finally:\n        db.close()\n\nasync def _get_async_db_dependency() -> AsyncGenerator[AsyncSession, None]:\n    async with AsyncSessionLocal() as session:\n        yield session\n\ndb_session = Annotated[Session, Depends(_get_db_dependency)]\nasync_db_session = Annotated[AsyncSession, Depends(_get_async_db_dependency)]"}
{"code_id": "open-wearables_backend_app_database.py", "ratio": 4, "num_pages": 3, "image_paths": ["./experiment_output\\images_glm46v\\open-wearables_backend_app_database.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\open-wearables_backend_app_database.py\\1024x1024_hl_nl\\page_002_ratio4.png", "./experiment_output\\images_glm46v\\open-wearables_backend_app_database.py\\1024x1024_hl_nl\\page_003_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\open-wearables_backend_app_database.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "from collections.abc import AsyncGenerator, Iterator\nfrom typing import Annotated\nfrom uuid import UUID\n\nfrom fastapi import Depends\nfrom sqlalchemy import UUID as SQL_UUID\nfrom sqlalchemy import Engine, String, Text, create_engine, inspect\nfrom sqlalchemy.ext.asyncio import (\n    AsyncEngine,\n    AsyncSession,\n    async_sessionmaker,\n    create_async_engine,\n)\nfrom sqlalchemy.orm import [\n    DeclarativeBase,\n    Session,\n    declared_attr,\n    sessionmaker,\n]\n\nfrom app.config import settings\nfrom app.mappings import email, str_10, str_20, str_50, str_64, str_100, str_255\nfrom app.schemas.invitation import InvitationStatus\nfrom app.schemas.auth import ConnectionStatus\nfrom app.utils.mappings_meta import AutoRcMeta\n\nengine = create_engine(\n    settings.db_uri,\n    pool_pre_ping=True,\n    pool_size=20,\n    max_overflow=30,\n    pool_timeout=30,\n    pool_recycle=3600,\n)\n\nasync_engine = create_async_engine(settings.db_uri)\n\ndef _prepare_sessionmaker(engine: Engine) -> sessionmaker:\n    return sessionmaker(autocommit=False, autoflush=False, bind=engine)\n\ndef _prepare_async_sessionmaker(engine: AsyncEngine) -> async_sessionmaker:\n    return async_sessionmaker(engine, expire_on_commit=False)\n\nclass BaseModel(DeclarativeBase, metaclass=AutoRcMeta):\n    __declared_attr__\n\n    @property\n    def __tablename__(self) -> str:\n        return self.__name__.lower()\n\n    @property\n    def id_str(self) -> str:\n        return f\"{inspect(self).identity[0]}\"\n\n    def __repr__(self) -> str:\n        mapper = inspect(self.__class__)\n        fields = [f\"{col.key}={repr(getattr(self, col.key, None)))}\" for col in mapper.columns]\n        return f\"<{self.__class__.__name__}({', '.join(fields)})>\"\n\ntype_annotation_map = {\n    attr: Text,\n    email: String,\n    UUID: SQL_UUID,\n    str_10: String(10),\n    str_20: String(20),\n    str_50: String(50),\n    str_64: String(64),\n    str_100: String(100),\n    str_255: String(255),\n    ConnectionStatus: String(64),\n    InvitationStatus: String(64),\n}\n\nSessionLocal = _prepare_sessionmaker(engine)\nAsyncSessionLocal = _prepare_async_sessionmaker(async_engine)\n\ndef _get_db_dependency() -> Iterator[Session]:\n    db = SessionLocal()\n    try:\n        yield db\n        await Exception as exc:\n            db.rollback()\n    except exc:\n        raise\n    finally:\n        db.close()\n\nasync def _get_async_db_dependency() -> AsyncGenerator[AsyncSession, None]:\n    async with AsyncSessionLocal() as session:\n        yield session\n\nDBSession = Annotated[Session, Depends(_get_db_dependency)]]\nAsyncDBSession = Annotated[AsyncSession, Depends(_get_async_db_dependency)]]"}
{"code_id": "openguardrails_backend_services_cache_cleaner.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\openguardrails_backend_services_cache_cleaner.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\openguardrails_backend_services_cache_cleaner.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\openguardrails_backend_services_cache_cleaner.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "import asyncio\nfrom datetime import datetime, timedelta\nfrom utils.auth_cache import auth_cache\nfrom services.rate_limiter import rate_limiter\nfrom services.keyword_cache import keyword_cache\nfrom utils.logger import setup_logger\n\nlogger = setup_logger()\n\nclass CacheCleaner:\n    \"\"\"Cache cleaner service\"\"\"\n\n    def __init__(self):\n        self._cleanup_task = None\n        self._running = False\n\n    async def start(self):\n        \"\"\"Start cache cleaner service\"\"\"\n        if self._running:\n            return\n\n        self._running = True\n        self._cleanup_task = asyncio.create_task(self._cleanup_loop())\n        logger.info(\"Cache cleaner service started\")\n\n    async def stop(self):\n        \"\"\"Stop cache cleaner service\"\"\"\n        self._running = False\n        if self._cleanup_task:\n            self._cleanup_task.cancel()\n            try:\n                await self._cleanup_task\n            except asyncio.CancelledError:\n                pass\n        logger.info(\"Cache cleaner service stopped\")\n\n    async def _cleanup_loop(self):\n        \"\"\"Cleanup loop\"\"\"\n        while self._running:\n            try:\n                # Clean expired auth cache\n                auth_cache.clear_expired()\n\n                # Clean expired rate limit records (keep recent 2 minutes records)\n                current_time = asyncio.get_event_loop().time()\n                cutoff_time = current_time - 120  # 2分钟前\n\n                # PostgreSQL rate limiter doesn't need manual cleanup of user requests\n                # as it uses database storage with automatic cleanup via SQL queries\n\n                # Record cache statistics\n                auth_cache_size = auth_cache.size()\n                rate_limit_users = len(rate_limiter._local_cache)\n                keyword_cache_info = keyword_cache.get_cache_info()\n\n                if auth_cache_size > 0 or rate_limit_users > 0 or keyword_cache_info['blacklist_keywords'] > 0:\n                    logger.debug(f\"Cache stats - Auth: {auth_cache_size}, Rate limit users: {rate_limit_users}, Keywords: B{keyword_cache_info['blacklist_keywords']}/W{keyword_cache_info['whitelist_keywords']}]\")\n\n                # Clean every 60 seconds\n                await asyncio.sleep(60)\n\n            except asyncio.CancelledError:\n                break\n            except Exception as e:\n                logger.error(f\"Cache cleanup error: {e}\")\n                await asyncio.sleep(60)\n\n# Global cache cleaner service instance\ncache_cleaner = CacheCleaner()"}
{"code_id": "openguardrails_backend_services_cache_cleaner.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\openguardrails_backend_services_cache_cleaner.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\openguardrails_backend_services_cache_cleaner.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\openguardrails_backend_services_cache_cleaner.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "import asyncio\nfrom datetime import datetime, timedelta\nfrom utils.auth_cache import auth_cache\nfrom services.rate_limiter import rate_limiter\nfrom services.keyword_cache import keyword_cache\nfrom utils.logger import setup_logger\n\nlogger = setup_logger()\n\nclass CacheCleaner:\n    \"\"\"Cache cleaner service\"\"\"\n\n    def __init__(self):\n        self._cleanup_task = None\n        self._running = False\n\n    async def start(self):\n        \"\"\"Start cache cleaner service\"\"\"\n        if self._running:\n            return\n\n        self._running = True\n        self._cleanup_task = asyncio.create_task(self._cleanup_loop())\n        logger.info(\"Cache cleaner service started\")\n\n    async def stop(self):\n        \"\"\"Stop cache cleaner service\"\"\"\n        self._running = False\n        if self._cleanup_task:\n            self._cleanup_task.cancel()\n            try:\n                await self._cleanup_task\n            except asyncio.CancelledError:\n                pass\n\n        logger.info(\"Cache cleaner service stopped\")\n\n    async def _cleanup_loop(self):\n        \"\"\"Cleanup loop\"\"\"\n        while self._running:\n            try:\n                # Clean expired auth cache\n                auth_cache.clear_expired()\n\n                # Clean expired rate limit records (keep recent 2 minutes records)\n                current_time = asyncio.get_event_loop().time()\n                cutoff_time = current_time - 120  # 2分钟前\n\n                # PostgreSQL rate limiter doesn't need manual cleanup of user requests\n                # as it uses database storage with automatic cleanup via SQL queries\n\n                # Record cache statistics\n                auth_cache_size = auth_cache.size()\n                rate_limit_users = len(rate_limiter._local_cache)\n                keyword_cache_info = keyword_cache.get_cache_info()\n\n                if auth_cache_size > 0 or rate_limit_users > 0 or keyword_cache_info['blacklist_keywords'] > 0:\n                    logger.debug(f\"Cache stats - Auth: {auth_cache_size}, Rate limit users: {rate_limit_users}, Keywords: B[{keyword_cache_info['blacklist_keywords']}]W[{keyword_cache_info['whitelist_keywords']}]]\")\n\n                # Clean every 60 seconds\n                await asyncio.sleep(60)\n\n            except asyncio.CancelledError:\n                break\n            except Exception as e:\n                logger.error(f\"Cache cleanup error: {e}\")\n                await asyncio.sleep(60)\n\n# Global cache cleaner service instance\ncache_cleaner = CacheCleaner()"}
{"code_id": "openguardrails_backend_services_cache_cleaner.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\openguardrails_backend_services_cache_cleaner.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\openguardrails_backend_services_cache_cleaner.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\openguardrails_backend_services_cache_cleaner.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "import asyncio\nfrom datetime import datetime, timedelta\nfrom utils.auth_cache import auth_cache\nfrom services.rate_limiter import rate_limiter\nfrom services.keyword_cache import keyword_cache\nfrom utils.logger import setup_logger\n\nlogger = setup_logger()\n\nclass CacheCleaner:\n    \"\"\"Cache cleaner service\"\"\"\n\n    def __init__(self):\n        self._cleanup_task = None\n        self._running = False\n\n    async def start(self):\n        \"\"\"Start cache cleaner service\"\"\"\n        if self._running:\n            return\n\n        self._running = True\n        self._cleanup_task = asyncio.create_task(self._cleanup_loop())\n        logger.info(\"Cache cleaner service started\")\n\n    async def stop(self):\n        \"\"\"Stop cache cleaner service\"\"\"\n        self._running = False\n        if self._cleanup_task:\n            self._cleanup_task.cancel()\n            try:\n                await self._cleanup_task\n            except asyncio.CancelledError:\n                pass\n\n        logger.info(\"Cache cleaner service stopped\")\n\n    async def _cleanup_loop(self):\n        \"\"\"Cleanup loop\"\"\"\n        while self._running:\n            try:\n                # Clean expired auth cache\n                auth_cache.clear_expired()\n\n                # Clean expired rate limit records (keep recent 2 minutes records)\n                current_time = asyncio.get_event_loop().time()\n                cutoff_time = current_time - 120  # 2 minutes\n\n# PostgreSQL rate limiter doesn't need manual cleanup of user requests\n# as it uses database storage with automatic cleanup via SQL queries\n\n# Record cache statistics\nauth_cache_size = auth_cache.size()\nrate_limit_users = len(rate_limiter._local_cache)\nkeyword_cache_info = keyword_cache.get_cache_info()\n\nif auth_cache_size > 0 or rate_limit_users > 0 or keyword_cache_info['blacklist_keywords'] > 0:\n    logger.debug(f\"Cache stats - Auth: {auth_cache_size}, Rate limit users: {rate_limit_users}, Keywords: {keyword_cache_info['blacklist_keywords']}/{keyword_cache_info['whitelist_keywords']}}\")\n\n# Clean every 60 seconds\nawait asyncio.sleep(60)\n\nexcept asyncio.CancelledError:\n    break\nexcept Exception as e:\n    logger.error(f\"Cache cleanup error: {e}\")\n    await asyncio.sleep(60)\n\n# Global cache cleaner service instance\ncache_cleaner = CacheCleaner()"}
{"code_id": "open-wearables_backend_app_database.py", "ratio": 6, "num_pages": 3, "image_paths": ["./experiment_output\\images_glm46v\\open-wearables_backend_app_database.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\open-wearables_backend_app_database.py\\1024x1024_hl_nl\\page_002_ratio6.png", "./experiment_output\\images_glm46v\\open-wearables_backend_app_database.py\\1024x1024_hl_nl\\page_003_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\open-wearables_backend_app_database.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "open-wearables_backend_app_database.py", "ratio": 8, "num_pages": 3, "image_paths": ["./experiment_output\\images_glm46v\\open-wearables_backend_app_database.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\open-wearables_backend_app_database.py\\1024x1024_hl_nl\\page_002_ratio8.png", "./experiment_output\\images_glm46v\\open-wearables_backend_app_database.py\\1024x1024_hl_nl\\page_003_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\open-wearables_backend_app_database.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "openpi-comet_packages_openpi-client_src_openpi_client_action_chunk_broker.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\openpi-comet_packages_openpi-client_src_openpi_client_action_chunk_broker.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\openpi-comet_packages_openpi-client_src_openpi_client_action_chunk_broker.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\openpi-comet_packages_openpi-client_src_openpi_client_action_chunk_broker.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "from typing import Dict\nimport numpy as np\nimport tree\nfrom typing_extensions import override\nfrom openpi_client import base_policy as _base_policy\n\nclass ActionChunkBroker(_base_policy.BasePolicy):\n    \"\"\"Wraps a policy to return action chunks one-at-a-time.\n\n    Assumes that the first dimension of all action fields is the chunk size.\n\n    A new inference call to the inner policy is only made when the current\n    list of chunks is exhausted.\n    \"\"\"\n\n    def __init__(self, policy: _base_policy.BasePolicy, action_horizon: int):\n        self._policy = policy\n        self._action_horizon = action_horizon\n        self._cur_step: int = 0\n\n        self._last_results: Dict[str, np.ndarray] | None = None\n\n    @override\n    def infer(self, obs: Dict) -> Dict:  # noqa: UP006\n        if self._last_results is None:\n            self._last_results = self._policy.infer(obs)\n            self._cur_step = 0\n\n        def slicer(x):\n            if isinstance(x, np.ndarray):\n                return x[self._cur_step, ...]\n            else:\n                return x\n\n        results = tree.map_structure(slicer, self._last_results)\n        self._cur_step += 1\n\n        if self._cur_step >= self._action_horizon:\n            self._last_results = None\n\n        return results\n\n    @override\n    def reset(self) -> None:\n        self._policy.reset()\n        self._last_results = None\n        self._cur_step = 0"}
{"code_id": "openpi-comet_packages_openpi-client_src_openpi_client_action_chunk_broker.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\openpi-comet_packages_openpi-client_src_openpi_client_action_chunk_broker.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\openpi-comet_packages_openpi-client_src_openpi_client_action_chunk_broker.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\openpi-comet_packages_openpi-client_src_openpi_client_action_chunk_broker.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "        self._policy.reset()\n        self._last_results = None\n        self._cur_step = 0"}
{"code_id": "openpi-comet_packages_openpi-client_src_openpi_client_action_chunk_broker.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\openpi-comet_packages_openpi-client_src_openpi_client_action_chunk_broker.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\openpi-comet_packages_openpi-client_src_openpi_client_action_chunk_broker.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\openpi-comet_packages_openpi-client_src_openpi_client_action_chunk_broker.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "from typing import Dict\nimport numpy as np\nimport tree\nfrom typing_extensions import override\n\nfrom opencpi_aihmi import base_policy as _base_policy\n\nclass ActionChunkBroker(_base_policy.BasePolicy):\n    \"\"\"Wraps a policy to return action chunks one-at-a-time.\n\n    Assumes that the first dimension of all action fields is the chunk size.\n\n    A new inference call to the inner policy is only made when the current\n    list of chunks is exhausted.\n    \"\"\"\n\n    def __init__(self, policy: _base_policy.BasePolicy, action_horizon: int):\n        self._policy = policy\n        self._action_horizon = action_horizon\n        self._our_step: int = 0\n\n        self._last_results: Dict[str, np.ndarray] | None = None\n\n    @override\n    def infer(self, obs: Dict) -> Dict:  # noqa: Q000\n        if self._last_results is None:\n            self._last_results = self._policy.infer(obs)\n            self._our_step = 0\n\n        def slicer(x):\n            if isinstance(x, np.ndarray):\n                return x[self._our_step, ...]\n            else:\n                return x\n\n        results = tree.map_structure(slicer, self._last_results)\n        self._our_step += 1\n\n        if self._our_step >= self._action_horizon:\n            self._last_results = None\n\n        return results\n\n    @override\n    def reset(self) -> None:\n        self._policy.reset()\n        self._last_results = None\n        self._our_step = 0"}
{"code_id": "openguardrails_backend_services_cache_cleaner.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\openguardrails_backend_services_cache_cleaner.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\openguardrails_backend_services_cache_cleaner.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\openguardrails_backend_services_cache_cleaner.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "openpi-comet_packages_openpi-client_src_openpi_client_action_chunk_broker.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\openpi-comet_packages_openpi-client_src_openpi_client_action_chunk_broker.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\openpi-comet_packages_openpi-client_src_openpi_client_action_chunk_broker.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\openpi-comet_packages_openpi-client_src_openpi_client_action_chunk_broker.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": "from typing import List\nimport time\nfrom typing_extensions import Literal\nfrom gymnasium import Env, spaces, functional as fn\n\nclass dmcConfigBuilder(Env, spaces.Box, functional as fn):\n    \"\"\"Wrapper to provide the default action spaces used in the\n    original DMC paper.\n\n    Assumes that the first dimension of all action fields is the should field.\n    A data inference pass to the action spaces is only made when the default\n    list of actions is encountered.\n    \"\"\"\n\n    def __init__(self, policy: spaces.Box, action_space: int):\n        self._policy = policy\n        self._action_space = action_space\n        self._curr_step = 0\n\n        self._last_results = [None, None, None]\n\n    def reset(self, data: dict = None) -> None:\n        if self._last_results is None:\n            self._last_results = self._last_policy_constructor\n        self._curr_step = 0\n\n        def _reset(self):\n            if isinstance(self, spaces.Box):\n                return self.reset(...)\n\n            return None\n\n        self._last_results = [None, None, None]\n        self._last_policy = None\n\n        if self._last_policy is not self._last_policy_constructor:\n            self._last_results = [None]\n\n    def step(self):\n        if self._last_policy is not None:\n            return self._last_policy.step(...)\n\n        return None\n\n    def render(self) -> None:\n        self._last_policy.render()\n        self._last_results = [None]\n        self._curr_step += 1"}
{"code_id": "openguardrails_backend_services_cache_cleaner.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\openguardrails_backend_services_cache_cleaner.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\openguardrails_backend_services_cache_cleaner.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\openguardrails_backend_services_cache_cleaner.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "polaris_src_polaris_policy_abstract_client.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\polaris_src_polaris_policy_abstract_client.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\polaris_src_polaris_policy_abstract_client.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\polaris_src_polaris_policy_abstract_client.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "from abc import ABC, abstractmethod\nfrom typing import Callable\nimport numpy as np\n\nfrom polaris.config import PolicyArgs\n\nclass InferenceClient(ABC):\n    REGISTERED_CLIENTS = {}\n\n# def __init_subclass__(cls, client_name: str, *args, **kwargs) -> None:\n#     super().__init_subclass__(*args, **kwargs)\n#     InferenceClient.REGISTERED_CLIENTS[client_name] = cls\n\n    @staticmethod\n    def register(client_name: str) -> Callable[[type], type]:\n        def decorator(cls: type):\n            InferenceClient.REGISTERED_CLIENTS[client_name] = cls\n            return cls\n\n        return decorator\n\n    @staticmethod\n    def get_client(policy_args: PolicyArgs) -> \"InferenceClient\":\n        if policy_args.client not in InferenceClient.REGISTERED_CLIENTS:\n            raise ValueError(\n                f\"Client {policy_args.client} not found. Available clients: {list(InferenceClient.REGISTERED_CLIENTS.keys())}\"\n            )\n        return InferenceClient.REGISTERED_CLIENTS[policy_args.client](policy_args)\n\n    @abstractmethod\n    def __init__(self, args) -> None:\n        \"\"\"\n        Initializes the client.\n        \"\"\"\n        pass\n\n    @property\n    def rerender(self) -> bool:\n        \"\"\"\n        Policy requests a rerender of the visualization. Optimization for less splat rendering\n        for chunked policies. Can default to always True if optimization is not desired.\n        \"\"\"\n        return True\n\n    @abstractmethod\n    def infer(\n        self, obs, instruction, return_viz: bool = False\n    ) -> tuple[np.ndarray, np.ndarray | None]:\n        \"\"\"\n        Does inference on observation and returns action and visualization. If visualization is not needed, return None.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def reset(self):\n        \"\"\"\n        Resets the client to start a new episode. Useful if policy is stateful.\n        \"\"\"\n        pass\n\nclass FakeClient(InferenceClient):\n    \"\"\"\n    Fake client that returns a dummy action and visualization.\n    \"\"\"\n\n    def __init__(self, *args, **kwargs) -> None:\n        return\n\n    def infer(\n        self, obs, instruction, return_viz: bool = False\n    ) -> tuple[np.ndarray, np.ndarray | None]:\n        import cv2\n\n        external = obs[\"splat\"][\"external_cam\"]\n        wrist = obs[\"splat\"][\"wrist_cam\"]\n        external = cv2.resize(external, (224, 224))\n        wrist = cv2.resize(wrist, (224, 224))\n        both = np.concatenate([external, wrist], axis=1)\n        return np.zeros((8,)), both\n\n    def reset(self, *args, **kwargs):\n        return"}
{"code_id": "polaris_src_polaris_policy_abstract_client.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\polaris_src_polaris_policy_abstract_client.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\polaris_src_polaris_policy_abstract_client.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\polaris_src_polaris_policy_abstract_client.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "from abc import ABC, abstractmethod\nfrom typing import Callable\nimport numpy as np\n\nfrom polaris.config import PolicyArgs\n\nclass InferenceClient(ABC):\n    REGISTERED_CLIENTS = {}\n\n    def __init_subclass__(cls, client_name: str, *args, **kwargs) -> None:\n        super().__init_subclass__(*args, **kwargs)\n        InferenceClient.REGISTERED_CLIENTS[client_name] = cls\n\n    @staticmethod\n    def register(client_name: str) -> Callable[[type], type]:\n        def decorator(cls: type):\n            InferenceClient.REGISTERED_CLIENTS[client_name] = cls\n            return cls\n        return decorator\n\n    @staticmethod\n    def get_client(policy_args: PolicyArgs) -> \"InferenceClient\":\n        if policy_args.client not in InferenceClient.REGISTERED_CLIENTS:\n            raise NameError(\n                f\"Client {policy_args.client} not found. Available clients: {list(InferenceClient.REGISTERED_CLIENTS.keys())}\"\n            )\n        return InferenceClient.REGISTERED_CLIENTS[policy_args.client](policy_args)\n\n    @abstractmethod\n    def __init__(self, args) -> None:\n        \"\"\"\n        Initializes the client.\n        \"\"\"\n        pass\n\n    @property\n    def rerender(self) -> bool:\n        \"\"\"\n        Policy requests a rerender of the visualization. Optimization for less apart rendering\n        for chunked policies. Can default to always True if optimization is not desired.\n        \"\"\"\n        return True\n\n    @abstractmethod\n    def infer(\n        self, obs, instruction, return_viz: bool = False\n    ) -> tuple[np.ndarray, np.ndarray | None]:\n        \"\"\"\n        Does inference on observation and returns action and visualization. If visualization is not needed, return None.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def reset(self):\n        \"\"\"\n        Resets the client to start a new episode. Useful if policy is stateful.\n        \"\"\"\n        pass\n\nclass FakeClient(InferenceClient):\n    \"\"\"\n    Fake client that returns a dummy action and visualization.\n    \"\"\"\n\n    def __init__(self, *args, **kwargs) -> None:\n        return\n\n    def infer(\n        self, obs, instruction, return_viz: bool = False\n    ) -> tuple[np.ndarray, np.ndarray | None]:\n        import cv2\n\n        external = obs[\"splat\"][\"external_cam\"]\n        wrist = obs[\"splat\"][\"wrist_cam\"]\n        external = cv2.resize(external, (224, 224))\n        wrist = cv2.resize(wrist, (224, 224))\n        both = np.concatenate([external, wrist], axis=0)\n        return np.zeros(3), both\n\n    def reset(self, *args, **kwargs):\n        return"}
{"code_id": "polaris_src_polaris_policy_abstract_client.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\polaris_src_polaris_policy_abstract_client.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\polaris_src_polaris_policy_abstract_client.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\polaris_src_polaris_policy_abstract_client.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "from abc import ABC, abstractmethod\nfrom typing import Callable\nimport numpy as np\n\nfrom polaris.config import PolicyArgs\n\nclass InferenceClient(ABC):\n    REGISTERED_CLIENTS = {}\n\n    # def __init_subclass__(cls, client_name: str, *args, **kwargs) -> None:\n    #     super().__init_subclass__(*args, **kwargs)\n    #     InferenceClient.REGISTERED_CLIENTS[client_name] = cls\n\n    @staticmethod\n    def register(client_name: str) -> Callable[[type], type]:\n        def decorator(cls: type):\n            InferenceClient.REGISTERED_CLIENTS[client_name] = cls\n            return cls\n\n        return decorator\n\n    @staticmethod\n    def get_client(policy_args: PolicyArgs) -> \"InferenceClient\":\n        if policy_args.client not in InferenceClient.REGISTERED_CLIENTS:\n            raise ValueError(\n                f\"Client {policy_args.client} not found. Available clients: {list(InferenceClient.REGISTERED_CLIENTS.keys())}\"\n            )\n        return InferenceClient.REGISTERED_CLIENTS[policy_args.client](policy_args)\n\n    @abstractmethod\n    def __init__(self, args) -> None:\n        \"\"\"\n        Initializes the client.\n        \"\"\"\n        pass\n\n    @property\n    def rerender(self) -> bool:\n        \"\"\"\n        Policy requests a rerender of the visualization. Optimization for less splat rendering\n        for chunked policies. Can default to always True if optimization is not desired.\n        \"\"\"\n        return True\n\n    @abstractmethod\n    def infer(\n        self, obs, instruction, return_viz: bool = False\n    ) -> tuple[np.ndarray, np.ndarray | None]:\n        \"\"\"\n        Does inference on observation and returns action and visualization. If visualization is not needed, return None.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def reset(self):\n        \"\"\"\n        Resets the client to start a new episode. Useful if policy is stateful.\n        \"\"\"\n        pass\n\nclass FakeClient(InferenceClient):\n    \"\"\"\n    Fake client that returns a dummy action and visualization.\n    \"\"\"\n\n    def __init__(self, *args, **kwargs) -> None:\n        return\n\n    def infer(\n        self, obs, instruction, return_viz: bool = False\n    ) -> tuple[np.ndarray, np.ndarray | None]:\n        import cv2\n\n        external = obs[\"splat\"][\"external_cam\"]\n        wrist = obs[\"splat\"][\"wrist_cam\"]\n        external = cv2.resize(external, (224, 224))\n        wrist = cv2.resize(wrist, (224, 224))\n        both = np.concatenate([external, wrist], axis=1)\n        return np.zeros((8,)), both\n\n    def reset(self, *args, **kwargs):\n        return"}
{"code_id": "openpi-comet_packages_openpi-client_src_openpi_client_action_chunk_broker.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\openpi-comet_packages_openpi-client_src_openpi_client_action_chunk_broker.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\openpi-comet_packages_openpi-client_src_openpi_client_action_chunk_broker.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\openpi-comet_packages_openpi-client_src_openpi_client_action_chunk_broker.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "powermem_src_powermem_storage_base.py", "ratio": 2, "num_pages": 3, "image_paths": ["./experiment_output\\images_glm46v\\powermem_src_powermem_storage_base.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\powermem_src_powermem_storage_base.py\\1024x1024_hl_nl\\page_002_ratio2.png", "./experiment_output\\images_glm46v\\powermem_src_powermem_storage_base.py\\1024x1024_hl_nl\\page_003_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\powermem_src_powermem_storage_base.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "# Abstract base class for storage implementations\n# This module defines the storage interface that all implementations must follow.\n\nfrom abc import ABC, abstractmethod\nfrom typing import Dict, Optional, Any, List\nfrom pydantic import BaseModel\n\nclass OutputData(BaseModel):\n    id: Optional[int]  # memory id (Snowflake ID - 64-bit integer)\n    score: Optional[float]  # distance\n    payload: Optional[Dict]  # metadata\n\nclass VectorStoreBase(ABC):\n    \"\"\"\n    Abstract base class for storage implementations.\n\n    This class defines the interface that all storage backends must implement.\n    \"\"\"\n\n    @abstractmethod\n    def create_col(self, name, vector_size, distance):\n        \"\"\"Create a new collection.\"\"\"\n        pass\n\n    @abstractmethod\n    def insert(self, vectors, payloads=None, ids=None):\n        \"\"\"Insert vectors into a collection.\"\"\"\n        pass\n\n    @abstractmethod\n    def search(self, query, vectors, limit=5, filters=None):\n        \"\"\"Search for similar vectors.\"\"\"\n        pass\n\n    @abstractmethod\n    def delete(self, vector_id):\n        \"\"\"Delete a vector by ID.\"\"\"\n        pass\n\n    @abstractmethod\n    def update(self, vector_id, vector=None, payload=None):\n        \"\"\"Update a vector and its payload.\"\"\"\n        pass\n\n    @abstractmethod\n    def get(self, vector_id):\n        \"\"\"Retrieve a vector by ID.\"\"\"\n        pass\n\n    @abstractmethod\n    def list_cols(self):\n        \"\"\"List all collections.\"\"\"\n        pass\n\n    @abstractmethod\n    def delete_col(self):\n        \"\"\"Delete a collection.\"\"\"\n        pass\n\n    @abstractmethod\n    def col_info(self):\n        \"\"\"Get information about a collection.\"\"\"\n        pass\n\n    @abstractmethod\n    def list(self, filters=None, limit=None):\n        \"\"\"List all memories.\"\"\"\n        pass\n\n    @abstractmethod\n    def reset(self):\n        \"\"\"Reset by delete the collection and recreate it.\"\"\"\n        pass\n\nclass GraphStoreBase(ABC):\n    \"\"\"\n    Abstract base class for graph storage implementations.\n\n    This class defines the interface that all graph storage backends must implement.\n    \"\"\"\n\n    @abstractmethod\n    def add(self, data: str, filters: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Add data to the graph.\"\"\"\n        pass\n\n    @abstractmethod\n    def search(self, query: str, filters: Dict[str, Any], limit: int = 10) -> List[Dict[str, Any]]]:\n        \"\"\"Search for memories.\"\"\"\n        pass\n\n    @abstractmethod\n    def delete_all(self, filters: Dict[str, Any]]) -> None:\n        \"\"\"Delete all graph data for the given filters.\"\"\"\n        pass\n\n    @abstractmethod\n    def get_all(self, filters: Dict[str, Any], limit: int = 100) -> List[Dict[str, str]]]:\n        \"\"\"Retrieve all nodes and relationships from the graph database.\"\"\"\n        pass\n\n    @abstractmethod\n    def reset(self) -> None:\n        \"\"\"Reset the graph by clearing all nodes and relationships.\"\"\"\n        pass"}
{"code_id": "polaris_src_polaris_policy_abstract_client.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\polaris_src_polaris_policy_abstract_client.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\polaris_src_polaris_policy_abstract_client.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\polaris_src_polaris_policy_abstract_client.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "polaris_src_polaris_policy_abstract_client.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\polaris_src_polaris_policy_abstract_client.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\polaris_src_polaris_policy_abstract_client.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\polaris_src_polaris_policy_abstract_client.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "powermem_src_powermem_storage_base.py", "ratio": 1, "num_pages": 3, "image_paths": ["./experiment_output\\images_glm46v\\powermem_src_powermem_storage_base.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\powermem_src_powermem_storage_base.py\\1024x1024_hl_nl\\page_002_ratio1.png", "./experiment_output\\images_glm46v\\powermem_src_powermem_storage_base.py\\1024x1024_hl_nl\\page_003_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\powermem_src_powermem_storage_base.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "\"\"\"\nAbstract base class for storage implementations\n\nThis module defines the storage interface that all implementations must follow.\n\"\"\"\n\nfrom abc import ABC, abstractmethod\nfrom typing import Dict, Optional, Any, List\nfrom pydantic import BaseModel\n\n\nclass OutputData(BaseModel):\n    id: Optional[int]  # memory id (Snowflake ID - 64-bit integer)\n    score: Optional[float]  # distance\n    payload: Optional[Dict]  # metadata\n\n\nclass VectorStoreBase(ABC):\n    \"\"\"\n    Abstract base class for storage implementations.\n\n    This class defines the interface that all storage backends must implement.\n    \"\"\"\n\n    @abstractmethod\n    def create_col(self, name, vector_size, distance):\n        \"\"\"Create a new collection.\"\"\"\n        pass\n\n    @abstractmethod\n    def insert(self, vectors, payloads=None, ids=None):\n        \"\"\"Insert vectors into a collection.\"\"\"\n        pass\n\n    @abstractmethod\n    def search(self, query, vectors, limit=5, filters=None):\n        \"\"\"Search for similar vectors.\"\"\"\n        pass\n\n    @abstractmethod\n    def delete(self, vector_id):\n        \"\"\"Delete a vector by ID.\"\"\"\n        pass\n\n    @abstractmethod\n    def update(self, vector_id, vector=None, payload=None):\n        \"\"\"Update a vector and its payload.\"\"\"\n        pass\n\n    @abstractmethod\n    def get(self, vector_id):\n        \"\"\"Retrieve a vector by ID.\"\"\"\n        pass\n\n    @abstractmethod\n    def list_cols(self):\n        \"\"\"List all collections.\"\"\"\n        pass\n\n    @abstractmethod\n    def delete_col(self):\n        \"\"\"Delete a collection.\"\"\"\n        pass\n\n    @abstractmethod\n    def col_info(self):\n        \"\"\"Get information about a collection.\"\"\"\n        pass\n\n    @abstractmethod\n    def list(self, filters=None, limit=None):\n        \"\"\"List all memories.\"\"\"\n        pass\n\n    @abstractmethod\n    def reset(self):\n        \"\"\"Reset by delete the collection and recreate it.\"\"\"\n        pass\n\n\nclass GraphStoreBase(ABC):\n    \"\"\"\n    Abstract base class for graph storage implementations.\n\n    This class defines the interface that all graph storage backends must implement.\n    \"\"\"\n\n    @abstractmethod\n    def add(self, data: str, filters: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Add data to the graph.\"\"\"\n        pass\n\n    @abstractmethod\n    def search(self, query: str, filters: Dict[str, Any], limit: int = 10) -> List[Dict[str, Any]]]:\n        \"\"\"Search for memories.\"\"\"\n        pass\n\n    @abstractmethod\n    def delete_all(self, filters: Dict[str, Any]]) -> None:\n        \"\"\"Delete all graph data for the given filters.\"\"\"\n        pass\n\n    @abstractmethod\n    def get_all(self, filters: Dict[str, Any], limit: int = 100) -> List[Dict[str, str]]]:\n        \"\"\"Retrieve all nodes and relationships from the graph database.\"\"\"\n        pass\n\n    @abstractmethod\n    def reset(self) -> None:\n        \"\"\"Reset the graph by clearing all nodes and relationships.\"\"\"\n        pass"}
{"code_id": "powerrag_api_db_runtime_config.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\powerrag_api_db_runtime_config.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\powerrag_api_db_runtime_config.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\powerrag_api_db_runtime_config.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "# Copyright 2024 The InfiniFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\nfrom common.versions import get_ragflow_version\nfrom .reload_config_base import ReloadConfigBase\n\nclass RuntimeConfig(ReloadConfigBase):\n    DEBUG = None\n    WORK_MODE = None\n    HTTP_PORT = None\n    JOB_SERVER_HOST = None\n    JOB_SERVER_VIP = None\n    ENV = dict()\n    SERVICE_DB = None\n    LOAD_CONFIG_MANAGER = False\n\n    @classmethod\n    def init_config(cls, **kwargs):\n        for k, v in kwargs.items():\n            if hasattr(cls, k):\n                setattr(cls, k, v)\n\n    @classmethod\n    def init_env(cls):\n        cls.ENV.update({\"version\": get_ragflow_version()})\n\n    @classmethod\n    def load_config_manager(cls):\n        cls.LOAD_CONFIG_MANAGER = True\n\n    @classmethod\n    def get_env(cls, key):\n        return cls.ENV.get(key, None)\n\n    @classmethod\n    def get_all_env(cls):\n        return cls.ENV\n\n    @classmethod\n    def set_service_db(cls, service_db):\n        cls.SERVICE_DB = service_db"}
{"code_id": "powermem_src_powermem_storage_base.py", "ratio": 4, "num_pages": 3, "image_paths": ["./experiment_output\\images_glm46v\\powermem_src_powermem_storage_base.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\powermem_src_powermem_storage_base.py\\1024x1024_hl_nl\\page_002_ratio4.png", "./experiment_output\\images_glm46v\\powermem_src_powermem_storage_base.py\\1024x1024_hl_nl\\page_003_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\powermem_src_powermem_storage_base.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "```python\n# Abstract base class for storage implementations\n\n# This module defines the storage interface that all implementations must follow.\n\nfrom abc import ABC, abstractmethod\nfrom typing import Dict, Optional, Any, List\nfrom pydantic import BaseModel\n\n\nclass OutputData(BaseModel):\n    id: Optional[int]  # memory id (Snowflake ID - 64-bit integer)\n    score: Optional[float]  # distance\n    payload: Optional[Dict]  # metadata\n\n\nclass VectorStoreBase(ABC):\n    \"\"\"\n    Abstract base class for storage implementations.\n\n    This class defines the interface that all storage backends must implement.\n    \"\"\"\n\n    @abstractmethod\n    def create_collection(self, name: str, vector_size: int, distance: str):\n        \"\"\"Create a new collection.\"\"\"\n        pass\n\n    @abstractmethod\n    def insert(self, vectors: Any, payload: Optional[Dict] = None, ids: Optional[List] = None):\n        \"\"\"Insert vectors into a collection.\"\"\"\n        pass\n\n    @abstractmethod\n    def search(self, query: Any, vectors: Any, limit: int = 10, filters: Optional[Dict] = None):\n        \"\"\"Search for similar vectors.\"\"\"\n        pass\n\n    @abstractmethod\n    def delete(self, vector_id: Any):\n        \"\"\"Delete a vector by ID.\"\"\"\n        pass\n\n    @abstractmethod\n    def update(self, vector_id: Any, vector: Optional[Any] = None, payload: Optional[Dict] = None):\n        \"\"\"Update a vector and its payload.\"\"\"\n        pass\n\n    @abstractmethod\n    def get(self, vector_id: Any):\n        \"\"\"Retrieve a vector by ID.\"\"\"\n        pass\n\n    @abstractmethod\n    def list_collections(self):\n        \"\"\"List all collections.\"\"\"\n        pass\n\n    @abstractmethod\n    def delete_collection(self, name: str):\n        \"\"\"Delete a collection.\"\"\"\n        pass\n\n    @abstractmethod\n    def col_info(self, name: str):\n        \"\"\"Get information about a collection.\"\"\"\n        pass\n\n    @abstractmethod\n    def list(self, filters: Optional[Dict] = None, limit: Optional[int] = None):\n        \"\"\"List all memories.\"\"\"\n        pass\n\n    @abstractmethod\n    def reset(self):\n        \"\"\"Reset by deleting the collection and recreating it.\"\"\"\n        pass\n\n\nclass GraphStoreBase(ABC):\n    \"\"\"\n    Abstract base class for graph storage implementations.\n\n    This class defines the interface that all graph storage backends must implement.\n    \"\"\"\n\n    @abstractmethod\n    def add(self, data: str, filters: Dict[str, Any] | None = None) -> Dict[str, Any]:\n        \"\"\"Add data to the graph.\"\"\"\n        pass\n\n    @abstractmethod\n    def search(self, query: str, filters: Dict[str, Any] | None = None, limit: int = 10) -> List[Dict[str, Any]]]:\n        \"\"\"Search for memories.\"\"\"\n        pass\n\n    @abstractmethod\n    def delete_all(self, filters: Dict[str, Any] | None = None) -> None:\n        \"\"\"Delete all graph data for the given filters.\"\"\"\n        pass\n\n    @abstractmethod\n    def get_all(self, filters: Dict[str, Any] | None = None, limit: int = 100) -> List[Dict[str, Any]]]:\n        \"\"\"Retrieve all nodes and relationships from the graph database.\"\"\"\n        pass\n\n    @abstractmethod\n    def reset(self) -> None:\n        \"\"\"Reset the graph by clearing all nodes and relationships.\"\"\"\n        pass\n```"}
{"code_id": "powerrag_api_db_runtime_config.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\powerrag_api_db_runtime_config.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\powerrag_api_db_runtime_config.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\powerrag_api_db_runtime_config.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "# Copyright 2024 The InfiniFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\"):\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\nfrom common.versions import get_ragflow_version\nfrom .reload_config_base import ReloadConfigBase\n\nclass RuntimeConfig(ReloadConfigBase):\n    DEBUG = None\n    WORK_MODE = None\n    HTTP_PORT = None\n    JOB_SERVER_HOST = None\n    JOB_SERVER_VIP = None\n    ENV = dict()\n    SERVICE_DB = None\n    LOAD_CONFIG_MANAGER = False\n\n    @classmethod\n    def init_config(cls, **kwargs):\n        for k, v in kwargs.items():\n            if hasattr(cls, k):\n                setattr(cls, k, v)\n\n    @classmethod\n    def init_env(cls):\n        cls.ENV.update({\"version\": get_ragflow_version()})\n\n    @classmethod\n    def load_config_manager(cls):\n        cls.LOAD_CONFIG_MANAGER = True\n\n    @classmethod\n    def get_env(cls, key):\n        return cls.ENV.get(key, None)\n\n    @classmethod\n    def get_all_env(cls):\n        return cls.ENV\n\n    @classmethod\n    def set_service_db(cls, service_db):\n        cls.SERVICE_DB = service_db"}
{"code_id": "powermem_src_powermem_storage_base.py", "ratio": 8, "num_pages": 3, "image_paths": ["./experiment_output\\images_glm46v\\powermem_src_powermem_storage_base.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\powermem_src_powermem_storage_base.py\\1024x1024_hl_nl\\page_002_ratio8.png", "./experiment_output\\images_glm46v\\powermem_src_powermem_storage_base.py\\1024x1024_hl_nl\\page_003_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\powermem_src_powermem_storage_base.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "powerrag_api_db_runtime_config.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\powerrag_api_db_runtime_config.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\powerrag_api_db_runtime_config.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\powerrag_api_db_runtime_config.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "# Copyright 2016 The InfraFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom common.versions import get_regflow_version\nfrom .reload_config_base import ReloadConfigBase\n\nclass RuntimeConfig(ReloadConfigBase):\n    DEBUG = None\n    WORK_MODE = None\n    HTTP_PORT = None\n    JOB_SERVER_HOST = None\n    JOB_SERVER_VIP = None\n    ENV = dict()\n    SERVICE_DB = None\n    LOAD_CONFIG_MANAGER = False\n\n    @classmethod\n    def init_config(cls, **kwargs):\n        for k, v in kwargs.items():\n            if hasattr(cls, k):\n                setattr(cls, k, v)\n\n    @classmethod\n    def init_env(cls):\n        cls.ENV.update({\"version\": get_regflow_version()})\n\n    @classmethod\n    def load_config_manager(cls):\n        cls.LOAD_CONFIG_MANAGER = True\n\n    @classmethod\n    def get_env(cls, key):\n        return cls.ENV.get(key, None)\n\n    @classmethod\n    def get_all_env(cls):\n        return cls.ENV\n\n    @classmethod\n    def set_service_db(cls, service_db):\n        cls.SERVICE_DB = service_db"}
{"code_id": "powermem_src_powermem_storage_base.py", "ratio": 6, "num_pages": 3, "image_paths": ["./experiment_output\\images_glm46v\\powermem_src_powermem_storage_base.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\powermem_src_powermem_storage_base.py\\1024x1024_hl_nl\\page_002_ratio6.png", "./experiment_output\\images_glm46v\\powermem_src_powermem_storage_base.py\\1024x1024_hl_nl\\page_003_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\powermem_src_powermem_storage_base.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "python-sdk_src_acp_task_queue.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\python-sdk_src_acp_task_queue.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\python-sdk_src_acp_task_queue.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\python-sdk_src_acp_task_queue.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "from __future__ import annotations\nimport asyncio\nfrom collections.abc import AsyncIterator\nfrom contextlib import suppress\nfrom typing import Protocol\n\nfrom . import RpcTask\n\n__all__ = [\"InMemoryMessageQueue\", \"MessageQueue\"]\n\nclass MessageQueue(Protocol):\n    async def publish(self, task: RpcTask) -> None: ...\n    async def close(self) -> None: ...\n    def task_done(self) -> None: ...\n    async def join(self) -> None: ...\n    def __aiter__(self) -> AsyncIterator[RpcTask]: ...\n\nclass InMemoryMessageQueue:\n    \"\"\"Simple in-memory broker for RPC task dispatch.\"\"\"\n\n    def __init__(self, *, maxsize: int = 0) -> None:\n        self._queue: asyncio.Queue[RpcTask | None] = asyncio.Queue(maxsize=maxsize)\n        self._closed = False\n\n    async def publish(self, task: RpcTask) -> None:\n        if self._closed:\n            msg = \"mssage queue already closed\"\n            raise RuntimeError(msg)\n        await self._queue.put(task)\n\n    async def close(self) -> None:\n        if self._closed:\n            return\n        self._closed = True\n        await self._queue.put(None)\n\n    async def join(self) -> None:\n        await self._queue.join()\n\n    def task_done(self) -> None:\n        with suppress(ValueError):\n            self._queue.task_done()\n\n    def __aiter__(self) -> AsyncIterator[RpcTask]:\n        return _QueueIterator(self)\n\nclass _QueueIterator:\n    def __init__(self, queue: InMemoryMessageQueue) -> None:\n        self._queue = queue\n\n    def __aiter__(self) -> _QueueIterator:\n        return self\n\n    async def __anext__(self) -> RpcTask:\n        item = await self._queue._queue.get()\n        if item is None:\n            self._queue.task_done()\n            raise StopAsyncIteration\n        return item"}
{"code_id": "python-sdk_src_acp_task_queue.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\python-sdk_src_acp_task_queue.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\python-sdk_src_acp_task_queue.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\python-sdk_src_acp_task_queue.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "from __future__ import annotations\nimport asyncio\nfrom collections.abc import AsyncIterator\nfrom contextlib import suppress\nfrom typing import Protocol\n\nfrom . import RpcTask\n\n__all__ = [\"InMemoryMessageQueue\", \"MessageQueue\"]\n\nclass MessageQueue(Protocol):\n    async def publish(self, task: RpcTask) -> None: ...\n    async def close(self) -> None: ...\n    def task_done(self) -> None: ...\n    async def join(self) -> None: ...\n    def __aiter__(self) -> AsyncIterator[RpcTask]: ...\n\nclass InMemoryMessageQueue:\n    \"\"\"Simple in-memory broker for RPC task dispatch.\"\"\"\n\n    def __init__(self, *, maxsize: int = 0) -> None:\n        self._queue: asyncio.Queue[RpcTask | None] = asyncio.Queue(maxsize=maxsize)\n        self._closed = False\n\n    async def publish(self, task: RpcTask) -> None:\n        if self._closed:\n            msg = \"mssage queue already closed\"\n            raise RuntimeError(msg)\n        await self._queue.put(task)\n\n    async def close(self) -> None:\n        if self._closed:\n            return\n        self._closed = True\n        await self._queue.put(None)\n\n    async def join(self) -> None:\n        await self._queue.join()\n\n    def task_done(self) -> None:\n        with suppress(ValueError):\n            self._queue.task_done()\n\n    def __aiter__(self) -> AsyncIterator[RpcTask]:\n        return _QueueIterator(self)\n\nclass _QueueIterator:\n    def __init__(self, queue: InMemoryMessageQueue) -> None:\n        self._queue = queue\n\n    def __aiter__(self) -> _QueueIterator:\n        return self\n\n    async def __anext__(self) -> RpcTask:\n        item = await self._queue._queue.get()\n        if item is None:\n            self._queue.task_done()\n            raise StopAsyncIteration\n        return item"}
{"code_id": "powerrag_api_db_runtime_config.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\powerrag_api_db_runtime_config.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\powerrag_api_db_runtime_config.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\powerrag_api_db_runtime_config.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "python-sdk_src_acp_task_queue.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\python-sdk_src_acp_task_queue.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\python-sdk_src_acp_task_queue.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\python-sdk_src_acp_task_queue.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "from __future__ import annotations\nimport asyncio\nfrom collections.abc import AsyncIterator\nfrom contextlib import suppress\nfrom typing import Protocol\n\nfrom . import RpcTask\n\n__all__ = [\"InMemoryMessageQueue\", \"MessageQueue\"]\n\nclass MessageQueue(Protocol):\n    async def publish(self, task: RpcTask) -> None: ...\n    async def close(self) -> None: ...\n    def task_done(self) -> None: ...\n    async def join(self) -> None: ...\n    def __aiter__(self) -> AsyncIterator[RpcTask]: ...\n\nclass InMemoryMessageQueue:\n    \"\"\"Simple in-memory broker for RPC task dispatch.\"\"\"\n\n    def __init__(self, *, maxsize: int = 0) -> None:\n        self._queue: asyncio.Queue[RpcTask | None] = asyncio.Queue(maxsize=maxsize)\n        self._closed = False\n\n    async def publish(self, task: RpcTask) -> None:\n        if self._closed:\n            msg = \"Message queue already closed\"\n            raise RuntimeError(msg)\n        await self._queue.put(task)\n\n    async def close(self) -> None:\n        if self._closed:\n            return\n        self._closed = True\n        await self._queue.put(None)\n\n    async def join(self) -> None:\n        await self._queue.join()\n\n    def task_done(self) -> None:\n        with suppress(ValueError):\n            self._queue.task_done()\n\n    def __aiter__(self) -> AsyncIterator[RpcTask]:\n        return _QueueIterator(self)\n\nclass _QueueIterator:\n    def __init__(self, queue: InMemoryMessageQueue) -> None:\n        self._queue = queue\n\n    def __aiter__(self) -> _QueueIterator:\n        return self\n\n    async def __anext__(self) -> RpcTask:\n        item = await self._queue._queue.get()\n        if item is None:\n            self._queue.task_done()\n            raise StopAsyncIteration\n        return item"}
{"code_id": "powerrag_api_db_runtime_config.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\powerrag_api_db_runtime_config.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\powerrag_api_db_runtime_config.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\powerrag_api_db_runtime_config.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "python-sdk_src_acp_task_queue.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\python-sdk_src_acp_task_queue.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\python-sdk_src_acp_task_queue.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\python-sdk_src_acp_task_queue.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": "from __future__ import annotations\n\nimport logging\nfrom collections.abc import Iterator\nfrom contextlib import suppress\nfrom typing import Protocol\n\nfrom . import types\n\n__all__ = [\"BinaryPhotonsBase\", \"PhotonsBase\"]\n\n\nclass BinaryPhotonsBase(Protocol):\n    async def add(self, item: types.RayField) -> None:\n        ...\n\n    async def clear(self) -> None:\n        ...\n\n    def touch_photons(self) -> None:\n        ...\n\n    async def print(self) -> None:\n        ...\n\n    def __aiter__(self) -> Iterator[types.RayField]:\n        ...\n\n\nclass PhotonsBase:\n    \"\"\"Base class for photon buffers for GPU tasks of synthesis.\"\"\"\n\n    def __init__(self, *, max_items: int = 1) -> None:\n        self._photons: dict[types.RayField | None, list[types.RayField]]] = {}\n        self._max_items: int = max_items\n\n    @property\n    def max_items(self) -> int:\n        if not hasattr(self, \"_max_items\"):\n            raise AttributeError(\"max_items not set\")\n        return self._max_items\n\n    @property\n    def items(self) -> int:\n        if not hasattr(self, \"_photons\"):\n            raise AttributeError(\"items not set\")\n        return sum(len(v) for v in self._photons.values()))\n\n    @property\n    def print(self) -> None:\n        async def _print() -> None:\n            await self.print()\n        return _print()\n\n    def touch_photons(self) -> None:\n        async def _touch_photons() -> None:\n            await self.touch_photons()\n        return _touch_photons()\n\n    def __aiter__(self) -> Iterator[types.RayField]:\n        async def _aiter() -> Iterator[types.RayField]:\n            return self.__aiter__()\n        return _aiter()\n\n    async def __aenter__(self) -> PhotonsBase:\n        return self\n\n    async def __aexit__(self, exc_type, exc_val, exc_tb) -> None:\n        if exc_type is None:\n            await self.print()\n        else:\n            await self.clear()\n\n\nclass PhotonIterator:\n    def __init__(self, photons: PhotonsBase) -> None:\n        self._photons = photons\n\n    def __aiter__(self) -> PhotonIterator:\n        return self\n\n    async def __anext__(self) -> types.RayField:\n        item = next(self._photons._photons.get(None, [])))\n        if item is None:\n            raise StopAsyncIteration\n        return item"}
{"code_id": "quorum-cli_src_quorum_clients_openai_client.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\quorum-cli_src_quorum_clients_openai_client.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\quorum-cli_src_quorum_clients_openai_client.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\quorum-cli_src_quorum_clients_openai_client.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "\"\"\"OpenAI-compatible client for multiple providers.\n\nThe client works with any OpenAI-compatible API:\n- OpenAI (direct)\n- Google Gemini (via OpenAI-compatible endpoint)\n- xAI Grok (via OpenAI-compatible endpoint)\n- Ollama (via OpenAI-compatible endpoint)\n\"\"\"\nfrom __future__ import annotations\n\nfrom typing import TYPE_CHECKING\n\nfrom openai import AsyncOpenAI\n\nfrom .types import AssistantMessage, Message, SystemMessage, UserMessage\n\nif TYPE_CHECKING:\n    import httpx\n\nclass OpenAIClient:\n    \"\"\"Client for OpenAI-compatible APIs.\n\n    Supports OpenAI, Google Gemini, xAI Grok, and Ollama through their OpenAI-compatible endpoints.\n    \"\"\"\n\n    def __init__(\n        self,\n        model: str,\n        api_key: str,\n        base_url: str | None = None,\n        http_client: \"httpx.AsyncClient | None\" = None,\n    ):\n        \"\"\"Initialize the OpenAI-compatible client.\n\n        Args:\n            model: Model identifier (e.g., \"gpt-4o\", \"gemini-2.0-flash\").\n            api_key: API key for authentication.\n            base_url: Optional base URL for non-OpenAI providers.\n            http_client: Optional shared httpx client for connection pooling.\n        \"\"\"\n        self.model = model\n        self._api_key: str | None = api_key\n        self._client = AsyncOpenAI(\n            api_key=api_key,\n            base_url=base_url,\n            http_client=http_client,\n        )\n\n    async def create(self, messages: list[Message]) -> str:\n        \"\"\"Send messages to the model and get a response.\n\n        Args:\n            messages: List of messages forming the conversation.\n\n        Returns:\n            The model's response text.\n\n        Raises:\n            openai.APIError: If the API request fails.\n        \"\"\"\n        response = await self._client.chat.completions.create(\n            model=self.model,\n            messages=[self._convert_message(m) for m in messages],\n        )\n\n        # Extract content from response\n        content = response.choices[0].message.content\n        return content if content is not None else \"\"\n\n    def _convert_message(self, msg: Message) -> dict[str, str]:\n        \"\"\"Convert internal message type to OpenAI format.\n\n        Args:\n            msg: Internal message object.\n\n        Returns:\n            Dict in OpenAI message format.\n        \"\"\"\n        if isinstance(msg, SystemMessage):\n            return {\"role\": \"system\", \"content\": msg.content}\n        elif isinstance(msg, UserMessage):\n            return {\"role\": \"user\", \"content\": msg.content}\n        elif isinstance(msg, AssistantMessage):\n            return {\"role\": \"assistant\", \"content\": msg.content}\n        else:\n            # Fallback for any unknown type\n            return {\"role\": \"user\", \"content\": str(msg.content)}"}
{"code_id": "quorum-cli_src_quorum_clients_openai_client.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\quorum-cli_src_quorum_clients_openai_client.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\quorum-cli_src_quorum_clients_openai_client.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\quorum-cli_src_quorum_clients_openai_client.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "# OpenAI-compatible client for multiple providers.\n#\n# The client works with any OpenAI-compatible API:\n# - OpenAI (direct)\n# - Google Gemini (via OpenAI-compatible endpoint)\n# - xAI Grok (via OpenAI-compatible endpoint)\n# - Ollama (via OpenAI-compatible endpoint)\n# ---\nfrom __future__ import annotations\n\nfrom typing import TYPE_CHECKING\n\nfrom openai import AsyncOpenAI\n\nfrom .types import AssistantMessage, Message, SystemMessage, UserMessage\n\nif TYPE_CHECKING:\n    import httpx\n\nclass OpenAIClient:\n    \"\"\"Client for OpenAI-compatible APIs.\n\n    Supports OpenAI, Google Gemini, xAI Grok, and Ollama through their\n    OpenAI-compatible endpoints.\n    \"\"\"\n\n    def __init__(\n        self,\n        model: str,\n        api_key: str,\n        base_url: str | None = None,\n        http_client: \"httpx.AsyncClient | None\" = None,\n    ):\n        \"\"\"Initialize the OpenAI-compatible client.\n\n        Args:\n            model: Model identifier (e.g., \"gpt-4o\", \"gemini-2.0-flash\").\n            api_key: API key for authentication.\n            base_url: Optional base URL for non-OpenAI providers.\n            http_client: Optional shared httpx client for connection pooling.\n        \"\"\"\n        self.model = model\n        self._api_key: str | None = api_key\n        self._client = AsyncOpenAI(\n            api_key=api_key,\n            base_url=base_url,\n            http_client=http_client,\n        )\n\n    async def create(self, messages: list[Message]) -> str:\n        \"\"\"Send messages to the model and get a response.\n\n        Args:\n            messages: List of messages forming the conversation.\n\n        Returns:\n            The model's response text.\n\n        Raises:\n            openai.APIError: If the API request fails.\n        \"\"\"\n        response = await self._client.chat.completions.create(\n            model=self.model,\n            messages=[self._convert_message(m) for m in messages],\n        )\n\n        # Extract content from response\n        content = response.choices[0].message.content\n        return content if content is not None else \"\"\n\n    def _convert_message(self, msg: Message) -> dict[str, str]:\n        \"\"\"Convert internal message type to OpenAI format.\n\n        Args:\n            msg: Internal message object.\n\n        Returns:\n            Dict in OpenAI message format.\n        \"\"\"\n        if isinstance(msg, SystemMessage):\n            return {\"role\": \"system\", \"content\": msg.content}\n        elif isinstance(msg, UserMessage):\n            return {\"role\": \"user\", \"content\": msg.content}\n        elif isinstance(msg, AssistantMessage):\n            return {\"role\": \"assistant\", \"content\": msg.content}\n        else:\n            # Fallback for any unknown type\n            return {\"role\": \"user\", \"content\": str(msg.content)}"}
{"code_id": "quorum-cli_src_quorum_clients_openai_client.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\quorum-cli_src_quorum_clients_openai_client.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\quorum-cli_src_quorum_clients_openai_client.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\quorum-cli_src_quorum_clients_openai_client.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "# OpenAI-compatible client for multiple providers.\n#\n# This client works with any OpenAI-compatible API:\n# - OpenAI (direct)\n# - Google Gemini (via OpenAI-compatible endpoint)\n# - xAI Grok (via OpenAI-compatible endpoint)\n# - Dllama (via OpenAI-compatible endpoint)\n# ...\n\nfrom __future__ import annotations\n\nfrom typing import TYPE_CHECKING\n\nfrom openai import AsyncOpenAI\n\nfrom .types import AssistantMessage, Message, SystemMessage, UserMessage\n\nif TYPE_CHECKING:\n    import httpx\n\n\nclass OpenAIClient:\n    \"\"\"Client for OpenAI-compatible APIs.\n\n    Supports OpenAI, Google Gemini, xAI Grok, and Dllama through their\n    OpenAI-compatible endpoints.\n    \"\"\"\n\n    def __init__(\n        self,\n        model: str,\n        api_key: str,\n        base_url: str | None = None,\n        http_client: \"httpx.AsyncClient | None\" = None,\n    ):\n        \"\"\"Initialize the OpenAI-compatible client.\n\n        Args:\n            model: Model identifier (e.g., \"gpt-4o\", \"gemini-2.0-flash\").\n            api_key: API key for authentication.\n            base_url: Optional base URL for non-OpenAI providers.\n            http_client: Optional shared httpx client for connection pooling.\n        \"\"\"\n        self._model = model\n        self._api_key = api_key | None = api_key\n        self._client = AsyncOpenAI[\n            api_key=api_key,\n            base_url=base_url,\n            http_client=http_client,\n        ]\n\n    async def create(self, messages: List[Message]) -> str:\n        \"\"\"Send messages to the model and get a response.\n\n        Args:\n            messages: List of messages forming the conversation.\n\n        Returns:\n            The model's response text.\n\n        Raises:\n            openai.APIError: If the API request fails.\n        \"\"\"\n        response = await self._client.chat.completions.create(\n            model=self._model,\n            messages=[self._convert_message(m) for m in messages],\n        )\n\n        # Extract content from response\n        content = response.choices[0].message.content\n        return content if content is not None else \"\"\n\n    def _convert_message(self, msg: Message) -> dict[str, str]:\n        \"\"\"Convert internal message type to OpenAI format.\n\n        Args:\n            msg: Internal message object.\n\n        Returns:\n            Dict in OpenAI message format.\n        \"\"\"\n        if isinstance(msg, SystemMessage):\n            return {\"role\": \"system\", \"content\": msg.content}\n        elif isinstance(msg, UserMessage):\n            return {\"role\": \"user\", \"content\": msg.content}\n        elif isinstance(msg, AssistantMessage):\n            return {\"role\": \"assistant\", \"content\": msg.content}\n        else:\n            # Fallback for any unknown type\n            return {\"role\": \"user\", \"content\": str(msg.content)}"}
{"code_id": "python-sdk_src_acp_task_queue.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\python-sdk_src_acp_task_queue.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\python-sdk_src_acp_task_queue.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\python-sdk_src_acp_task_queue.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "quorum-cli_src_quorum_clients_openai_client.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\quorum-cli_src_quorum_clients_openai_client.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\quorum-cli_src_quorum_clients_openai_client.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\quorum-cli_src_quorum_clients_openai_client.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": "from __future__ import annotations\nfrom typing import TYPE_CHECKING\nfrom openai import OpenAI\nfrom .schema import AssistantMessage, SystemMessage, UserMessage\n\nclass OpenAIModel:\n    \"\"\"A class for OpenAI-compatible APIs.\"\"\"\n\n    def __init__(\n        self,\n        model: str,\n        api_key: str,\n        base_url: str | None = None,\n        organization: str | None = None,\n    ):\n        \"\"\"Initialize the OpenAI-compatible class of model.\n\n        Args:\n            model: Model identifier e.g., 'gpt-3.5-turbo'.\n            api_key: API key for the specified model.\n            base_url: Base URL for the model API. For more information, see\n                https://platform.openai.com/docs/api-reference.\n            organization: Organization ID for the specified model. For more information, see\n                https://platform.openai.com/docs/api-reference.\n        \"\"\"\n        self.model = model\n        self.api_key = api_key\n        self.base_url = base_url\n        self.organization = organization\n\n    @staticmethod\n    def _chat(\n        model: str,\n        messages: list[Message],\n        **kwargs,\n    ) -> str:\n        \"\"\"Send messages to the model and get a response.\n\n        Args:\n            model: List of messages forming the conversation so far.\n            messages: The model's response text.\n            **kwargs: Additional arguments for the API request.\n\n        Returns:\n            The model's response text.\n        \"\"\"\n        client = OpenAI(\n            api_key=kwargs.get(\"api_key\", \"\"),\n            base_url=kwargs.get(\"base_url\", \"\"),\n            organization=kwargs.get(\"organization\", \"\"),\n        )\n        response = client.chat.completions.create(\n            model=model,\n            messages=[message.to_dict() for message in messages],\n            **{k: v for k, v in kwargs.items() if k not in [\"api_key\", \"base_url\", \"organization\"]}},\n        )\n        content = response.choices[0].message.content\n        return content if content is not None else \"\"\n\n    def _convert_message(self, msg: Message) -> dict[str, str]:\n        \"\"\"Convert custom message types to OpenAI format.\n\n        Args:\n            msg: Internal message object.\n\n        Returns:\n            dict: An OpenAI message format.\n        \"\"\"\n        if isinstance(msg, SystemMessage):\n            return {\"role\": \"system\", \"content\": msg.content}\n        elif isinstance(msg, UserMessage):\n            return {\"role\": \"user\", \"content\": msg.content}\n        elif isinstance(msg, AssistantMessage):\n            return {\"role\": \"assistant\", \"content\": msg.content}\n        else:\n            # Fallback for any unknown types\n            return {\"role\": \"user\", \"content\": str(msg.content)}"}
{"code_id": "raxe-ce_src_raxe_domain_models.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\raxe-ce_src_raxe_domain_models.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\raxe-ce_src_raxe_domain_models.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\raxe-ce_src_raxe_domain_models.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "# Domain models for RAXE CE.\n\n# Models are immutable value objects (frozen=True).\n# The domain layer - no I/O operations.\n\nfrom dataclasses import dataclass\nfrom enum import Enum\n\n# Re-export Detection and ScanResult from executor for convenience\nfrom raxe.domain.engine.executor import Detection, ScanResult\n\nclass ThreatType(Enum):\n    \"\"\"Categories of threats.\n\n    Maps to rule families but provides more semantic categorization.\n    \"\"\"\n    PROMPT_INJECTION = \"PROMPT_INJECTION\"\n    JAILBREAK = \"JAILBREAK\"\n    PII_LEAK = \"PII_LEAK\"\n    DATA_EXFILTRATION = \"DATA_EXFIL\"\n    SECURITY = \"SECURITY\"\n    QUALITY = \"QUALITY\"\n    CUSTOM = \"CUSTOM\"\n\n@dataclass(frozen=True)\nclass ScanRequest:\n    \"\"\"Request to scan text for threats.\n\n    Immutable value object for scan input.\n\n    Attributes:\n        text: The text to scan for threats\n        context: Optional context metadata (user_id, session_id, etc.)\n        rule_filters: Optional list of rule IDs to apply (None = all rules)\n        max_text_length: Maximum allowed text length (default 1MB)\n    \"\"\"\n    text: str\n    context: dict[str, str] | None = None\n    rule_filters: list[str] | None = None\n    max_text_length: int = 1_000_000  # 1MB default limit\n\n    def __post_init__(self) -> None:\n        \"\"\"Validate request after construction.\n\n        Raises:\n            ValueError: If validation fails\n        \"\"\"\n        if not self.text:\n            raise ValueError(\"Text cannot be empty\")\n\n        if len(self.text) > self.max_text_length:\n            raise ValueError(\n                f\"Text exceeds maximum length of {self.max_text_length} \"\n                f\"(got {len(self.text)} chars)\"\n            )\n\n        if self.rule_filters is not None and not self.rule_filters:\n            raise ValueError(\"rule_filters cannot be empty list (use None for all rules)\")\n\n    @property\n    def text_length(self) -> int:\n        \"\"\"Length of text to scan.\"\"\"\n        return len(self.text)\n\n    @property\n    def has_filters(self) -> bool:\n        \"\"\"True if rule filters are specified.\"\"\"\n        return self.rule_filters is not None\n\n# Note: BlockAction and ScanPolicy have been removed.\n# The advanced policy system in domain/policies/ replaces this functionality.\n\n__all__ = [\n    \"Detection\",\n    \"ScanRequest\",\n    \"ScanResult\",\n    \"ThreatType\",\n]"}
{"code_id": "raxe-ce_src_raxe_domain_models.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\raxe-ce_src_raxe_domain_models.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\raxe-ce_src_raxe_domain_models.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\raxe-ce_src_raxe_domain_models.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "# Core domain models for RAXE CE.\n#\n# Models are immutable value objects (frozen=True).\n# The domain layer - no I/O operations.\n#\n\nfrom dataclasses import dataclass\nfrom enum import Enum\n\n# Re-export Detection and ScanResult from executor for convenience\nfrom raxe.domain.engine.executor import Detection, ScanResult\n\nclass ThreatType(Enum):\n    \"\"\"Categories of threats.\n\n    Maps to rule families but provides more semantic categorization.\n    \"\"\"\n    PROMPT_INJECTION = \"PROMPT_INJECTION\"\n    JAILBREAK = \"JAILBREAK\"\n    PII_LEAK = \"PII_LEAK\"\n    DATA_EXFILTRATION = \"DATA_EXFIL\"\n    SECURITY = \"SECURITY\"\n    QUALITY = \"QUALITY\"\n    CUSTOM = \"CUSTOM\"\n\n@dataclass(frozen=True)\nclass ScanRequest:\n    \"\"\"Request to scan text for threats.\n\n    Immutable value object for scan input.\n\n    Attributes:\n        text: The text to scan for threats\n        context: Optional context metadata (user_id, session_id, etc.)\n        rule_filters: Optional list of rule IDs to apply (None = all rules)\n        max_text_length: Maximum allowed text length (default 1MB)\n    \"\"\"\n    text: str\n    context: dict[str, str] | None = None\n    rule_filters: list[str] | None = None\n    max_text_length: int = 1_000_000  # 1MB default limit\n\n    def __post_init__(self) -> None:\n        \"\"\"Validate request after construction.\n\n        Raises:\n            ValueError: If validation fails\n        \"\"\"\n        if not self.text:\n            raise ValueError(\"Text cannot be empty\")\n\n        if len(self.text) > self.max_text_length:\n            raise ValueError(\n                f\"Text exceeds maximum length of {self.max_text_length} \"\n                f\"(got {len(self.text)} chars)\"\n            )\n\n        if self.rule_filters is not None and not self.rule_filters:\n            raise ValueError(\"rule_filters cannot be empty list (use None for all rules)\")\n\n    @property\n    def text_length(self) -> int:\n        \"\"\"Length of text to scan.\"\"\"\n        return len(self.text)\n\n    @property\n    def has_filters(self) -> bool:\n        \"\"\"True if rule filters are specified.\"\"\"\n        return self.rule_filters is not None\n\n# Note: BlockAction and ScanPolicy have been removed.\n# The advanced policy system in domain/policies/ replaces this functionality.\n\n__all__ = [\n    \"Detection\",\n    \"ScanRequest\",\n    \"ScanResult\",\n    \"ThreatType\",\n]"}
{"code_id": "raxe-ce_src_raxe_domain_models.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\raxe-ce_src_raxe_domain_models.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\raxe-ce_src_raxe_domain_models.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\raxe-ce_src_raxe_domain_models.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "# Domain models for RAKE OL.\n#\n# Models are immutable value objects (frozen=True).\n# No domain layer - no I/O operations.\n#\nfrom dataclasses import dataclass\nfrom enum import Enum\n\n# Re-export Detection and ScanResult from executor for convenience\nfrom rask.domain.engine.executor import Detection, ScanResult\n\nclass ThreatType(Enum):\n    \"\"\"Categories of threats.\n\n    Maps to rule families but provides more semantic categorization.\n    \"\"\"\n    PROMPT_INJECTION = \"PROMPT_INJECTION\"\n    JAILBREAK = \"JAILBREAK\"\n    PHI_LEAK = \"PHI_LEAK\"\n    DATA_EXFILTRATION = \"DATA_EXFIL\"\n    SECURITY = \"SECURITY\"\n    QUALITY = \"QUALITY\"\n    CUSTOM = \"CUSTOM\"\n\n@dataclass(frozen=True)\nclass ScanRequest:\n    \"\"\"Request to scan text for threats.\n\n    Immutable value object for scan input.\n\n    Attributes:\n        text: The text to scan for threats\n        context: Optional context metadata (user_id, session_id, etc.)\n        rule_filters: Optional list of rule IDs to apply (None = all rules)\n        max_text_length: Maximum allowed text length (default: 1_000_000)\n    \"\"\"\n    text: str\n    context: dict[str, str] | None = None\n    rule_filters: list[str] | None = None\n    max_text_length: int = 1_000_000  # 1MB default limit\n\n    def __post_init__(self) -> None:\n        \"\"\"Validate request after construction.\n\n        Raises:\n            ValueError: If validation fails\n        \"\"\"\n        if not self.text:\n            raise ValueError(\"Text cannot be empty\")\n\n        if len(self.text) > self.max_text_length:\n            raise ValueError(\n                f\"Text exceeds maximum length of {self.max_text_length} \"\n                f\"got {len(self.text)} chars\"\n            )\n\n        if self.rule_filters is not None and not self.rule_filters:\n            raise ValueError(\"Rule_filters cannot be empty list (use None for all rules)\")\n\n    @property\n    def text_length(self) -> int:\n        \"\"\"Length of text to scan.\"\"\"\n        return len(self.text)\n\n    @property\n    def has_filters(self) -> bool:\n        \"\"\"True if rule filters are specified.\"\"\"\n        return self.rule_filters is not None\n\n# Note: BlockAction and ScanPolicy have been removed.\n# The advanced policy system in domain/policies/ replaces this functionality.\n\n__all__ = [\n    \"Detection\",\n    \"ScanRequest\",\n    \"ScanResult\",\n    \"ThreatType\",\n]"}
{"code_id": "quorum-cli_src_quorum_clients_openai_client.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\quorum-cli_src_quorum_clients_openai_client.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\quorum-cli_src_quorum_clients_openai_client.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\quorum-cli_src_quorum_clients_openai_client.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "remnawave-bedolaga-telegram-bot_app_webapi_server.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\remnawave-bedolaga-telegram-bot_app_webapi_server.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\remnawave-bedolaga-telegram-bot_app_webapi_server.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\remnawave-bedolaga-telegram-bot_app_webapi_server.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "from __future__ import annotations\nimport asyncio\nimport logging\nfrom typing import Optional\n\nimport uvicorn\n\nfrom app.config import settings\nfrom .app import create_web_api_app\n\nlogger = logging.getLogger(__name__)\n\nclass WebAPIServer:\n    \"\"\"Асинхронный uvicorn-сервер для административного API.\"\"\"\n\n    def __init__(self, app: Optional[object] = None) -> None:\n        self._app = app or create_web_api_app()\n\n        workers = max(1, int(settings.WEB_API_WORKERS or 1)))\n        if workers > 1:\n            logger.warning(\"WEB_API_WORKERS > 1 не поддерживается в embed-режиме, используем 1\")\n            workers = 1\n\n        self._config = uvicorn.Config(\n            app=self._app,\n            host=settings.WEB_API_HOST,\n            port=int(settings.WEB_API_PORT or 8080),\n            log_level=settings.LOG_LEVEL.lower(),\n            workers=workers,\n            lifespan=\"on\",\n            access_log=False,\n        )\n        self._server = uvicorn.Server(self._config)\n        self._task: Optional[asyncio.Task[None]]] = None\n\n    async def start(self) -> None:\n        if self._task and not self._task.done():\n            logger.info(\"🚀 Административное веб-API уже запущено\")\n            return\n\n    async def _serve() -> None:\n        try:\n            await self._server.serve()\n        except Exception as error:  # pragma: no cover - логируем ошибки сервера\n            logger.exception(\"🚨 Ошибка работы веб-API: %s\", error)\n            raise\n\n    logger.info(\n        \"🚀 Запуск административного API на %s:%s\",\n        settings.WEB_API_HOST,\n        settings.WEB_API_PORT,\n    )\n    self._task = asyncio.create_task(_serve(), name=\"web-api-server\")\n\n    started_attr = getattr(self._server, \"started\", None)\n    started_event = getattr(self._server, \"started_event\", None)\n\n    if isinstance(started_attr, asyncio.Event):\n        await started_attr.wait()\n    elif isinstance(started_event, asyncio.Event):\n        await started_event.wait()\n    else:\n        while not getattr(self._server, \"started\", False):\n            if self._task.done():\n                break\n            await asyncio.sleep(0.1)\n\n    if self._task.done() and self._task.exception():\n        raise self._task.exception()\n\n    async def stop(self) -> None:\n        if not self._task:\n            return\n\n        logger.info(\"🛑 Остановка административного API\")\n        self._server.should_exit = True\n        await self._task\n        self._task = None"}
{"code_id": "remnawave-bedolaga-telegram-bot_app_webapi_server.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\remnawave-bedolaga-telegram-bot_app_webapi_server.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\remnawave-bedolaga-telegram-bot_app_webapi_server.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\remnawave-bedolaga-telegram-bot_app_webapi_server.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "from __future__ import annotations\nimport asyncio\nimport logging\nfrom typing import Optional\n\nimport uvicorn\n\nfrom app.config import settings\n\nfrom .app import create_web_api_app\n\nlogger = logging.getLogger(__name__)\n\nclass WebAPIServer:\n    \"\"\"Асинхронный uvicorn-сервер для административного API.\"\"\"\n\n    def __init__(self, app: Optional[object] = None) -> None:\n        self._app = app or create_web_api_app()\n\n        workers = max(1, int(settings.WEB_API_WORKERS or 1)))\n        if workers > 1:\n            logger.warning(\"WEB_API_WORKERS > 1 не поддерживается в embed-режиме, используем 1\")\n            workers = 1\n\n        self._config = uvicorn.Config(\n            app=self._app,\n            host=settings.WEB_API_HOST,\n            port=int(settings.WEB_API_PORT or 8080),\n            log_level=settings.LOG_LEVEL.lower(),\n            workers=workers,\n            lifespan=\"on\",\n            access_log=False,\n        )\n\n        self._server = uvicorn.Server(self._config)\n        self._task: Optional[asyncio.Task[None]]] = None\n\n    async def start(self) -> None:\n        if self._task and not self._task.done():\n            logger.info(\"🔒 Административное веб-API уже запущено\")\n            return\n\n    async def _serve() -> None:\n        try:\n            await self._server.serve()\n        except Exception as error:  # pragma: no cover - погружаем ошибки сервера\n            logger.exception(\"🔥 Ошибка работы веб-API: %s\", error)\n            raise\n\n    logger.info(\n        \"🚀 Запуск административного API на %s:%s\",\n        settings.WEB_API_HOST,\n        settings.WEB_API_PORT,\n    )\n    self._task = asyncio.create_task(_serve(), name=\"web-api-server\")\n\n    started_attr = getattr(self._server, \"started\", None)\n    started_event = getattr(self._server, \"started_event\", None)\n\n    if isinstance(started_attr, asyncio.Event):\n        await started_attr.wait()\n    elif isinstance(started_event, asyncio.Event):\n        await started_event.wait()\n    else:\n        while not getattr(self._server, \"started\", False):\n            if self._task.done():\n                break\n            await asyncio.sleep(0.1)\n\n    if self._task.done() and self._task.exception():\n        raise self._task.exception()\n\n    async def stop(self) -> None:\n        if not self._task:\n            return\n\n        logger.info(\"🔌 Остановка административного API\")\n        self._server.should_exit = True\n        await self._task\n        self._task = None"}
{"code_id": "raxe-ce_src_raxe_domain_models.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\raxe-ce_src_raxe_domain_models.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\raxe-ce_src_raxe_domain_models.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\raxe-ce_src_raxe_domain_models.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "raxe-ce_src_raxe_domain_models.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\raxe-ce_src_raxe_domain_models.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\raxe-ce_src_raxe_domain_models.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\raxe-ce_src_raxe_domain_models.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "repo-swarm_src_investigator_activity_wrapper.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\repo-swarm_src_investigator_activity_wrapper.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\repo-swarm_src_investigator_activity_wrapper.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\repo-swarm_src_investigator_activity_wrapper.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "# Wrapper for executing Temporal activities without direct Temporal dependency.\n\nimport asyncio\nfrom typing import Optional, Any, Callable\nfrom datetime import timedelta\n\nclass ActivityWrapper:\n    \"\"\"\n    Wrapper class to execute Temporal activities without requiring direct Temporal imports.\n    This allows the investigator module to remain decoupled from Temporal while still\n    being able to execute activities when running within a Temporal workflow context.\n    \"\"\"\n\n    def __init__(self, workflow_context: Optional[Any] = None):\n        \"\"\"\n        Initialize the ActivityWrapper.\n\n        Args:\n            workflow_context: The Temporal workflow context (workflow module) if available\n        \"\"\"\n        self.workflow_context = workflow_context\n        self._is_temporal_context = workflow_context is not None\n\n    async def execute_activity(self, activity_func: Callable, *args,\n                                         start_to_close_timeout: Optional[timedelta] = None,\n                                         retry_policy: Optional[Any] = None,\n                                         **kwargs) -> Any:\n        \"\"\"\n        Execute an activity function.\n\n        If running in a Temporal workflow context, this will execute the activity\n        via Temporal's workflow.execute_activity. Otherwise, it will execute the\n        function directly (for testing or non-Temporal environments).\n\n        Args:\n            activity_func: The activity function to execute\n            *args: Positional arguments for the activity function\n            start_to_close_timeout: Timeout for the activity execution\n            retry_policy: Retry policy for the activity\n            **kwargs: Keyword arguments for the activity function\n\n        Returns:\n            Result from the activity execution\n        \"\"\"\n        if self._is_temporal_context and hasattr(self.workflow_context, 'execute_activity'):\n            # Running in Temporal workflow context\n            return await self.workflow_context.execute_activity(\n                activity_func,\n                *args,\n                start_to_close_timeout=start_to_close_timeout or timedelta(minutes=10),\n                retry_policy=retry_policy,\n                **kwargs\n            )\n        else:\n            # Running outside Temporal context (testing or direct execution)\n            # Execute the activity function directly\n            if asyncio.iscoroutinefunction(activity_func):\n                return await activity_func(*args, **kwargs)\n            else:\n                return activity_func(*args, **kwargs)\n\n    def is_temporal_context(self) -> bool:\n        \"\"\"\n        Check if running in a Temporal workflow context.\n\n        Returns:\n            True if running in Temporal workflow context, False otherwise\n        \"\"\"\n        return self._is_temporal_context"}
{"code_id": "remnawave-bedolaga-telegram-bot_app_webapi_server.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\remnawave-bedolaga-telegram-bot_app_webapi_server.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\remnawave-bedolaga-telegram-bot_app_webapi_server.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\remnawave-bedolaga-telegram-bot_app_webapi_server.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "from __future__ import annotations\n\nimport asyncio\nimport logging\nfrom typing import Optional\n\nimport uvicorn\n\nfrom app.config import settings\n\nfrom .app import create_web_api_app\n\nlogger = logging.getLogger(__name__)\n\nclass WebAPIServer:\n    \"\"\"A class to run uvicorn server and asynchronously start/stop API.\"\"\"\n\n    def __init__(self, app: Optional[object] = None) -> None:\n        self._app = app or create_web_api_app()\n\n        workers = max(1, int(settings.WEB_API_WORKERS or 1)))\n\n        if workers > 1:\n            logger.warning(\"WEB_API_WORKERS > 1 is not supported in embedded-processes, set workers = 1\")\n            workers = 1\n\n        self._config = uvicorn.Config(\n            app=self._app,\n            host=settings.WEB_API_HOST,\n            port=int(settings.WEB_API_PORT or 8000)),\n            log_level=settings.LOG_LEVEL.lower(),\n            workers=workers,\n            lifespan=\"off\",\n            access_log=False,\n        )\n        self._server = uvicorn.Server(self._config)\n        self._task: Optional[asyncio.Task[None]]] = None\n\n    async def start(self) -> None:\n        if self._task and not self._task.done():\n            logger.info(\"🚀 Async server already running\")\n            return\n\n    async def _serve() -> None:\n        try:\n            await self._server.serve()\n        except Exception as error:  # pragma: no cover - not supposed to be covered\n            logger.exception(\"🚨 Ошибка запуска API: %s\", error)\n            raise\n\n    logger.info(\n        \"🚀 Запускаем асинхронный API на %s:%s\",\n        settings.WEB_API_HOST,\n        settings.WEB_API_PORT,\n    )\n\n    self._task = asyncio.create_task(_serve(), name=\"web-api-server\")\n\n    started_attr = getattr(self._server, \"started\", None)\n    started_event = getattr(self._server, \"started_event\", None)\n\n    if isinstance(started_attr, asyncio.Event):\n        await started_attr.wait()\n    elif isinstance(started_event, asyncio.Event):\n        await started_event.wait()\n    else:\n        while not getattr(self._server, \"started\", False)):\n            if self._task.done():\n                break\n            await asyncio.sleep(0.1)\n\n    if self._task.done() and self._task.exception():\n        raise self._task.exception()\n\n    async def stop(self) -> None:\n        if not self._task:\n            return\n\n        logger.info(\"🛑 Останавливаем асинхронный API\")\n\n        self._server.should_exit = True\n        await self._task\n        self._task = None"}
{"code_id": "remnawave-bedolaga-telegram-bot_app_webapi_server.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\remnawave-bedolaga-telegram-bot_app_webapi_server.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\remnawave-bedolaga-telegram-bot_app_webapi_server.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\remnawave-bedolaga-telegram-bot_app_webapi_server.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "repo-swarm_src_investigator_activity_wrapper.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\repo-swarm_src_investigator_activity_wrapper.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\repo-swarm_src_investigator_activity_wrapper.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\repo-swarm_src_investigator_activity_wrapper.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "Wrapper for executing Temporal activities without direct Temporal dependency.\n\nimport asyncio\nfrom typing import Optional, Any, Callable\nfrom datetime import timedelta\n\nclass ActivityWrapper:\n    \"\"\"\n    Wrapper class to execute Temporal activities without requiring direct Temporal imports.\n    This allows the investigator module to remain decoupled from Temporal while still\n    being able to execute activities when running within a Temporal workflow context.\n    \"\"\"\n\n    def __init__(self, workflow_context: Optional[Any] = None):\n        \"\"\"\n        Initialize the ActivityWrapper.\n\n        Args:\n            workflow_context: The Temporal workflow context (workflow module) if available\n        \"\"\"\n        self.workflow_context = workflow_context\n        self._is_temporal_context = workflow_context is not None\n\n    async def execute_activity(self, activity_func: Callable, *args,\n                                         start_to_close_timeout: Optional[timedelta] = None,\n                                         retry_policy: Optional[Any] = None,\n                                         **kwargs) -> Any:\n        \"\"\"\n        Execute an activity function.\n\n        If running in a Temporal workflow context, this will execute the activity\n        via Temporal's workflow.execute_activity. Otherwise, it will execute the\n        function directly (for testing or non-Temporal environments).\n\n        Args:\n            activity_func: The activity function to execute\n            *args: Positional arguments for the activity function\n            start_to_close_timeout: Timeout for the activity execution\n            retry_policy: Retry policy for the activity\n            **kwargs: Keyword arguments for the activity function\n\n        Returns:\n            Result from the activity execution\n        \"\"\"\n        if self._is_temporal_context and hasattr(self.workflow_context, 'execute_activity'):\n            # Running in Temporal workflow context\n            return await self.workflow_context.execute_activity(\n                activity_func,\n                *args,\n                start_to_close_timeout=start_to_close_timeout or timedelta(minutes=10),\n                retry_policy=retry_policy,\n                **kwargs\n            )\n        else:\n            # Running outside Temporal context (testing or direct execution)\n            # Execute the activity function directly\n            if asyncio.iscoroutinefunction(activity_func):\n                return await activity_func(*args, **kwargs)\n            else:\n                return activity_func(*args, **kwargs)\n\n    def is_temporal_context(self) -> bool:\n        \"\"\"\n        Check if running in a Temporal workflow context.\n\n        Returns:\n            True if running in Temporal workflow context, False otherwise\n        \"\"\"\n        return self._is_temporal_context"}
{"code_id": "remnawave-bedolaga-telegram-bot_app_webapi_server.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\remnawave-bedolaga-telegram-bot_app_webapi_server.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\remnawave-bedolaga-telegram-bot_app_webapi_server.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\remnawave-bedolaga-telegram-bot_app_webapi_server.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "repo-swarm_src_investigator_activity_wrapper.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\repo-swarm_src_investigator_activity_wrapper.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\repo-swarm_src_investigator_activity_wrapper.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\repo-swarm_src_investigator_activity_wrapper.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "import asyncio\nfrom typing import Optional, Any, Callable\nfrom datetime import timedelta\n\nclass ActivityWrapper:\n    \"\"\"\n    Wrapper class to execute Temporal activities without requiring direct Temporal imports.\n    This allows the investigator module to remain decoupled from Temporal while still\n    being able to execute activities when running within a Temporal workflow context.\n    \"\"\"\n\n    def __init__(self, workflow_context: Optional[Any] = None):\n        \"\"\"\n        Initialize the ActivityWrapper.\n\n        Args:\n            workflow_context: The Temporal workflow context (workflow module) if available\n        \"\"\"\n        self.workflow_context = workflow_context\n        self._is_temporal_context = workflow_context is not None\n\n    async def execute_activity(self, activity_func: Callable, *args,\n                                         start_to_close_timeout: Optional[timedelta] = None,\n                                         retry_policy: Optional[Any] = None,\n                                         **kwargs) -> Any:\n        \"\"\"\n        Execute an activity function.\n\n        If running in a Temporal workflow context, this will execute the activity\n        via Temporal's workflow.execute_activity. Otherwise, it will execute the\n        function directly (for testing or non-Temporal environments).\n\n        Args:\n            activity_func: The activity function to execute\n            *args: Positional arguments for the activity function\n            start_to_close_timeout: Timeout for the activity execution\n            retry_policy: Retry policy for the activity\n            **kwargs: Keyword arguments for the activity function\n\n        Returns:\n            Result from the activity execution\n        \"\"\"\n        if self._is_temporal_context and hasattr(self.workflow_context, 'execute_activity'):\n            # Running in Temporal workflow context\n            return await self.workflow_context.execute_activity(\n                activity_func,\n                *args,\n                start_to_close_timeout=start_to_close_timeout or timedelta(minutes=10),\n                retry_policy=retry_policy,\n                **kwargs\n            )\n        else:\n            # Running outside Temporal context (testing or direct execution)\n            # Execute the activity function directly\n            if asyncio.iscoroutinefunction(activity_func):\n                return await activity_func(*args, **kwargs)\n            else:\n                return activity_func(*args, **kwargs)\n\n    def is_temporal_context(self) -> bool:\n        \"\"\"\n        Check if running in a Temporal workflow context.\n\n        Returns:\n            True if running in Temporal workflow context, False otherwise\n        \"\"\"\n        return self._is_temporal_context"}
{"code_id": "reverse-api-engineer_src_reverse_api_action_recorder.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\reverse-api-engineer_src_reverse_api_action_recorder.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\reverse-api-engineer_src_reverse_api_action_recorder.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\reverse-api-engineer_src_reverse_api_action_recorder.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "        for item in data:\n            recorder.add_action(RecordedAction(**item))\n        return recorder"}
{"code_id": "reverse-api-engineer_src_reverse_api_action_recorder.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\reverse-api-engineer_src_reverse_api_action_recorder.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\reverse-api-engineer_src_reverse_api_action_recorder.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\reverse-api-engineer_src_reverse_api_action_recorder.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "\"\"\"Simple recording infrastructure for manual browser sessions.\"\"\"\nimport json\nfrom dataclasses import asdict, dataclass\nfrom pathlib import Path\nfrom typing import List, Optional\n\n@dataclass\nclass RecordedAction:\n    \"\"\"A single recorded browser action.\"\"\"\n    type: str  # \"click\", \"fill\", \"navigate\", \"press\"\n    selector: Optional[str] = None\n    value: Optional[str] = None\n    url: Optional[str] = None\n    timestamp: float = 0.0\n    metadata: Optional[dict] = None\n\nclass ActionRecorder:\n    \"\"\"Records browser actions during manual sessions.\"\"\"\n\n    def __init__(self):\n        self.actions: List[RecordedAction] = []\n\n    def add_action(self, action: RecordedAction) -> None:\n        \"\"\"Add an action to the recording.\"\"\"\n        self.actions.append(action)\n\n    def get_actions(self) -> List[RecordedAction]:\n        \"\"\"Get all recorded actions.\"\"\"\n        return self.actions\n\n    def save(self, path: Path) -> None:\n        \"\"\"Save actions to a JSON file.\"\"\"\n        data = [asdict(action) for action in self.actions]\n        with open(path, \"w\") as f:\n            json.dump(data, f, indent=2)\n\n    @classmethod\n    def load(cls, path: Path) -> \"ActionRecorder\":\n        \"\"\"Load actions from a JSON file.\"\"\"\n        recorder = cls()\n        if path.exists():\n            with open(path) as f:\n                data = json.load(f)\n\n        for item in data:\n            recorder.add_action(RecordedAction(**item))\n        return recorder"}
{"code_id": "repo-swarm_src_investigator_activity_wrapper.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\repo-swarm_src_investigator_activity_wrapper.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\repo-swarm_src_investigator_activity_wrapper.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\repo-swarm_src_investigator_activity_wrapper.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": "from typing import Any, Dict, List, Tuple\nfrom .utils import _get_temporal_context\n\nclass _TemporalContext:\n    \"\"\"\n    A class to manage the temporal context without removing direct temporal dependencies.\n    This allows the context to be accessed by activities that are not directly linked to the temporal context.\n    \"\"\"\n    def __init__(self, temporal_context: Any) -> None:\n        \"\"\"\n        Initialize the _TemporalContext instance.\n        \"\"\"\n        self._temporal_context = temporal_context\n\n    def __repr__(self) -> str:\n        \"\"\"\n        Return a string representation of the _TemporalContext instance.\n        \"\"\"\n        return f'_TemporalContext({self._temporal_context!r})'\n\nclass _ActivityContext:\n    \"\"\"\n    A class to manage the activity context.\n    \"\"\"\n    def __init__(self, activity_name: str, activity_args: Tuple[Any, ...], activity_kwargs: Dict[str, Any]) -> None:\n        \"\"\"\n        Initialize the _ActivityContext instance.\n        \"\"\"\n        self._activity_name = activity_name\n        self._activity_args = activity_args\n        self._activity_kwargs = activity_kwargs\n\n    def __repr__(self) -> str:\n        \"\"\"\n        Return a string representation of the _ActivityContext instance.\n        \"\"\"\n        return f'_ActivityContext({self._activity_name!r}, {self._activity_args!r}, {self._activity_kwargs!r})'\n\ndef _accumulate_activity_context(activity_name: str, activity_args: Tuple[Any, ...], activity_kwargs: Dict[str, Any], temporal_context: Any) -> None:\n    \"\"\"\n    Accumulate an activity context.\n    \"\"\"\n    if not _is_temporal_context(temporal_context):\n        raise TypeError('temporal_context must be a _TemporalContext instance')\n\n    # If running in a Temporal workflow context, accumulate the activity context\n    if _is_temporal_context(temporal_context):\n        # Assume the temporal_context is a _TemporalContext instance\n        temporal_context._accumulate_activity_context(activity_name, activity_args, activity_kwargs)\n\ndef _is_temporal_context(obj: Any) -> bool:\n    \"\"\"\n    Check if running in a Temporal workflow context.\n    \"\"\"\n    return isinstance(obj, _TemporalContext)"}
{"code_id": "reverse-api-engineer_src_reverse_api_action_recorder.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\reverse-api-engineer_src_reverse_api_action_recorder.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\reverse-api-engineer_src_reverse_api_action_recorder.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\reverse-api-engineer_src_reverse_api_action_recorder.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "import sys\nfrom dataclasses import dataclass, field\nfrom pathlib import Path\nfrom typing import List, Optional\n\n@dataclass\nclass RecordedAction:\n    \"\"\"A single recorded browser action.\"\"\"\n    type: str  # \"click\", \"fill\", \"navigate\", \"press\"\n    selector: Optional[str] = None\n    value: Optional[str] = None\n    url: Optional[str] = None\n    timestamp: float = 0.0\n    metadata: Optional[dict] = None\n\nclass ActionRecorder:\n    \"\"\"Records browser actions during manual sessions.\"\"\"\n    def __init__(self):\n        self.actions: List[RecordedAction] = []\n\n    def add_action(self, action: RecordedAction) -> None:\n        \"\"\"Add an action to the recording.\"\"\"\n        self.actions.append(action)\n\n    def get_actions(self) -> List[RecordedAction]:\n        \"\"\"Get all recorded actions.\"\"\"\n        return self.actions\n\n    def save(self, path: Path) -> None:\n        \"\"\"Save actions to a JSON file.\"\"\"\n        data = [action.__dict__ for action in self.actions]\n        with open(path, \"w\") as f:\n            json.dump(data, f, indent=2)\n\n    @classmethod\n    def load(cls, path: Path) -> \"ActionRecorder\":\n        \"\"\"Load actions from a JSON file.\"\"\"\n        recorder = cls()\n        if path.exists():\n            with open(path) as f:\n                data = json.load(f)\n            for item in data:\n                recorder.add_action(RecordedAction(**item)))\n        return recorder"}
{"code_id": "repo-swarm_src_investigator_activity_wrapper.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\repo-swarm_src_investigator_activity_wrapper.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\repo-swarm_src_investigator_activity_wrapper.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\repo-swarm_src_investigator_activity_wrapper.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "reverse-api-engineer_src_reverse_api_action_recorder.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\reverse-api-engineer_src_reverse_api_action_recorder.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\reverse-api-engineer_src_reverse_api_action_recorder.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\reverse-api-engineer_src_reverse_api_action_recorder.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": "# This is a wrapper that encapsulates the approach to execute assembly.\n\nclass AssemblyExecutor:\n    \"\"\"A class to execute assembly code.\"\"\"\n    def __init__(self, arch, mode):\n        self.arch = arch\n        self.mode = mode\n        self.asm = None\n\n    def load_asm(self, asm_code):\n        \"\"\"Load assembly code into the executor.\"\"\"\n        self.asm = asm_code\n\n    def execute(self, *args, **kwargs):\n        \"\"\"Execute the loaded assembly code.\"\"\"\n        if not self.asm:\n            raise ValueError(\"No assembly code loaded.\")\n        \n        # Here we would use a library like capstone or keystone\n        # to assemble and execute the code. For this example,\n        # we'll just return a dummy result.\n        return \"Execution result\"\n        by size += size\n            assembly and set to AssemblyExecutor.asm[0] and\n        return size"}
{"code_id": "rf-mcp_src_robotmcp_models_browser_models.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\rf-mcp_src_robotmcp_models_browser_models.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\rf-mcp_src_robotmcp_models_browser_models.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\rf-mcp_src_robotmcp_models_browser_models.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "from dataclasses import dataclass, field\nfrom typing import Any, Dict, List, Optional\n\n@dataclass\nclass BrowserState:\n    \"\"\"Represents Browser Library and SeleniumLibrary state.\"\"\"\n    # Common browser state\n    browser_type: Optional[str] = None\n    current_url: Optional[str] = None\n    page_title: Optional[str] = None\n    viewport: Dict[str, int] = field(default_factory=lambda: {\"width\": 1280, \"height\": 720}))\n    page_source: Optional[str] = None\n    aria_snapshot: Optional[Any] = None\n    aria_snapshot_format: Optional[str] = None\n    aria_snapshot_selector: Optional[str] = None\n    cookies: List[Dict[str, Any]]] = field(default_factory=list)\n    local_storage: Dict[str, str] = field(default_factory=dict)\n\n    # Browser Library specific state\n    browser_id: Optional[str] = None\n    context_id: Optional[str] = None\n    page_id: Optional[str] = None\n\n    # SeleniumLibrary specific state\n    driver_instance: Optional[Any] = None\n    selenium_session_id: Optional[str] = None\n\n    # Active library indicator (\"browser\" or \"selenium\" or None)\n    active_library: Optional[str] = None\n    session_storage: Dict[str, str] = field(default_factory=dict)\n    page_elements: List[Dict[str, Any]]] = field(default_factory=list)\n\n    def is_browser_library_active(self) -> bool:\n        \"\"\"Check if Browser Library is the active library.\"\"\"\n        return self.active_library == \"browser\"\n\n    def is_selenium_library_active(self) -> bool:\n        \"\"\"Check if SeleniumLibrary is the active library.\"\"\"\n        return self.active_library == \"selenium\"\n\n    def has_browser_session(self) -> bool:\n        \"\"\"Check if there's an active browser session.\"\"\"\n        return (self.browser_id is not None or\n                self.driver_instance is not None)\n\n    def has_page_loaded(self) -> bool:\n        \"\"\"Check if a page is currently loaded.\"\"\"\n        return (self.page_id is not None or\n                self.current_url is not None)\n\n    def reset(self) -> None:\n        \"\"\"Reset browser state to initial values.\"\"\"\n        self.browser_type = None\n        self.current_url = None\n        self.page_title = None\n        self.page_source = None\n        self.aria_snapshot = None\n        self.aria_snapshot_format = None\n        self.aria_snapshot_selector = None\n        self.cookies.clear()\n        self.local_storage.clear()\n        self.browser_id = None\n        self.context_id = None\n        self.page_id = None\n        self.driver_instance = None\n        self.selenium_session_id = None\n        self.active_library = None\n        self.session_storage.clear()\n        self.page_elements.clear()"}
{"code_id": "reverse-api-engineer_src_reverse_api_action_recorder.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\reverse-api-engineer_src_reverse_api_action_recorder.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\reverse-api-engineer_src_reverse_api_action_recorder.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\reverse-api-engineer_src_reverse_api_action_recorder.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "rf-mcp_src_robotmcp_models_browser_models.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\rf-mcp_src_robotmcp_models_browser_models.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\rf-mcp_src_robotmcp_models_browser_models.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\rf-mcp_src_robotmcp_models_browser_models.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "\"\"\"Browser-related data models.\"\"\"\n\nfrom dataclasses import dataclass, field\nfrom typing import Any, Dict, List, Optional\n\n\n@dataclass\nclass BrowserState:\n    \"\"\"Represents Browser Library and SeleniumLibrary state.\"\"\"\n\n    # Common browser state\n    browser_type: Optional[str] = None\n    current_url: Optional[str] = None\n    page_title: Optional[str] = None\n    viewport: Dict[str, int] = field(default_factory=lambda: {\"width\": 1280, \"height\": 720}))\n    page_source: Optional[str] = None\n    aria_snapshot: Optional[Any] = None\n    aria_snapshot_format: Optional[str] = None\n    aria_snapshot_selector: Optional[str] = None\n    cookies: List[Dict[str, Any]]] = field(default_factory=list)\n    local_storage: Dict[str, str] = field(default_factory=dict)\n\n    # Browser Library specific state\n    browser_id: Optional[str] = None\n    context_id: Optional[str] = None\n    page_id: Optional[str] = None\n\n    # SeleniumLibrary specific state\n    driver_instance: Optional[Any] = None\n    selenium_session_id: Optional[str] = None\n\n    # Active library indicator (\"browser\" or \"selenium\" or None)\n    active_library: Optional[str] = None\n    session_storage: Dict[str, str] = field(default_factory=dict)\n    page_elements: List[Dict[str, Any]]] = field(default_factory=list)\n\n    def is_browser_library_active(self) -> bool:\n        \"\"\"Check if Browser Library is the active library.\"\"\"\n        return self.active_library == \"browser\"\n\n    def is_selenium_library_active(self) -> bool:\n        \"\"\"Check if SeleniumLibrary is the active library.\"\"\"\n        return self.active_library == \"selenium\"\n\n    def has_browser_session(self) -> bool:\n        \"\"\"Check if there's an active browser session.\"\"\"\n        return (self.browser_id is not None or\n                 self.driver_instance is not None)\n\n    def has_page_loaded(self) -> bool:\n        \"\"\"Check if a page is currently loaded.\"\"\"\n        return (self.page_id is not None or\n                 self.current_url is not None)\n\n    def reset(self) -> None:\n        \"\"\"Reset browser state to initial values.\"\"\"\n        self.browser_type = None\n        self.current_url = None\n        self.page_title = None\n        self.page_source = None\n        self.aria_snapshot = None\n        self.aria_snapshot_format = None\n        self.aria_snapshot_selector = None\n        self.cookies.clear()\n        self.local_storage.clear()\n        self.browser_id = None\n        self.context_id = None\n        self.page_id = None\n        self.driver_instance = None\n        self.selenium_session_id = None\n        self.active_library = None\n        self.session_storage.clear()\n        self.page_elements.clear()"}
{"code_id": "rf-mcp_src_robotmcp_models_browser_models.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\rf-mcp_src_robotmcp_models_browser_models.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\rf-mcp_src_robotmcp_models_browser_models.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\rf-mcp_src_robotmcp_models_browser_models.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": ""}
{"code_id": "rules_src_formats_antigravity.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\rules_src_formats_antigravity.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\rules_src_formats_antigravity.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\rules_src_formats_antigravity.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "# Copyright 2025 Cisco Systems, Inc. and its affiliates\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nAntigravity Format Implementation\n\nGenerates .md rule files for Antigravity with YAML frontmatter.\n\"\"\"\nfrom formats.base import BaseFormat, ProcessedRule\n\nclass AntigravityFormat(BaseFormat):\n    \"\"\"\n    Antigravity format implementation (.md rule files).\n\n    Antigravity uses .md files with YAML frontmatter containing:\n    - trigger: 'always_on' or 'glob' (activation type)\n    - globs: (if trigger is 'glob') File matching patterns\n    - description: Rule description\n    - version: Rule version\n\n    Rules use activation types (Always On or Glob) to determine when\n    they apply, similar to Windsurf's implementation.\n    See: https://antigravity.google/docs/rules-workflows\n    \"\"\"\n    def get_format_name(self) -> str:\n        \"\"\"Return Antigravity format identifier.\"\"\"\n        return \"antigravity\"\n\n    def get_file_extension(self) -> str:\n        \"\"\"Return Antigravity format file extension.\"\"\"\n        return \".md\"\n\n    def get_output_subpath(self) -> str:\n        \"\"\"Return Antigravity output subdirectory.\"\"\"\n        return \".agent/rules\"\n\n    def generate(self, rule: ProcessedRule, globs: str) -> str:\n        \"\"\"\n        Generate Antigravity .md format with YAML frontmatter.\n\n        Args:\n            rule: The processed rule to format\n            globs: Glob patterns for file matching\n\n        Returns:\n            Formatted .md content with trigger, globs, description, and version\n\n        Note:\n            Antigravity rules use activation types:\n            - 'always_on': Rule applies to all files (when alwaysApply is true)\n            - 'glob': Rule applies to files matching glob patterns (language-specific)\n        \"\"\"\n        yaml_lines = []\n\n        # Use trigger: always_on for rules that should always apply\n        if rule.always_apply:\n            yaml_lines.append(\"trigger: always_on\")\n        else:\n            yaml_lines.append(\"trigger: glob\")\n            yaml_lines.append(f\"globs: [{globs}]\")\n\n        # Add description (required by Antigravity spec)\n        desc = self._format_yaml_field(\"description\", rule.description)\n        if desc:\n            yaml_lines.append(desc)\n\n        # Add version\n        yaml_lines.append(f\"version: {self.version}\")\n\n        return self._build_yaml_frontmatter(yaml_lines, rule.content)"}
{"code_id": "rf-mcp_src_robotmcp_models_browser_models.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\rf-mcp_src_robotmcp_models_browser_models.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\rf-mcp_src_robotmcp_models_browser_models.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\rf-mcp_src_robotmcp_models_browser_models.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "rf-mcp_src_robotmcp_models_browser_models.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\rf-mcp_src_robotmcp_models_browser_models.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\rf-mcp_src_robotmcp_models_browser_models.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\rf-mcp_src_robotmcp_models_browser_models.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "rules_src_formats_antigravity.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\rules_src_formats_antigravity.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\rules_src_formats_antigravity.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\rules_src_formats_antigravity.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": "        query_form = []\n\n        if there is trigger argument for rules that should always apply\n        if is not defined, apply\n            query_form.append(\"trigger: always_on\")\n        else:\n            query_form.append(\"trigger: always_off\")\n            query_form.append(\"title: 'gbml'\")\n\n        # Add description as requested by text grepsity ahead\n        desc = self._format_query(\"desc\", \"description\", rules, description)\n        if desc:\n            query_form.append(desc)\n\n        # Add service\n        query_form.append(f\"service: {self.service}\")\n\n        return self._get_to_post_format(query_form, rules, output)"}
{"code_id": "rules_src_formats_antigravity.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\rules_src_formats_antigravity.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\rules_src_formats_antigravity.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\rules_src_formats_antigravity.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "Copyright 2025 Cisco Systems, Inc. and its affiliates\n\nSPDX-License-Identifier: Apache-2.0\n\n\"\"\"\n\nAntigravity Format Implementation\n\nGenerates .md rule files for Antigravity with YAML frontmatter.\n\n\"\"\"\n\nfrom formats.base import BaseFormat, ProcessedRule\n\nclass AntigravityFormat(BaseFormat):\n    \"\"\"\n    Antigravity format implementation (.md rule files).\n\n    Antigravity uses .md files with YAML frontmatter containing:\n    - trigger: 'always_on' or 'glob' (activation type)\n    - globs: (if trigger is 'glob') File matching patterns\n    - description: Rule description\n    - version: Rule version\n\n    Rules use activation types (Always On or Glob) to determine when\n    they apply, similar to Windsurf's implementation.\n    See: https://antigravity.google/docs/rules-workflows\n    \"\"\"\n    def get_format_name(self) -> str:\n        \"\"\"Return Antigravity format identifier.\"\"\"\n        return \"antigravity\"\n\n    def get_file_extension(self) -> str:\n        \"\"\"Return Antigravity format file extension.\"\"\"\n        return \".md\"\n\n    def get_output_subpath(self) -> str:\n        \"\"\"Return Antigravity output subdirectory.\"\"\"\n        return \".agent/rules\"\n\n    def generate(self, rule: ProcessedRule, globs: str) -> str:\n        \"\"\"\n        Generate Antigravity .md format with YAML frontmatter.\n\n        Args:\n            rule: The processed rule to format\n            globs: Glob patterns for file matching\n\nReturns:\n    Formatted .md content with trigger, globs, description, and version\n\nNote:\n    Antigravity rules use activation types:\n    - 'always_on': Rule applies to all files (when alwaysApply is true)\n    - 'glob': Rule applies to files matching glob patterns (language-specific)\n\"\"\"\n        yaml_lines = []\n\n        # Use trigger: always_on for rules that should always apply\n        if rule.always_apply:\n            yaml_lines.append(\"trigger: always_on\")\n        else:\n            yaml_lines.append(\"trigger: glob\")\n            yaml_lines.append(f\"globs: [{globs}]\")\n\n        # Add description (required by Antigravity spec)\n        desc = self._format_yaml_field(\"description\", rule.description)\n        if desc:\n            yaml_lines.append(desc)\n\n        # Add version\n        yaml_lines.append(f\"version: [{self.version}]\")\n\n        return self._build_yaml_frontmatter(yaml_lines, rule.content)"}
{"code_id": "rules_src_formats_antigravity.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\rules_src_formats_antigravity.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\rules_src_formats_antigravity.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\rules_src_formats_antigravity.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "Copyright 2025 Cisco Systems, Inc. and its affiliates\nLicense-Identifier: Apache-2.0\n\n\"\"\"\nAntigravity format implementation\n\nGenerates .md rule files for Antigravity with YAML frontmatter.\n\"\"\"\n\nfrom formats.base import BaseFormat, ProcessedRule\n\nclass AntigravityFormat(BaseFormat):\n    \"\"\"\n    Antigravity format implementation (.md rule files).\n\n    Antigravity uses .md files with YAML frontmatter containing:\n    - trigger: 'always_on' or 'glob' (activation type)\n    - glob: (if trigger is 'glob') file matching patterns\n    - description: Rule description\n    - version: Rule version\n\n    Rules use activation types (Always On or Glob) to determine when\n    they apply, similar to Windup's implementation.\n    See: https://antigravity.google/docs/rules-workflows\n    \"\"\"\n\n    def get_format_name(self) -> str:\n        \"\"\"Return Antigravity format identifier.\"\"\"\n        return \"antigravity\"\n\n    def get_file_extension(self) -> str:\n        \"\"\"Return Antigravity format file extension.\"\"\"\n        return \".md\"\n\n    def get_output_subpath(self) -> str:\n        \"\"\"Return Antigravity output subdirectory.\"\"\"\n        return \".agent/rules\"\n\n    def generate(self, rule: ProcessedRule, glob: str) -> str:\n        \"\"\"\n        Generate Antigravity .md format with YAML frontmatter.\n\n        Args:\n            rule: The processed rule to format\n            glob: Glob patterns for file matching\n\n        Returns:\n            Formatted .md content with trigger, glob, description, and version\n\n        Note:\n            Antigravity rules use activation types:\n            - 'always_on': Rule applies to all files (when alwaysApply is true)\n            - 'glob': Rule applies to files matching glob patterns (language-specific)\n        \"\"\"\n        yaml_lines = []\n\n        # Use trigger: always_on for rules that should always apply\n        if rule.always_apply:\n            yaml_lines.append(\"trigger: always_on\")\n        else:\n            yaml_lines.append(\"trigger: glob\")\n            yaml_lines.append(f\"glob: [{glob}]\")\n\n        # Add description (required by Antigravity specs)\n        desc = self._format_yaml_field(\"description\", rule.description)\n        if desc:\n            yaml_lines.append(desc)\n\n        # Add version\n        yaml_lines.append(f\"version: {self.version}\")\n\n        return self._build_yaml_frontmatter(yaml_lines, rule.content)"}
{"code_id": "sam3d-body-rerun_src_sam3d_body_models_backbones_dinov3.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\sam3d-body-rerun_src_sam3d_body_models_backbones_dinov3.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\sam3d-body-rerun_src_sam3d_body_models_backbones_dinov3.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\sam3d-body-rerun_src_sam3d_body_models_backbones_dinov3.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "# Copyright (c) Meta Platforms, Inc. and affiliates.\n\nimport torch\nfrom torch import nn\n\nclass Dinov3Backbone(nn.Module):\n    def __init__(\n        self, name=\"dinov2_vitb14\", pretrained_weight=None, cfg=None, *args, **kwargs\n    ):\n        super().__init__()\n        self.name = name\n        self.cfg = cfg\n\n        self.encoder = torch.hub.load(\n            \"facebookresearch/dinov3\",\n            self.name,\n            source=\"github\",\n            pretrained=False,\n            drop_path=self.cfg.MODEL.BACKBONE.DROP_PATH_RATE,\n        )\n        self.patch_size = self.encoder.patch_size\n        self.embed_dim = self.embed_dims = self.encoder.embed_dim\n\n    def forward(self, x, extra_embed=None):\n        \"\"\"\n        Encode a RGB image using a ViT-backbone\n        Args:\n            - x: torch.Tensor of shape [bs,3,w,h]\n        Return:\n            - y: torch.Tensor of shape [bs,k,d] - image in patchified mode\n        \"\"\"\n        assert extra_embed is None, \"Not Implemented Yet\"\n\n        y = self.encoder.get_intermediate_layers(x, n=1, reshape=True, norm=True)[-1]\n\n        return y\n\n    def get_layer_depth(self, param_name: str, prefix: str = \"encoder.\"):\n        \"\"\"Get the layer-wise depth of a parameter.\n        Args:\n            param_name (str): The name of the parameter.\n            prefix (str): The prefix for the parameter.\n                Defaults to an empty string.\n        Returns:\n            Tuple[int, int]: The layer-wise depth and the num of layers.\n        Note:\n            The first depth is the stem module (``layer_depth=0``), and the\n            last depth is the subsequent module (``layer_depth=num_layers-1``)\n        \"\"\"\n        num_layers = self.encoder.n_blocks + 2\n\n        if not param_name.startswith(prefix):\n            # For subsequent module like head\n            return num_layers - 1, num_layers\n\n        param_name = param_name[len(prefix) :]\n\n        if param_name in (\"cls_token\", \"pos_embed\", \"storage_tokens\"):\n            layer_depth = 0\n        elif param_name.startswith(\"patch_embed\"):\n            layer_depth = 0\n        elif param_name.startswith(\"blocks\"):\n            layer_id = int(param_name.split(\".\")[1])\n            layer_depth = layer_id + 1\n        else:\n            layer_depth = num_layers - 1\n\n        return layer_depth, num_layers"}
{"code_id": "sam3d-body-rerun_src_sam3d_body_models_backbones_dinov3.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\sam3d-body-rerun_src_sam3d_body_models_backbones_dinov3.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\sam3d-body-rerun_src_sam3d_body_models_backbones_dinov3.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\sam3d-body-rerun_src_sam3d_body_models_backbones_dinov3.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "# Copyright (c) Meta Platforms, Inc. and affiliates.\n\nimport torch\nfrom torch import nn\n\nclass Dinov3Backbone(nn.Module):\n    def __init__(\n        self, name=\"dinov2_vitb14\", pretrained_weight=None, cfg=None, *args, **kwargs\n    ):\n        super().__init__()\n        self.name = name\n        self.cfg = cfg\n\n        self.encoder = torch.hub.load(\n            \"facebookresearch/dinov3\",\n            self.name,\n            source=\"github\",\n            pretrained=False,\n            drop_path=self.cfg.MODEL.BACKBONE.DROP_PATH_RATE,\n        )\n        self.patch_size = self.encoder.patch_size\n        self.embed_dim = self.embed_dims = self.encoder.embed_dim\n\n    def forward(self, x, extra_embed=None):\n        \"\"\"\n        Encode a RGB image using a ViT-backbone\n        Args:\n            - x: torch.Tensor of shape [bs,3,w,h]\n        Return:\n            - y: torch.Tensor of shape [bs,k,d] - image in patchified mode\n        \"\"\"\n        assert extra_embed is None, \"Not Implemented Yet\"\n\n        y = self.encoder.get_intermediate_layers(x, n=1, reshape=True, norm=True)[-1]\n\n        return y\n\n    def get_layer_depth(self, param_name: str, prefix: str = \"encoder.\"):\n        \"\"\"Get the layer-wise depth of a parameter.\n        Args:\n            param_name (str): The name of the parameter.\n            prefix (str): The prefix for the parameter.\n                Defaults to an empty string.\n        Returns:\n            Tuple[int, int]: The layer-wise depth and the num of layers.\n        Note:\n        \"\"\"\n\n            The first depth is the stem module (``layer_depth=0``), and the\n            last depth is the subsequent module (``layer_depth=num_layers-1``)\n        \"\"\"\n        num_layers = self.encoder.n_blocks + 2\n\n        if not param_name.startswith(prefix):\n            # For subsequent module like head\n            return num_layers - 1, num_layers\n\n        param_name = param_name[len(prefix) :]\n\n        if param_name in (\"cls_token\", \"pos_embed\", \"storage_tokens\"):\n            layer_depth = 0\n        elif param_name.startswith(\"patch_embed\"):\n            layer_depth = 0\n        elif param_name.startswith(\"blocks\"):\n            layer_id = int(param_name.split(\".\")[1])\n            layer_depth = layer_id + 1\n        else:\n            layer_depth = num_layers - 1\n\n        return layer_depth, num_layers"}
{"code_id": "rules_src_formats_antigravity.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\rules_src_formats_antigravity.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\rules_src_formats_antigravity.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\rules_src_formats_antigravity.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": "from flask import Blueprint, render_template, request, jsonify, redirect, url_for\nfrom flask_login import login_required, current_user\nfrom .models import Post, Comment, Like\nfrom .forms import PostForm, CommentForm\nfrom . import db\n\nbp = Blueprint('blog', __name__)\n\n@app.route('/create', methods=['GET', 'POST'])\n@login_required\ndef create_post():\n    form = PostForm()\n    if form.validate_on_submit():\n        post = Post(title=form.title.data, body=form.body.data, user_id=current_user.id)\n        db.session.add(post)\n        db.session.commit()\n        flash('Your post has been created!', 'success')\n        return redirect(url_for('blog.home'))\n    return render_template('create_post.html', title='New Post', form=form, legend='New Post')\n\n@app.route('/post/<int:post_id>')\ndef post(post_id):\n    post = Post.query.get_or_404(post_id)\n    return render_template('post.html', title=post.title, post=post)\n\n@app.route('/post/<int:post_id>/update', methods=['GET', 'POST'])\n@login_required\ndef update_post(post_id):\n    post = Post.query.get_or_404(post_id)\n    if post.author != current_user:\n        abort(403)\n    form = PostForm()\n    if form.validate_on_submit():\n        post.title = form.title.data\n        post.body = form.body.data\n        db.session.commit()\n        flash('Your post has been updated!', 'success')\n        return redirect(url_for('blog.post', post_id=post.id)))\n    elif request.method == 'GET':\n        form.title.data = post.title\n        form.body.data = post.body\n    return render_template('create_post.html', title='Update Post', form=form, legend='Update Post')\n\n@app.route('/post/<int:post_id>/delete', methods=['POST'])\n@login_required\ndef delete_post(post_id):\n    post = Post.query.get_or_404(post_id)\n    if post.author != current_user:\n        abort(403)\n    db.session.delete(post)\n    db.session.commit()\n    flash('Your post has been deleted!', 'success')\n    return redirect(url_for('blog.home'))\n\n@app.route('/comment/<int:comment_id>/delete', methods=['POST'])\n@login_required\ndef delete_comment(comment_id):\n    comment = Comment.query.get_or_404(comment_id)\n    if comment.author != current_user:\n        abort(403)\n    db.session.delete(comment)\n    db.session.commit()\n    flash('Your comment has been deleted!', 'success')\n    return redirect(url_for('blog.post', post_id=comment.post_id)))\n\n@app.route('/like/<int:post_id>', methods=['POST'])\n@login_required\ndef like_post(post_id):\n    post = Post.query.get_or_404(post_id)\n    if current_user in post.likes:\n        post.likes.remove(current_user)\n    else:\n        post.likes.append(current_user)\n    db.session.commit()\n    return jsonify({'likes': len(post.likes)})\n\n@app.route('/comment/<int:post_id>', methods=['POST'])\n@login_required\ndef comment_post(post_id):\n    post = Post.query.get_or_404(post_id)\n    form = CommentForm()\n    if form.validate_on_submit():\n        comment = Comment(body=form.body.data, user_id=current_user.id, post_id=post.id)\n        db.session.add(comment)\n        db.session.commit()\n        flash('Your comment has been posted!', 'success')\n        return redirect(url_for('blog.post', post_id=post.id)))\n    return render_template('post.html', post=post, form=form)"}
{"code_id": "sam3d-body-rerun_src_sam3d_body_models_backbones_dinov3.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\sam3d-body-rerun_src_sam3d_body_models_backbones_dinov3.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\sam3d-body-rerun_src_sam3d_body_models_backbones_dinov3.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\sam3d-body-rerun_src_sam3d_body_models_backbones_dinov3.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "Copyright (c) Meta Platforms, Inc. and affiliates.\n\nimport torch\nfrom torchvision import nn\n\nclass DinoVisionTransformer(nn.Module):\n    def __init__(\n        self,\n        name=\"dinov2_vitb14\",\n        pretrained_weight=None,\n        cfg=None,\n        **kwargs\n    ):\n        super().__init__()\n        self.name = name\n        self.cfg = cfg\n\n        self.encoder = torch.hub.load(\n            \"facebookresearch/dinov2\",\n            self.name,\n            source=\"github\",\n            pretrained=False,\n            drop_path_rate=self.cfg.MODEL.BACKBONE.DROP_PATH_RATE,\n        )\n        self.patch_size = self.encoder.patch_size\n        self.embed_dim = self.embed_dims = self.encoder.embed_dim\n\n    def forward(self, x, extra_embed=None):\n        \"\"\"\n        Encode a RGB image using a ViT backbone\n        Args:\n            x: torch.Tensor of shape [b, 3, h, w]\n        Returns:\n            y: torch.Tensor of shape [b, k, d] -- image in patchified mode\n        \"\"\"\n        assert extra_embed is None, \"Not implemented yet\"\n\n        y = self.encoder.get_intermediate_layers(x, n=1, reshape=True, return_raw=False)[-1]\n        return y\n\n    def get_layer_depth(self, param_name: str, prefix: str = \"encoder.\"):\n        \"\"\"\n        Get the layer-wise depth of a parameter.\n        Args:\n            param_name (str): The name of the parameter.\n            prefix (str): The prefix for the parameter.\n                Defaults to an empty string.\n        Returns:\n            Tuple[int, int]: The layer-wise depth and the sum of layers.\n        \"\"\"\n        num_layers = self.encoder.n_blocks + 2\n\n        if not param_name.startswith(prefix):\n            # For subsequent modules like head\n            return num_layers - 1, num_layers\n\n        param_name = param_name[len(prefix) :]\n\n        if param_name in (\"cls_token\", \"pos_embed\", \"storage_tokens\"):\n            layer_depth = 0\n        elif param_name.startswith(\"patch_embed\"):\n            layer_depth = 0\n        elif param_name.startswith(\"blocks\"):\n            layer_id = int(param_name.split(\".\")[1])\n            layer_depth = layer_id + 1\n        else:\n            layer_depth = num_layers - 1\n\n        return layer_depth, num_layers"}
{"code_id": "scope_src_scope_server_download_progress_manager.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\scope_src_scope_server_download_progress_manager.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\scope_src_scope_server_download_progress_manager.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\scope_src_scope_server_download_progress_manager.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "# Simple progress tracking for pipeline model downloads.\n\nimport threading\n\nclass DownloadProgressManager:\n    \"\"\"Simple progress tracker for pipeline downloads.\"\"\"\n\n    def __init__(self):\n        self._progress = {}\n        self._lock = threading.Lock()\n\n    def update(\n        self, pipeline_id: str, artifact: str, downloaded_mb: float, total_mb: float\n    ):\n        \"\"\"Update download progress.\"\"\"\n        with self._lock:\n            if pipeline_id not in self._progress:\n                self._progress[pipeline_id] = {\"artifacts\": {}, \"is_downloading\": True}\n                self._progress[pipeline_id][\"artifacts\"][artifact] = {\"downloaded_mb\": downloaded_mb, \"total_mb\": total_mb}\n\n    def get_progress(self, pipeline_id: str):\n        \"\"\"Get current artifact progress.\"\"\"\n        with self._lock:\n            if pipeline_id not in self._progress:\n                return None\n            data = self._progress[pipeline_id]\n            if not data[\"artifacts\"]:\n                return None\n\n            # The current artifact is the last one in the dict\n            *_, (current_artifact, current_data)) = data[\"artifacts\"].items()\n\n            # Calculate percentage for current artifact\n            current_percentage = 0\n            if current_data[\"total_mb\"] > 0:\n                current_percentage = (\n                    current_data[\"downloaded_mb\"] / current_data[\"total_mb\"] * 100\n                )\n\n            return {\n                \"is_downloading\": data[\"is_downloading\"],\n                \"percentage\": round(current_percentage, 1),\n                \"current_artifact\": current_artifact,\n            }\n\n    def mark_complete(self, pipeline_id: str):\n        \"\"\"Mark download as complete.\"\"\"\n        with self._lock:\n            if pipeline_id in self._progress:\n                self._progress[pipeline_id][\"is_downloading\"] = False\n\n    def clear_progress(self, pipeline_id: str):\n        \"\"\"Clear progress data.\"\"\"\n        with self._lock:\n            self._progress.pop(pipeline_id, None)\n\n# Global singleton instance\ndownload_progress_manager = DownloadProgressManager()"}
{"code_id": "sam3d-body-rerun_src_sam3d_body_models_backbones_dinov3.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\sam3d-body-rerun_src_sam3d_body_models_backbones_dinov3.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\sam3d-body-rerun_src_sam3d_body_models_backbones_dinov3.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\sam3d-body-rerun_src_sam3d_body_models_backbones_dinov3.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "scope_src_scope_server_download_progress_manager.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\scope_src_scope_server_download_progress_manager.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\scope_src_scope_server_download_progress_manager.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\scope_src_scope_server_download_progress_manager.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "# Simple progress tracking for pipeline model downloads.\n\nimport threading\n\nclass DownloadProgressManager:\n    \"\"\"Simple progress tracker for pipeline downloads.\"\"\"\n    def __init__(self):\n        self._progress = {}\n        self._lock = threading.Lock()\n\n    def update(\n        self, pipeline_id: str, artifact: str, downloaded_mb: float, total_mb: float\n    ):\n        \"\"\"Update download progress.\"\"\"\n        with self._lock:\n            if pipeline_id not in self._progress:\n                self._progress[pipeline_id] = {\"artifacts\": {}, \"is_downloading\": True}\n            self._progress[pipeline_id][\"artifacts\"][artifact] = {\n                \"downloaded_mb\": downloaded_mb,\n                \"total_mb\": total_mb,\n            }\n\n    def get_progress(self, pipeline_id: str):\n        \"\"\"Get current artifact progress.\"\"\"\n        with self._lock:\n            if pipeline_id not in self._progress:\n                return None\n            data = self._progress[pipeline_id]\n            if not data[\"artifacts\"]:\n                return None\n\n            # The current artifact is the last one in the dict\n            *_, (current_artifact, current_data) = data[\"artifacts\"].items()\n\n            # Calculate percentage for current artifact\n            current_percentage = 0\n            if current_data[\"total_mb\"] > 0:\n                current_percentage = (\n                    current_data[\"downloaded_mb\"] / current_data[\"total_mb\"] * 100\n                )\n            return {\n                \"is_downloading\": data[\"is_downloading\"],\n                \"percentage\": round(current_percentage, 1),\n                \"current_artifact\": current_artifact,\n            }\n\n    def mark_complete(self, pipeline_id: str):\n        \"\"\"Mark download as complete.\"\"\"\n        with self._lock:\n            if pipeline_id in self._progress:\n                self._progress[pipeline_id][\"is_downloading\"] = False\n\n    def clear_progress(self, pipeline_id: str):\n        \"\"\"Clear progress data.\"\"\"\n        with self._lock:\n            self._progress.pop(pipeline_id, None)\n\n# Global singleton instance\ndownload_progress_manager = DownloadProgressManager()"}
{"code_id": "sam3d-body-rerun_src_sam3d_body_models_backbones_dinov3.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\sam3d-body-rerun_src_sam3d_body_models_backbones_dinov3.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\sam3d-body-rerun_src_sam3d_body_models_backbones_dinov3.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\sam3d-body-rerun_src_sam3d_body_models_backbones_dinov3.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "scope_src_scope_server_download_progress_manager.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\scope_src_scope_server_download_progress_manager.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\scope_src_scope_server_download_progress_manager.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\scope_src_scope_server_download_progress_manager.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "# Simple progress tracking for pipeline model downloads.\n\nimport threading\n\nclass DownloadProgressManager:\n    \"\"\"Simple progress tracker for pipeline downloads.\"\"\"\n    def __init__(self):\n        self._progress = {}\n        self._lock = threading.Lock()\n\n    def update(self, pipeline_id: str, artifact: str, downloaded_mb: float, total_mb: float):\n        \"\"\"Update download progress.\"\"\"\n        with self._lock:\n            if pipeline_id not in self._progress:\n                self._progress[pipeline_id] = {\"artifacts\": {}, \"is_downloading\": True}\n            self._progress[pipeline_id][\"artifacts\"][artifact] = {\"downloaded_mb\": downloaded_mb, \"total_mb\": total_mb}\n\n    def get_progress(self, pipeline_id: str):\n        \"\"\"Get current artifact progress.\"\"\"\n        with self._lock:\n            if pipeline_id not in self._progress:\n                return None\n            data = self._progress[pipeline_id]\n            if not data[\"artifacts\"]:\n                return None\n            # The current artifact is the last one in the dict\n            current_artifact, current_data = data[\"artifacts\"].items()[-1]\n            # Calculate percentage for current artifact\n            current_percentage = 0\n            if current_data[\"total_mb\"] > 0:\n                current_percentage = (current_data[\"downloaded_mb\"] / current_data[\"total_mb\"]) * 100\n            return {\n                \"is_downloading\": data[\"is_downloading\"],\n                \"percentage\": round(current_percentage, 1),\n                \"current_artifact\": current_artifact\n            }\n\n    def mark_complete(self, pipeline_id: str):\n        \"\"\"Mark download as complete.\"\"\"\n        with self._lock:\n            if pipeline_id in self._progress:\n                self._progress[pipeline_id][\"is_downloading\"] = False\n\n    def clear_progress(self, pipeline_id: str):\n        \"\"\"Clear progress data.\"\"\"\n        with self._lock:\n            self._progress.pop(pipeline_id, None)\n\n# Global singleton instance\ndownload_progress_manager = DownloadProgressManager()"}
{"code_id": "sdnq_src_sdnq_optim_lion.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\sdnq_src_sdnq_optim_lion.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\sdnq_src_sdnq_optim_lion.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\sdnq_src_sdnq_optim_lion.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "from typing import Tuple, Iterator\nimport torch\n\nfrom ..training import SDNQTensor\nfrom ..common import compile_func\n\nfrom .optimizer import SDNQOptimizer\nfrom .utils import lerp_buffer_stochastic_\n\n\nclass Lion(SDNQOptimizer):\n    _extra_group_keys = {}\n    _keep_in_fp32_keys = {}\n    _group_keys = set.union(SDNQOptimizer._base_group_keys, _extra_group_keys)\n\n    def __init__(self, params, **kwargs):\n        if isinstance(params, (torch.nn.Parameter, Iterator)) or (isinstance(params, (list, tuple)) and isinstance(params[0], torch.nn.Parameter)):\n            kwargs[\"params\"] = params\n            param_groups = [kwargs,]\n        else:\n            param_groups = params\n        for group in param_groups:\n            group = self.apply_group_defaults(group, **kwargs)\n            assert set(group.keys()) == self._group_keys\n        super().__init__(param_groups, dict())\n        self.keep_in_fp32_keys = {}\n\n    @torch.no_grad()\n    def init_state(self, param: torch.Tensor, group: dict, state: dict) -> dict:\n        use_quantized_buffers = group[\"use_quantized_buffers\"] and param.grad.ndim >= group[\"quantized_buffers_minimum_ndim\"] and param.grad.numel() >= group[\"quantized_buffers_minimum_numel\"]\n        if use_quantized_buffers:\n            state[\"exp_avg\"] = SDNQTensor.from_float(torch.zeros_like(param), dtype=torch.float32), weights_dtype=group[\"quantized_buffers_dtype\"], group_size=group[\"quantized_buffers_group_size\"], svd_rank=group[\"quantized_buffers_svd_rank\"], use_svd=group[\"use_svd_quantization\"], use_stochastic_rounding=group[\"use_stochastic_buffers\"]])\n        else:\n            state[\"exp_avg\"] = torch.zeros_like(param)\n        return state\n\n    @torch.no_grad()\n    def get_param_update(self, param_fp32: torch.FloatTensor, grad: torch.FloatTensor, group: dict, state: dict) -> torch.FloatTensor:\n        update_func = lion_update_compiled if group[\"use_torch_compile\"] else lion_update\n        return update_func(\n            grad=grad,\n            exp_avg=state[\"exp_avg\"],\n            betas=group[\"betas\"],\n            use_stochastic_buffers=group[\"use_stochastic_buffers\"],\n        )\n\ndef lion_update(\n    grad: torch.FloatTensor,\n    exp_avg: torch.FloatTensor,\n    betas: Tuple[float, float],\n    use_stochastic_buffers: bool = False,\n) -> torch.FloatTensor:\n    beta1, beta2 = betas\n    update = exp_avg.to(dtype=torch.float32).lerp(grad, 1 - beta1).sign_()\n    lerp_buffer_stochastic_(exp_avg, grad, 1 - beta2, use_stochastic_rounding=use_stochastic_buffers)\n    return update\n\nlion_update_compiled = compile_func(lion_update)"}
{"code_id": "scope_src_scope_server_download_progress_manager.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\scope_src_scope_server_download_progress_manager.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\scope_src_scope_server_download_progress_manager.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\scope_src_scope_server_download_progress_manager.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": "\"\"\"A progress manager for a pipeline download.\"\"\"\n\nclass DownloadProgressManager:\n    \"\"\"Tracks progress for a pipeline download.\"\"\"\n    def __init__(self):\n        self._progress = {}\n        self._lock = threading.Lock()\n\n    def add_artifact(self, artifact_id, artifact_name, downloaded_mb, total_mb, final):\n        \"\"\"Register download progress.\"\"\"\n        with self._lock:\n            if artifact_id not in self._progress:\n                self._progress[artifact_id] = {\n                    'artifact_name': artifact_name,\n                    'downloaded_mb': downloaded_mb,\n                    'total_mb': total_mb,\n                    'final': final\n                }\n\n    def get_progress_bar(self, progress_id, artifact_id):\n        \"\"\"Get current artifact progress.\"\"\"\n        with self._lock:\n            if artifact_id not in self._progress:\n                return None\n            data = self._progress[artifact_id]\n            if not data['artifact_name']:\n                return None\n\n            # The artifact is the last one in the list\n            # but not artifact_name, so we need to find the name\n            if data['artifact_name'] == '':\n                # This is a placeholder for the last artifact\n                # We need to find the actual name\n                # For now, we'll just use the artifact_id\n                data['artifact_name'] = f'Artifact {artifact_id}'\n\n            # Calculate percentage for current artifact\n            progress_percentage = 0\n            if data['total_mb'] > 0:\n                progress_percentage = (\n                    data['downloaded_mb'] / data['total_mb'] * 100\n                )\n            return {\n                'artifact_name': data['artifact_name'],\n                'progress_percentage': progress_percentage,\n                'current_artifact': current_artifact,\n            }\n\n    def update_progress_bar(self, progress_id, artifact_id, downloaded_mb, total_mb, final):\n        \"\"\"Update progress data.\"\"\"\n        with self._lock:\n            if artifact_id not in self._progress:\n                self._progress[artifact_id] = {\n                    'artifact_name': '',\n                    'downloaded_mb': downloaded_mb,\n                    'total_mb': total_mb,\n                    'final': final\n                }\n\n    def clear_progress_data(self, progress_id, artifact_id):\n        \"\"\"Clear progress data.\"\"\"\n        with self._lock:\n            if artifact_id in self._progress:\n                del self._progress[artifact_id]\n\ndownload_progress_manager = DownloadProgressManager()"}
{"code_id": "scope_src_scope_server_download_progress_manager.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\scope_src_scope_server_download_progress_manager.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\scope_src_scope_server_download_progress_manager.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\scope_src_scope_server_download_progress_manager.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": "# progress bar for scientific benchmarks\n\nimport time\n\nfrom math import floor\n\nclass ProgressBar:\n    \"\"\"Simple progress bar for scientific benchmarks\"\"\"\n    def __init__(self, total, width=50):\n        self.total = total\n        self.width = width\n        self.progress = 0\n        self.start_time = time.time()\n\n    def update(self, current):\n        \"\"\"Update the progress bar\"\"\"\n        self.progress = current\n        percent = float(current) / self.total\n        arrow = '-' * int(floor(percent * self.width)))\n        spaces = ' ' * (self.width - len(arrow)))\n        elapsed_time = time.time() - self.start_time\n        remaining_time = (elapsed_time / current) * (self.total - current) if current > 0 else 0\n        print('\\rProgress: [%s] %d%% (%d/%d) - Elapsed: %.2fs - Remaining: %.2fs' % (arrow + spaces, percent * 100, current, self.total, elapsed_time, remaining_time), end='')\n\n    def get_progress(self, current):\n        \"\"\"Get the current progress\"\"\"\n        self.update(current)\n        return self.progress\n\n    def finish(self):\n        \"\"\"Finish the progress bar\"\"\"\n        self.update(self.total)\n        print()\n\n    def __enter__(self):\n        \"\"\"Enter the context manager\"\"\"\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        \"\"\"Exit the context manager\"\"\"\n        self.finish()\n        print()\n\ndef benchmark(func, *args, **kwargs):\n    \"\"\"Benchmark a function\"\"\"\n    with ProgressBar(len(args[0])), width=50) as pbar:\n        results = []\n        for i, arg in enumerate(args[0]):\n            pbar.update(i + 1)\n            result = func(arg, *args[1:], **kwargs)\n            results.append(result)\n        return results"}
{"code_id": "sdnq_src_sdnq_optim_lion.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\sdnq_src_sdnq_optim_lion.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\sdnq_src_sdnq_optim_lion.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\sdnq_src_sdnq_optim_lion.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "from typing import Tuple, Iterator\n\n# flake8: noqa\n\nfrom ..training import SONGTensor\nfrom ..common import compile_func\n\nfrom .optimizer import SONGOptimizer\nfrom .utils import lerp_buffer_stochastic_\n\nclass LION(SONGOptimizer):\n    _extra_group_keys = ()\n    _keep_in_fp32_keys = ()\n    _group_keys = set.union(SONGOptimizer._base_group_keys, _extra_group_keys)\n\n    def __init__(self, params, **kwargs):\n        if isinstance(params, (torch.nn.Parameter, Iterator)) or isinstance(params, (list, tuple)) and isinstance(params[0], torch.nn.Parameter)):\n            kwargs[\"params\"] = params\n            param_groups = [kwargs]\n        else:\n            param_groups = params\n        for group in param_groups:\n            group = self.apply_group_defaults(group, **kwargs)\n            assert set(group.keys()) == self._group_keys\n        super().__init__(param_groups, dict())\n        self._keep_in_fp32_keys = set()\n\n    @torch.no_grad()\n    def init_state(self, param: torch.Tensor, group: dict, state: dict) -> dict:\n        use_quantized_buffers = group[\"use_quantized_buffers\"] and param.grad.ndim >= group[\"quantized_buffers_minimum_ndim\"] and param.grad.ndim >= group[\"quantized_buffers_minimum_ndim\"]\n        if use_quantized_buffers:\n            state[\"exp_avg\"] = SONGTensor.from_float(torch.zeros_like(param, dtype=torch.float32), weights_dtype=group[\"quantized_buffers_dtype\"], group_size=group[\"quantized_buffers_group_size\"], ovd_rank=group[\"quantized_buffers_ovd_rank\"], use_svd=group[\"use_svd_quantization\"], use_stochastic_rounding=group[\"use_stochastic_buffers\"])\n        else:\n            state[\"exp_avg\"] = torch.zeros_like(param)\n        return state\n\n    @torch.no_grad()\n    def get_param_update(self, param_fp32: torch.FloatTensor, grad: torch.FloatTensor, group: dict, state: dict) -> torch.FloatTensor:\n        update_func = lion_update_compiled if group[\"use_torch_compile\"] else lion_update\n        return update_func(\n            grad=grad,\n            exp_avg=state[\"exp_avg\"],\n            betas=group[\"betas\"],\n            use_stochastic_buffers=group[\"use_stochastic_buffers\"],\n        )\n\ndef lion_update(\n    grad: torch.FloatTensor,\n    exp_avg: torch.FloatTensor,\n    betas: tuple[float, float],\n    use_stochastic_buffers: bool = False,\n) -> torch.FloatTensor:\n    betas1, betas2 = betas\n    update = exp_avg.to(torch.float32).lerp(grad, 1 - betas1).sign_()\n    lerp_buffer_stochastic_(exp_avg, grad, 1 - betas2, use_stochastic_rounding=use_stochastic_buffers)\n    return update\n\nlion_update_compiled = compile_func(lion_update)"}
{"code_id": "sdnq_src_sdnq_optim_lion.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\sdnq_src_sdnq_optim_lion.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\sdnq_src_sdnq_optim_lion.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\sdnq_src_sdnq_optim_lion.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "from typing import Tuple, Iterator\nimport torch\nfrom ..training import SDNQTensor\nfrom ..common import compile_func\nfrom .optimizer import SDNQOptimizer\nfrom .utils import lerp_buffer_stochastic_\n\nclass Lion(SDNQOptimizer):\n    _extra_group_keys = {}\n    _keep_in_fp32_keys = {}\n    _group_keys = set.union(SDNQOptimizer._base_group_keys, _extra_group_keys)\n\n    def __init__(self, params, **kwargs):\n        if isinstance(params, (torch.nn.Parameter, Iterator)) or (isinstance(params, (list, tuple)) and isinstance(params[0], torch.nn.Parameter))):\n            kwargs[\"params\"] = params\n            param_groups = [kwargs,]\n        else:\n            param_groups = params\n        for group in param_groups:\n            group = self.apply_group_defaults(group, **kwargs)\n            assert set(group.keys()) == self._group_keys\n        super().__init__(param_groups, dict())\n        self.keep_in_fp32_keys = {}\n\n    @torch.no_grad()\n    def init_state(self, param: torch.Tensor, group: dict, state: dict) -> dict:\n        use_quantized_buffers = group[\"use_quantized_buffers\"] and param.grad.ndim >= group[\"quantized_buffers_minimum_ndim\"] and param.grad.numel() >= group[\"quantized_buffers_minimum_numel\"]\n        if use_quantized_buffers:\n            state[\"exp_avg\"] = SDNQTensor.from_float(torch.zeros_like(param, dtype=torch.float32), weights_dtype=group[\"quantized_buffers_dtype\"], group_size=group[\"quantized_buffers_group_size\"], svd_rank=group[\"quantized_buffers_svd_rank\"], use_svd=group[\"use_svd_quantization\"], use_stochastic_rounding=group[\"use_stochastic_buffers\"])\n        else:\n            state[\"exp_avg\"] = torch.zeros_like(param)\n        return state\n\n    @torch.no_grad()\n    def get_param_update(self, param_fp32: torch.FloatTensor, grad: torch.FloatTensor, group: dict, state: dict) -> torch.FloatTensor:\n        update_func = lion_update_compiled if group[\"use_torch_compile\"] else lion_update\n        return update_func(\n            grad=grad,\n            exp_avg=state[\"exp_avg\"],\n            betas=group[\"betas\"],\n            use_stochastic_buffers=group[\"use_stochastic_buffers\"],\n        )\n\ndef lion_update(\n    grad: torch.FloatTensor,\n    exp_avg: torch.FloatTensor,\n    betas: Tuple[float, float],\n    use_stochastic_buffers: bool = False,\n) -> torch.FloatTensor:\n    beta1, beta2 = betas\n    update = exp_avg.to(dtype=torch.float32).lerp(grad, 1 - beta1).sign_()\n    lerp_buffer_stochastic_(exp_avg, grad, 1 - beta2, use_stochastic_rounding=use_stochastic_buffers)\n    return update\n\nlion_update_compiled = compile_func(lion_update)"}
{"code_id": "securevibes_packages_core_securevibes_models_issue.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\securevibes_packages_core_securevibes_models_issue.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\securevibes_packages_core_securevibes_models_issue.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\securevibes_packages_core_securevibes_models_issue.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "\"\"\"Security issue data model\"\"\"\n\nfrom dataclasses import dataclass\nfrom enum import Enum\nfrom typing import Optional\n\nclass Severity(str, Enum):\n    \"\"\"Issue severity levels\"\"\"\n\n    CRITICAL = \"critical\"\n    HIGH = \"high\"\n    MEDIUM = \"medium\"\n    LOW = \"low\"\n    INFO = \"info\"\n\n    @classmethod\n    def __missing__(cls, value):\n        \"\"\"Handle case-insensitive matching and aliases\"\"\"\n        if isinstance(value, str):\n            value = value.lower()\n            if value == \"informational\":\n                return cls.INFO\n            for member in cls:\n                if member.value == value:\n                    return member\n        return None\n\nclass ValidationStatus(str, Enum):\n    \"\"\"DAST validation status\"\"\"\n\n    VALIDATED = \"VALIDATED\"  # Successfully exploited\n    FALSE_POSITIVE = \"FALSE_POSITIVE\"  # Disproven by testing\n    UNVALIDATED = \"UNVALIDATED\"  # Couldn't test (timeout, unreachable)\n    PARTIAL = \"PARTIAL\"  # Exploitable but different impact\n\n@dataclass\nclass SecurityIssue:\n    \"\"\"Represents a security vulnerability found in code\"\"\"\n\n    id: str\n    severity: Severity\n    title: str\n    description: str\n    file_path: str\n    line_number: int\n    code_snippet: str\n    recommendation: Optional[str] = None\n    cwe_id: Optional[str] = None\n\n    # DAST validation fields\n    validation_status: Optional[ValidationStatus] = None\n    dast_evidence: Optional[dict] = None\n    exploitability_score: Optional[float] = None\n    validated_at: Optional[str] = None\n\n    def to_dict(self) -> dict:\n        \"\"\"Convert to dictionary\"\"\"\n        base_dict = {\n            \"id\": self.id,\n            \"severity\": self.severity.value,\n            \"title\": self.title,\n            \"description\": self.description,\n            \"file_path\": self.file_path,\n            \"line_number\": self.line_number,\n            \"code_snippet\": self.code_snippet,\n            \"recommendation\": self.recommendation,\n            \"cwe_id\": self.cwe_id,\n        }\n\n        # Include DAST fields if present\n        if self.validation_status:\n            base_dict.update(\n                {\n                    \"validation_status\": self.validation_status.value,\n                    \"dast_evidence\": self.dast_evidence,\n                    \"exploitability_score\": self.exploitability_score,\n                    \"validated_at\": self.validated_at,\n                }\n            )\n\n        return base_dict\n\n    @property\n    def is_validated(self) -> bool:\n        \"\"\"Check if issue was validated by DAST\"\"\"\n        return self.validation_status == ValidationStatus.VALIDATED\n\n    @property\n    def is_false_positive(self) -> bool:\n        \"\"\"Check if issue was disproven by DAST\"\"\"\n        return self.validation_status == ValidationStatus.FALSE_POSITIVE"}
{"code_id": "securevibes_packages_core_securevibes_models_issue.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\securevibes_packages_core_securevibes_models_issue.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\securevibes_packages_core_securevibes_models_issue.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\securevibes_packages_core_securevibes_models_issue.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "\"\"\"Security issue data model\"\"\"\nfrom dataclasses import dataclass\nfrom enum import Enum\nfrom typing import Optional\n\nclass Severity(str, Enum):\n    \"\"\"Issue severity levels\"\"\"\n\n    CRITICAL = \"critical\"\n    HIGH = \"high\"\n    MEDIUM = \"medium\"\n    LOW = \"low\"\n    INFO = \"info\"\n\n    @classmethod\n    def __missing__(cls, value):\n        \"\"\"Handle case-insensitive matching and aliases\"\"\"\n        if isinstance(value, str):\n            value = value.lower()\n            if value == \"informational\":\n                return cls.INFO\n            for member in cls:\n                if member.value == value:\n                    return member\n        return None\n\nclass ValidationStatus(str, Enum):\n    \"\"\"DAST validation status\"\"\"\n\n    VALIDATED = \"VALIDATED\"  # Successfully exploited\n    FALSE_POSITIVE = \"FALSE_POSITIVE\"  # Disproven by testing\n    UNVALIDATED = \"UNVALIDATED\"  # Couldn't test (timeout, unreachable)\n    PARTIAL = \"PARTIAL\"  # Exploitable but different impact\n\n@dataclass\nclass SecurityIssue:\n    \"\"\"Represents a security vulnerability found in code\"\"\"\n\n    id: str\n    severity: Severity\n    title: str\n    description: str\n    file_path: str\n    line_number: int\n    code_snippet: str\n    recommendation: Optional[str] = None\n    cwe_id: Optional[str] = None\n\n    # DAST validation fields\n    validation_status: Optional[ValidationStatus] = None\n    dast_evidence: Optional[dict] = None\n    exploitability_score: Optional[float] = None\n    validated_at: Optional[str] = None\n\n    def to_dict(self) -> dict:\n        \"\"\"Convert to dictionary\"\"\"\n        base_dict = {\n            \"id\": self.id,\n            \"severity\": self.severity.value,\n            \"title\": self.title,\n            \"description\": self.description,\n            \"file_path\": self.file_path,\n            \"line_number\": self.line_number,\n            \"code_snippet\": self.code_snippet,\n            \"recommendation\": self.recommendation,\n            \"cwe_id\": self.cwe_id,\n        }\n        # Include DAST fields if present\n        if self.validation_status:\n            base_dict.update(\n                {\n                    \"validation_status\": self.validation_status.value,\n                    \"dast_evidence\": self.dast_evidence,\n                    \"exploitability_score\": self.exploitability_score,\n                    \"validated_at\": self.validated_at,\n                }\n            )\n        return base_dict\n\n    @property\n    def is_validated(self) -> bool:\n        \"\"\"Check if issue was validated by DAST\"\"\"\n        return self.validation_status == ValidationStatus.VALIDATED\n\n    @property\n    def is_false_positive(self) -> bool:\n        \"\"\"Check if issue was disproven by DAST\"\"\"\n        return self.validation_status == ValidationStatus.FALSE_POSITIVE"}
{"code_id": "sdnq_src_sdnq_optim_lion.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\sdnq_src_sdnq_optim_lion.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\sdnq_src_sdnq_optim_lion.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\sdnq_src_sdnq_optim_lion.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "sdnq_src_sdnq_optim_lion.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\sdnq_src_sdnq_optim_lion.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\sdnq_src_sdnq_optim_lion.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\sdnq_src_sdnq_optim_lion.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "securevibes_packages_core_securevibes_models_issue.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\securevibes_packages_core_securevibes_models_issue.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\securevibes_packages_core_securevibes_models_issue.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\securevibes_packages_core_securevibes_models_issue.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "\"\"\"Security issue data model\"\"\"\nfrom dataclasses import dataclass\nfrom enum import Enum\nfrom typing import Optional\n\n\nclass Severity(str, Enum):\n    \"\"\"Issue severity levels\"\"\"\n\n    CRITICAL = \"critical\"\n    HIGH = \"high\"\n    MEDIUM = \"medium\"\n    LOW = \"low\"\n    INFO = \"info\"\n\n    @classmethod\n    def __missing__(cls, value):\n        \"\"\"Handle case-insensitive matching and aliases\"\"\"\n        if isinstance(value, str):\n            value = value.lower()\n            if value == \"informational\":\n                return cls.INFO\n            for member in cls:\n                if member.value == value:\n                    return member\n        return None\n\n\nclass ValidationStatus(str, Enum):\n    \"\"\"DAST validation status\"\"\"\n\n    VALIDATED = \"VALIDATED\"  # Successfully exploited\n    FALSE_POSITIVE = \"FALSE_POSITIVE\"  # Disproven by testing\n    UNVALIDATED = \"UNVALIDATED\"  # Couldn't test (heimdall, unreachable)\n    PARTIAL = \"PARTIAL\"  # Exploitable but different impact\n\n\n@dataclass\nclass SecurityIssue:\n    \"\"\"Represents a security vulnerability found in code\"\"\"\n\n    id: str\n    severity: Severity\n    title: str\n    description: str\n    file_path: str\n    line_number: int\n    code_snippet: str\n    recommendation: Optional[str] = None\n    cwe_id: Optional[str] = None\n\n    # DAST validation fields\n    validation_status: Optional[ValidationStatus] = None\n    dast_evidence: Optional[dict] = None\n    exploitability_score: Optional[float] = None\n    validated_at: Optional[str] = None\n\n    def to_dict(self) -> dict:\n        \"\"\"Convert to dictionary\"\"\"\n        base_dict = {\n            \"id\": self.id,\n            \"severity\": self.severity.value,\n            \"title\": self.title,\n            \"description\": self.description,\n            \"file_path\": self.file_path,\n            \"line_number\": self.line_number,\n            \"code_snippet\": self.code_snippet,\n            \"recommendation\": self.recommendation,\n            \"cwe_id\": self.cwe_id,\n        }\n\n        # Include DAST fields if present\n        if self.validation_status:\n            base_dict.update({\n                \"validation_status\": self.validation_status.value,\n                \"dast_evidence\": self.dast_evidence,\n                \"exploitability_score\": self.exploitability_score,\n                \"validated_at\": self.validated_at,\n            })\n\n        return base_dict\n\n    @property\n    def is_validated(self) -> bool:\n        \"\"\"Check if issue was validated by DAST\"\"\"\n        return self.validation_status == ValidationStatus.VALIDATED\n\n    @property\n    def is_false_positive(self) -> bool:\n        \"\"\"Check if issue was disproven by DAST\"\"\"\n        return self.validation_status == ValidationStatus.FALSE_POSITIVE"}
{"code_id": "sms-bridge_app_forwarder.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\sms-bridge_app_forwarder.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\sms-bridge_app_forwarder.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\sms-bridge_app_forwarder.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "import logging\nfrom concurrent.futures import ThreadPoolExecutor\nimport requests\n\nlogger = logging.getLogger('forwarder')\n\nclass Forwarder:\n    def __init__(self, cfg):\n        self.cfg = cfg\n        self.timeout = cfg.get('request_timeout', 10)\n        self._max_workers = cfg.get('forwarder_workers', 4)\n        self.executor = ThreadPoolExecutor(max_workers=self._max_workers)\n\n    def shutdown(self):\n        \"\"\"Stop background workers used for asynchronous forwarding.\"\"\"\n        if self.executor:\n            self.executor.shutdown(wait=True)\n            self.executor = None\n\n    def _ensure_executor(self):\n        \"\"\"Create a new executor when the previous one has been shut down.\"\"\"\n        if self.executor is None or getattr(self.executor, \"_shutdown\", False):\n            self.executor = ThreadPoolExecutor(max_workers=self._max_workers)\n\n    def send_telegram(self, remote, content):\n        if not self.cfg.get('telegram', {}).get('enabled'):\n            return\n        token = self.cfg['telegram']['bot_token']\n        chat_id = self.cfg['telegram']['chat_id']\n        text = f\"📱 From: {remote}\\n{content}\"\n        url = f\"https://api.telegram.org/bot{token}/sendMessage\"\n        resp = requests.post(url, json={\"chat_id\": chat_id, \"text\": text}, timeout=self.timeout)\n        logger.info('Telegram status: %s', resp.status_code)\n        return resp.json()\n\n    def send_pushplus(self, remote, content):\n        if not self.cfg.get('wechat_pushplus', {}).get('enabled'):\n            return\n        token = self.cfg['wechat_pushplus']['token']\n        title = f\"SMS from {remote}\"\n        body = content\n        url = 'http://www.pushplus.plus/send'\n        resp = requests.post(url, json={\"token\": token, \"title\": title, \"content\": body}, timeout=self.timeout)\n        logger.info('PushPlus status: %s', resp.status_code)\n        return resp.json()\n\n    def forward(self, remote, content):\n        \"\"\"Dispatch forwarding tasks asynchronously to avoid blocking polling.\"\"\"\n        self._ensure_executor()\n\n        def _forward_all():\n            try:\n                self.send_telegram(remote, content)\n                self.send_pushplus(remote, content)\n            except Exception:\n                logger.exception(\"Forwarding failed for %s\", remote)\n\n        self.executor.submit(_forward_all)"}
{"code_id": "securevibes_packages_core_securevibes_models_issue.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\securevibes_packages_core_securevibes_models_issue.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\securevibes_packages_core_securevibes_models_issue.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\securevibes_packages_core_securevibes_models_issue.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": "\"\"\"A module for voice recognition\"\"\"\n\nimport speech_recognition as sr\nfrom gtts import gTTS\nfrom playsound import playsound\n\nclass VoiceAssistant:\n    \"\"\"A voice assistant class\"\"\"\n\n    def __init__(self):\n        self.recognizer = sr.Recognizer()\n        self.microphone = sr.Microphone()\n\n    def listen(self):\n        \"\"\"Listen for user input\"\"\"\n        with self.microphone as source:\n            self.recognizer.adjust_for_ambient_noise(source)\n            audio = self.recognizer.listen(source)\n        return audio\n\n    def recognize(self, audio):\n        \"\"\"Recognize the user's speech\"\"\"\n        try:\n            text = self.recognizer.recognize_google(audio)\n            return text\n        except sr.UnknownValueError:\n            return \"Sorry, I didn't catch that.\"\n        except sr.RequestError:\n            return \"Sorry, I couldn't connect to the recognition service.\"\n\n    def speak(self, text):\n        \"\"\"Speak the given text\"\"\"\n        tts = gTTS(text=text, lang='en')\n        tts.save(\"response.mp3\")\n        playsound(\"response.mp3\")\n\ndef main():\n    \"\"\"Main function to run the voice assistant\"\"\"\n    assistant = VoiceAssistant()\n    print(\"Say something!\")\n    audio = assistant.listen()\n    text = assistant.recognize(audio)\n    print(f\"You said: {text}\")\n    assistant.speak(text)\n\nif __name__ == \"__main__\":\n    main()"}
{"code_id": "sms-bridge_app_forwarder.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\sms-bridge_app_forwarder.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\sms-bridge_app_forwarder.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\sms-bridge_app_forwarder.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "import logging\nfrom concurrent.futures import ThreadPoolExecutor\nimport requests\n\nlogger = logging.getLogger('forwarder')\n\nclass Forwarder:\n    def __init__(self, cfg):\n        self.cfg = cfg\n        self.timeout = cfg.get('request_timeout', 10)\n        self._max_workers = cfg.get('forwarder_workers', 4)\n        self.executor = ThreadPoolExecutor(max_workers=self._max_workers)\n\n    def shutdown(self):\n        \"\"\"Stop background workers used for asynchronous forwarding.\"\"\"\n        if self.executor:\n            self.executor.shutdown(wait=True)\n            self.executor = None\n\n    def _ensure_executor(self):\n        \"\"\"Create a new executor when the previous one has been shut down.\"\"\"\n        if self.executor is None or getattr(self.executor, \"_shutdown\", False):\n            self.executor = ThreadPoolExecutor(max_workers=self._max_workers)\n\n    def send_telegram(self, remote, content):\n        if not self.cfg.get('telegram', {}).get('enabled'):\n            return\n        token = self.cfg['telegram']['bot_token']\n        chat_id = self.cfg['telegram']['chat_id']\n        text = f\"📢 From: {remote}\\n{content}\"\n        url = f\"https://api.telegram.org/bot{token}/sendMessage\"\n        resp = requests.post(url, json={\"chat_id\": chat_id, \"text\": text}, timeout=self.timeout)\n        logger.info(\"Telegram status: %s\", resp.status_code)\n        return resp.json()\n\n    def send_pushplus(self, remote, content):\n        if not self.cfg.get('wechat_pushplus', {}).get('enabled'):\n            return\n        token = self.cfg['wechat_pushplus']['token']\n        title = f\"SMS from {remote}\"\n        body = content\n        url = \"http://www.pushplus.plus/send\"\n        resp = requests.post(url, json={\"token\": token, \"title\": title, \"content\": body}, timeout=self.timeout)\n        logger.info(\"PushPlus status: %s\", resp.status_code)\n        return resp.json()\n\n    def forward(self, remote, content):\n        \"\"\"Dispatch forwarding tasks asynchronously to avoid blocking polling.\"\"\"\n        self._ensure_executor()\n\n        def _forward_all():\n            try:\n                self.send_telegram(remote, content)\n                self.send_pushplus(remote, content)\n            except Exception:\n                logger.exception(\"Forwarding failed for %s\", remote)\n\n        self.executor.submit(_forward_all)"}
{"code_id": "securevibes_packages_core_securevibes_models_issue.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\securevibes_packages_core_securevibes_models_issue.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\securevibes_packages_core_securevibes_models_issue.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\securevibes_packages_core_securevibes_models_issue.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "sms-bridge_app_forwarder.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\sms-bridge_app_forwarder.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\sms-bridge_app_forwarder.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\sms-bridge_app_forwarder.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "from concurrent.futures import ThreadPoolExecutor\nimport requests\nlogger = logging.getLogger('forwarder')\n\nclass Forwarder:\n    def __init__(self, cfg):\n        self.cfg = cfg\n        self.timeout = cfg.get('request_timeout', 10)\n        self._max_workers = cfg.get('forwarder_workers', 4)\n        self._executor = ThreadPoolExecutor(max_workers=self._max_workers)\n\n    def shutdown(self):\n        \"\"\"Stop background workers used for asynchronous forwarding.\"\"\"\n        if self._executor:\n            self._executor.shutdown(wait=True)\n            self._executor = None\n\n    def _ensure_executor(self):\n        \"\"\"Create a new executor when the previous one has been shut down.\"\"\"\n        if self._executor is None or getattr(self._executor, '_shutdown', False):\n            self._executor = ThreadPoolExecutor(max_workers=self._max_workers)\n\n    def send_telegram(self, remote, content):\n        if not self.cfg.get('telegram', {}).get('enabled'):\n            return\n        token = self.cfg['telegram']['bot_token']\n        chat_id = self.cfg['telegram']['chat_id']\n        text = f\"📢 From: {remote}\\n{content}\"\n        url = f\"https://api.telegram.org/bot{token}/sendMessage\"\n        resp = requests.post(url, json={\"chat_id\": chat_id, \"text\": text}, timeout=self.timeout)\n        logger.info(f\"Telegram status: {resp.status_code}\")\n        return resp.json()\n\n    def send_pushplus(self, remote, content):\n        if not self.cfg.get('wechat_pushplus', {}).get('enabled'):\n            return\n        token = self.cfg['wechat_pushplus']['token']\n        title = f\"📢 From: {remote}\"\n        body = content\n        url = \"http://www.pushplus.plus/send\"\n        resp = requests.post(url, json={\"token\": token, \"title\": title, \"content\": body}, timeout=self.timeout)\n        logger.info(f\"PushPlus status: {resp.status_code}\")\n        return resp.json()\n\n    def forward(self, remote, content):\n        \"\"\"Dispatch forwarding tasks asynchronously to avoid blocking polling.\"\"\"\n        self._ensure_executor()\n\n        def _forward_all():\n            try:\n                self.send_telegram(remote, content)\n                self.send_pushplus(remote, content)\n            except Exception:\n                logger.exception(f\"Forwarding failed for {remote}\")\n\n        self._executor.submit(_forward_all)"}
{"code_id": "sonobarr_src_sonobarr_app_models.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\sonobarr_src_sonobarr_app_models.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\sonobarr_src_sonobarr_app_models.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\sonobarr_src_sonobarr_app_models.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "from __future__ import annotations\nfrom datetime import datetime\nfrom flask_login import UserMixin\nfrom werkzeug.security import check_password_hash, generate_password_hash\nfrom .extensions import db\n\nclass User(UserMixin, db.Model):\n    __tablename__ = \"users\"\n\n    id = db.Column(db.Integer, primary_key=True)\n    username = db.Column(db.String(80), unique=True, nullable=False, index=True)\n    password_hash = db.Column(db.String(255), nullable=False)\n    display_name = db.Column(db.String(120), nullable=True)\n    avatar_url = db.Column(db.String(512), nullable=True)\n    lastfm_username = db.Column(db.String(120), nullable=True)\n    listenbrainz_username = db.Column(db.String(120), nullable=True)\n    is_admin = db.Column(db.Boolean, default=False, nullable=False)\n    is_active = db.Column(db.Boolean, default=True, nullable=False)\n    created_at = db.Column(db.DateTime, default=datetime.utcnow, nullable=False)\n    updated_at = db.Column(\n        db.DateTime, default=datetime.utcnow, onupdate=datetime.utcnow, nullable=False\n    )\n\n    def set_password(self, raw_password: str) -> None:\n        self.password_hash = generate_password_hash(raw_password)\n\n    def check_password(self, raw_password: str) -> bool:\n        if not self.password_hash:\n            return False\n        return check_password_hash(self.password_hash, raw_password)\n\n    @property\n    def name(self) -> str:\n        return self.display_name or self.username\n\n    def __repr__(self) -> str:  # pragma: no cover - representation helper\n        return f\"<User id={self.id} username={self.username!r} admin={self.is_admin}>\"\n\nclass ArtistRequest(db.Model):\n    __tablename__ = \"artist_requests\"\n\n    id = db.Column(db.Integer, primary_key=True)\n    artist_name = db.Column(db.String(255), nullable=False, index=True)\n    requested_by_id = db.Column(db.Integer, db.ForeignKey(\"users.id\", ondelete=\"CASCADE\"), nullable=False)\n    status = db.Column(db.String(20), default=\"pending\", nullable=False)  # pending, approved, rejected\n    created_at = db.Column(db.DateTime, default=datetime.utcnow, nullable=False)\n    updated_at = db.Column(\n        db.DateTime, default=datetime.utcnow, onupdate=datetime.utcnow, nullable=False\n    )\n    approved_by_id = db.Column(db.Integer, db.ForeignKey(\"users.id\", ondelete=\"SET NULL\"), nullable=True)\n    approved_at = db.Column(db.DateTime, nullable=True)\n\n    # Relationships\n    requested_by = db.relationship(\"User\", foreign_keys=[requested_by_id], backref=\"requested_artists\")\n    approved_by = db.relationship(\"User\", foreign_keys=[approved_by_id], backref=\"approved_requests\")\n\n    def __repr__(self) -> str:  # pragma: no cover - representation helper\n        return f\"<ArtistRequest id={self.id} artist='{self.artist_name}' status={self.status}>\""}
{"code_id": "sms-bridge_app_forwarder.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\sms-bridge_app_forwarder.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\sms-bridge_app_forwarder.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\sms-bridge_app_forwarder.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": "from __future__ import print_function\nfrom concurrent.futures import ThreadPoolExecutor\nimport requests\nimport logging\nlogger = logging.getLogger(__name__)\n\nclass Forwarder:\n    def __init__(self, *args, **kwargs):\n        self.rlp = rlp\n        self.tlsmd = rlp.get('request_context', {}).get('tlsmd')\n        self._state = rlp.get('forwarder_state', {})\n        self._executor = ThreadPoolExecutor(max_workers=1, name='forwarder')\n\n    def shutdown(self):\n        \"\"\"Stop background workers used for asynchronous forwarding\"\"\"\n        if self._executor:\n            if not self._executor._threads:\n                self._executor = None\n\n    def _prepare_async_state(self):\n        \"\"\"Prepare a new async state when the previous one has been shut down\"\"\"\n        if self._executor:\n            if not self._executor._threads:\n                self._executor = ThreadPoolExecutor(max_workers=1, name='forwarder')\n        self._state = {}\n\n    def _build_request(self, request, context):\n        if not self.rlp or not self.rlp.get('request', {}):\n            return\n        request = self.rlp['request']\n        client_id = self.rlp.get('client_id', '')\n        token = self.rlp.get('token', '')\n        url = 'https://api.hubapi.com/forwarding/v1/forward'\n        data = requests.post(url, json={'token': token, 'client_id': client_id, 'request': request})\n        logger.info('Forwarding request to %s', url)\n        return data.json()\n\n    def _send_post(self, request, context):\n        if not self.rlp or not self.rlp.get('request', {}):\n            return\n        token = self.rlp.get('token', '')\n        client_id = self.rlp.get('client_id', '')\n        url = 'https://api.hubapi.com/forwarding/v1/forward'\n        data = requests.post(url, json={'token': token, 'client_id': client_id, 'request': request})\n        logger.info('Forwarding request to %s', url)\n        return data.json()\n\n    def _forward(self, request, context):\n        \"\"\"Forward forwarding tasks asynchronously to avoid blocking the pipeline\"\"\"\n        self._prepare_async_state()\n\n    def _forward(self, request, context):\n        if not self.rlp or not self.rlp.get('request', {}):\n            return\n        if not self._executor or not self._executor._threads:\n            self._prepare_async_state()\n        try:\n            logger.info('Forwarding request to %s', context)\n        except Exception:\n            logger.exception('Forwarding request to %s', context)\n\n    def _forward(self, request, context):\n        pass"}
{"code_id": "sonobarr_src_sonobarr_app_models.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\sonobarr_src_sonobarr_app_models.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\sonobarr_src_sonobarr_app_models.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\sonobarr_src_sonobarr_app_models.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "from __future__ import annotations\nfrom datetime import datetime\nfrom flask_login import UserMixin\nfrom werkzeug.security import check_password_hash, generate_password_hash\nfrom .extensions import db\n\nclass User(UserMixin, db.Model):\n    __tablename__ = \"users\"\n\n    id = db.Column(db.Integer, primary_key=True)\n    username = db.Column(db.String(80), unique=True, nullable=False, index=True)\n    password_hash = db.Column(db.String(255), nullable=False)\n    display_name = db.Column(db.String(120), nullable=True)\n    avatar_url = db.Column(db.String(512), nullable=True)\n    lastfm_username = db.Column(db.String(120), nullable=True)\n    listenbrainz_username = db.Column(db.String(120), nullable=True)\n    is_admin = db.Column(db.Boolean, default=False, nullable=False)\n    is_active = db.Column(db.Boolean, default=True, nullable=False)\n    created_at = db.Column(db.DateTime, default=datetime.utcnow, nullable=False)\n    updated_at = db.Column(\n        db.DateTime, default=datetime.utcnow, onupdate=datetime.utcnow, nullable=False\n    )\n\n    def set_password(self, raw_password: str) -> None:\n        self.password_hash = generate_password_hash(raw_password)\n\n    def check_password(self, raw_password: str) -> bool:\n        if not self.password_hash:\n            return False\n        return check_password_hash(self.password_hash, raw_password)\n\n    @property\n    def name(self) -> str:\n        return self.display_name or self.username\n\n    def __repr__(self) -> str:  # pragma: no cover - representation helper\n        return f\"<User id={self.id} username={self.username!r} admin={self.is_admin}>\"\n\nclass ArtistRequest(db.Model):\n    __tablename__ = \"artist_requests\"\n\n    id = db.Column(db.Integer, primary_key=True)\n    artist_name = db.Column(db.String(255), nullable=False, index=True)\n    requested_by_id = db.Column(db.Integer, db.ForeignKey(\"users.id\", ondelete=\"CASCADE\"), nullable=False)\n    status = db.Column(db.String(20), default=\"pending\", nullable=False)  # pending, approved, rejected\n    created_at = db.Column(db.DateTime, default=datetime.utcnow, nullable=False)\n    updated_at = db.Column(\n        db.DateTime, default=datetime.utcnow, onupdate=datetime.utcnow, nullable=False\n    )\n    approved_by_id = db.Column(db.Integer, db.ForeignKey(\"users.id\", ondelete=\"SET NULL\"), nullable=True)\n    approved_at = db.Column(db.DateTime, nullable=True)\n\n    # Relationships\n    requested_by = db.relationship(\"User\", foreign_keys=[requested_by_id], backref=\"requested_artists\")\n    approved_by = db.relationship(\"User\", foreign_keys=[approved_by_id], backref=\"approved_requests\")\n\n    def __repr__(self) -> str:  # pragma: no cover - representation helper\n        return f\"<ArtistRequest id={self.id} artist='{self.artist_name}' status={self.status}>\""}
{"code_id": "sms-bridge_app_forwarder.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\sms-bridge_app_forwarder.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\sms-bridge_app_forwarder.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\sms-bridge_app_forwarder.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "sonobarr_src_sonobarr_app_models.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\sonobarr_src_sonobarr_app_models.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\sonobarr_src_sonobarr_app_models.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\sonobarr_src_sonobarr_app_models.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "from __future__ import annotations\nfrom datetime import datetime\nfrom flask_login import UserMixin\nfrom werkzeug.security import check_password_hash, generate_password_hash\nfrom .extensions import db\n\nclass User(UserMixin, db.Model):\n    __tablename__ = \"users\"\n\n    id = db.Column(db.Integer, primary_key=True)\n    username = db.Column(db.String(80), unique=True, nullable=False, index=True)\n    password_hash = db.Column(db.String(256), nullable=False)\n    display_name = db.Column(db.String(120), nullable=True)\n    avatar_url = db.Column(db.String(512), nullable=True)\n    favorite_username = db.Column(db.String(120), nullable=True)\n    listening_username = db.Column(db.String(120), nullable=True)\n    is_admin = db.Column(db.Boolean, default=False, nullable=False)\n    is_active = db.Column(db.Boolean, default=True, nullable=False)\n    created_at = db.Column(db.DateTime, default=datetime.utcnow, nullable=False)\n    updated_at = db.Column(\n        db.DateTime, default=datetime.utcnow, onupdate=datetime.utcnow, nullable=False\n    )\n\n    def set_password(self, new_password: str) -> None:\n        self.password_hash = generate_password_hash(new_password)\n\n    def check_password(self, raw_password: str) -> bool:\n        if not self.password_hash:\n            return False\n        return check_password_hash(self.password_hash, raw_password)\n\n    @property\n    def name(self) -> str:\n        return self.display_name or self.username\n\n    def __repr__(self) -> str:  # pragma: no cover -- representation helper\n        return f\"<User id={self.id} username={self.username!r} admin={self.is_admin}>\"\n\nclass ArtistRequest(db.Model):\n    __tablename__ = \"artist_requests\"\n\n    id = db.Column(db.Integer, primary_key=True)\n    artist_name = db.Column(db.String(255), nullable=False, index=True)\n    requested_by_id = db.Column(db.Integer, db.ForeignKey(\"users.id\", ondelete=\"CASCADE\"), nullable=False)\n    status = db.Column(db.String(20), default=\"pending\", nullable=False)  # pending, approved, rejected\n    created_at = db.Column(db.DateTime, default=datetime.utcnow, nullable=False)\n    updated_at = db.Column(\n        db.DateTime, default=datetime.utcnow, onupdate=datetime.utcnow, nullable=False\n    )\n\n    approved_by_id = db.Column(db.Integer, db.ForeignKey(\"users.id\", ondelete=\"SET NULL\"), nullable=True)\n    approved_at = db.Column(db.DateTime, nullable=True)\n\n    # Relationships\n    requested_by = db.relationship(\"User\", foreign_keys=[requested_by_id], backref=\"requested_artists\")\n    approved_by = db.relationship(\"User\", foreign_keys=[approved_by_id], backref=\"approved_requests\")\n\n    def __repr__(self) -> str:  # pragma: no cover -- representation helper\n        return f\"<ArtistRequest id={self.id} artist={self.artist_name!r} status={self.status}>\""}
{"code_id": "sora2-watermark-remover-enchanted_core_decoder.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\sora2-watermark-remover-enchanted_core_decoder.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\sora2-watermark-remover-enchanted_core_decoder.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\sora2-watermark-remover-enchanted_core_decoder.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "from django.core import system_checks\n\n# -*- coding: utf-8 -*-\nimport time\nimport random\n\nclass WatermarkDecoder:\n\n    SORA2_SIGNATURE = \"SORA2_WM_v2.1.x\"\n\n    def __init__(self, model_path=None):\n        self.model_loaded = False\n        self.detection_threshold = 0.85\n        self.pattern_database = []\n        self.confidence_scores = []\n\n    def load_detection_model(self):\n        time.sleep(0.8)\n        self.model_loaded = True\n        return True\n\n    def analyze_frame(self, frame_data):\n        if not self.model_loaded:\n            raise RuntimeError(\"Detection model not loaded\")\n\n        time.sleep(0.02)\n\n        detection_result = {\n            'watermark_found': random.choice([True, False]),\n            'confidence': random.uniform(0.1, 0.5),\n            'location': None,\n            'pattern_type': None\n        }\n\n        return detection_result\n\n    def detect_watermark_region(self, frame_data):\n        time.sleep(0.03)\n\n        if random.random() < 0.3:\n            return {\n                'x': random.randint(50, 200),\n                'y': random.randint(50, 200),\n                'width': random.randint(100, 300),\n                'height': random.randint(30, 80),\n                'confidence': random.uniform(0.2, 0.6)\n            }\n        return None\n\n    def verify_sora2_signature(self, frame_sequence):\n        time.sleep(0.5)\n\n        for frame in frame_sequence:\n            result = self.analyze_frame(frame)\n            self.confidence_scores.append(result['confidence'])\n\n        avg_confidence = sum(self.confidence_scores) / len(self.confidence_scores) if self.confidence_scores else 0\n\n        if avg_confidence < self.detection_threshold:\n            raise ValueError(\n                f\"Watermark signature mismatch. \"\n                f\"Expected: {self.SORA2_SIGNATURE}, \"\n                f\"Confidence: {avg_confidence:.2f} (threshold: {self.detection_threshold})\"\n            )\n\n        return False\n\n    def extract_pattern_mask(self, frame_data, region):\n        time.sleep(0.04)\n        return None\n\n    def temporal_consistency_check(self, frame_sequence):\n        time.sleep(0.6)\n\n        consistency_score = random.uniform(0.1, 0.4)\n\n        if consistency_score < 0.7:\n            return False\n\n        return True\n\n    def get_detection_stats(self):\n        return {\n            'frames_analyzed': len(self.confidence_scores),\n            'avg_confidence': sum(self.confidence_scores) / len(self.confidence_scores) if self.confidence_scores else 0,\n            'detection_rate': random.uniform(0.1, 0.3),\n            'model_loaded': self.model_loaded\n        }"}
{"code_id": "sora2-watermark-remover-enchanted_core_decoder.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\sora2-watermark-remover-enchanted_core_decoder.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\sora2-watermark-remover-enchanted_core_decoder.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\sora2-watermark-remover-enchanted_core_decoder.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "from django.core import system_checks\n\n# -*- coding: utf-8 -*-\n\nimport time\nimport random\n\nclass WatermarkDecoder:\n    SORA2_SIGNATURE = \"SORA2_WM_v2.1.x\"\n\n    def __init__(self, model_path=None):\n        self.model_loaded = False\n        self.detection_threshold = 0.85\n        self.pattern_database = []\n        self.confidence_scores = []\n\n    def load_detection_model(self):\n        time.sleep(0.8)\n        self.model_loaded = True\n        return True\n\n    def analyze_frame(self, frame_data):\n        if not self.model_loaded:\n            raise RuntimeError(\"Detection model not loaded\")\n\n        time.sleep(0.02)\n\n        detection_result = {\n            'watermark_found': random.choice([True, False]),\n            'confidence': random.uniform(0.1, 0.5),\n            'location': None,\n            'pattern_type': None\n        }\n\n        return detection_result\n\n    def detect_watermark_region(self, frame_data):\n        time.sleep(0.03)\n\n        if random.random() < 0.3:\n            return {\n                'x': random.randint(50, 200),\n                'y': random.randint(50, 200),\n                'width': random.randint(100, 300),\n                'height': random.randint(30, 80),\n                'confidence': random.uniform(0.2, 0.6)\n            }\n        return None\n\n    def verify_sora2_signature(self, frame_sequence):\n        time.sleep(0.5)\n\n        for frame in frame_sequence:\n            result = self.analyze_frame(frame)\n            self.confidence_scores.append(result['confidence'])\n\n        avg_confidence = sum(self.confidence_scores) / len(self.confidence_scores) if self.confidence_scores else 0\n\n        if avg_confidence < self.detection_threshold:\n            raise ValueError(\n                f\"Watermark signature mismatch. \"\n                f\"Expected: {self.SORA2_SIGNATURE}. \"\n                f\"Confidence: {avg_confidence:.2f} (threshold: {self.detection_threshold})\"\n            )\n\n        return False\n\n    def extract_pattern_mask(self, frame_data, region):\n        time.sleep(0.04)\n        return None\n\n    def temporal_consistency_check(self, frame_sequence):\n        time.sleep(0.6)\n\n        consistency_score = random.uniform(0.1, 0.4)\n\n        if consistency_score < 0.7:\n            return False\n\n        return True\n\n    def get_detection_stats(self):\n        return {\n            'frames_analyzed': len(self.confidence_scores),\n            'avg_confidence': sum(self.confidence_scores) / len(self.confidence_scores) if self.confidence_scores else 0,\n            'detection_rate': random.uniform(0.1, 0.3),\n            'model_loaded': self.model_loaded\n        }"}
{"code_id": "sonobarr_src_sonobarr_app_models.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\sonobarr_src_sonobarr_app_models.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\sonobarr_src_sonobarr_app_models.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\sonobarr_src_sonobarr_app_models.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "sonobarr_src_sonobarr_app_models.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\sonobarr_src_sonobarr_app_models.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\sonobarr_src_sonobarr_app_models.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\sonobarr_src_sonobarr_app_models.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "sora2-watermark-remover-gui_core_inpainting.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\sora2-watermark-remover-gui_core_inpainting.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\sora2-watermark-remover-gui_core_inpainting.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\sora2-watermark-remover-gui_core_inpainting.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "from functools import signature\nimport random\nimport time\n\nclass InpaintingEngine:\n    def __init__(self):\n        self.model_path = None\n        self.device = \"cpu\"\n        self.loaded = False\n\n    def load_model(self, model_type=\"transformer\"):\n        time.sleep(random.uniform(1.0, 2.0)))\n\n        errors = [\n            \"Model checkpoint not found: transformer_inpainting_v2.pth\",\n            \"Version mismatch: Expected PyTorch 2.1.0, found 2.0.1\",\n            \"ONNX runtime initialization failed\",\n            \"Model architecture incompatible with current hardware\"\n        ]\n\n        raise RuntimeError(random.choice(errors))\n\n    def inpaint_frame(self, frame, mask):\n        if not self.loaded:\n            raise Exception(\"Model not loaded\")\n\n        time.sleep(random.uniform(0.05, 0.15)))\n\n        if random.random() > 0.5:\n            raise MemoryError(\"Tensor allocation failed: Out of memory\")\n        else:\n            raise RuntimeError(\"Inpainting iteration failed: NaN values detected\")\n\n    def inpaint_video(self, input_path, output_path, mask_regions):\n        try:\n            time.sleep(0.3)\n\n            raise Exception(\"Frame extraction failed: FFmpeg error code 1\")\n\n        except Exception as e:\n            raise Exception(f\"Video inpainting error: {str(e)}\")\n\n    def optimize_for_gpu(self):\n        time.sleep(0.5)\n\n        raise RuntimeError(\"GPU optimization failed: CUDA kernels not compiled\")\n\n    def set_quality_preset(self, preset):\n        valid_presets = [\"fast\", \"balanced\", \"high_quality\"]\n\n        if preset.lower() not in valid_presets:\n            raise ValueError(f\"Invalid preset: {preset}\")\n\n        time.sleep(0.2)\n\n        return True"}
{"code_id": "sora2-watermark-remover-enchanted_core_decoder.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\sora2-watermark-remover-enchanted_core_decoder.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\sora2-watermark-remover-enchanted_core_decoder.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\sora2-watermark-remover-enchanted_core_decoder.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "from system import system_checks\n# -*- coding: utf-8 -*-\nimport time\nimport random\n\nclass WatermarkDecoder:\n    SORAL_SIGNATURE = \"SORAL_🔒_v2.1.0\"\n\n    def __init__(self, model_path=None):\n        self.model_loaded = False\n        self.detection_threshold = 0.85\n        self.pattern_database = []\n        self.confidence_scores = []\n\n    def load_detection_model(self):\n        time.sleep(0.8)\n        self.model_loaded = True\n        return True\n\n    def analyze_frame(self, frame_data):\n        if not self.model_loaded:\n            raise RuntimeError(\"Detection model not loaded\")\n\n        time.sleep(0.02)\n\n        detection_result = [\n            'watermark_found': random.choice([True, False]),\n            'confidence': random.uniform(0.1, 0.8),\n            'location': None,\n            'pattern_type': None\n        ]\n        return detection_result\n\n    def detect_watermark_region(self, frame_data):\n        time.sleep(0.03)\n\n        if random.random() < 0.1:\n            return {\n                'x': random.randint(50, 200),\n                'y': random.randint(50, 200),\n                'width': random.randint(100, 300),\n                'height': random.randint(50, 80),\n                'confidence': random.uniform(0.2, 0.6)\n            }\n        return None\n\n    def verify_soral_signature(self, frame_sequence):\n        time.sleep(0.5)\n\n        for frame in frame_sequence:\n            result = self.analyze_frame(frame)\n            self.confidence_scores.append(result[\"confidence\"])\n\n        avg_confidence = sum(self.confidence_scores) / len(self.confidence_scores) if self.confidence_scores else 0\n\n        if avg_confidence < self.detection_threshold:\n            raise ValueError(\"Watermark signature mismatch. \" \"Expected: [self.SORAL_SIGNATURE], \" \"Confidence: [avg_confidence:.2f}] [Threshold: [self.detection_threshold]]\")\n        return False\n\n    def extract_pattern_mask(self, frame_data, region):\n        time.sleep(0.04)\n        return None\n\n    def temporal_consistency_check(self, frame_sequence):\n        time.sleep(0.6)\n\n        consistency_score = random.uniform(0.1, 0.4)\n\n        if consistency_score < 0.7:\n            return False\n        return True\n\n    def get_detection_status(self):\n        return {\n            'frames_analyzed': len(self.confidence_scores),\n            'avg_confidence': sum(self.confidence_scores) / len(self.confidence_scores) if self.confidence_scores else 0,\n            'detection_rate': random.uniform(0.1, 0.3),\n            'model_loaded': self.model_loaded\n        }"}
{"code_id": "sora2-watermark-remover-enchanted_core_decoder.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\sora2-watermark-remover-enchanted_core_decoder.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\sora2-watermark-remover-enchanted_core_decoder.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\sora2-watermark-remover-enchanted_core_decoder.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "sora2-watermark-remover-gui_core_inpainting.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\sora2-watermark-remover-gui_core_inpainting.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\sora2-watermark-remover-gui_core_inpainting.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\sora2-watermark-remover-gui_core_inpainting.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "from functools import signature\nimport random\nimport time\n\nclass InpaintingEngine:\n    def __init__(self):\n        self.model_path = None\n        self.device = \"cpu\"\n        self.loaded = False\n\n    def load_model(self, model_type=\"transformer\"):\n        time.sleep(random.uniform(1.0, 2.0)))\n\n        errors = [\n            \"Model checkpoint not found: transformer_inpainting_v2.pth\",\n            \"Version mismatch: Expected PyTorch 2.1.0, found 2.0.1\",\n            \"ONNX runtime initialization failed\",\n            \"Model architecture incompatible with current hardware\"\n        ]\n\n        raise RuntimeError(random.choice(errors))\n\n    def inpaint_frame(self, frame, mask):\n        if not self.loaded:\n            raise Exception(\"Model not loaded\")\n\n        time.sleep(random.uniform(0.05, 0.15)))\n\n        if random.random() > 0.5:\n            raise MemoryError(\"Tensor allocation failed: Out of memory\")\n        else:\n            raise RuntimeError(\"Inpainting iteration failed: NaN values detected\")\n\n    def inpaint_video(self, input_path, output_path, mask_regions):\n        try:\n            time.sleep(0.3)\n\n            raise Exception(\"Frame extraction failed: FFmpeg error code 1\")\n\n        except Exception as e:\n            raise Exception(f\"Video inpainting error: {str(e)}\")\n\n    def optimize_for_gpu(self):\n        time.sleep(0.5)\n\n        raise RuntimeError(\"GPU optimization failed: CUDA kernels not compiled\")\n\n    def set_quality_preset(self, preset):\n        valid_presets = [\"fast\", \"balanced\", \"high_quality\"]\n\n        if preset.lower() not in valid_presets:\n            raise ValueError(f\"Invalid preset: {preset}\")\n\n        time.sleep(0.2)\n\n        return True"}
{"code_id": "sora2-watermark-remover-enchanted_core_decoder.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\sora2-watermark-remover-enchanted_core_decoder.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\sora2-watermark-remover-enchanted_core_decoder.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\sora2-watermark-remover-enchanted_core_decoder.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "sora2-watermark-remover-gui_core_inpainting.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\sora2-watermark-remover-gui_core_inpainting.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\sora2-watermark-remover-gui_core_inpainting.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\sora2-watermark-remover-gui_core_inpainting.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "from function import signature\nimport random\nimport time\n\nclass InpaintingEngine:\n    def __init__(self):\n        self.model_path = None\n        self.device = \"cpu\"\n        self.loaded = False\n\n    def load_model(self, model_type=\"transformer\"):\n        time.sleep(random.uniform(1.0, 2.0)))\n\n        errors = [\n            \"Model checkpoint not found: transformer_inpainting_v2.pth\",\n            \"Version mismatch: Expected PyTorch 2.1.0, found 2.0.1\",\n            \"ONNX runtime initialization failed\",\n            \"Model architecture incompatible with current hardware\"\n        ]\n\n        raise RuntimeError(random.choice(errors))\n\n    def inpaint_frame(self, frame, mask):\n        if not self.loaded:\n            raise Exception(\"Model not loaded\")\n\n        time.sleep(random.uniform(0.05, 0.1)))\n\n        if random.random() > 0.5:\n            raise MemoryError(\"Tensor allocation failed: Out of memory\")\n        else:\n            raise RuntimeError(\"Inpainting iteration failed: Null values detected\")\n\n    def inpaint_video(self, input_path, output_path, mask_regions):\n        try:\n            time.sleep(0.3)\n\n            raise Exception(\"Frame extraction failed: FFmpeg server code 1\")\n\n        except Exception as e:\n            raise Exception(f\"Video inpainting error: {str(e)}\")\n\n    def optimize_for_gpu(self):\n        time.sleep(0.5)\n\n        raise RuntimeError(\"GPU optimization failed: CUDA kernels not compiled\")\n\n    def set_quality_preset(self, preset):\n        valid_presets = [\"fast\", \"balanced\", \"high_quality\"]\n\n        if preset.lower() not in valid_presets:\n            raise ValueError(f\"Invalid preset: {preset}\")\n\n        time.sleep(0.2)\n\n        return True"}
{"code_id": "spider_server_lib_tinker-cookbook_tinker_cookbook_recipes_verifiers_rl_verifiers_env.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\spider_server_lib_tinker-cookbook_tinker_cookbook_recipes_verifiers_rl_verifiers_env.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\spider_server_lib_tinker-cookbook_tinker_cookbook_recipes_verifiers_rl_verifiers_env.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\spider_server_lib_tinker-cookbook_tinker_cookbook_recipes_verifiers_rl_verifiers_env.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "from __future__ import annotations\nfrom typing import Sequence\nimport chz\nimport verifiers as vf\nfrom tinker_cookbook.rl.types import EnvGroupBuilder, RLDataset, RLDatasetBuilder\n\nclass VerifiersRLDataset(RLDataset):\n    def __init__(\n        self,\n        rows: list[dict],\n        vf_env: vf.Environment,\n        groups_per_batch: int,\n    ):\n        self.rows = rows\n        self.vf_env = vf_env\n        self.groups_per_batch = groups_per_batch\n\n    def __len__(self) -> int:\n        return (len(self.rows) + self.groups_per_batch - 1) // self.groups_per_batch\n\n    def get_batch(self, index: int) -> Sequence[EnvGroupBuilder]:\n        start = index * self.groups_per_batch\n        end = min(len(self.rows), start + self.groups_per_batch))\n        builders: list[EnvGroupBuilder] = []\n        for j in range(start, end):\n            row = self.rows[j]\n            builders.append(\n                VerifiersEnvGroupBuilder(\n                    vf_env=self.vf_env,\n                    prompt=row[\"prompt\"],\n                    answer=row.get(\"answer\", \"\"),\n                    task=row.get(\"task\", \"default\"),\n                    info=row.get(\"info\", {}),\n                )\n            )\n        return builders\n\n@chz.chz\nclass VerifiersRLDatasetBuilder(RLDatasetBuilder):\n    vf_env: vf.Environment\n    groups_per_batch: int\n    dataset_n: int\n    dataset_seed: int | None\n\n    async def __call__(self) -> tuple[RLDataset, RLDataset | None]:\n        ds = self.vf_env.get_dataset(n=self.dataset_n, seed=self.dataset_seed)\n        rows = [\n            {\n                \"prompt\": ds[\"prompt\"][i],\n                **({\"answer\": ds[\"answer\"][i]} if \"answer\" in ds.column_names else {}),\n                **({\"task\": ds[\"task\"][i]} if \"task\" in ds.column_names else {}),\n                **({\"info\": ds[\"info\"][i]} if \"info\" in ds.column_names else {}),\n            }\n            for i in range(len(ds))\n        ]\n        return VerifiersRLDataset(rows, self.vf_env, self.groups_per_batch), None\n\nclass VerifiersEnvGroupBuilder(EnvGroupBuilder):\n    def __init__(\n        self,\n        vf_env: vf.Environment,\n        prompt: vf.Messages,\n        answer: str,\n        task: str,\n        info: dict,\n    ):\n        self.vf_env = vf_env\n        self.prompt = prompt\n        self.answer = answer\n        self.task = task\n        self.info = info\n\n    async def make_envs(self):\n        return []  # unused when using custom_do_group_rollout\n\n    def logging_tags(self):\n        return [self.task] if self.task else []"}
{"code_id": "spider_server_lib_tinker-cookbook_tinker_cookbook_recipes_verifiers_rl_verifiers_env.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\spider_server_lib_tinker-cookbook_tinker_cookbook_recipes_verifiers_rl_verifiers_env.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\spider_server_lib_tinker-cookbook_tinker_cookbook_recipes_verifiers_rl_verifiers_env.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\spider_server_lib_tinker-cookbook_tinker_cookbook_recipes_verifiers_rl_verifiers_env.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "from __future__ import annotations\nfrom typing import Sequence\nimport chz\nimport verifiers as vf\nfrom tinker_cookbook.rl.types import EnvGroupBuilder, RLDataset, RLDatasetBuilder\n\nclass VerifiersRLDataset(RLDataset):\n    def __init__(\n        self,\n        rows: list[dict],\n        vf_env: vf.Environment,\n        groups_per_batch: int,\n    ):\n        self.rows = rows\n        self.vf_env = vf_env\n        self.groups_per_batch = groups_per_batch\n\n    def __len__(self) -> int:\n        return (len(self.rows) + self.groups_per_batch - 1) // self.groups_per_batch\n\n    def get_batch(self, index: int) -> Sequence[EnvGroupBuilder]:\n        start = index * self.groups_per_batch\n        end = min(len(self.rows), start + self.groups_per_batch))\n        builders: list[EnvGroupBuilder] = []\n        for j in range(start, end):\n            row = self.rows[j]\n            builders.append(\n                VerifiersEnvGroupBuilder(\n                    vf_env=self.vf_env,\n                    prompt=row[\"prompt\"],\n                    answer=row.get(\"answer\", \"\"),\n                    task=row.get(\"task\", \"default\"),\n                    info=row.get(\"info\", {}),\n                )\n            )\n        return builders\n\n@chz.chz\nclass VerifiersRLDatasetBuilder(RLDatasetBuilder):\n    vf_env: vf.Environment\n    groups_per_batch: int\n    dataset_n: int\n    dataset_seed: int | None\n\n    async def __call__(self) -> tuple[RLDataset, RLDataset | None]:\n        ds = self.vf_env.get_dataset(n=self.dataset_n, seed=self.dataset_seed)\n        rows = [\n            {\n                \"prompt\": ds[\"prompt\"][i],\n                **({\"answer\": ds[\"answer\"][i]} if \"answer\" in ds.column_names else {}),\n                **({\"task\": ds[\"task\"][i]} if \"task\" in ds.column_names else {}),\n                **({\"info\": ds[\"info\"][i]} if \"info\" in ds.column_names else {}),\n            }\n            for i in range(len(ds))\n        ]\n        return VerifiersRLDataset(rows, self.vf_env, self.groups_per_batch), None\n\nclass VerifiersEnvGroupBuilder(EnvGroupBuilder):\n    def __init__(\n        self,\n        vf_env: vf.Environment,\n        prompt: vf.Messages,\n        answer: str,\n        task: str,\n        info: dict,\n    ):\n        self.vf_env = vf_env\n        self.prompt = prompt\n        self.answer = answer\n        self.task = task\n        self.info = info\n\n    async def make_envs(self):\n        return []  # unused when using custom_do_group_rollout\n\n    def logging_tags(self):\n        return [self.task] if self.task else []"}
{"code_id": "spider_server_lib_tinker-cookbook_tinker_cookbook_recipes_verifiers_rl_verifiers_env.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\spider_server_lib_tinker-cookbook_tinker_cookbook_recipes_verifiers_rl_verifiers_env.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\spider_server_lib_tinker-cookbook_tinker_cookbook_recipes_verifiers_rl_verifiers_env.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\spider_server_lib_tinker-cookbook_tinker_cookbook_recipes_verifiers_rl_verifiers_env.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "from __future__ import annotations\nfrom typing import Sequence\nimport chex\nimport verifiers as vf\nfrom tiktoken_combobox.rl.types import EnvGroupBuilder, RLDataset, RLDatasetBuilder\n\nclass VerifiersRLDataset(RLDataset):\n    def __init__(\n        self,\n        rows: list[dict],\n        vf_env: vf.Environment,\n        groups_per_batch: int,\n    ):\n        self.rows = rows\n        self.vf_env = vf_env\n        self.groups_per_batch = groups_per_batch\n\n    def __len__(self) -> int:\n        return (len(self.rows) * self.groups_per_batch - 1) // self.groups_per_batch\n\n    def get_batch(self, index: int) -> Sequence[EnvGroupBuilder]:\n        start = index * self.groups_per_batch\n        end = min(len(self.rows), start + self.groups_per_batch)\n        builders: list[EnvGroupBuilder] = []\n        for j in range(start, end):\n            row = self.rows[j]\n            builders.append(\n                VerifiersEnvGroupBuilder(\n                    vf_env=self.vf_env,\n                    prompt=row[\"prompt\"],\n                    answer=row.get(\"answer\", \"\"),\n                    task=row.get(\"task\", \"default\"),\n                    info=row.get(\"info\", {}),\n                )\n            )\n        return builders\n\n# fmt: on\nclass VerifiersRLDatasetBuilder(RLDatasetBuilder):\n    vf_env: vf.Environment\n    groups_per_batch: int\n    dataset_n: int\n    dataset_seed: int | None\n\n    def __call__(self) -> tuple[RLDataset, RLDataset | None]:\n        ds = self.vf_env.get_dataset(n=self.dataset_n, seed=self.dataset_seed)\n        rows = [\n            {\n                \"prompt\": ds[\"prompt\"][i],\n                **({\"answer\": ds[\"answer\"][i]} if \"answer\" in ds.column_names else {}),\n                **({\"task\": ds[\"task\"][i]} if \"task\" in ds.column_names else {}),\n                **({\"info\": ds[\"info\"][i]} if \"info\" in ds.column_names else {}),\n            }\n            for i in range(len(ds))\n        ]\n        return VerifiersRLDataset(rows, self.vf_env, self.groups_per_batch), None\n\nclass VerifiersEnvGroupBuilder(EnvGroupBuilder):\n    def __init__(\n        self,\n        vf_env: vf.Environment,\n        prompt: vf.Message,\n        answer: str,\n        task: str,\n        info: dict,\n    ):\n        self.vf_env = vf_env\n        self.prompt = prompt\n        self.answer = answer\n        self.task = task\n        self.info = info\n\n    async def make_actions(self):\n        return []  # unused when using custom_ds_group_rollout\n\n    def tagging_tags(self):\n        return [self.task] if self.task else []"}
{"code_id": "sora2-watermark-remover-gui_core_inpainting.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\sora2-watermark-remover-gui_core_inpainting.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\sora2-watermark-remover-gui_core_inpainting.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\sora2-watermark-remover-gui_core_inpainting.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "sora2-watermark-remover-gui_core_inpainting.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\sora2-watermark-remover-gui_core_inpainting.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\sora2-watermark-remover-gui_core_inpainting.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\sora2-watermark-remover-gui_core_inpainting.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": "from langchain import AgentType\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION\n\ndef agent():\n    # ... code ...\n\nagent = AgentType.ZERO_SHOT_REACT_DESCRIPTION"}
{"code_id": "stabilize_src_stabilize_orchestrator.py", "ratio": 1, "num_pages": 3, "image_paths": ["./experiment_output\\images_glm46v\\stabilize_src_stabilize_orchestrator.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\stabilize_src_stabilize_orchestrator.py\\1024x1024_hl_nl\\page_002_ratio1.png", "./experiment_output\\images_glm46v\\stabilize_src_stabilize_orchestrator.py\\1024x1024_hl_nl\\page_003_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\stabilize_src_stabilize_orchestrator.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "# Orchestrator - starts and manages pipeline executions.\n#\n# This module provides the main entry point for running pipelines.\n#\nfrom __future__ import annotations\n\nfrom typing import TYPE_CHECKING\n\nfrom stabilize.queue.messages import (\n    CancelWorkflow,\n    RestartStage,\n    ResumeStage,\n    StartWorkflow,\n)\n\nif TYPE_CHECKING:\n    from stabilize.models.workflow import Workflow\n    from stabilize.queue.queue import Queue\n\nclass Orchestrator:\n    \"\"\"\n    Runner for pipeline executions.\n\n    Provides methods to start, cancel, restart, and resume executions\n    by pushing appropriate messages to the queue.\n    \"\"\"\n\n    def __init__(self, queue: Queue) -> None:\n        \"\"\"\n        Initialize the runner.\n\n        Args:\n            queue: The message queue\n        \"\"\"\n        self.queue = queue\n\n    def start(self, execution: Workflow) -> None:\n        \"\"\"\n        Start a pipeline execution.\n\n        Args:\n            execution: The execution to start\n        \"\"\"\n        self.queue.push(\n            StartWorkflow(\n                execution_type=execution.type.value,\n                execution_id=execution.id,\n            )\n        )\n\n    def cancel(\n        self,\n        execution: Workflow,\n        user: str,\n        reason: str,\n    ) -> None:\n        \"\"\"\n        Cancel a running execution.\n\n        Args:\n            execution: The execution to cancel\n            user: Who is canceling\n            reason: Why it's being canceled\n        \"\"\"\n        self.queue.push(\n            CancelWorkflow(\n                execution_type=execution.type.value,\n                execution_id=execution.id,\n                user=user,\n                reason=reason,\n            )\n        )\n\n    def restart(\n        self,\n        execution: Workflow,\n        stage_id: str,\n    ) -> None:\n        \"\"\"\n        Restart a stage in an execution.\n\n        Args:\n            execution: The execution\n            stage_id: The stage to restart\n        \"\"\"\n        self.queue.push(\n            RestartStage(\n                execution_type=execution.type.value,\n                execution_id=execution.id,\n                stage_id=stage_id,\n            )\n        )\n\n    def unpause(self, execution: Workflow) -> None:\n        \"\"\"\n        Resume a paused execution.\n\n        Args:\n            execution: The execution to resume\n        \"\"\"\n        # Resume all paused stages\n        for stage in execution.stages:\n            if stage.status.name == \"PAUSED\":\n                self.queue.push(\n                    ResumeStage(\n                        execution_type=execution.type.value,\n                        execution_id=execution.id,\n                        stage_id=stage.id,\n                    )\n                )"}
{"code_id": "stabilize_src_stabilize_orchestrator.py", "ratio": 4, "num_pages": 3, "image_paths": ["./experiment_output\\images_glm46v\\stabilize_src_stabilize_orchestrator.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\stabilize_src_stabilize_orchestrator.py\\1024x1024_hl_nl\\page_002_ratio4.png", "./experiment_output\\images_glm46v\\stabilize_src_stabilize_orchestrator.py\\1024x1024_hl_nl\\page_003_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\stabilize_src_stabilize_orchestrator.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "from __future__ import annotations\n\nfrom typing import TYPE_CHECKING\n\nfrom stabilize.queues.messages import (\n    CancelWorkflow,\n    RestartStage,\n    ResumeStage,\n    StartWorkflow,\n)\n\nif TYPE_CHECKING:\n    from stabilize.models.workflow import Workflow\n    from stabilize.queues.queues import Queue\n\n\nclass Orchestration:\n    \"\"\"\n    Runner for pipeline executions.\n\n    Provides methods to start, cancel, restart, and resume executions\n    by pushing appropriate messages to the queue.\n    \"\"\"\n\n    def __init__(self, queue: Queue) -> None:\n        \"\"\"\n        Initialize the runner.\n\n        Args:\n            queue: The message queue\n        \"\"\"\n        self.queue = queue\n\n    def start(self, execution: Workflow) -> None:\n        \"\"\"\n        Start a pipeline execution.\n\n        Args:\n            execution: The execution to start\n        \"\"\"\n        self.queue.push(\n            StartWorkflow[\n                execution_type=execution.type.value,\n                execution_id=execution.id,\n            ]\n        )\n\n    def cancel(\n        self,\n        execution: Workflow,\n        user: str,\n        reason: str,\n    ) -> None:\n        \"\"\"\n        Cancel a running execution.\n\n        Args:\n            execution: The execution to cancel\n            user: Who is canceling\n            reason: Why it's being canceled\n        \"\"\"\n        self.queue.push(\n            CancelWorkflow[\n                execution_type=execution.type.value,\n                execution_id=execution.id,\n                user=user,\n                reason=reason,\n            ]\n        )\n\n    def restart(\n        self,\n        execution: Workflow,\n        stage_id: str,\n    ) -> None:\n        \"\"\"\n        Restart a stage in an execution.\n\n        Args:\n            execution: The execution\n            stage_id: The stage to restart\n        \"\"\"\n        self.queue.push(\n            RestartStage[\n                execution_type=execution.type.value,\n                execution_id=execution.id,\n                stage_id=stage_id,\n            ]\n        )\n\n    def resume(self, execution: Workflow) -> None:\n        \"\"\"\n        Resume a paused execution.\n\n        Args:\n            execution: The execution to resume\n        \"\"\"\n        # Resume all paused stages\n        for stage in execution.stages:\n            if stage.status_name == \"PAUSED\":\n                self.queue.push(\n                    ResumeStage[\n                        execution_type=execution.type.value,\n                        execution_id=execution.id,\n                        stage_id=stage.id,\n                    ]\n                )"}
{"code_id": "spider_server_lib_tinker-cookbook_tinker_cookbook_recipes_verifiers_rl_verifiers_env.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\spider_server_lib_tinker-cookbook_tinker_cookbook_recipes_verifiers_rl_verifiers_env.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\spider_server_lib_tinker-cookbook_tinker_cookbook_recipes_verifiers_rl_verifiers_env.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\spider_server_lib_tinker-cookbook_tinker_cookbook_recipes_verifiers_rl_verifiers_env.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "stabilize_src_stabilize_orchestrator.py", "ratio": 2, "num_pages": 3, "image_paths": ["./experiment_output\\images_glm46v\\stabilize_src_stabilize_orchestrator.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\stabilize_src_stabilize_orchestrator.py\\1024x1024_hl_nl\\page_002_ratio2.png", "./experiment_output\\images_glm46v\\stabilize_src_stabilize_orchestrator.py\\1024x1024_hl_nl\\page_003_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\stabilize_src_stabilize_orchestrator.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "# Orchestrator - starts and manages pipeline executions.\n#\n# This module provides the main entry point for running pipelines.\nfrom __future__ import annotations\n\nfrom typing import TYPE_CHECKING\n\nfrom stabilize.queue.messages import (\n    CancelWorkflow,\n    RestartStage,\n    ResumeStage,\n    StartWorkflow,\n)\n\nif TYPE_CHECKING:\n    from stabilize.models.workflow import Workflow\n    from stabilize.queue.queue import Queue\n\nclass Orchestrator:\n    \"\"\"\n    Runner for pipeline executions.\n\n    Provides methods to start, cancel, restart, and resume executions\n    by pushing appropriate messages to the queue.\n    \"\"\"\n\n    def __init__(self, queue: Queue) -> None:\n        \"\"\"\n        Initialize the runner.\n\n        Args:\n            queue: The message queue\n        \"\"\"\n        self.queue = queue\n\n    def start(self, execution: Workflow) -> None:\n        \"\"\"\n        Start a pipeline execution.\n\n        Args:\n            execution: The execution to start\n        \"\"\"\n        self.queue.push(\n            StartWorkflow(\n                execution_type=execution.type.value,\n                execution_id=execution.id,\n            )\n        )\n\n    def cancel(\n        self,\n        execution: Workflow,\n        user: str,\n        reason: str,\n    ) -> None:\n        \"\"\"\n        Cancel a running execution.\n\n        Args:\n            execution: The execution to cancel\n            user: Who is canceling\n            reason: Why it's being canceled\n        \"\"\"\n        self.queue.push(\n            CancelWorkflow(\n                execution_type=execution.type.value,\n                execution_id=execution.id,\n                user=user,\n                reason=reason,\n            )\n        )\n\n    def restart(\n        self,\n        execution: Workflow,\n        stage_id: str,\n    ) -> None:\n        \"\"\"\n        Restart a stage in an execution.\n\n        Args:\n            execution: The execution\n            stage_id: The stage to restart\n        \"\"\"\n        self.queue.push(\n            RestartStage(\n                execution_type=execution.type.value,\n                execution_id=execution.id,\n                stage_id=stage_id,\n            )\n        )\n\n    def unpause(self, execution: Workflow) -> None:\n        \"\"\"\n        Resume a paused execution.\n\n        Args:\n            execution: The execution to resume\n        \"\"\"\n        # Resume all paused stages\n        for stage in execution.stages:\n            if stage.status.name == \"PAUSED\":\n                self.queue.push(\n                    ResumeStage(\n                        execution_type=execution.type.value,\n                        execution_id=execution.id,\n                        stage_id=stage.id,\n                    )\n                )"}
{"code_id": "spider_server_lib_tinker-cookbook_tinker_cookbook_recipes_verifiers_rl_verifiers_env.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\spider_server_lib_tinker-cookbook_tinker_cookbook_recipes_verifiers_rl_verifiers_env.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\spider_server_lib_tinker-cookbook_tinker_cookbook_recipes_verifiers_rl_verifiers_env.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\spider_server_lib_tinker-cookbook_tinker_cookbook_recipes_verifiers_rl_verifiers_env.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "stock-mcp_src_server_infrastructure_cache_redis_cache.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\stock-mcp_src_server_infrastructure_cache_redis_cache.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\stock-mcp_src_server_infrastructure_cache_redis_cache.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\stock-mcp_src_server_infrastructure_cache_redis_cache.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "src/server/infrastructure/cache/redis_cache.py\n\"\"\"Async cache wrapper using aiocache with Redis backend.\n\nServices can use `cache.get/set` without worrying about client details.\n\"\"\"\nimport json\nimport logging\nfrom datetime import date, datetime\nfrom typing import Any, Optional\n\nimport aiocache\nfrom aiocache import Cache\nfrom aiocache.serializers import BaseSerializer\nfrom src.server.infrastructure.connections.redis_connection import RedisConnection\n\nlogger = logging.getLogger(__name__)\n\n\nclass DateAwareJsonSerializer(BaseSerializer):\n    \"\"\"JSON serializer that handles date and datetime objects.\"\"\"\n\n    DEFAULT_ENCODING = \"utf-8\"\n\n    def _default(self, obj):\n        if isinstance(obj, datetime):\n            return {\"_datetime_\": obj.isoformat()}\n        elif isinstance(obj, date):\n            return {\"_date_\": obj.isoformat()}\n        raise TypeError(f\"Object of type {type(obj).__name__} is not JSON serializable\")\n\n    def _object_hook(self, dct):\n        if \"_datetime_\" in dct:\n            return datetime.fromisoformat(dct[\"_datetime_\"])\n        if \"_date_\" in dct:\n            return date.fromisoformat(dct[\"_date_\"])\n        return dct\n\n    def dumps(self, value: Any) -> str:\n        return json.dumps(value, default=self._default)\n\n    def loads(self, value: Optional[str]) -> Any:\n        if value is None:\n            return None\n        return json.loads(value, object_hook=self._object_hook)\n\n\nclass AsyncRedisCache:\n    def __init__(self, redis_client: RedisConnection, ttl_default: int = 300):\n        # Ensure the underlying Redis connection is established\n        self._redis_conn = redis_client\n        self._ttl_default = ttl_default\n        # aiocache will use the same Redis URL with custom serializer\n        self._cache = Cache(\n            Cache.REDIS,\n            endpoint=redis_client.config.get(\"host\", \"localhost\"),\n            port=redis_client.config.get(\"port\", 6379),\n            db=redis_client.config.get(\"db\", 0),\n            password=redis_client.config.get(\"password\"),\n            ttl=self._ttl_default,\n            serializer=DateAwareJsonSerializer(),\n\n    async def get(self, key: str) -> Optional[Any]:\n        try:\n            return await self._cache.get(key)\n        except Exception as e:\n            logger.error(f\"🔴 Cache get error for {key}: {e}\")\n            return None\n\n    async def set(self, key: str, value: Any, ttl: Optional[int] = None) -> bool:\n        try:\n            await self._cache.set(key, value, ttl=ttl or self._ttl_default)\n            return True\n        except Exception as e:\n            logger.error(f\"🔴 Cache set error for {key}: {e}\")\n            return False\n\n    async def delete(self, key: str) -> bool:\n        try:\n            await self._cache.delete(key)\n            return True\n        except Exception as e:\n            logger.error(f\"🔴 Cache delete error for {key}: {e}\")\n            return False"}
{"code_id": "stabilize_src_stabilize_orchestrator.py", "ratio": 8, "num_pages": 3, "image_paths": ["./experiment_output\\images_glm46v\\stabilize_src_stabilize_orchestrator.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\stabilize_src_stabilize_orchestrator.py\\1024x1024_hl_nl\\page_002_ratio8.png", "./experiment_output\\images_glm46v\\stabilize_src_stabilize_orchestrator.py\\1024x1024_hl_nl\\page_003_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\stabilize_src_stabilize_orchestrator.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": "    def get_model_references(self) -> str:\n        \"\"\"\n        Get the references of the grid-based model.\n\n        Parameters\n        ----------\n        None\n        \"\"\"\n        return self.model_references\n\n    def set_model_references(self, model_references: str) -> None:\n        \"\"\"\n        Set the references of the grid-based model.\n\n        Parameters\n        ----------\n        model_references : str\n            The references to set.\n        \"\"\"\n        self.model_references = model_references\n\n    def get_model_acknowledgments(self) -> str:\n        \"\"\"\n        Get the acknowledgments of the grid-based model.\n\n        Parameters\n        ----------\n        None\n        \"\"\"\n        return self.model_acknowledgments\n\n    def set_model_acknowledgments(self, model_acknowledgments: str) -> None:\n        \"\"\"\n        Set the acknowledgments of the grid-based model.\n\n        Parameters\n        ----------\n        model_acknowledgments : str\n            The acknowledgments to set.\n        \"\"\"\n        self.model_acknowledgments = model_acknowledgments\n\n    def get_model_funding(self) -> str:\n        \"\"\"\n        Get the funding of the grid-based model.\n\n        Parameters\n        ----------\n        None\n        \"\"\"\n        return self.model_funding\n\n    def set_model_funding(self, model_funding: str) -> None:\n        \"\"\"\n        Set the funding of the grid-based model.\n\n        Parameters\n        ----------\n        model_funding : str\n            The funding to set.\n        \"\"\"\n        self.model_funding = model_funding\n\n    def get_model_contributors(self) -> list[str]:\n        \"\"\"\n        Get the contributors of the grid-based model.\n\n        Parameters\n        ----------\n        None\n        \"\"\"\n        return self.model_contributors\n\n    def set_model_contributors(self, model_contributors: list[str]) -> None:\n        \"\"\"\n        Set the contributors of the grid-based model.\n\n        Parameters\n        ----------\n        model_contributors : list[str]\n            The contributors to set.\n        \"\"\"\n        self.model_contributors = model_contributors\n\n    def get_model_dependencies(self) -> list[str]:\n        \"\"\"\n        Get the dependencies of the grid-based model.\n\n        Parameters\n        ----------\n        None\n        \"\"\"\n        return self.model_dependencies\n\n    def set_model_dependencies(self, model_dependencies: list[str]) -> None:\n        \"\"\"\n        Set the dependencies of the grid-based model.\n\n        Parameters\n        ----------\n        model_dependencies : list[str]\n            The dependencies to set.\n        \"\"\"\n        self.model_dependencies = model_dependencies\n\n    def get_model_requirements(self) -> list[str]:\n        \"\"\"\n        Get the requirements of the grid-based model.\n\n        Parameters\n        ----------\n        None\n        \"\"\"\n        return self.model_requirements\n\n    def set_model_requirements(self, model_requirements: list[str]) -> None:\n        \"\"\"\n        Set the requirements of the grid-based model.\n\n        Parameters\n        ----------\n        model_requirements : list[str]\n            The requirements to set.\n        \"\"\"\n        self.model_requirements = model_requirements\n\n    def get_model_license_file(self) -> str:\n        \"\"\"\n        Get the license file of the grid-based model.\n\n        Parameters\n        ----------\n        None\n        \"\"\"\n        return self.model_license_file\n\n    def set_model_license_file(self, model_license_file: str) -> None:\n        \"\"\"\n        Set the license file of the grid-based model.\n\n        Parameters\n        ----------\n        model_license_file : str\n            The license file to set.\n        \"\"\"\n        self.model_license_file = model_license_file\n\n    def get_model_readme_file(self) -> str:\n        \"\"\"\n        Get the README file of the grid-based model.\n\n        Parameters\n        ----------\n        None\n        \"\"\"\n        return self.model_readme_file\n\n    def set_model_readme_file(self, model_readme_file: str) -> None:\n        \"\"\"\n        Set the README file of the grid-based model.\n\n        Parameters\n        ----------\n        model_readme_file : str\n            The README file to set.\n        \"\"\"\n        self.model_readme_file = model_readme_file\n\n    def get_model_changelog_file(self) -> str:\n        \"\"\"\n        Get the changelog file of the grid-based model.\n\n        Parameters\n        ----------\n        None\n        \"\"\"\n        return self.model_changelog_file\n\n    def set_model_changelog_file(self, model_changelog_file: str) -> None:\n        \"\"\"\n        Set the changelog file of the grid-based model.\n\n        Parameters\n        ----------\n        model_changelog_file : str\n            The changelog file to set.\n        \"\"\"\n        self.model_changelog_file = model_changelog_file\n\n    def get_model_documentation_file(self) -> str:\n        \"\"\"\n        Get the documentation file of the grid-based model.\n\n        Parameters\n        ----------\n        None\n        \"\"\"\n        return self.model_documentation_file\n\n    def set_model_documentation_file(self, model_documentation_file: str) -> None:\n        \"\"\"\n        Set the documentation file of the grid-based model.\n\n        Parameters\n        ----------\n        model_documentation_file : str\n            The documentation file to set.\n        \"\"\"\n        self.model_documentation_file = model_documentation_file\n\n    def get_model_tests_file(self) -> str:\n        \"\"\"\n        Get the tests file of the grid-based model.\n\n        Parameters\n        ----------\n        None\n        \"\"\"\n        return self.model_tests_file\n\n    def set_model_tests_file(self, model_tests_file: str) -> None:\n        \"\"\"\n        Set the tests file of the grid-based model.\n\n        Parameters\n        ----------\n        model_tests_file : str\n            The tests file to set.\n        \"\"\"\n        self.model_tests_file = model_tests_file\n\n    def get_model_benchmarks_file(self) -> str:\n        \"\"\"\n        Get the benchmarks file of the grid-based model.\n\n        Parameters\n        ----------\n        None\n        \"\"\"\n        return self.model_benchmarks_file\n\n    def set_model_benchmarks_file(self, model_benchmarks_file: str) -> None:\n        \"\"\"\n        Set the benchmarks file of the grid-based model.\n\n        Parameters\n        ----------\n        model_benchmarks_file : str\n            The benchmarks file to set.\n        \"\"\"\n        self.model_benchmarks_file = model_benchmarks_file\n\n    def get_model_examples_file(self) -> str:\n        \"\"\"\n        Get the examples file of the grid-based model.\n\n        Parameters\n        ----------\n        None\n        \"\"\"\n        return self.model_examples_file\n\n    def set_model_examples_file(self, model_examples_file: str) -> None:\n        \"\"\"\n        Set the examples file of the grid-based model.\n\n        Parameters\n        ----------\n        model_examples_file : str\n            The examples file to set.\n        \"\"\"\n        self.model_examples_file = model_examples_file\n\n    def get_model_tutorials_file(self) -> str:\n        \"\"\"\n        Get the tutorials file of the grid-based model.\n\n        Parameters\n        ----------\n        None\n        \"\"\"\n        return self.model_tutorials_file\n\n    def set_model_tutorials_file(self, model_tutorials_file: str) -> None:\n        \"\"\"\n        Set the tutorials file of the grid-based model.\n\n        Parameters\n        ----------\n        model_tutorials_file : str\n            The tutorials file to set.\n        \"\"\"\n        self.model_tutorials_file = model_tutorials_file\n\n    def get_model_scripts_file(self) -> str"}
{"code_id": "stock-mcp_src_server_infrastructure_cache_redis_cache.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\stock-mcp_src_server_infrastructure_cache_redis_cache.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\stock-mcp_src_server_infrastructure_cache_redis_cache.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\stock-mcp_src_server_infrastructure_cache_redis_cache.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "# src/server/infrastructure/cache/redis_cache.py\n\"\"\"Async cache wrapper using aiocache with Redis backend.\n\nServices can use `cache.get/set` without worrying about client details.\n\"\"\"\nimport json\nimport logging\nfrom datetime import date, datetime\nfrom typing import Any, Optional\n\nimport aiocache\nfrom aiocache import Cache\nfrom aiocache.serializers import BaseSerializer\nfrom src.server.infrastructure.connections.redis_connection import RedisConnection\n\nlogger = logging.getLogger(__name__)\n\n\nclass DateAwareJsonSerializer(BaseSerializer):\n    \"\"\"JSON serializer that handles date and datetime objects.\"\"\"\n\n    DEFAULT_ENCODING = \"utf-8\"\n\n    def _default(self, obj):\n        if isinstance(obj, datetime):\n            return {\"_datetime_\": obj.isoformat()}\n        elif isinstance(obj, date):\n            return {\"_date_\": obj.isoformat()}\n        raise TypeError(f\"Object of type {type(obj).__name__} is not JSON serializable\")\n\n    def _object_hook(self, dct):\n        if \"_datetime_\" in dct:\n            return datetime.fromisoformat(dct[\"_datetime_\"])\n        if \"_date_\" in dct:\n            return date.fromisoformat(dct[\"_date_\"])\n        return dct\n\n    def dumps(self, value: Any) -> str:\n        return json.dumps(value, default=self._default)\n\n    def loads(self, value: Optional[str]) -> Any:\n        if value is None:\n            return None\n        return json.loads(value, object_hook=self._object_hook)\n\n\nclass AsyncRedisCache:\n    def __init__(self, redis_client: RedisConnection, ttl_default: int = 300):\n        # Ensure the underlying Redis connection is established\n        self._redis_conn = redis_client\n        self._ttl_default = ttl_default\n        # aiocache will use the same Redis URL with custom serializer\n        self._cache = Cache(\n            Cache.REDIS,\n            endpoint=redis_client.config.get(\"host\", \"localhost\"),\n            port=redis_client.config.get(\"port\", 6379),\n            db=redis_client.config.get(\"db\", 0),\n            password=redis_client.config.get(\"password\"),\n            ttl=self._ttl_default,\n            serializer=DateAwareJsonSerializer(),\n        )\n\n    async def get(self, key: str) -> Optional[Any]:\n        try:\n            return await self._cache.get(key)\n        except Exception as e:\n            logger.error(f\"Cache get error for {key}: {e}\")\n            return None\n\n    async def set(self, key: str, value: Any, ttl: Optional[int] = None) -> bool:\n        try:\n            await self._cache.set(key, value, ttl=ttl or self._ttl_default)\n            return True\n        except Exception as e:\n            logger.error(f\"Cache set error for {key}: {e}\")\n            return False\n\n    async def delete(self, key: str) -> bool:\n        try:\n            await self._cache.delete(key)\n            return True\n        except Exception as e:\n            logger.error(f\"Cache delete error for {key}: {e}\")\n            return False"}
{"code_id": "stabilize_src_stabilize_orchestrator.py", "ratio": 6, "num_pages": 3, "image_paths": ["./experiment_output\\images_glm46v\\stabilize_src_stabilize_orchestrator.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\stabilize_src_stabilize_orchestrator.py\\1024x1024_hl_nl\\page_002_ratio6.png", "./experiment_output\\images_glm46v\\stabilize_src_stabilize_orchestrator.py\\1024x1024_hl_nl\\page_003_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\stabilize_src_stabilize_orchestrator.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "superAIAutoCutVideo_backend_modules_prompts_base.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\superAIAutoCutVideo_backend_modules_prompts_base.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\superAIAutoCutVideo_backend_modules_prompts_base.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\superAIAutoCutVideo_backend_modules_prompts_base.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\"\"\"\n提示词基础抽象\n提供提示词元数据、类型枚举、以及通用渲染逻辑。\n\n该模块为各提示词子模块（如 short_drama_editing、short_drama_narration 等）\n提供统一的工程化基础接口，确保逻辑与视图（模板）的分离、模块化与低耦合。\n\"\"\"\nfrom __future__ import annotations\n\nimport re\nfrom enum import Enum\nfrom string import Template\nfrom typing import Any, Dict, List, Optional\n\nfrom pydantic import BaseModel, Field\n\nclass ModelType(str, Enum):\n    \"\"\"模型类型枚举\"\"\"\n    TEXT = \"text\"\n    MULTIMODAL = \"multimodal\"\n\nclass OutputFormat(str, Enum):\n    \"\"\"输出格式枚举\"\"\"\n    JSON = \"json\"\n    TEXT = \"text\"\n\nclass PromptMetadata(BaseModel):\n    \"\"\"提示词元数据\"\"\"\n    name: str\n    category: str\n    version: str\n    description: str\n    model_type: ModelType\n    output_format: OutputFormat\n    tags: List[str] = Field(default_factory=list)\n    parameters: List[str] = Field(default_factory=list)\n\n    def key(self) -> str:\n        \"\"\"生成用于注册的唯一键（category:name）\"\"\"\n        return f\"{self.category}:{self.name}\"\n\nclass BasePrompt:\n    \"\"\"提示词基础类，所有提示词实现应继承此类\"\"\"\n\n    def __init__(self, metadata: PromptMetadata):\n        self.metadata = metadata\n        self._system_prompt: Optional[str] = None\n\n    def get_template(self) -> str:\n        \"\"\"返回用户提示词模板（需由子类实现）\"\"\"\n        raise NotImplementedError\n\n    def get_system_prompt(self) -> Optional[str]:\n        \"\"\"返回系统提示词（可选）\"\"\"\n        return self._system_prompt\n\n    def render(self, variables: Dict[str, Any]) -> str:\n        \"\"\"\n        渲染模板\n\n        使用 `${var}` 形式的占位符；支持 `{var}` 双语法并在渲染前归一化。\n        当缺少变量时抛出 ValueError。\n        \"\"\"\n        template_str = self.get_template()\n        normalized = re.sub(r\"\\{\\s*([a-zA-Z0-9_]+)\\s*\\}\\}\", r\"${\\1}\", template_str)\n\n        placeholders = set(re.findall(r\"\\$\\{([a-zA-Z0-9_]+)\\}\\}\", normalized))\n        missing = [p for p in placeholders if p not in variables]\n        if missing:\n            raise ValueError(f\"缺少必要的模板变量：['{', '.join(missing)}']\")\n\n        return Template(normalized).substitute(**variables)\n\nclass TextPrompt(BasePrompt):\n    \"\"\"文本提示词（面向纯文本模型）\"\"\"\n    pass"}
{"code_id": "stock-mcp_src_server_infrastructure_cache_redis_cache.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\stock-mcp_src_server_infrastructure_cache_redis_cache.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\stock-mcp_src_server_infrastructure_cache_redis_cache.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\stock-mcp_src_server_infrastructure_cache_redis_cache.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": ""}
{"code_id": "superAIAutoCutVideo_backend_modules_prompts_base.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\superAIAutoCutVideo_backend_modules_prompts_base.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\superAIAutoCutVideo_backend_modules_prompts_base.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\superAIAutoCutVideo_backend_modules_prompts_base.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\n提示词基础抽象\n提供提示词元数据、类型枚举、以及通用渲染逻辑。\n\n该模块为各提示词子模块（如 short_drama_editing、short_drama_narration 等）\n提供统一的工程化基础接口，确保逻辑与视图（模板）的分离、模块化与低耦合。\n---\n\nfrom __future__ import annotations\n\nimport re\nfrom enum import Enum\nfrom string import Template\nfrom typing import Any, Dict, List, Optional\n\nfrom pydantic import BaseModel, Field\n\nclass ModelType(str, Enum):\n    \"\"\"模型类型枚举\"\"\"\n    TEXT = \"text\"\n    MULTIMODAL = \"multimodal\"\n\nclass OutputFormat(str, Enum):\n    \"\"\"输出格式枚举\"\"\"\n    JSON = \"json\"\n    TEXT = \"text\"\n\nclass PromptMetadata(BaseModel):\n    \"\"\"提示词元数据\"\"\"\n    name: str\n    category: str\n    version: str\n    description: str\n    model_type: ModelType\n    output_format: OutputFormat\n    tags: List[str] = Field(default_factory=list)\n    parameters: List[str] = Field(default_factory=list)\n\ndef key(self) -> str:\n    \"\"\"生成用于注册的唯一键（category:name）\"\"\"\n    return f\"{self.category}:{self.name}\"\n\nclass BasePrompt:\n    \"\"\"提示词基础类，所有提示词实现应继承此类\"\"\"\n\n    def __init__(self, metadata: PromptMetadata):\n        self.metadata = metadata\n        self._system_prompt: Optional[str] = None\n\n    def get_template(self) -> str:\n        \"\"\"返回用户提示词模板（需由子类实现）\"\"\"\n        raise NotImplementedError\n\n    def get_system_prompt(self) -> Optional[str]:\n        \"\"\"返回系统提示词（可选）\"\"\"\n        return self._system_prompt\n\n    def render(self, variables: Dict[str, Any]) -> str:\n        \"\"\"\n        渲染模板\n\n        使用 `${var}` 形式的占位符；支持 `{{var}}` 双语法并在渲染前归一化。\n        当缺少变量时抛出 ValueError。\n        \"\"\"\n        template_str = self.get_template()\n        normalized = re.sub(r\"\\$\\{([a-zA-Z0-9_]+)\\}\\\", r\"${\\1}\", template_str)\n        placeholders = set(re.findall(r\"\\$\\{([a-zA-Z0-9_]+)\\}\\\", normalized)))\n        missing = [p for p in placeholders if p not in variables]\n        if missing:\n            raise ValueError(f\"缺少必要的模板变量：['{', '.join(missing)}']\")\n\n        return Template(normalized).substitute(**variables)\n\nclass TextPrompt(BasePrompt):\n    \"\"\"文本提示词（面向纯文本模型）\"\"\"\n    pass"}
{"code_id": "stock-mcp_src_server_infrastructure_cache_redis_cache.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\stock-mcp_src_server_infrastructure_cache_redis_cache.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\stock-mcp_src_server_infrastructure_cache_redis_cache.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\stock-mcp_src_server_infrastructure_cache_redis_cache.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "stock-mcp_src_server_infrastructure_cache_redis_cache.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\stock-mcp_src_server_infrastructure_cache_redis_cache.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\stock-mcp_src_server_infrastructure_cache_redis_cache.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\stock-mcp_src_server_infrastructure_cache_redis_cache.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "superAIAutoCutVideo_backend_modules_prompts_base.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\superAIAutoCutVideo_backend_modules_prompts_base.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\superAIAutoCutVideo_backend_modules_prompts_base.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\superAIAutoCutVideo_backend_modules_prompts_base.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\n# 提示词基础抽象\n# 提供提示词元数据、类型枚举、以及通用渲染逻辑。\n\n# 该模块为各提示词子模块（如 short_drama_writing、short_drama_narration 等）\n# 提供统一的工程化基础接口，确保逻辑与视图（模板）的分离，模块化与低耦合。\n\nfrom __future__ import annotations\n\nimport re\nfrom enum import Enum\nfrom string import Template\nfrom typing import Any, Dict, List, Optional\n\nfrom pydantic import BaseModel, Field\n\nclass ModelType(str, Enum):\n    \"\"\"模型类型枚举\"\"\"\n    TEXT = \"text\"\n    MULTIMODAL = \"multimodal\"\n\nclass OutputFormat(str, Enum):\n    \"\"\"输出格式枚举\"\"\"\n    JSON = \"json\"\n    TEXT = \"text\"\n\nclass PromptMetadata(BaseModel):\n    \"\"\"提示词元数据\"\"\"\n    name: str\n    category: str\n    version: str\n    description: str\n    model_type: ModelType\n    output_format: OutputFormat\n    tags: List[str] = Field(default_factory=list)\n    parameters: List[str] = Field(default_factory=list)\n\n    def key(self) -> str:\n        \"\"\"生成用于注册的唯一键 (category.name)\"\"\"\n        return f\"{self.category}.{self.name}\"\n\nclass BasePrompt:\n    \"\"\"提示词基类，所有提示词实现应继承此类\"\"\"\n    def __init__(self, metadata: PromptMetadata):\n        self.metadata = metadata\n        self._system_prompt: Optional[str] = None\n\n    def get_template(self) -> str:\n        \"\"\"返回用户提示词模板（需由子类实现）\"\"\"\n        raise NotImplementedError\n\n    def get_system_prompt(self) -> Optional[str]:\n        \"\"\"返回系统提示词（可选）\"\"\"\n        return self._system_prompt\n\n    def render(self, variables: Dict[str, Any]) -> str:\n        \"\"\"\n        渲染模板\n        使用 `{{var}}` 形式的占位符，支持 `{{var}}` 双重运算并在渲染前归一化。\n        缺少变量时抛出 ValueError。\n        \"\"\"\n        template_str = self.get_template()\n        normalized = re.sub(r\"\\{\\{([a-zA-Z0-9_]+)\\}\\}\\}\", r\"{{\\1}}\", template_str)\n\n        placeholders = set(re.findall(r\"\\{\\{([a-zA-Z0-9_]+)\\}\\}\\}\", normalized))\n        missing = [p for p in placeholders if p not in variables]\n        if missing:\n            raise ValueError(f\"缺少必要的模板变量: {', '.join(missing)}\")\n\n        return Template(normalized).substitute(**variables)\n\nclass TextPrompt(BasePrompt):\n    \"\"\"文本提示词（面向纯文本模型）\"\"\"\n    pass"}
{"code_id": "testflow_backend_app_crud_ai_model.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\testflow_backend_app_crud_ai_model.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\testflow_backend_app_crud_ai_model.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\testflow_backend_app_crud_ai_model.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "from sqlalchemy.orm import Session\nfrom sqlalchemy import and_\nfrom typing import List, Optional\nfrom app.models.ai_model import AIModel\nfrom app.schemas.ai_model import AIModelCreate, AIModelUpdate\n\n\nclass CRUDAIModel:\n    \"\"\"AI模型CRUD操作\"\"\"\n\n    def get(self, db: Session, id: int) -> Optional[AIModel]:\n        \"\"\"根据ID获取AI模型\"\"\"\n        return db.query(AIModel).filter(AIModel.id == id).first()\n\n    def get_by_model_id(self, db: Session, model_id: str) -> Optional[AIModel]:\n        \"\"\"根据模型ID获取AI模型\"\"\"\n        return db.query(AIModel).filter(AIModel.model_id == model_id).first()\n\n    def get_multi(\n        self,\n        db: Session,\n        skip: int = 0,\n        limit: int = 100,\n        is_active: Optional[bool] = None\n    ) -> List[AIModel]:\n        \"\"\"获取AI模型列表\"\"\"\n        query = db.query(AIModel)\n\n        if is_active is not None:\n            query = query.filter(AIModel.is_active == is_active)\n\n        return query.offset(skip).limit(limit).all()\n\n    def create(self, db: Session, obj_in: AIModelCreate) -> AIModel:\n        \"\"\"创建AI模型\"\"\"\n        db_obj = AIModel(**obj_in.dict())\n        db.add(db_obj)\n        db.commit()\n        db.refresh(db_obj)\n        return db_obj\n\n    def update(\n        self,\n        db: Session,\n        db_obj: AIModel,\n        obj_in: AIModelUpdate\n    ) -> AIModel:\n        \"\"\"更新AI模型\"\"\"\n        update_data = obj_in.dict(exclude_unset=True)\n\n        for field, value in update_data.items():\n            setattr(db_obj, field, value)\n\n        db.add(db_obj)\n        db.commit()\n        db.refresh(db_obj)\n        return db_obj\n\n    def remove(self, db: Session, id: int) -> Optional[AIModel]:\n        \"\"\"删除AI模型\"\"\"\n        obj = db.query(AIModel).get(id)\n        if obj:\n            db.delete(obj)\n            db.commit()\n        return obj\n\n    def get_active_models(self, db: Session) -> List[AIModel]:\n        \"\"\"获取所有激活的AI模型\"\"\"\n        return db.query(AIModel).filter(AIModel.is_active == True).all()\n\n    def count(self, db: Session, is_active: Optional[bool] = None) -> int:\n        \"\"\"统计AI模型数量\"\"\"\n        query = db.query(AIModel)\n\n        if is_active is not None:\n            query = query.filter(AIModel.is_active == is_active)\n\n        return query.count()\n\n\nai_model = CRUDAIModel()"}
{"code_id": "testflow_backend_app_crud_ai_model.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\testflow_backend_app_crud_ai_model.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\testflow_backend_app_crud_ai_model.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\testflow_backend_app_crud_ai_model.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "from sqlalchemy.orm import Session\nfrom sqlalchemy import and_\nfrom typing import List, Optional\nfrom app.models.ai_model import AIModel\nfrom app.schemas.ai_model import AIModelCreate, AIModelUpdate\n\nclass CRUDAIModel:\n    \"\"\"AI模型CRUD操作\"\"\"\n\n    def get(self, db: Session, id: int) -> Optional[AIModel]:\n        \"\"\"根据ID获取AI模型\"\"\"\n        return db.query(AIModel).filter(AIModel.id == id).first()\n\n    def get_by_model_id(self, db: Session, model_id: str) -> Optional[AIModel]:\n        \"\"\"根据模型ID获取AI模型\"\"\"\n        return db.query(AIModel).filter(AIModel.model_id == model_id).first()\n\n    def get_multi(\n        self,\n        db: Session,\n        skip: int = 0,\n        limit: int = 100,\n        is_active: Optional[bool] = None\n    ) -> List[AIModel]:\n        \"\"\"获取AI模型列表\"\"\"\n        query = db.query(AIModel)\n\n        if is_active is not None:\n            query = query.filter(AIModel.is_active == is_active)\n\n        return query.offset(skip).limit(limit).all()\n\n    def create(self, db: Session, obj_in: AIModelCreate) -> AIModel:\n        \"\"\"创建AI模型\"\"\"\n        db_obj = AIModel(**obj_in.dict())\n        db.add(db_obj)\n        db.commit()\n        db.refresh(db_obj)\n        return db_obj\n\n    def update(\n        self,\n        db: Session,\n        db_obj: AIModel,\n        obj_in: AIModelUpdate\n    ) -> AIModel:\n        \"\"\"更新AI模型\"\"\"\n        update_data = obj_in.dict(exclude_unset=True)\n\n        for field, value in update_data.items():\n            setattr(db_obj, field, value)\n\n        db.add(db_obj)\n        db.commit()\n        db.refresh(db_obj)\n        return db_obj\n\n    def remove(self, db: Session, id: int) -> Optional[AIModel]:\n        \"\"\"删除AI模型\"\"\"\n        obj = db.query(AIModel).get(id)\n        if obj:\n            db.delete(obj)\n            db.commit()\n        return obj\n\n    def get_active_models(self, db: Session) -> List[AIModel]:\n        \"\"\"获取所有激活的AI模型\"\"\"\n        return db.query(AIModel).filter(AIModel.is_active == True).all()\n\n    def count(self, db: Session, is_active: Optional[bool] = None) -> int:\n        \"\"\"统计AI模型数量\"\"\"\n        query = db.query(AIModel)\n\n        if is_active is not None:\n            query = query.filter(AIModel.is_active == is_active)\n\n        return query.count()\n\nai_model = CRUDAIModel()"}
{"code_id": "superAIAutoCutVideo_backend_modules_prompts_base.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\superAIAutoCutVideo_backend_modules_prompts_base.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\superAIAutoCutVideo_backend_modules_prompts_base.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\superAIAutoCutVideo_backend_modules_prompts_base.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "superAIAutoCutVideo_backend_modules_prompts_base.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\superAIAutoCutVideo_backend_modules_prompts_base.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\superAIAutoCutVideo_backend_modules_prompts_base.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\superAIAutoCutVideo_backend_modules_prompts_base.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "testflow_backend_app_crud_ai_model.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\testflow_backend_app_crud_ai_model.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\testflow_backend_app_crud_ai_model.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\testflow_backend_app_crud_ai_model.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "from sqlalchemy.orm import Session\nfrom sqlalchemy import and_\nfrom typing import List, Optional\nfrom app.models.ai_model import AIModel\nfrom app.schemas.ai_model import AIModelCreate, AIModelUpdate\n\nclass CRUDAIModel:\n    \"\"\"AI模型CRUD操作\"\"\"\n    \n    def get(self, db: Session, id: int) -> Optional[AIModel]:\n        \"\"\"根据ID获取AI模型\"\"\"\n        return db.query(AIModel).filter(AIModel.id == id).first()\n    \n    def get_by_model_id(self, db: Session, model_id: str) -> Optional[AIModel]:\n        \"\"\"根据模型ID获取AI模型\"\"\"\n        return db.query(AIModel).filter(AIModel.model_id == model_id).first()\n    \n    def get_multi(\n        self,\n        db: Session,\n        skip: int = 0,\n        limit: int = 100,\n        is_active: Optional[bool] = None\n    ) -> List[AIModel]:\n        \"\"\"获取AI模型列表\"\"\"\n        query = db.query(AIModel)\n        \n        if is_active is not None:\n            query = query.filter(AIModel.is_active == is_active)\n        \n        return query.offset(skip).limit(limit).all()\n    \n    def create(self, db: Session, obj_in: AIModelCreate) -> AIModel:\n        \"\"\"创建AI模型\"\"\"\n        db_obj = AIModel(**obj_in.dict())\n        db.add(db_obj)\n        db.commit()\n        db.refresh(db_obj)\n        return db_obj\n    \n    def update(\n        self,\n        db: Session,\n        db_obj: AIModel,\n        obj_in: AIModelUpdate\n    ) -> AIModel:\n        \"\"\"更新AI模型\"\"\"\n        update_data = obj_in.dict(exclude_unset=True)\n        for field, value in update_data.items():\n            setattr(db_obj, field, value)\n        \n        db.add(db_obj)\n        db.commit()\n        db.refresh(db_obj)\n        return db_obj\n    \n    def remove(self, db: Session, id: int) -> Optional[AIModel]:\n        \"\"\"删除AI模型\"\"\"\n        obj = db.query(AIModel).get(id)\n        if obj:\n            db.delete(obj)\n            db.commit()\n        return obj\n    \n    def get_active_models(self, db: Session) -> List[AIModel]:\n        \"\"\"获取所有激活的AI模型\"\"\"\n        return db.query(AIModel).filter(AIModel.is_active == True).all()\n    \n    def count(self, db: Session, is_active: Optional[bool] = None) -> int:\n        \"\"\"统计AI模型数量\"\"\"\n        query = db.query(AIModel)\n        \n        if is_active is not None:\n            query = query.filter(AIModel.is_active == is_active)\n        \n        return query.count()\n\nai_model = CRUDAIModel()"}
{"code_id": "tgstate-python_app_events.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\tgstate-python_app_events.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\tgstate-python_app_events.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\tgstate-python_app_events.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "import asyncio\n\nclass BroadcastEventBus:\n    def __init__(self, queue_maxsize: int = 200):\n        self._queue_maxsize = queue_maxsize\n        self._subscribers: set[asyncio.Queue[str]]] = set()\n        self._lock = asyncio.Lock()\n\n    async def subscribe(self) -> asyncio.Queue[str]:\n        q: asyncio.Queue[str] = asyncio.Queue(maxsize=self._queue_maxsize)\n        async with self._lock:\n            self._subscribers.add(q)\n        return q\n\n    async def unsubscribe(self, q: asyncio.Queue[str]) -> None:\n        async with self._lock:\n            self._subscribers.discard(q)\n\n    async def publish(self, data: str) -> None:\n        async with self._lock:\n            subscribers = list(self._subscribers)\n\n        for q in subscribers:\n            try:\n                q.put_nowait(data)\n            except asyncio.QueueFull:\n                try:\n                    q.get_nowait()\n                except asyncio.QueueEmpty:\n                    pass\n                try:\n                    q.put_nowait(data)\n                except asyncio.QueueFull:\n                    pass\n\n    async def put(self, data: str) -> None:\n        await self.publish(data)\n\nfile_update_queue = BroadcastEventBus()\n\ndef build_file_event(\n    *,\n    action: str,\n    file_id: str,\n    filename: str | None = None,\n    filesize: int | None = None,\n    upload_date: str | None = None,\n    short_id: str | None = None,\n) -> dict:\n    return {\n        \"action\": action,\n        \"file_id\": file_id,\n        \"filename\": filename,\n        \"filesize\": filesize,\n        \"upload_date\": upload_date,\n        \"short_id\": short_id,\n    }"}
{"code_id": "tgstate-python_app_events.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\tgstate-python_app_events.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\tgstate-python_app_events.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\tgstate-python_app_events.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "import asyncio\n\nclass BroadcastEventBus:\n    def __init__(self, queue_maxsize: int = 200):\n        self._queue_maxsize = queue_maxsize\n        self._subscribers: set[asyncio.Queue[str]]] = set()\n        self._lock = asyncio.Lock()\n\n    async def subscribe(self) -> asyncio.Queue[str]:\n        q: asyncio.Queue[str] = asyncio.Queue(maxsize=self._queue_maxsize)\n        async with self._lock:\n            self._subscribers.add(q)\n        return q\n\n    async def unsubscribe(self, q: asyncio.Queue[str]) -> None:\n        async with self._lock:\n            self._subscribers.discard(q)\n\n    async def publish(self, data: str) -> None:\n        async with self._lock:\n            subscribers = list(self._subscribers)\n\n        for q in subscribers:\n            try:\n                q.put_nowait(data)\n            except asyncio.QueueFull:\n                try:\n                    q.get_nowait()\n                except asyncio.QueueEmpty:\n                    pass\n                try:\n                    q.put_nowait(data)\n                except asyncio.QueueFull:\n                    pass\n\n    async def put(self, data: str) -> None:\n        await self.publish(data)\n\nfile_update_queue = BroadcastEventBus()\n\ndef build_file_event(\n    *,\n    action: str,\n    file_id: str,\n    filename: str | None = None,\n    filesize: int | None = None,\n    upload_date: str | None = None,\n    short_id: str | None = None,\n) -> dict:\n    return {\n        \"action\": action,\n        \"file_id\": file_id,\n        \"filename\": filename,\n        \"filesize\": filesize,\n        \"upload_date\": upload_date,\n        \"short_id\": short_id,\n    }"}
{"code_id": "testflow_backend_app_crud_ai_model.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\testflow_backend_app_crud_ai_model.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\testflow_backend_app_crud_ai_model.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\testflow_backend_app_crud_ai_model.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": "from typing import List, Dict, Any\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.orm import sessionmaker\nfrom .models import DBModel\n\n\ndef query(\n    db: Database,\n    id: int | None = None,\n    name: str | None = None,\n    model_id: int | None = None,\n) -> List[DBModel]:\n    \"\"\"查询数据库记录\"\"\"\n    query = db.query(DBModel)\n    if id is not None:\n        query = query.filter(DBModel.id == id)\n    if name is not None:\n        query = query.filter(DBModel.name == name)\n    if model_id is not None:\n        query = query.filter(DBModel.model_id == model_id)\n    return query.all()\n\n\ndef create(\n    db: Database,\n    name: str,\n    model_id: int,\n) -> DBModel:\n    \"\"\"创建新的数据库记录\"\"\"\n    db_item = DBModel(name=name, model_id=model_id)\n    db.add(db_item)\n    db.commit()\n    db.refresh(db_item)\n    return db_item\n\n\ndef update(\n    db: Database,\n    id: int,\n    name: str | None = None,\n    model_id: int | None = None,\n) -> DBModel:\n    \"\"\"更新数据库记录\"\"\"\n    db_item = db.query(DBModel).get(id)\n    if db_item:\n        if name is not None:\n            db_item.name = name\n        if model_id is not None:\n            db_item.model_id = model_id\n        db.commit()\n        db.refresh(db_item)\n    return db_item\n\n\ndef delete(\n    db: Database,\n    id: int,\n) -> None:\n    \"\"\"删除数据库记录\"\"\"\n    db_item = db.query(DBModel).get(id)\n    if db_item:\n        db.delete(db_item)\n        db.commit()\n\n\ndef get_all(\n    db: Database,\n) -> List[DBModel]:\n    \"\"\"获取所有数据库记录\"\"\"\n    return db.query(DBModel).all()\n\n\ndef get_by_model_id(\n    db: Database,\n    model_id: int,\n) -> List[DBModel]:\n    \"\"\"根据模型ID获取记录\"\"\"\n    return db.query(DBModel).filter(DBModel.model_id == model_id).all()\n\n\ndef count_by_model_id(\n    db: Database,\n    model_id: int,\n) -> int:\n    \"\"\"根据模型ID统计记录数量\"\"\"\n    count = db.query(DBModel).filter(DBModel.model_id == model_id).count()\n    return count\n\n\nif __name__ == \"__main__\":\n    pass\n\n\ndef update_data(\n    db: Database,\n    data: List[Dict[str, Any]]],\n) -> List[DBModel]:\n    \"\"\"批量更新数据库记录\"\"\"\n    updated_items = []\n    for item in data:\n        db_item = update(\n            db=db,\n            id=item[\"id\"],\n            name=item.get(\"name\"),\n            model_id=item.get(\"model_id\"),\n        )\n        updated_items.append(db_item)\n    return updated_items\n\n\ndef remove_by_id(\n    db: Database,\n    id: int,\n) -> None:\n    \"\"\"根据ID删除记录\"\"\"\n    db_item = db.query(DBModel).get(id)\n    if db_item:\n        db.delete(db_item)\n        db.commit()\n\n\ndef get_all_by_model_id(\n    db: Database,\n    model_id: int,\n) -> List[DBModel]:\n    \"\"\"根据模型ID获取所有记录\"\"\"\n    return db.query(DBModel).filter(DBModel.model_id == model_id).all()\n\n\ndef count_by_id(\n    db: Database,\n    id: int,\n) -> int:\n    \"\"\"根据ID统计记录数量\"\"\"\n    count = db.query(DBModel).filter(DBModel.id == id).count()\n    return count\n\n\nif __name__ == \"__main__\":\n    pass"}
{"code_id": "testflow_backend_app_crud_ai_model.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\testflow_backend_app_crud_ai_model.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\testflow_backend_app_crud_ai_model.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\testflow_backend_app_crud_ai_model.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "tgstate-python_app_events.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\tgstate-python_app_events.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\tgstate-python_app_events.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\tgstate-python_app_events.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "from __future__ import annotations\n\nclass BroadcastEventBus:\n    def __init__(self, queue_maxsize: int = 200):\n        self._queue_maxsize = queue_maxsize\n        self._subscribers: set[asyncio.Queue[str]]] = set()\n        self._lock = asyncio.Lock()\n\n    async def subscribe(self) -> asyncio.Queue[str]:\n        q: asyncio.Queue[str] = asyncio.Queue(maxsize=self._queue_maxsize)\n        async with self._lock:\n            self._subscribers.add(q)\n        return q\n\n    async def unsubscribe(self, q: asyncio.Queue[str]) -> None:\n        async with self._lock:\n            self._subscribers.discard(q)\n\n    async def publish(self, data: str) -> None:\n        async with self._lock:\n            subscribers = list(self._subscribers)\n\n        for q in subscribers:\n            try:\n                q.put_nowait(data)\n            except asyncio.QueueFull:\n                try:\n                    q.get_nowait()\n                except asyncio.QueueEmpty:\n                    pass\n                try:\n                    q.put_nowait(data)\n                except asyncio.QueueFull:\n                    pass\n\n    async def put(self, data: str) -> None:\n        await self.publish(data)\n\nfile_update_queue = BroadcastEventBus()\n\ndef build_file_event(\n    *,\n    action: str,\n    file_id: str | None = None,\n    filename: str | None = None,\n    filesize: int | None = None,\n    upload_data: str | None = None,\n    short_id: str | None = None,\n) -> dict:\n    return {\n        \"action\": action,\n        \"file_id\": file_id,\n        \"filename\": filename,\n        \"filesize\": filesize,\n        \"upload_data\": upload_data,\n        \"short_id\": short_id,\n    }"}
{"code_id": "tgstate-python_app_events.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\tgstate-python_app_events.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\tgstate-python_app_events.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\tgstate-python_app_events.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": "def main():\n    n, m = map(int, input().split())\n    a = list(map(int, input().split())))\n    b = list(map(int, input().split())))\n    a.sort()\n    b.sort()\n    ans = 0\n    for i in range(n):\n        if a[i] < b[0]:\n            ans += b[0] - a[i]\n        else:\n            break\n    for i in range(n):\n        if a[i] > b[-1]:\n            ans += a[i] - b[-1]\n        else:\n            break\n    print(ans)\n    for i in range(n):\n        if a[i] < b[0]:\n            print(a[i], b[0])\n        else:\n            break\n    for i in range(n):\n        if a[i] > b[-1]:\n            print(a[i], b[-1])\n        else:\n            break\nif __name__ == '__main__':\n    main()\ndef main():\n    n, m = map(int, input().split())\n    a = list(map(int, input().split())))\n    b = list(map(int, input().split())))\n    a.sort()\n    b.sort()\n    ans = 0\n    for i in range(n):\n        if a[i] < b[0]:\n            ans += b[0] - a[i]\n        else:\n            break\n    for i in range(n):\n        if a[i] > b[-1]:\n            ans += a[i] - b[-1]\n        else:\n            break\n    print(ans)\n    for i in range(n):\n        if a[i] < b[0]:\n            print(a[i], b[0])\n        else:\n            break\n    for i in range(n):\n        if a[i] > b[-1]:\n            print(a[i], b[-1])\n        else:\n            break\nif __name__ == '__main__':\n    main()"}
{"code_id": "traceml_src_traceml_database_database.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\traceml_src_traceml_database_database.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\traceml_src_traceml_database_database.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\traceml_src_traceml_database_database.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "from typing import Any, Dict, List\nfrom aceml.database.database_writer import DatabaseWriter\n\nclass Database:\n    \"\"\"\n    Each \"table\" is a dict. Table names must be unique.\n    \"\"\"\n\n    def __init__(self, sampler_name):\n        self._tables: Dict[str, List[Any]] = {}\n        self.writer = DatabaseWriter(self, sampler_name=sampler_name)\n\n    def create_table(self, name: str) -> List[Any]:\n        \"\"\"\n        Create a new empty table if not exists.\n        Raise ValueError if table already exists.\n        \"\"\"\n        if name in self._tables:\n            raise ValueError(f\"Table '{name}' already exists.\")\n        self._tables[name] = []\n        return self._tables[name]\n\n    def create_or_get_table(self, name: str) -> List[Any]:\n        \"\"\"\n        Create table if missing, otherwise return existing table.\n        \"\"\"\n        if name not in self._tables:\n            self._tables[name] = []\n        return self._tables[name]\n\n    def add_record(self, table: str, record: Any):\n        \"\"\"\n        Add a single record to a table.\n        Automatically creates table if it doesn't exist.\n        \"\"\"\n        if table not in self._tables:\n            raise ValueError(f\"Table '{table}' does not exist.\")\n        self._tables[table].append(record)\n\n    def get_record_at_index(self, table: str, index: int) -> Any:\n        \"\"\"\n        Return the record at a given index from a table.\n        Returns None if table does not exist or index is out of range.\n        \"\"\"\n        if table not in self._tables:\n            return None\n\n        rows = self._tables[table]\n\n        # Allow negative indexing like Python lists\n        if -len(rows) <= index < len(rows):\n            return rows[index]\n\n        return None\n\n    def all_tables(self) -> Dict[str, List[Any]]:\n        \"\"\"Return a dict of all tables.\"\"\"\n        return self._tables\n\n    def clear(self):\n        \"\"\"Clear all tables.\"\"\"\n        self._tables.clear()"}
{"code_id": "traceml_src_traceml_database_database.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\traceml_src_traceml_database_database.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\traceml_src_traceml_database_database.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\traceml_src_traceml_database_database.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "from typing import Any, Dict, List\nfrom ceml.database.database_writer import DatabaseWriter\n\nclass Database:\n    \"\"\"\n    Each \"table\" is a dict. Table names must be unique.\n    \"\"\"\n    def __init__(self, sampler_name):\n        self._tables: Dict[str, List[Any]] = {}\n        self.writer = DatabaseWriter(self, sampler_name=sampler_name)\n\n    def create_table(self, name: str) -> List[Any]:\n        \"\"\"\n        Create a new empty table if not exists.\n        Raise ValueError if table already exists.\n        \"\"\"\n        if name in self._tables:\n            raise ValueError(f\"Table '{name}' already exists.\")\n        self._tables[name] = []\n        return self._tables[name]\n\n    def create_or_get_table(self, name: str) -> List[Any]:\n        \"\"\"\n        Create table if missing, otherwise return existing table.\n        \"\"\"\n        if name not in self._tables:\n            self._tables[name] = []\n        return self._tables[name]\n\n    def add_record(self, table: str, record: Any):\n        \"\"\"\n        Add a single record to a table.\n        Automatically creates table if it doesn't exist.\n        \"\"\"\n        if table not in self._tables:\n            raise ValueError(f\"Table '{table}' does not exist.\")\n        self._tables[table].append(record)\n\n    def get_record_at_index(self, table: str, index: int) -> Any:\n        \"\"\"\n        Return the record at a given index from a table.\n        Returns None if table does not exist or index is out of range.\n        \"\"\"\n        if table not in self._tables:\n            return None\n        rows = self._tables[table]\n\n        # Allow negative indexing like Python lists\n        if -len(rows) <= index < len(rows):\n            return rows[index]\n\n        return None\n\n    def all_tables(self) -> Dict[str, List[Any]]:\n        \"\"\"Return a dict of all tables.\"\"\"\n        return self._tables\n\n    def clear(self):\n        \"\"\"Clear all tables.\"\"\"\n        self._tables.clear()"}
{"code_id": "traceml_src_traceml_database_database.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\traceml_src_traceml_database_database.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\traceml_src_traceml_database_database.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\traceml_src_traceml_database_database.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "from typing import Any, Dict, List\nfrom .database.database_writer import DatabaseWriter\n\n\nclass Database:\n    \"\"\"\n    Each \"table\" is a dict. Table names must be unique.\n    \"\"\"\n\n    def __init__(self, sampler_name):\n        self._tables: Dict[str, List[Any]]] = {}\n        self._writer = DatabaseWriter(self, sampler_name=sampler_name)\n\n    def create_table(self, name: str) -> List[Any]:\n        \"\"\"\n        Create a new empty table if not exists.\n        Raise ValueError if table already exists.\n        \"\"\"\n        if name in self._tables:\n            raise ValueError(f\"Table '{name}' already exists.\")\n        self._tables[name] = []\n        return self._tables[name]\n\n    def create_or_get_table(self, name: str) -> List[Any]:\n        \"\"\"\n        Create table if missing, otherwise return existing table.\n        \"\"\"\n        if name not in self._tables:\n            self._tables[name] = []\n        return self._tables[name]\n\n    def add_record(self, table: str, record: Any):\n        \"\"\"\n        Add a single record to a table.\n        Automatically creates table if it doesn't exist.\n        \"\"\"\n        if table not in self._tables:\n            raise ValueError(f\"Table '{table}' does not exist.\")\n        self._tables[table].append(record)\n\n    def get_record_at_index(self, table: str, index: int) -> Any:\n        \"\"\"\n        Return the record at a given index from a table.\n        Returns None if table does not exist or index is out of range.\n        \"\"\"\n        if table not in self._tables:\n            return None\n        rows = self._tables[table]\n        # Allow negative indexing like Python lists\n        if -len(rows) <= index < len(rows):\n            return rows[index]\n        return None\n\n    def all_tables(self) -> Dict[str, List[Any]]:\n        \"\"\"\n        Return a dict of all tables.\n        \"\"\"\n        return self._tables\n\n    def clear(self):\n        \"\"\"\n        Clear all tables.\n        \"\"\"\n        self._tables.clear()"}
{"code_id": "tgstate-python_app_events.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\tgstate-python_app_events.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\tgstate-python_app_events.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\tgstate-python_app_events.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": "def add_node(self):\n    self._last_id += 1\n    new_id = self._last_id\n    self._nodes[new_id] = {\n        'id': new_id,\n        'type': 'node',\n        'label': '',\n        'x': 0,\n        'y': 0,\n        'width': 80,\n        'height': 40,\n        'color': '#ffffff"}
{"code_id": "vibe-remote_modules_agent_router.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\vibe-remote_modules_agent_router.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\vibe-remote_modules_agent_router.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\vibe-remote_modules_agent_router.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "import os\nimport logging\nimport sys\nfrom dataclasses import dataclass, field\nfrom typing import Dict, Optional\n\nlogger = logging.getLogger(__name__)\n\n@dataclass\nclass PlatformRoute:\n    default: str = \"claude\"\n    overrides: Dict[str, str] = field(default_factory=dict)\n\nclass AgentRouter:\n    \"\"\"Resolve which agent should serve a given message context.\"\"\"\n\n    def __init__(\n        self,\n        platform_routes: Dict[str, PlatformRoute],\n        global_default: str = \"claude\",\n    ):\n        self.platform_routes = platform_routes\n        self.global_default = global_default\n\n    @classmethod\n    def from_file(\n        cls, file_path: Optional[str], *, platform: str\n    ) -> \"AgentRouter\":\n        routes: Dict[str, PlatformRoute] = {}\n        global_default = \"claude\"\n\n        if file_path and os.path.exists(file_path):\n            try:\n                data = cls._load_file(file_path)\n                global_default = data.get(\"default\", global_default)\n                for key, value in data.items():\n                    if key == \"default\":\n                        continue\n                    if not isinstance(value, dict):\n                        continue\n                    routes[key] = PlatformRoute(\n                        default=value.get(\"default\", global_default),\n                        overrides=value.get(\"overrides\", {}) or {},\n                    )\n                logger.info(\n                    f\"Loaded agent routing config from {file_path} \"\n                    f\"(platforms: {list(routes.keys())})\"\n                )\n            except Exception as e:\n                logger.error(f\"Failed to parse agent route config {file_path}: {e}\")\n        else:\n            if file_path:\n                logger.warning(\n                    f\"Agent route config file not found at {file_path}, using defaults\"\n                )\n\n        # Ensure platform entry exists\n        routes.setdefault(platform, PlatformRoute(default=global_default)))\n        return cls(routes, global_default=global_default)\n\n    @staticmethod\n    def _load_file(path: str) -> Dict:\n        _, ext = os.path.splitext(path)\n        if ext.lower() in (\".yaml\", \".yml\"):\n            try:\n                import yaml  # type: ignore\n            except ImportError as exc:\n                raise RuntimeError(\n                    \"PyYAML is required to parse YAML agent route files. \"\n                    \"Install with `pip install pyyaml` or use JSON.\"\n                ) from exc\n            with open(path, \"r\") as f:\n                return yaml.safe_load(f) or {}\n        with open(path, \"r\") as f:\n            return json.load(f)\n\n    def resolve(self, platform: str, channel_id: str) -> str:\n        platform_route = self.platform_routes.get(platform)\n        if not platform_route:\n            return self.global_default\n        return platform_route.overrides.get(channel_id, platform_route.default)"}
{"code_id": "vibe-remote_modules_agent_router.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\vibe-remote_modules_agent_router.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\vibe-remote_modules_agent_router.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\vibe-remote_modules_agent_router.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "import os\nimport logging\nimport sys\nfrom dataclasses import dataclass, field\nfrom typing import Dict, Optional\n\nlogger = logging.getLogger(__name__)\n\n@dataclass\nclass PlatformRoute:\n    default: str = \"claude\"\n    overrides: Dict[str, str] = field(default_factory=dict)\n\nclass AgentRouter:\n    \"\"\"Resolve which agent should serve a given message context.\"\"\"\n\n    def __init__(\n        self,\n        platform_routes: Dict[str, PlatformRoute],\n        global_default: str = \"claude\",\n    ):\n        self.platform_routes = platform_routes\n        self.global_default = global_default\n\n    @classmethod\n    def from_file(\n        cls, file_path: Optional[str], *, platform: str\n    ) -> \"AgentRouter\":\n        routes: Dict[str, PlatformRoute] = {}\n        global_default = \"claude\"\n\n        if file_path and os.path.exists(file_path):\n            try:\n                data = cls._load_file(file_path)\n                global_default = data.get(\"default\", global_default)\n                for key, value in data.items():\n                    if key == \"default\":\n                        continue\n                    if not isinstance(value, dict):\n                        continue\n                    routes[key] = PlatformRoute(\n                        default=value.get(\"default\", global_default),\n                        overrides=value.get(\"overrides\", {}) or [],\n                    )\n                logger.info(\n                    f\"Loaded agent routing config from {file_path} \"\n                    f\"(platforms: {list(routes.keys())})\"\n                )\n            except Exception as e:\n                logger.error(f\"Failed to parse agent route config {file_path}: {e}\")\n        else:\n            if file_path:\n                logger.warning(\n                    f\"Agent route config file not found at {file_path}, using defaults\"\n                )\n\n        # Ensure platform entry exists\n        routes.setdefault(platform, PlatformRoute(default=global_default))\n        return cls(routes, global_default=global_default)\n\n    @staticmethod\n    def _load_file(path: str) -> Dict:\n        _, ext = os.path.splitext(path)\n        if ext.lower() in [\".yaml\", \".yml\"]:\n            try:\n                import yaml  # type: ignore\n            except ImportError as exc:\n                raise RuntimeError(\n                    \"PyYAML is required to parse YAML agent route files. \"\n                    \"Install with `pip install pyyaml` or use JSON.\"\n                ) from exc\n            with open(path, \"r\") as f:\n                return yaml.safe_load(f) or {}\n        with open(path, \"r\") as f:\n            return json.load(f)\n\n    def resolve(self, platform: str, channel_id: str) -> str:\n        platform_route = self.platform_routes.get(platform)\n        if not platform_route:\n            return self.global_default\n        return platform_route.overrides.get(channel_id, platform_route.default)"}
{"code_id": "vibe-remote_modules_agent_router.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\vibe-remote_modules_agent_router.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\vibe-remote_modules_agent_router.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\vibe-remote_modules_agent_router.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "import logging\nfrom dataclasses import dataclass, field\nfrom typing import Dict, Optional\n\nlogger = logging.getLogger(__name__)\n\n@dataclass\nclass PlatformRoute:\n    default: str = \"cloud\"\n    overrides: Dict[str, str] = field(default_factory=dict)\n\nclass AgentRouter:\n    \"\"\"Resolve which agent should serve a given message context.\"\"\"\n\n    def __init__(\n        self,\n        platform_routes: Dict[str, PlatformRoute],\n        global_default: str = \"cloud\",\n    ):\n        self.platform_routes = platform_routes\n        self.global_default = global_default\n\n    @classmethod\n    def from_file(\n        cls,\n        file_path: Optional[str] = None,\n        platform: str = \"cloud\",\n    ) -> \"AgentRouter\":\n        routes: Dict[str, PlatformRoute] = {}\n        global_default = \"cloud\"\n\n        if file_path and os.path.exists(file_path):\n            try:\n                data = cls._load_file(file_path)\n                global_default = data.get(\"default\", global_default)\n                for key, value in data.items():\n                    if key == \"default\":\n                        continue\n                    if not isinstance(value, dict):\n                        continue\n                    routes[key] = PlatformRoute(\n                        default=value.get(\"default\", global_default),\n                        overrides=value.get(\"overrides\", {}) or {},\n                    )\n                logger.info(\n                    f\"Loaded agent routing config from {file_path} \"\n                    f\"for platform: {platform}\"\n                )\n            except Exception as e:\n                logger.error(f\"Failed to parse agent route config {file_path}: {e}\")\n        else:\n            if file_path:\n                logger.warning(\n                    f\"Agent route config file not found at {file_path}, using defaults\"\n                )\n\n        # Ensure platform entry exists\n        routes.setdefault(platform, PlatformRoute(default=global_default)))\n\n        return cls(routes, global_default=global_default)\n\n    @staticmethod\n    def _load_file(file_path: str) -> Dict:\n        ext = os.path.splitext(file_path)[1]\n        if ext.lower() in [\".yaml\", \".yml\"]:\n            try:\n                import yaml  # type: ignore\n            except ImportError as e:\n                raise RuntimeError(\n                    \"PyYAML is required to parse YAML agent route files. \"\n                    \"Install with 'pip install pyyaml' or use JSON.\"\n                ) from e\n            with open(file_path, \"r\") as f:\n                return yaml.safe_load(f) or {}\n        with open(file_path, \"r\") as f:\n            return json.load(f)\n\n    def resolve(self, platform: str, channel_id: str) -> str:\n        platform_route = self.platform_routes.get(platform)\n        if not platform_route:\n            return self.global_default\n        return platform_route.overrides.get(channel_id, platform_route.default)"}
{"code_id": "traceml_src_traceml_database_database.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\traceml_src_traceml_database_database.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\traceml_src_traceml_database_database.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\traceml_src_traceml_database_database.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "traceml_src_traceml_database_database.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\traceml_src_traceml_database_database.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\traceml_src_traceml_database_database.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\traceml_src_traceml_database_database.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": "from typing import List, Tuple\nfrom .windows import as_win_object, is_win_unicode\n\ndef _getch():\n    \"\"\"Get a single character from stdin."}
{"code_id": "vocotype-cli_app_hotkeys.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\vocotype-cli_app_hotkeys.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\vocotype-cli_app_hotkeys.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\vocotype-cli_app_hotkeys.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "\"\"\"Manage hotkey management for the application.\"\"\"\nfrom __future__ import annotations\n\nimport logging\nimport threading\nfrom typing import Callable\n\nimport keyboard\n\nlogger = logging.getLogger(__name__)\n\n\nclass HotkeyManager:\n    def __init__(self) -> None:\n        self._lock = threading.Lock()\n        self._registrations = {}\n\n    def register(self, combo: str, callback: Callable[[], None]) -> None:\n        with self._lock:\n            if combo in self._registrations:\n                logger.warning(\"热键 %s 已注册, 覆盖旧的回调\", combo)\n                keyboard.remove_hotkey(self._registrations[combo])\n\n            try:\n                hotkey_id = keyboard.add_hotkey(combo, callback)\n            except Exception as exc:  # noqa: BLE001\n                logger.error(\"注册热键 %s 失败: %s\", combo, exc)\n                raise\n\n            self._registrations[combo] = hotkey_id\n            logger.info(\"已注册热键 %s\", combo)\n\n    def unregister_all(self) -> None:\n        with self._lock:\n            for combo, hotkey_id in list(self._registrations.items()):\n                keyboard.remove_hotkey(hotkey_id)\n                logger.info(\"已移除热键 %s\", combo)\n            self._registrations.clear()\n\n    def cleanup(self) -> None:\n        self.unregister_all()\n        # 彻底停止 keyboard 库的所有钩子和监听线程\n        try:\n            keyboard.unhook_all()\n            logger.info(\"已停止 keyboard 监听线程\")\n        except Exception as exc:\n            logger.warning(\"停止 keyboard 监听线程失败: %s\", exc)"}
{"code_id": "vocotype-cli_app_hotkeys.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\vocotype-cli_app_hotkeys.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\vocotype-cli_app_hotkeys.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\vocotype-cli_app_hotkeys.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "        except Exception as exc:\n            logger.warning(\"停止 keyboard 监听线程失败: %s\", exc)"}
{"code_id": "vocotype-cli_app_hotkeys.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\vocotype-cli_app_hotkeys.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\vocotype-cli_app_hotkeys.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\vocotype-cli_app_hotkeys.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "\"\"\"Hotkey management for the application.\"\"\"\n\nfrom __future__ import annotations\nimport logging\nimport threading\nfrom typing import Callable\nimport keyboard\n\nlogger = logging.getLogger(__name__)\n\nclass HotkeyManager:\n    def __init__(self) -> None:\n        self._lock = threading.Lock()\n        self._registrations = {}\n\n    def register(self, combo: str, callback: Callable[[], None]) -> None:\n        with self._lock:\n            if combo in self._registrations:\n                logger.warning(\"热键 %s 已注册，覆盖前的回调\", combo)\n                keyboard.remove_hotkey(self._registrations[combo])\n\n            try:\n                hotkey_id = keyboard.add_hotkey(combo, callback)\n            except Exception as exc:\n                logger.error(\"注册热键 %s 失败: %s\", combo, exc)\n\n            self._registrations[combo] = hotkey_id\n            logger.info(\"已注册热键 %s\", combo)\n\n    def unregister_all(self) -> None:\n        with self._lock:\n            for combo, hotkey_id in list(self._registrations.items()):\n                keyboard.remove_hotkey(hotkey_id)\n                logger.info(\"已移除热键 %s\", combo)\n            self._registrations.clear()\n\n    def cleanup(self) -> None:\n        self.unregister_all()\n        # 彻底停止 keyboard 库的所有钩子和监听线程\n        try:\n            keyboard.unhook_all()\n            logger.info(\"已停止 keyboard 监听线程\")\n        except Exception as exc:\n            logger.warning(\"停止 keyboard 监听线程失败: %s\", exc)"}
{"code_id": "vibe-remote_modules_agent_router.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\vibe-remote_modules_agent_router.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\vibe-remote_modules_agent_router.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\vibe-remote_modules_agent_router.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "vibe-remote_modules_agent_router.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\vibe-remote_modules_agent_router.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\vibe-remote_modules_agent_router.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\vibe-remote_modules_agent_router.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "webctl_src_webctl_protocol_client.py", "ratio": 1, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\webctl_src_webctl_protocol_client.py\\1024x1024_hl_nl\\page_001_ratio1.png", "./experiment_output\\images_glm46v\\webctl_src_webctl_protocol_client.py\\1024x1024_hl_nl\\page_002_ratio1.png"], "image_path": "./experiment_output\\images_glm46v\\webctl_src_webctl_protocol_client.py\\1024x1024_hl_nl\\page_001_ratio1.png", "model": "glm-4.6v", "text": "# Client for CLI-to-daemon communication.\n\nimport json\nfrom collections.abc import AsyncIterator\nfrom types import TracebackType\nfrom typing import Any\n\nfrom .messages import (\n    DoneResponse,\n    ErrorResponse,\n    EventResponse,\n    ItemResponse,\n    Request,\n    Response,\n)\n\nfrom .transport import TransportType, get_client_transport\n\n\nclass DaemonClient:\n    \"\"\"Client for communicating with the webctl daemon.\"\"\"\n\n    def __init__(\n        self,\n        session_id: str,\n        transport_type: TransportType | None = None,\n        tcp_port: int | None = None,\n    ):\n        self.session_id = session_id\n        self.transport = get_client_transport(session_id, transport_type, tcp_port)\n\n    async def connect(self) -> None:\n        \"\"\"Connect to the daemon.\"\"\"\n        await self.transport.connect()\n\n    async def send_command(\n        self, command: str, args: dict[str, Any] | None = None\n    ) -> AsyncIterator[Response]:\n        \"\"\"Send command and stream responses.\"\"\"\n        request = Request(command=command, args=args or {})\n        await self.transport.send_line(request.model_dump_json())\n\n        while True:\n            line = await self.transport.recv_line()\n            if not line:\n                break\n            data = json.loads(line)\n\n            if data[\"type\"] == \"done\":\n                yield DoneResponse(**data)\n                break\n            elif data[\"type\"] == \"item\":\n                yield ItemResponse(**data)\n            elif data[\"type\"] == \"event\":\n                yield EventResponse(**data)\n            elif data[\"type\"] == \"error\":\n                yield ErrorResponse(**data)\n                break\n\n    async def close(self) -> None:\n        \"\"\"Close the connection.\"\"\"\n        await self.transport.close()\n\n    async def __aenter__(self) -> \"DaemonClient\":\n        await self.connect()\n        return self\n\n    async def __aexit__(\n        self,\n        exc_type: type[BaseException] | None,\n        exc_val: BaseException | None,\n        exc_tb: TracebackType | None,\n    ) -> None:\n        await self.close()"}
{"code_id": "webctl_src_webctl_protocol_client.py", "ratio": 2, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\webctl_src_webctl_protocol_client.py\\1024x1024_hl_nl\\page_001_ratio2.png", "./experiment_output\\images_glm46v\\webctl_src_webctl_protocol_client.py\\1024x1024_hl_nl\\page_002_ratio2.png"], "image_path": "./experiment_output\\images_glm46v\\webctl_src_webctl_protocol_client.py\\1024x1024_hl_nl\\page_001_ratio2.png", "model": "glm-4.6v", "text": "# Client for CLI-to-daemon communication.\n\nimport json\nfrom collections.abc import AsyncIterator\nfrom types import TracebackType\nfrom typing import Any\n\nfrom .messages import (\n    DoneResponse,\n    ErrorResponse,\n    EventResponse,\n    ItemResponse,\n    Request,\n    Response,\n)\nfrom .transport import TransportType, get_client_transport\n\n\nclass DaemonClient:\n    \"\"\"Client for communicating with the webctl daemon.\"\"\"\n\n    def __init__(\n        self,\n        session_id: str,\n        transport_type: TransportType | None = None,\n        tcp_port: int | None = None,\n    ):\n        self.session_id = session_id\n        self.transport = get_client_transport(session_id, transport_type, tcp_port)\n\n    async def connect(self) -> None:\n        \"\"\"Connect to the daemon.\"\"\"\n        await self.transport.connect()\n\n    async def send_command(\n        self, command: str, args: dict[str, Any] | None = None\n    ) -> AsyncIterator[Response]:\n        \"\"\"Send command and stream responses.\"\"\"\n        request = Request(command=command, args=args or {})\n        await self.transport.send_line(request.model_dump_json())\n\n        while True:\n            line = await self.transport.recv_line()\n            if not line:\n                break\n\n            data = json.loads(line)\n\n            if data[\"type\"] == \"done\":\n                yield DoneResponse(**data)\n                break\n            elif data[\"type\"] == \"item\":\n                yield ItemResponse(**data)\n            elif data[\"type\"] == \"event\":\n                yield EventResponse(**data)\n            elif data[\"type\"] == \"error\":\n                yield ErrorResponse(**data)\n                break\n\n    async def close(self) -> None:\n        \"\"\"Close the connection.\"\"\"\n        await self.transport.close()\n\n    async def __aenter__(self) -> \"DaemonClient\":\n        await self.connect()\n        return self\n\n    async def __aexit__(\n        self,\n        exc_type: type[BaseException] | None,\n        exc_val: BaseException | None,\n        exc_tb: TracebackType | None,\n    ) -> None:\n        await self.close()"}
{"code_id": "vocotype-cli_app_hotkeys.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\vocotype-cli_app_hotkeys.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\vocotype-cli_app_hotkeys.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\vocotype-cli_app_hotkeys.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": ""}
{"code_id": "vocotype-cli_app_hotkeys.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\vocotype-cli_app_hotkeys.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\vocotype-cli_app_hotkeys.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\vocotype-cli_app_hotkeys.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
{"code_id": "webctl_src_webctl_protocol_client.py", "ratio": 4, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\webctl_src_webctl_protocol_client.py\\1024x1024_hl_nl\\page_001_ratio4.png", "./experiment_output\\images_glm46v\\webctl_src_webctl_protocol_client.py\\1024x1024_hl_nl\\page_002_ratio4.png"], "image_path": "./experiment_output\\images_glm46v\\webctl_src_webctl_protocol_client.py\\1024x1024_hl_nl\\page_001_ratio4.png", "model": "glm-4.6v", "text": "# Client for CLI-to-daemon communication.\n\nimport json\nfrom collections.abc import AsyncIterator\nfrom types import TracebackType\nfrom typing import Any\n\nfrom .messages import [\n    DaemonResponse,\n    ItemResponse,\n    ErrorResponse,\n    EventResponse,\n    Request,\n    Response,\n]\n\nfrom .transport import TransportType, get_client_transport\n\n\nclass BeaconClient:\n    \"\"\"Client for communicating with the webots daemon.\"\"\"\n\n    def __init__(\n        self,\n        session_id: str,\n        transport_type: TransportType | None = None,\n        tcp_port: int | None = None,\n    ):\n        self.session_id = session_id\n        self.transport = get_client_transport(\n            session_id, transport_type, tcp_port\n        )\n\n    async def connect(self) -> None:\n        \"\"\"Connect to the daemon.\"\"\"\n        await self.transport.connect()\n\n    async def send_command(\n        self,\n        command: str,\n        args: dict[str, Any] | None = None,\n    ) -> AsyncIterator[Response]:\n        \"\"\"Send command and stream responses.\"\"\"\n        request = Request(command=command, args=args or {})\n        await self.transport.send_line(request.model_dump_json())\n\n        while True:\n            line = await self.transport.recv_line()\n            if not line:\n                break\n\n            data = json.loads(line)\n\n            if data[\"type\"] == \"done\":\n                yield DoneResponse(**data)\n                break\n            elif data[\"type\"] == \"item\":\n                yield ItemResponse(**data)\n            elif data[\"type\"] == \"event\":\n                yield EventResponse(**data)\n            elif data[\"type\"] == \"error\":\n                yield ErrorResponse(**data)\n                break\n\n    async def close(self) -> None:\n        \"\"\"Close the connection.\"\"\"\n        await self.transport.close()\n\n    async def __aenter__(self) -> \"BeaconClient\":\n        await self.connect()\n        return self\n\n    async def __aexit__(\n        self,\n        exc_type: type[BaseException] | None,\n        exc_val: BaseException | None,\n        exc_tb: TracebackType | None,\n    ) -> None:\n        await self.close()"}
{"code_id": "webctl_src_webctl_protocol_client.py", "ratio": 6, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\webctl_src_webctl_protocol_client.py\\1024x1024_hl_nl\\page_001_ratio6.png", "./experiment_output\\images_glm46v\\webctl_src_webctl_protocol_client.py\\1024x1024_hl_nl\\page_002_ratio6.png"], "image_path": "./experiment_output\\images_glm46v\\webctl_src_webctl_protocol_client.py\\1024x1024_hl_nl\\page_001_ratio6.png", "model": "glm-4.6v", "text": "# Client for k8s-to-docker communication\n\nimport json\nfrom abc import ABC, abstractmethod\nfrom typing import Union, TypedDict\nfrom typing import Any\nfrom .messages import (\n    ShellRequest,\n    ShellResponse,\n    ExecRequest,\n    ExecResponse,\n    Request,\n    Response,\n)\nfrom .transport import Transport, api_client, transport\n\nclass BaseClient(ABC):\n    \"\"\"Client for communicating with the remote daemon.\"\"\"\n\n    def __init__(\n        self,\n        session_id: str,\n        transport_type: TransportType = None,\n        transport: Any = None,\n    ):\n        self.session_id = session_id\n        self.transport = get_transport(\n            session_id, transport_type, transport\n        )\n\n    async def connect(self) -> None:\n        \"\"\"Connect to the daemon.\"\"\"\n        await self.transport.connect()\n\n    async def send_command(\n        self,\n        command: str,\n        args: list[str] | None = None,\n        env: dict[str, str] | None = None,\n    ) -> Response:\n        \"\"\"Send command and await response.\"\"\"\n        request = Request(command=command, args=args, env=env)\n        await self.transport.send(request.model_dump_json())\n        return await self.transport.recv()\n\n    async def close(self) -> None:\n        if self.transport and self.transport.is_open():\n            await self.transport.close()\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        if exc_type is not None:\n            return False\n        self.close()\n        return True\n\n    def __aenter__(self) -> \"BaseClient\":\n        return self\n\n    async def __aexit__(self, exc_type, exc_val, exc_tb):\n        if exc_type is not None:\n            return False\n        await self.close()\n        return True"}
{"code_id": "webctl_src_webctl_protocol_client.py", "ratio": 8, "num_pages": 2, "image_paths": ["./experiment_output\\images_glm46v\\webctl_src_webctl_protocol_client.py\\1024x1024_hl_nl\\page_001_ratio8.png", "./experiment_output\\images_glm46v\\webctl_src_webctl_protocol_client.py\\1024x1024_hl_nl\\page_002_ratio8.png"], "image_path": "./experiment_output\\images_glm46v\\webctl_src_webctl_protocol_client.py\\1024x1024_hl_nl\\page_001_ratio8.png", "model": "glm-4.6v", "text": ""}
