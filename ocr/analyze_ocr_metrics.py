"""
è¯¦ç»†åˆ†æ OCR ç»“æœä¸åŸå§‹ä»£ç çš„å·®å¼‚ï¼Œè®¡ç®—å„é¡¹æŒ‡æ ‡

ä½¿ç”¨æ–¹æ³•:
    python analyze_ocr_metrics.py <code_id> <compression_ratio>
    
ç¤ºä¾‹:
    python analyze_ocr_metrics.py crypto-trader-bot-with-AI-algo_indicator_calculator.py 2
"""
import json
import sys
import os
import glob
from pathlib import Path


# ç®€å•çš„ç¼–è¾‘è·ç¦»å®ç°
def levenshtein_distance(s1, s2):
    """è®¡ç®—ä¸¤ä¸ªåºåˆ—çš„ç¼–è¾‘è·ç¦»"""
    if len(s1) < len(s2):
        return levenshtein_distance(s2, s1)
    
    if len(s2) == 0:
        return len(s1)
    
    previous_row = range(len(s2) + 1)
    for i, c1 in enumerate(s1):
        current_row = [i + 1]
        for j, c2 in enumerate(s2):
            insertions = previous_row[j + 1] + 1
            deletions = current_row[j] + 1
            substitutions = previous_row[j] + (c1 != c2)
            current_row.append(min(insertions, deletions, substitutions))
        previous_row = current_row
    
    return previous_row[-1]


# ç®€å•çš„ BLEU å®ç°
def simple_bleu(reference, hypothesis, max_n=4):
    """è®¡ç®— BLEU score (1-4 gram)"""
    from collections import Counter
    import math
    
    ref_words = reference.split()
    hyp_words = hypothesis.split()
    
    # å¦‚æœå‡è®¾ä¸ºç©ºï¼Œè¿”å›0
    if not hyp_words:
        return 0.0
    
    # è®¡ç®— n-gram precision
    precisions = []
    for n in range(1, max_n + 1):
        ref_ngrams = Counter([tuple(ref_words[i:i+n]) for i in range(len(ref_words)-n+1)])
        hyp_ngrams = Counter([tuple(hyp_words[i:i+n]) for i in range(len(hyp_words)-n+1)])
        
        matches = sum((ref_ngrams & hyp_ngrams).values())
        total = sum(hyp_ngrams.values())
        
        if total == 0:
            precision = 0
        else:
            precision = matches / total
        
        precisions.append(precision)
    
    # å‡ ä½•å¹³å‡
    if any(p == 0 for p in precisions):
        geo_mean = 0
    else:
        geo_mean = math.exp(sum(math.log(p) for p in precisions) / len(precisions))
    
    # Brevity penalty
    bp = 1.0 if len(hyp_words) >= len(ref_words) else math.exp(1 - len(ref_words) / len(hyp_words))
    
    return bp * geo_mean


def load_dataset(dataset_path: str = "../experiment_output/dataset.json") -> dict:
    """ä» dataset.json åŠ è½½åŸå§‹ä»£ç æ•°æ®"""
    if not os.path.exists(dataset_path):
        # å°è¯•å½“å‰ç›®å½•
        dataset_path = "experiment_output/dataset.json"
    
    if not os.path.exists(dataset_path):
        raise FileNotFoundError(f"æ‰¾ä¸åˆ° dataset.json: {dataset_path}")
    
    with open(dataset_path, 'r', encoding='utf-8') as f:
        return {item['id']: item for item in json.load(f)}


def load_ocr_results(code_id: str, ratio: int, 
                     base_path: str = "../experiment_output") -> str:
    """
    åŠ è½½æŒ‡å®š code_id å’Œ compression ratio çš„æ‰€æœ‰ OCR ç»“æœé¡µé¢ï¼Œå¹¶æ‹¼æ¥
    
    Args:
        code_id: ä»£ç æ–‡ä»¶ ID (å¦‚ "crypto-trader-bot-with-AI-algo_indicator_calculator.py")
        ratio: å‹ç¼©æ¯”ä¾‹ (1, 2, 4, 8)
        base_path: å®éªŒè¾“å‡ºæ ¹ç›®å½•
    
    Returns:
        æ‹¼æ¥åçš„å®Œæ•´ OCR æ–‡æœ¬
    """
    if not os.path.exists(base_path):
        base_path = "experiment_output"
    
    # æ„å»ºå›¾ç‰‡ç›®å½•è·¯å¾„
    # æ ¼å¼: experiment_output/images/{code_id}/1024x1024_hl_nl/
    image_dir = os.path.join(base_path, "images", code_id, "1024x1024_hl_nl")
    
    if not os.path.exists(image_dir):
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°å›¾ç‰‡ç›®å½•: {image_dir}")
    
    # æŸ¥æ‰¾æ‰€æœ‰è¯¥ ratio çš„ OCR ç»“æœæ–‡ä»¶
    # æ ¼å¼: page_001_ratio2_ocr.txt, page_002_ratio2_ocr.txt, ...
    pattern = os.path.join(image_dir, f"page_*_ratio{ratio}_ocr.txt")
    ocr_files = sorted(glob.glob(pattern))
    
    if not ocr_files:
        raise FileNotFoundError(f"æ‰¾ä¸åˆ° OCR ç»“æœæ–‡ä»¶: {pattern}")
    
    print(f"ğŸ“„ æ‰¾åˆ° {len(ocr_files)} ä¸ª OCR ç»“æœæ–‡ä»¶:")
    for f in ocr_files:
        print(f"   - {os.path.basename(f)}")
    
    # è¯»å–å¹¶æ‹¼æ¥æ‰€æœ‰é¡µé¢
    ocr_pages = []
    for ocr_file in ocr_files:
        with open(ocr_file, 'r', encoding='utf-8') as f:
            content = f.read()
            # å»é™¤ç‰¹æ®Šæ ‡è®°
            content = content.replace('<|begin_of_box|>', '').replace('<|end_of_box|>', '')
            ocr_pages.append(content.strip())
    
    # ç”¨æ¢è¡Œç¬¦æ‹¼æ¥æ‰€æœ‰é¡µé¢
    full_ocr_text = '\n'.join(ocr_pages)
    
    print(f"âœ… æ‹¼æ¥å®Œæˆ: {len(ocr_pages)} é¡µ â†’ {len(full_ocr_text)} å­—ç¬¦\n")
    
    return full_ocr_text


def main():
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) < 3:
        print("ä½¿ç”¨æ–¹æ³•:")
        print(f"  python {sys.argv[0]} <code_id> <compression_ratio>")
        print("\nç¤ºä¾‹:")
        print(f"  python {sys.argv[0]} crypto-trader-bot-with-AI-algo_indicator_calculator.py 2")
        print(f"  python {sys.argv[0]} moon-dev-ai-agents_src_config.py 1")
        print("\nå¯ç”¨çš„ code_id è¯·æŸ¥çœ‹ experiment_output/dataset.json")
        sys.exit(1)
    
    code_id = sys.argv[1]
    ratio = int(sys.argv[2])
    
    print("=" * 80)
    print("ğŸ“Š OCR ç»“æœè¯¦ç»†åˆ†æå·¥å…·")
    print("=" * 80)
    print(f"Code ID: {code_id}")
    print(f"Compression Ratio: {ratio}x")
    print("=" * 80)
    print()
    
    # 1. åŠ è½½æ•°æ®é›†
    print("1ï¸âƒ£ åŠ è½½æ•°æ®é›†...")
    try:
        dataset = load_dataset()
        print(f"âœ… æ•°æ®é›†åŠ è½½æˆåŠŸï¼ŒåŒ…å« {len(dataset)} ä¸ªä»£ç æ ·æœ¬\n")
    except Exception as e:
        print(f"âŒ åŠ è½½æ•°æ®é›†å¤±è´¥: {e}")
        sys.exit(1)
    
    # 2. è·å–åŸå§‹ä»£ç 
    if code_id not in dataset:
        print(f"âŒ é”™è¯¯: æ•°æ®é›†ä¸­ä¸å­˜åœ¨ code_id '{code_id}'")
        print(f"\nå¯ç”¨çš„ code_id:")
        for cid in sorted(dataset.keys()):
            print(f"  - {cid}")
        sys.exit(1)
    
    original_code = dataset[code_id]['code']
    print(f"2ï¸âƒ£ åŸå§‹ä»£ç :")
    print(f"   - å­—ç¬¦æ•°: {len(original_code)}")
    print(f"   - è¡Œæ•°: {len(original_code.splitlines())}")
    print(f"   - æ¥æº: {dataset[code_id]['repo']}")
    print()
    
    # 3. åŠ è½½å¹¶æ‹¼æ¥ OCR ç»“æœ
    print(f"3ï¸âƒ£ åŠ è½½ OCR ç»“æœ (ratio={ratio})...")
    try:
        ocr_text = load_ocr_results(code_id, ratio)
    except Exception as e:
        print(f"âŒ åŠ è½½ OCR ç»“æœå¤±è´¥: {e}")
        sys.exit(1)
    
    # 4. åŸºæœ¬ä¿¡æ¯å¯¹æ¯”
    print("=" * 80)
    print("4ï¸âƒ£ åŸºæœ¬ä¿¡æ¯å¯¹æ¯”")
    print("=" * 80)
    print(f"åŸå§‹ä»£ç å­—ç¬¦æ•°: {len(original_code)}")
    print(f"åŸå§‹ä»£ç è¡Œæ•°: {len(original_code.splitlines())}")
    print(f"OCR ç»“æœå­—ç¬¦æ•°: {len(ocr_text)}")
    print(f"OCR ç»“æœè¡Œæ•°: {len(ocr_text.splitlines())}")
    print(f"å­—ç¬¦å·®å¼‚: {abs(len(original_code) - len(ocr_text))} ({abs(len(original_code) - len(ocr_text)) / len(original_code) * 100:.1f}%)")
    print(f"è¡Œæ•°å·®å¼‚: {abs(len(original_code.splitlines()) - len(ocr_text.splitlines()))}")

    # 5. è®¡ç®—è¯„ä¼°æŒ‡æ ‡
    print("\n" + "=" * 80)
    print("5ï¸âƒ£ è®¡ç®—è¯„ä¼°æŒ‡æ ‡")
    print("=" * 80)

    # === CER (Character Error Rate) ===
    def calculate_cer(reference, hypothesis):
        lev_dist = levenshtein_distance(reference, hypothesis)
        cer = lev_dist / len(reference) * 100
        return cer, lev_dist

    cer, lev_dist = calculate_cer(original_code, ocr_text)

    print(f"\nã€CER - å­—ç¬¦é”™è¯¯ç‡ã€‘")
    print(f"  {cer:.2f}% (ç¼–è¾‘è·ç¦»: {lev_dist})")

    # === WER (Word Error Rate) ===
    def calculate_wer(reference, hypothesis):
        ref_words = reference.split()
        hyp_words = hypothesis.split()
        lev_dist = levenshtein_distance(ref_words, hyp_words)
        wer = lev_dist / len(ref_words) * 100
        return wer, lev_dist

    wer, wer_lev = calculate_wer(original_code, ocr_text)

    print(f"\nã€WER - å•è¯é”™è¯¯ç‡ã€‘")
    print(f"  {wer:.2f}% (ç¼–è¾‘è·ç¦»: {wer_lev})")

    # === BLEU Score ===
    def calculate_bleu(reference, hypothesis):
        return simple_bleu(reference, hypothesis)

    bleu = calculate_bleu(original_code, ocr_text)

    print(f"\nã€BLEU Scoreã€‘")
    print(f"  {bleu * 100:.2f}")

    # === Exact Match Rate (é€è¡Œæ¯”è¾ƒ) ===
    def calculate_exact_match_rate(reference, hypothesis):
        ref_lines = reference.splitlines()
        hyp_lines = hypothesis.splitlines()
        
        max_len = max(len(ref_lines), len(hyp_lines))
        matches = 0
        
        for i in range(max_len):
            ref_line = ref_lines[i] if i < len(ref_lines) else ""
            hyp_line = hyp_lines[i] if i < len(hyp_lines) else ""
            if ref_line.strip() == hyp_line.strip():
                matches += 1
        
        rate = matches / max_len * 100
        return rate, matches, max_len

    emr, match_count, total_lines = calculate_exact_match_rate(original_code, ocr_text)

    print(f"\nã€Exact Match Rate - é€è¡Œç²¾ç¡®åŒ¹é…ç‡ã€‘")
    print(f"  {emr:.2f}% ({match_count}/{total_lines} è¡ŒåŒ¹é…)")

    # 6. é€è¡Œå·®å¼‚åˆ†æ
    print("\n" + "=" * 80)
    print("6ï¸âƒ£ é€è¡Œå·®å¼‚åˆ†æ (å‰ 30 è¡Œ)")
    print("=" * 80)

    ref_lines = original_code.splitlines()
    ocr_lines = ocr_text.splitlines()

    max_display = min(30, max(len(ref_lines), len(ocr_lines)))
    diff_count = 0

    for i in range(max_display):
        ref_line = ref_lines[i] if i < len(ref_lines) else ""
        ocr_line = ocr_lines[i] if i < len(ocr_lines) else ""
        
        if ref_line.strip() == ocr_line.strip():
            status = "âœ…"
        else:
            status = "âŒ"
            diff_count += 1
        
        print(f"\nç¬¬ {i+1} è¡Œ {status}")
        print(f"  åŸå§‹: {repr(ref_line[:100])}")
        print(f"  OCR:  {repr(ocr_line[:100])}")

    if max(len(ref_lines), len(ocr_lines)) > max_display:
        remaining = max(len(ref_lines), len(ocr_lines)) - max_display
        print(f"\n... (è¿˜æœ‰ {remaining} è¡Œæœªæ˜¾ç¤º)")

    print(f"\nå‰ {max_display} è¡Œä¸­æœ‰ {diff_count} è¡Œå­˜åœ¨å·®å¼‚")

    # 7. å®Œæ•´æ€§åˆ†æ
    print("\n" + "=" * 80)
    print("7ï¸âƒ£ å®Œæ•´æ€§åˆ†æ")
    print("=" * 80)

    print(f"\nåŸå§‹ä»£ç æ€»è¡Œæ•°: {len(ref_lines)}")
    print(f"OCR ç»“æœæ€»è¡Œæ•°: {len(ocr_lines)}")
    
    if len(ref_lines) > len(ocr_lines):
        print(f"\nâš ï¸ OCR ç»“æœç¼ºå°‘ {len(ref_lines) - len(ocr_lines)} è¡Œ")
        print("\nç¼ºå¤±çš„å†…å®¹ (æœ€åå‡ è¡Œ):")
        for i in range(len(ocr_lines), len(ref_lines)):
            print(f"  ç¬¬ {i+1} è¡Œ: {ref_lines[i]}")
    elif len(ocr_lines) > len(ref_lines):
        print(f"\nâš ï¸ OCR ç»“æœå¤šå‡º {len(ocr_lines) - len(ref_lines)} è¡Œ")
        print("\nå¤šä½™çš„å†…å®¹ (æœ€åå‡ è¡Œ):")
        for i in range(len(ref_lines), len(ocr_lines)):
            print(f"  ç¬¬ {i+1} è¡Œ: {ocr_lines[i]}")
    else:
        print("\nâœ… è¡Œæ•°å®Œå…¨åŒ¹é…")

    # 8. æ€»ç»“
    print("\n" + "=" * 80)
    print("8ï¸âƒ£ è¯„ä¼°æ€»ç»“")
    print("=" * 80)

    print(f"\nğŸ“Š æŒ‡æ ‡æ±‡æ€»:")
    print(f"  - CER (å­—ç¬¦é”™è¯¯ç‡): {cer:.2f}%")
    print(f"  - WER (å•è¯é”™è¯¯ç‡): {wer:.2f}%")
    print(f"  - BLEU Score: {bleu * 100:.2f}")
    print(f"  - Exact Match Rate: {emr:.2f}%")
    
    print(f"\nğŸ“ˆ è´¨é‡è¯„ä»·:")
    if cer < 5:
        print("  âœ… ä¼˜ç§€ - CER < 5%")
    elif cer < 10:
        print("  âœ… è‰¯å¥½ - CER < 10%")
    elif cer < 20:
        print("  âš ï¸ ä¸€èˆ¬ - CER < 20%")
    else:
        print("  âŒ è¾ƒå·® - CER >= 20%")
    
    if emr > 90:
        print("  âœ… é€è¡ŒåŒ¹é…ç‡ä¼˜ç§€ (>90%)")
    elif emr > 80:
        print("  âœ… é€è¡ŒåŒ¹é…ç‡è‰¯å¥½ (>80%)")
    else:
        print("  âš ï¸ é€è¡ŒåŒ¹é…ç‡éœ€æ”¹è¿› (<80%)")

    print("\n" + "=" * 80)


if __name__ == "__main__":
    main()
